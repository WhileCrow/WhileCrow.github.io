{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"ANR","text":"机制描述： （//ps：AOSP源码中Service的前台Service的TIMEOUT时间是20s，后台Service的TIMEOUT时间是200s） android-10 // How long we wait for a service to finish executing. ​ static final int SERVICE_TIMEOUT = 20*1000; ​ // How long we wait for a service to finish executing. ​ static final int SERVICE_BACKGROUND_TIMEOUT = SERVICE_TIMEOUT * 10;原理： Service：前台Service启动超过20s没有启动完成：在Service启动时发送一个延迟20s的消息（该消息内部即为 报ANR并分析ANR栈），之后在Service的启动完成时将这个消息remove掉。如果成功remove那就啥事没有，如果超过20s没有remove就消息触发，执行消息体内的ANR动作。（后台消息） https://segmentfault.com/a/1190000022967452 https://mp.weixin.qq.com/s/fWoXprt2TFL1tTapt7esYg https://mp.weixin.qq.com/s/ApNSEWxQdM19QoCNijagtg","link":"/2021/11/02/ANR/"},{"title":"Android Build","text":"Apk总构建流程简述Aapt 会将主工程、依赖库中的资源(res、assets)和androidManifest都合并，产出R.java、资源及资源索引resources.arsc； 之后javac编译包括R.java文件、主工程的java文件、aidl产生的java文件，产出class文件；如果需要插桩的话就插桩 之后使用Proguard/R8混淆工具对.class文件脱糖、压缩、混淆等，产出新的class文件； 之后使用Dx/D8编译工具将新的class文件再转换成dex文件， 之后打包成apk，然后签名、zipalign优化。 工具：aapt/aapt2、javac、Proguard/R8、Dx/D8、ApkBuilder、zipalign 典型的APK中内容 AndroidManifest.xml 程序全局配置文件 classes.dex Dalvik字节码 resources.arsc 资源索引表 META-INF该目录下存放的是签名信息 res 该目录存放资源文件 assets该目录可以存放一些配置或资源文件 流程大致总结为： 1、资源编译：主工程和三方库中的Mainifest、资源（res和assets）的合并，而后由aapt编译构建后产生R.java、resources.arsc（资源索引表）。如果是AAPT2的话会将资源编译成二进制文件.flat 2、**.aidl编译生成.java文件** 3、java源码编译：AIDL产生的.java文件、主工程中的java文件、上述的R.java文件 一起经过javac工具编译后，产生.class文件 3又1/2、 Tramform插桩 &amp; ASM修改字节码 4、Proguard/新为R8：脱糖、压缩、优化、混淆 5、转化为dex：调用dx.bat（新为D8）将所有的class文件（上一个Transform的结果，包括3、java源码编译和第三方库中的.class）转化为 classes.dex文件（如果是multiDex的话就是classesN.dex），dx会将class转换为Dalvik字节码 6、打包生成apk：通过sdklib.jar的ApkBuilder类进行打包，生成apk 7、签名：签名过程主要利用apksign.jar或者jarsinger.jar两个工具 8、zipalign优化：通过 zipalign工具进行内存对齐工作。 资源文件编译（AAPT2）resource（/res）目录 ：res/ 目录下的所有资源文件 和 AndroidManifest.xml 都会被编译成 .flat 的二进制文件（体积更小，解析速度更快），同时会被映射到R.java文件，resource.arsc文件，访问的时候直接使用资源ID即 R.id.filename （另外，依赖库中的resource也会被引入而assets不会） //如果是AAPT则是直接合并AndroidMenifest，直接使用res。而不会将这两者编译成二进制文件。 assets（ /assets）目录：会被原封不动打包进apk中，没有R文件映射，访问的时候需要AssetManager类。 java文件编译javac 是将 .java 文件编译成 .class文件的工具，是JRE提供的工具。 Tramform插桩 &amp; ASM修改字节码在javac执行完成，生成.class文件之后，会经过desugar脱糖、shrinker压缩、optimizer优化、等transform，而我们可以通过自定义Transform，自定义Transform会插到整个Transform链条的最前面，并且除了主工程java文件编译后的class文件，也能拉去到第三方依赖包jar/aar，及asset文件。 然后我们在自定义Transform中拿到的字节码（主工程和三方库）可以用ASM进行修改，最后结果产物又会传递给Transform链后面的脱糖、压缩、优化等Transform继续处理。 混淆(Proguard-&gt;R8)简述： R8之后：.class文件会在一个步骤中执行：脱糖、摇树、混淆、Dex处理 脱糖(Desugar)：去除语法糖，还原原有代码，kt很多语法糖比如拓展函数之类； 摇树(Code shrinking)：tree shaking，从AndroidMainifest中的所有入口(Activity、Serivce等)入手，构建运行所需要的所有类，形成一张图，不在图上的类都可能被移除； 资源缩减(Resource shrinking)：只有在打开了minifyEnabled才有效，配合摇树，删除所有不被引用的资源，包括依赖的库资源。 混淆(Obfuscation)：缩短应用的所有非保留代码(@Keep)中的类名、方法名、字段名 Dex处理：.class转.dex 优化(Optimization)： 如果您的代码从未采用过给定 if/else 语句的 else {} 分支，R8 可能会移除 else {} 分支的代码。 如果您的代码只在一个位置调用某个方法，R8 可能会移除该方法并将其内嵌在这一个调用点。 如果 R8 确定某个类只有一个唯一子类且该类本身未实例化（例如，一个仅由一个具体实现类使用的抽象基类），它就可以将这两个类组合在一起并从应用中移除一个类。 简述： 引入R8前，.class文件得先由Proguard压缩、摇树、混淆、预校验后生成新的.class文件，再经过D8编译成.dex 引入R8后，.class文件会在一个步骤中压缩、摇树、混淆、预校验、D8编译后直接生成.dex Proguard 如果打开了混淆（minifyEnabled = true） 那么在上述编译过程中， 工程项目和R.java 文件编成 .class 文件后，R8（旧Progurad 新R8）即会对 .class文件进行 脱糖、压缩、混淆、优化。 之后形成 新的 .class文件后再交给 D8 编译器 编译成.dex文件 ，之后继续走下一步构建流程。 ProGuard 与 R8 都提供了压缩（shrinker）、优化（optimizer）、混淆（obfuscator）、预校验（preverifier）四大功能： 压缩（也称为摇树优化，tree shaking）：从 应用及依赖项 中移除 未使用 的类、方法和字段，有助于规避 64 方法数的瓶颈 优化：通过代码分析移除更多未使用的代码，甚至重写代码 混淆：使用无意义的简短名称 重命名 类/方法/字段，增加逆向难度 预校验：对于面向 Java 6 或者 Java 7 JVM 的 class 文件，编译时可以把 预校验信息 添加到类文件中（StackMap 和 StackMapTable属性），从而加快类加载效率。预校验对于 Java 7 JVM 来说是必须的，但是对于 Android 平台 无效 minifyEnabled只对代码进行压缩、优化、混淆 shrinkResourcesPs:shrink 美 [ʃrɪŋk] 如需启用资源缩减功能，请将 build.gradle 文件中的 shrinkResources 属性（若为代码缩减，则还包括 minifyEnabled）设为 true。 123456789101112android { ... buildTypes { release { shrinkResources true minifyEnabled true proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' } }} 资源缩减只有在与代码缩减配合使用时才能发挥作用。在代码缩减器移除所有不使用的代码后，资源缩减器便可确定应用仍要使用的资源，当您添加包含资源的代码库时尤其如此。您必须移除不使用的库代码，使库资源变为未引用资源，因而可由资源缩减器移除。 .class文件编译(DX-&gt;D8)DX和D8就是将 .class 文件转成 .dex文件的工具 资源文件编译后产出的R.java 和 工程中的其他.java 文件一起，先通过 javac命令编译成**.class**文件，然后所有产出的 .class 文件再通过 dx指令（现默认D8编译器） 编译成 .dex文件 ， class转换为Dalvik字节码，生成常量池，消除冗余数据等，目的是其中各个类能够共享数据，在一定程度上降低了冗余，同时也是文件结构更加经凑，实验表明，dex文件是传统jar文件大小的50%左右。class文件结构和dex文件结构比对。 打包成Apk打包生成APK文件。旧的apkbuilder脚本已经废弃，现在都已经通过sdklib.jar的ApkBuilder类进行打包了。输入为我们之前生成的包含resources.arcs的.ap_文件，上一步生成的dex文件，以及其他资源如jni、jar包内的资源。 大致步骤为以包含resources.arcs的.ap_文件为基础，new一个ApkBuilder，设置debugModeapkBuilder.addZipFile(f);apkBuilder.addSourceFolder(f);apkBuilder.addResourcesFromJar(f);apkBuilder.addNativeLibraries(nativeFileList);apkBuilder.sealApk(); // 关闭apk文件generateDependencyFile(depFile, inputPaths, outputFile.getAbsolutePath()); 签名对一个APK文件签名之后，APK文件根目录下会增加META-INF目录，该目录下增加三个文件： MANIFEST.MF [CERT].RSA [CERT] Android系统就是根据这三个文件的内容对APK文件进行签名检验的。 zipalign优化调用buildtoolszipalign，对签名后的apk文件进行对齐处理，使apk中所有资源文件距离文件起始偏移为4字节的整数倍，从而在通过内存映射访问apk文件时会更快。同时也减少了在设备上运行时的内存消耗。 附录：版本迭代，R8、D8引入 安装安装方式系统程序安装，开机时安装，没有安装界面。第一步，将apk文件解压复制到程序目录下（/data/app/）；第二步，为应用创建数据目录（/data/data/package name/）、提取dex文件到指定目录（/data/dalvik-cache/）、修改系统包管理信息。由开机时启动的PackageManagerService服务完成，会在启动时扫描/system/app, vender/app, /data/app, /data/app-private并安装。PackageInstallerActivity当Android系统请求安装apk程序时，会启动这个Activity，并通过Intent读取传来的apk信息。下面是apk安装的具体过程。 解析过程会首先读取AndroidManifest.xml获取程序包名以构建Package对象，然后再处理manifest的其他标签包括四大组件，并把信息全都存到Package对象里面。 首先检测该程序是否已安装，是则弹框提示是否替换程序，否则直接调用startInstallConfirm()，做UI初始化和事件绑定，于是当我们点击安装的时候则会触发onClick下的OK按钮事件: 无论是替换还是新安装，都会调用scanPackageLI()，然后跑去scanPackageDirtyLI，它会判断是否为系统程序，解析apk程序包，检查依赖库，验证签名，检查sharedUser签名、权限冲突、ContentProvider冲突，更新native库目录文件（检测abi），进行dexopt，杀掉现有进程（仅对覆盖安装的场景）等等，最后调用createDataDirsLI()进行实际安装:4.执行完毕后，通过socket回传结果，而PackageInstaller根据返回结果做对应处理并显示给用户，至此为止，整个apk安装过程结束。 包名签名相关android系统使用包名(package name)来判定应用程序的同一性，但是由于包名可以由开发者自由设置，为了保护应用程序不被其他开发者开发的同包名应用覆盖，用于发布的Android应用程序需要加上开发者签名。在应用程序被升级的时候，Android系统将会验证被升级的应用程序包与升级后的应用程序包是否使用了同样的开发者签名，如果一致，该应用程序可以被升级；如果不一致，那么将被视为非同一开发者开发的应用程序，用户需要先卸载已经安装的应用然后再安装新应用，在卸载的过程中，应用在android系统中所保存的设置信息（SavedPreferences）将被删除，以保护应用本地保存的资料不被盗取。综上，应用是否可以覆盖的方式是对于包名的判断，然后是对于该APK签名的判断。 AOP原理 在确定好技术选型以后我们来看下ASM的相关原理。其实通过上图我们已经能够大概了解其大致的原理。AS Gradle的编译会将我们的java class文件、jar包以及resource资源文件打包最为最原始的数据输出给第一个Transform，第一个transform处理完的产物再输出给第二个transform，以此类推形成完整的链路。而ASM就是作用于图中的第一个红色TransformA。它会拿到一开始的原始数据以后会进行一定的分析。并且按照JVM字节码的格式针对类、变量、方法等类型调用相关的回调方法。在相应的回调方法中我们可以对相关的字节码指令进行操作。比如新增、删除等等。中间的图片就是它具体的运行时序图。最后两者结合编译 手动构建 APK(aapt2)最后我们通过命令行来手动打包一个可执行的 APK，能让我们对 APK 构建的理解更加深入。首先需要准备下 代码、资源文件、AndroidManifest 这些构建 APK 的必要文件。 ① 通过 aapt2 compile 将 res 资源编译成 .flat 的二进制文件： 1aapt2 compile -o build/res.zip --dir res ② 通过 aapt2 link 将 .flat 和 AndroidManifest 进行连接，转化成不包含 dex 的 apk 和 R.java： 1aapt2 link build/res.zip -I $ANDROID_HOME/platforms/android-30/android.jar --java build --manifest AndroidManifest.xml -o build/app-debug.apk ③ 通过 javac 将 Java 文件编译成 .class 文件： 1javac -d build -cp $ANDROID_HOME/platforms/android-30/android.jar com/**/**/**/*.java ④ 通过 d8 将 .class 文件转化成 dex 文件： 1d8 --output build/ --lib $ANDROID_HOME/platforms/android-30/android.jar build/com/tencent/hockeyli/androidbuild/*.class ⑤ 合并 dex ⽂件和资源⽂件： 1zip -j build/app-debug.apk build/classes.dex ⑥ 对 apk 通过 apksigner 进行签名： 1apksigner sign -ks ~/.android/debug.keystore build/appdebug.apk 参考10分钟了解Android项目构建流程 - 掘金 (juejin.cn) APK打包安装过程 - SegmentFault 思否","link":"/2021/04/01/AndroidBuild/"},{"title":"APM","text":"主线程卡顿监控方案一、Looper Printer监控每次 dispatchMessage 的执行耗时：DoKit &amp; BlockCanary &amp; Matrix滴滴的哆啦A梦的卡顿检测其实就是blockCanary，和Matrix 的EvilMethodTracer和AnrTracer （当然后来Matrix还增加了native的Signal信号监听）使用的 方案也就是Looper设置Printer监听卡顿 都是根据handler原理，通过给Looper.loop() 中设置printer(无论是通过反射替换Looper的mLogging还是通过setMessageLogging设置printer)，监控超过 设定阈值(matrix700ms) 的主线程消息（超过5s报为ANR），printer 中判断start和end，来获取主线程dispatch该message的开始和结束时间，并判定该时间超过阈值为主线程卡慢发生，并 打印当时堆栈 + 方法耗时(matrix/dokit) 123456789101112131415161718192021222324252627282930Looper.loop() { for (;;) { Message msg = queue.next(); // might block if (msg == null) { ... // 执行dispatchMessage前，执行Printer的println方法 final Printer logging = me.mLogging; if (logging != null) { logging.println(&quot;&gt;&gt;&gt;&gt;&gt; Dispatching to &quot; + msg.target + &quot; &quot; + msg.callback + &quot;: &quot; + msg.what); } ... try { msg.target.dispatchMessage(msg); dispatchEnd = needEndTime ? SystemClock.uptimeMillis() : 0; } finally { ... } ... // 执行dispatchMessage后，执行Printer的println方法 if (logging != null) { logging.println(&quot;&lt;&lt;&lt;&lt;&lt; Finished to &quot; + msg.target + &quot; &quot; + msg.callback); } ... }} Matrix：无论是通过反射替换Looper的mLogging还是通过setMessageLogging设置printer，我们只需要替换主线程Looper的printer对象，通过计算执行dispatchMessage方法之后和之前打印字符串的时间的差值，就可以拿到到dispatchMessage方法执行的时间。而大部分的主线程的操作最终都会执行到这个dispatchMessage方法中。 printer监控方案存在问题及解决方案：简述：一是主线程空闲时message.next()会阻塞并且Touch事件也是执行在next中的natviePollOnce里面的，二是IdleHandler空闲handler的queueIdle回调 Q：如果排除主线程空闲的情况，究竟会是什么原因会卡在MessageQueue的next方法中呢？下图是next方法简化过后的源码，*frameworks/base/core/java/android/os/MessageQueue.java:* 1234567891011121314151617181920212223242526272829303132333435for (;;) { if (nextPollTimeoutMillis != 0) { Binder.flushPendingCommands(); } nativePollOnce(ptr, nextPollTimeoutMillis); //...... // Run the idle handlers. // We only ever reach this code block during the first iteration. for (int i = 0; i &lt; pendingIdleHandlerCount; i++) { final IdleHandler idler = mPendingIdleHandlers[i]; mPendingIdleHandlers[i] = null; // release the reference to the handler boolean keep = false; try { keep = idler.queueIdle(); } catch (Throwable t) { Log.wtf(TAG, &quot;IdleHandler threw exception&quot;, t); } if (!keep) { synchronized (this) { mIdleHandlers.remove(idler); } } } //......}/*1. 如果本次循环拿到的Message为空，或者！这个Message是一个延时的消息而且还没到指定的触发时间，那么，就认定当前的队列为空闲状态，2. 接着就会遍历mPendingIdleHandlers数组(这个数组里面的元素每次都会到mIdleHandlers中去拿)来调用每一个IdleHandler实例的queueIdle方法，3. 果这个方法返回false的话，那么这个实例就会从mIdleHandlers中移除，也就是当下次队列空闲的时候，不会继续回调它的queueIdle方法了。*/ 因为有些情况的卡顿，这种方案从原理上就无法监控到。看到上面的queue.next()，这里给了注释：might block，直接跟你说这里是可能会卡住的，这时候再计算dispatchMessage方法的耗时显然就没有意义了。有的同学可能会想，那我改成计算相邻两次dispatchMessage执行之前打印字符串的时间差值不就好了？这样就可以把next方法的耗时也计算在内。 1、主线程空闲也就是queue.next()阻塞的时候，同时也是应用的Touch事件。不幸的是，主线程空闲时，也会阻塞在MessageQueue的next方法中，我们很难区分究竟是发生了卡顿还是主线程空闲，除了主线程空闲时就是阻塞在nativePollOnce之外，非常重要的是，应用的Touch事件也是在这里被处理的。这就意味着，View的TouchEvent中的卡顿这种方案是无法监控的。（微信中有大量的自定义View，这些View中充满了各种各样很多的onTouch回调，卡在这里面的情况非常普遍，这种情况的卡顿监控不到是很难接受的） 2、IdleHandler的queueIdle()回调方法。这个方法会在主线程空闲的时候被调用。然而实际上，很多开发同学都先入为主的认为这个时候反正主线程空闲，做一些耗时操作也没所谓。其实主线程MessageQueue的queueIdle默认当然也是执行在主线程中，所以这里的耗时操作其实是很容易引起卡顿和ANR的。（例如微信之前就使用IdleHandler在进入微信的主界面后，做一些读写文件的IO操作，就造成了一些卡顿和ANR问题） 3、SyncBarrier泄露。还有一类相对少见的问题是SyncBarrier（同步屏障）的泄漏同样无法被监控到 A：A.1. 监控IdleHandler卡顿首先从简单的下手，对于IdleHandler的queueIdle回调方法的监控。我们惊喜的发现MessageQueue中的mIdleHandlers是可以被反射的，这个变量保存了所有将要执行的IdleHandler，我们只需要把ArrayList类型的mIdleHandlers，通过反射，替换为MyArrayList，在我们自定义的MyArrayList中重写add方法，再将我们自定义的MyIdleHandler添加到MyArrayList中，就完成了“偷天换日”。从此之后MessageQueue每次执行queueIdle回调方法，都会执行到我们的MyIdleHandler中的的queueIdle方法，就可以在这里监控queueIdle的执行时间了。 12345678910111213141516171819202122232425262728293031323334353637383940private static void detectIdleHandler() { try { MessageQueue mainQueue = Looper.getMainLooper().getQueue(); Field field = MessageQueue.class.getDeclaredField(&quot;mIdleHandlers&quot;); field.setAccessible(true); MyArrayList&lt;MessageQueue.IdleHandler&gt; myIdleHandlerArrayList = new MyArrayList&lt;&gt;(); field.set(mainQueue, myIdleHandlerArrayList); } catch (Throwable t) { t.printStackTrace(); }}static class MyArrayList&lt;T&gt; extends ArrayList { Map&lt;MessageQueue.IdleHandler, MyIdleHandler&gt; map = new HashMap&lt;&gt;(); @Override public boolean add(Object o) { if (o instanceof MessageQueue.IdleHandler) { MyIdleHandler myIdleHandler = new MyIdleHandler((MessageQueue.IdleHandler) o); map.put((MessageQueue.IdleHandler) o, myIdleHandler); return super.add(myIdleHandler); } return super.add(o); } @Override public boolean remove(@Nullable Object o) { if (o instanceof MyIdleHandler) { MessageQueue.IdleHandler idleHandler = ((MyIdleHandler) o).idleHandler; map.remove(idleHandler); return super.remove(o); } else { MyIdleHandler myIdleHandler = map.remove(o); if (myIdleHandler != null) { return super.remove(myIdleHandler); } return super.remove(o); } }} A.2. 监控TouchEvent卡顿那么TouchEvent我们有什么办法监控吗？首先想到的可能是反射View的mListenerInfo，然后进一步替换其中的mTouchListenr，但是这需要我们枚举所有需要被监控的View，全部反射替换一遍，这完全是憨憨行为。那有没有更加根本，全局性的方法呢？ 熟悉input系统的同学应该知道，Touch事件最终是通过server端的InputDispatcher线程传递给Client端的UI线程的，并且使用的是一对Socket进行通讯的。我们可以通过PLT Hook，去Hook这对Socket的send和recv方法来监控Touch事件啊！我们先捋一下一次Touch事件的处理过程： 我们通过PLT Hook，成功hook到libinput.so中的recvfrom和sendto方法，使用我们自己的方法进行替换。当调用到了recvfrom时，说明我们的应用接收到了Touch事件，当调用到了sendto时，说明这个Touch事件已经被成功消费掉了，当两者的时间相差过大时即说明产生了一次Touch事件的卡顿。这种方案经过验证是可行的！ A.3. 监控SyncBarrier泄漏最后，SyncBarrier泄漏的问题，有什么好办法能监控到吗？目前我们的方案是不断轮询主线程Looper的MessageQueue的mMessage(也就是主线程当前正在处理的Message)。而SyncBarrier本身也是一种特殊的Message，其特殊在它的target是null。如果我们通过反射mMessage，发现当前的Message的target为null，并且通过这个Message的when发现其已经存在很久了，这个时候我们合理怀疑产生了SyncBarrier的泄漏（但还不能完全确定，因为如果当时因为其他原因导致主线程卡死，也可能会导致这种现象），然后再发送一个同步消息和一个异步消息，如果异步消息被处理了，但是同步消息一直无法被处理，这时候就说明产生了SyncBarrier的泄漏。如果激进一些，这个时候我们甚至可以反射调用*MessageQueue*的*removeSyncBarrier*方法，手动把这个SyncBarrier移除掉，从而从错误状态中恢复。 坏消息是，这种方案只能监控到问题的产生，也可以直接解决问题，但是无法溯源问题究竟是哪个View导致的。其实我们也尝试过，通过插桩或者Java hook的方法，监控invalidate方法是否在非主线程中进行，但是考虑到风险以及对性能影响都比较大，没有在线上使用。所幸，通过监控发现，这个问题对我们来说，发生的概率并不高。如果发现某个场景下该问题确实较为严重，可以考虑使用插桩或者Java hook在测试环境下debug该问题。 方案二、依赖 Choreographer 模块，监控相邻两次 Vsync 事件通知的时间差利用系统 Choreographer 模块，向该模块注册一个 FrameCallback 监听对象，同时通过另外一条线程循环记录主线程堆栈信息，并在每次 Vsync 事件 doFrame 通知回来时，循环注册该监听对象，间接统计两次 Vsync 事件的时间间隔，当超出阈值时，取出记录的堆栈进行分析上报。 12345678910Choreographer.getInstance().postFrameCallback(new Choreographer.FrameCallback() { @Override public void doFrame(long frameTimeNanos) { if(frameTimeNanos - mLastFrameNanos &gt; 100) { ... } mLastFrameNanos = frameTimeNanos; Choreographer.getInstance().postFrameCallback(this); }}); 卡顿发生时堆栈的收集BlocakCanary：在执行前利用另外一条线程，通过 Thread#getStackTrace 接口，以轮询的方式获取主线程执行堆栈信息并记录起来，同时统计每次 dispatchMessage 方法执行耗时，当超出阈值时，将该次获取的堆栈进行分析上报，从而来捕捉卡顿信息，否则丢弃此次记录的堆栈信息。 Matrix：根据编译期插桩记录函数耗时，在卡顿发生时获取之前一段时间的函数进行归堆，性能更佳， 不仅在编译期时对特殊无需插桩函数排除（方法字节码中是否只包含PUT/READ FIELD等简单指令、默认或匿名构造函数）、插桩函数用ID映射 还在运行期时用long[]数组记录函数id和函数函数，极大程度的减少占用内存、另一个线程每5ms更新时间减少调用System.nanoTime的耗时 Dokit：也是插桩，但优化不细。 函数耗时统计：DoKit：上面说的插桩 Matrix：上面说的插桩 一些细节上的区别：","link":"/2021/10/19/APM/"},{"title":"bidi 算法","text":"逻辑顺序与视觉顺序[I] 逻辑顺序：指人们阅读和从键盘上输入的文字顺序，文本在内存里也是以逻辑顺序存储的。[II] 视觉顺序：则是文本在屏幕或是打印机中显示的顺序。 字符类型[I] 阿拉伯文、希伯来文及其派生语言的本土字符为“强RTL字符”[II] 我们通常见到的中文、英文等语言的本土字符为“强LTR字符”[III] 欧洲数字、东方阿拉伯，数字，逗号，冒号，句号（即小数点）等为“弱字符”[IV] 括号，中括号，尖括号，空格符，大多数标点符号为“中性字符” 规则bidi算法具体规则十分复杂， 但其基本规则应做了解： 文本的全局方向取决于句子中首个强字符 确定了文本的全局显示方向后，若局部出现了反向字符，则连续的反向字符保持其局部顺序e.g: 若在连续的阿拉伯文中出现了中文单词，如”奔跑吧”，则其仍按照中文顺序显示，不会显示为”吧跑奔” 弱字符保持自身方向 没有被强字符包裹的中性字符追随全局方向 有时，这会导致意外显示错误，这些错误可以通过使用“定向格式化字符”来预防。 参考：https://zhuanlan.zhihu.com/p/392525771 方向串方向串是指在一段文字中具有相同方向性的连续字符，并且其前后没有相同方向性的其它方向串。如以下例子： 1234&lt;p&gt;phone:(415)555-3695&lt;/p&gt;&lt;p&gt;هاتف:(415)555-3695&lt;/p&gt;&lt;p dir=&quot;ltr&quot;&gt;هاتف:(415)555-3695&lt;/p&gt;&lt;p dir=&quot;rtl&quot;&gt;هاتف:(415)555-3695&lt;/p&gt; 我们可以看到，含有阿拉伯文字的段落，电话号码好像按符号分割分组反方向显示了。但实际上并非故意这样输入的，而是电话号码输入完成后再在电话号码前加上阿拉伯文字之后就变成这样了。 文中首个强类型字符是阿拉伯文字，因此其所在的文本区域的全局方向为RTL，但弱类型的数字则保持了原方向LTR，而中性字符”😦)-“没有被强字符包围则跟随了全局方向。 对于以上含有阿拉伯文字的段落，我们可以得到6个不同的方向串。正是因为中性符号被全局方向影响，使得原本的号码被拆分成不同的方向串，从而重新排列。 原文链接：https://blog.csdn.net/qq_40834030/article/details/105111971","link":"/2023/07/12/BIDI-%E7%AE%97%E6%B3%95/"},{"title":"AndroidVm","text":"热知识：java常见的虚拟机如Hotspot虚拟机是基于栈结构的，而Dalvik是基于寄存器结构的。 常见的java虚拟机跑的是.class文件，而Dalvik跑的是.dex（.odex）文件。 BoostMultiDex优化Dalvik虚拟机多Dex启动速度 Android 4.4 及以下采用的是 Dalvik 虚拟机，在通常情况下，Dalvik 虚拟机只能执行做过 OPT 优化的 DEX 文件，也就是我们常说的 ODEX 文件。 一个 APK 在安装的时候，其中的classes.dex会自动做 ODEX 优化，并在启动的时候由系统默认直接加载到 APP 的PathClassLoader里面，因此classes.dex中的类肯定能直接访问，不需要我们操心。 除它之外的 DEX 文件，也就是classes2.dex、classes3.dex、classes4.dex等 DEX 文件（这里我们统称为 Secondary DEX 文件），这些文件都需要靠我们自己进行 ODEX 优化，并加载到 ClassLoader 里，才能正常使用其中的类。否则在访问这些类的时候，就会抛出ClassNotFound异常从而引起崩溃。 因此，Android 官方推出了 MultiDex 方案。只需要在 APP 程序执行最早的入口，也就是Application.attachBaseContext里面直接调MultiDex.install，它会解开 APK 包，对第二个以后的 DEX 文件做 ODEX 优化并加载。这样，带有多个 DEX 文件的 APK 就可以顺利执行下去了。 这个操作会在 APP 安装或者更新后首次冷启动的时候发生，正是由于这个过程耗时漫长，才导致了我们最开始提到的耗时黑屏问题。 12345if (Build.VERSION.SDK_INT &lt;= 19) { BoostMultiDex.install(this); } else { MultiDex.install(this); } Tips: 除以 2 ，右移 1，谁更好A：没区别（ART有优化） ART 使用左移/右移重写了二次幂的乘法/除法(处理负数时会有增加额外的指令)。 右移和二次幂除法之间并没有明显的性能差距。 移位和乘除法的 Dalvik 字节码大小是一样的。 没有人优化了无符号除法(至少现在没有)，但是你应该也没有用过。","link":"/2021/04/10/AndroidVm/"},{"title":"ByteCode","text":"美团文章 java字节码操作码手册","link":"/2021/04/10/ByteCode/"},{"title":"Animation","text":"Android动画分三种：View动画、帧动画、属性动画 是的， check， √ View动画View动画定义了渐变Alpha、旋转Rotate、缩放Scale、平移Translate四种基本动画，并且通过这四种基本动画的组合使用，可以实现多种交互效果。View动画使用非常简单，不仅可以通过XML文件来定义动画，同样可以通过Java代码来实现动画过程。 原理： 首先view的绘制是 drawBackground() -&gt; onDraw() -&gt; dispatchDraw() -&gt; onDrawForeground() 的顺序， //android/view/View.java中的boolean draw(Canvas canvas, ViewGroup parent, long drawingTime)方法 View.setAnimation会将旋转、缩放、平移等动画存下来，动画启动后通过invalidate() ，每一帧中在draw的时候通过canvas.translate、canvas.scale、cavas.setLayerAlpha等方式，执行动画。 故而view动画只会影响view的视觉效果，而不影响起事件响应区域，因为只有draw中处理了，measure和layout都没动 Xml文件实现通过xml来定义View动画涉及到一些公有的属性（在AndroidStudio上不能提示）： 1234567android:duration 动画持续时间android:fillAfter 为true动画结束时，View将保持动画结束时的状态android:fillBefore 为true动画结束时，View将还原到开始开始时的状态android:repeatCount 动画重复执行的次数android:repeatMode 动画重复模式 ，重复播放时restart重头开始，reverse重复播放时倒叙回放，该属性需要和android:repeatCount一起使用android:repeatCount 默认是0，-1是无限循环android:interpolator 插值器，相当于变速器，改变动画的不同阶段的执行速度 这些属性是从Animation中继承下来的，在alpha、rotate、scale、translate标签中都可以直接使用。利用xml文件定义View动画需要在工程的res目录下创建anim文件夹，所有的xml定义的View动画都要放在anim目录下。其中标签 translate、scale、alpha、rotate，就是对应四种动画。set标签是动画集合，对应AnimationSet类，有多个动画构成。 其中android:duration是指动画时间，fillAfter为true是动画结束后保持，false会回到初始状态。interpolator是指动画的执行速度，默认是先加速后减速。其他标签及属性较简单可自行研究验证。 1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;set xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:duration=&quot;5000&quot; android:fillAfter=&quot;true&quot; android:interpolator=&quot;@android:anim/accelerate_decelerate_interpolator&quot;&gt; &lt;!--set里面的duration如果有值，会覆盖子标签的duration--&gt; &lt;translate android:duration=&quot;1000&quot; android:fromXDelta=&quot;0&quot; android:toXDelta=&quot;400&quot; /&gt; &lt;scale android:duration=&quot;2000&quot; android:fromXScale=&quot;0.5&quot; android:fromYScale=&quot;0.5&quot; android:toXScale=&quot;1&quot; android:toYScale=&quot;1&quot; /&gt; &lt;alpha android:duration=&quot;3000&quot; android:fromAlpha=&quot;0.2&quot; android:toAlpha=&quot;1&quot; /&gt; &lt;rotate android:fromDegrees=&quot;0&quot; android:toDegrees=&quot;90&quot; /&gt;&lt;/set&gt; 定义好动画后，使用也很简单，调用view的startAnimation方法即可。 123//view动画使用，方式一：xml，建议使用。 Animation animation = AnimationUtils.loadAnimation(this, R.anim.animation_test); textView1.startAnimation(animation); rotate、scale动画的android:pivotX和android:pivotY属性、translate动画的android:toXDelta和android:toYDelta属性的取值都可以是都可以数值、百分数、百分数p，比如：50、50%、50%p，他们取值的代表的意义各不相同：50表示以View左上角为原点沿坐标轴正方向(x轴向右，y轴向下)偏移50px的位置；50%表示以View左上角为原点沿坐标轴正方向(x轴向右，y轴向下)偏移View宽度或高度的50%处的位置；50%p表示以View左上角为原点沿坐标轴正方向(x轴向右，y轴向下)偏移父控件宽度或高度的50%处的位置（p表示相对于ParentView的位置）。 “50”： ； “50%”； “50%p” 代码动态实现在平常的业务逻辑中也可以直接用Java代码来实现Veiw动画，Android系统给我们提供了AlphaAnimation、RotateAnimation、ScaleAnimation、TranslateAnimation四个动画类分别来实现View的渐变、旋转、缩放、平移动画。 1234567891011121314151617181920212223242526272829//view动画使用，方式二：new 动画对象 AnimationSet animationSet = new AnimationSet(false); animationSet.setDuration(3000); animationSet.addAnimation(new TranslateAnimation(0, 100, 0, 0)); animationSet.addAnimation(new ScaleAnimation(0.1f, 1f, 0.1f, 1f)); animationSet.setFillAfter(true); textView2.startAnimation(animationSet); //view动画使用，方式二：new 动画对象,使用setAnimation AnimationSet animationSet2 = new AnimationSet(false); animationSet2.setDuration(3000); animationSet2.addAnimation(new TranslateAnimation(0, 100, 0, 0)); animationSet2.addAnimation(new ScaleAnimation(0.1f, 1f, 0.1f, 1f)); animationSet2.setFillAfter(true); animationSet2.setAnimationListener(new Animation.AnimationListener() { @Override public void onAnimationStart(Animation animation) { } @Override public void onAnimationEnd(Animation animation) { MyToast.showMsg(AnimationTestActivity.this, &quot;View动画：代码 set：View动画结束~&quot;); } @Override public void onAnimationRepeat(Animation animation) { } }); textView3.setAnimation(animationSet2); 注意点： startAnimation方法是立刻播放动画；setAnimation是设置要播放的下一个动画。 setAnimationListener可以监听动画的开始、结束、重复。 自定义动画[3D旋转动画] Like:ProgressBarAnimation 12345678class ProgressBarAnimation(private val progressBar: ProgressBar, private val from: Int, private val to: Int) : Animation() { override fun applyTransformation(interpolatedTime: Float, t: Transformation?) { super.applyTransformation(interpolatedTime, t) val value = from + (to - from) * interpolatedTime progressBar.progress = value.toInt() }} 布局动画LayoutTransition使用LayoutAnimation给ViewGroup指定child的出场动画，方法如下： 1.先用xml定义标签LayoutAnimation： android:animation设置child的出场动画 android:animationOrder设置child的出场顺序，normal就是顺序 delay是指：每个child延迟（在android:animation中指定的动画时间）0.8倍后播放动画。如果android:animation中的动画时间是100ms，那么每个child都会延迟800ms后播放动画。 如果不设置delay，那么所有child同时执行动画。 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;layoutAnimation xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:animation=&quot;@anim/enter_from_left_for_child_of_group&quot; android:animationOrder=&quot;normal&quot; android:delay=&quot;0.8&quot;&gt;&lt;/layoutAnimation&gt;R.anim.enter_from_left_for_child_of_group&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;set xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;&gt; &lt;translate android:duration=&quot;1000&quot; android:fromXDelta=&quot;-100%p&quot; android:toXDelta=&quot;0&quot;/&gt;&lt;/set&gt; 2.把LayoutAnimation设置给ViewGroup 1234567891011121314151617181920212223&lt;LinearLayout android:id=&quot;@+id/ll_layout_animation&quot; android:layout_width=&quot;match_parent&quot; android:layout_height=&quot;wrap_content&quot; android:orientation=&quot;horizontal&quot; android:layoutAnimation=&quot;@anim/layout_animation&quot;&gt; &lt;TextView android:layout_width=&quot;50dp&quot; android:layout_height=&quot;wrap_content&quot; android:textColor=&quot;#ff0000&quot; android:text=&quot;呵呵呵&quot;/&gt; &lt;TextView android:layout_width=&quot;60dp&quot; android:layout_height=&quot;wrap_content&quot; android:textColor=&quot;#ff0000&quot; android:text=&quot;qq&quot; android:background=&quot;@color/colorPrimary&quot;/&gt; &lt;TextView android:layout_width=&quot;30dp&quot; android:layout_height=&quot;wrap_content&quot; android:textColor=&quot;#ff0000&quot; android:text=&quot;啊啊&quot;/&gt;&lt;/LinearLayout&gt; 除了xml，当然也可以使用LayoutAnimationController 指定： 123456//代码设置LayoutAnimation，实现ViewGroup的child的出场动画Animation enterAnim = AnimationUtils.loadAnimation(this, R.anim.enter_from_left_for_child_of_group);LayoutAnimationController controller = new LayoutAnimationController(enterAnim);controller.setDelay(0.8f);controller.setOrder(LayoutAnimationController.ORDER_NORMAL);llLayoutAnimation.setLayoutAnimation(controller); animateLayoutChanges用处及原理1android:animateLayoutChanges=&quot;true&quot; animateLayoutChanges的实际实现就是LayoutTransition， android.view.ViewGroup.java Dialog/Activity转场动画Activity转场overridePendingTransition 123456789class XXActivity : Activity() { override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_checkout_rec) overridePendingTransition( R.anim.slide_in_down, R.anim.slide_in_down ) }} 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;set xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:interpolator=&quot;@android:anim/decelerate_interpolator&quot; &gt; &lt;translate android:duration=&quot;200&quot; android:fromYDelta=&quot;100%p&quot; android:toYDelta=&quot;0%p&quot; /&gt;&lt;/set&gt; 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;set xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:interpolator=&quot;@android:anim/decelerate_interpolator&quot; &gt; &lt;translate android:duration=&quot;200&quot; android:fromYDelta=&quot;0%p&quot; android:toYDelta=&quot;100%p&quot; /&gt;&lt;/set&gt; Dialog转场Window?.setWindowAnimatinos() 123456789class XXDialog(context: Context, val anim: PointBean.PointAnimation) :Dialog(context) { init { setContentView(R.layout.threshold_dialog) setCanceledOnTouchOutside(true) window?.setGravity(Gravity.CENTER) window?.setLayout(MATCH_PARENT, AndroidUtil.getScreenWidth(context)) window?.setBackgroundDrawable(ColorDrawable(Color.TRANSPARENT)); window?.setWindowAnimations(R.style.XXDialogAnim)} 1234&lt;style name=&quot;XXDialogAnim&quot; mce_bogus=&quot;1&quot; parent=&quot;android:Animation&quot;&gt; &lt;item name=&quot;android:windowEnterAnimation&quot;&gt;@anim/cart_threshold_dialog_enter_anim&lt;/item&gt; &lt;item name=&quot;android:windowExitAnimation&quot;&gt;@anim/cart_threshold_dialog_exit_anim&lt;/item&gt; &lt;/style&gt; 属性动画属性动画本质上是 使用反射调用对象的setXX()、getXX()方法，根据插值器的值变化曲线修改对象属性，所以是视图实实在在的位置、尺寸等属性发生变化并会触发measure、layout，因此点击区域也就发生变化。 属性动画可对任意对象做动画，不仅仅是View。默认动画时间是300ms，10ms/帧。具体理解就是：可在给定的时间间隔内 实现 对象的某属性值 从 value1 到 value2的改变。 使用很简单，可以直接代码实现（推荐），也可xml实现，举例如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//属性动画使用，方式一：代码，建议使用。 横移 ObjectAnimator translationX = ObjectAnimator .ofFloat(textView6, &quot;translationX&quot;, 0, 200) .setDuration(1000); translationX.setInterpolator(new LinearInterpolator()); setAnimatorListener(translationX); //属性动画使用，方式二：xml。 竖移 Animator animatorUpAndDown = AnimatorInflater.loadAnimator(this, R.animator.animator_test); animatorUpAndDown.setTarget(textView6); //文字颜色变化 ObjectAnimator textColor = ObjectAnimator .ofInt(textView6, &quot;textColor&quot;, 0xffff0000, 0xff00ffff) .setDuration(1000); textColor.setRepeatCount(ValueAnimator.INFINITE); textColor.setRepeatMode(ValueAnimator.REVERSE); //注意，这里如果不设置 那么颜色就是跳跃的，设置ArgbEvaluator 就是连续过度的颜色变化 textColor.setEvaluator(new ArgbEvaluator()); //animatorSet mAnimatorSet = new AnimatorSet(); mAnimatorSet .play(animatorUpAndDown) .with(textColor) .after(translationX); mAnimatorSet.start(); /** * 设置属性动画的监听 * @param translationX */ private void setAnimatorListener(ObjectAnimator translationX) { translationX.addUpdateListener(new ValueAnimator.AnimatorUpdateListener() { @Override public void onAnimationUpdate(ValueAnimator animation) { //每播放一帧，都会调用 } }); if (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.KITKAT) { translationX.addPauseListener(new AnimatorListenerAdapter() { @Override public void onAnimationResume(Animator animation) { super.onAnimationResume(animation); } }); } translationX.addListener(new AnimatorListenerAdapter() { @Override public void onAnimationEnd(Animator animation) { super.onAnimationEnd(animation); } }); } R.animator.animator_test，是放在res/animator中。 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;!--属性动画test,一般建议采用代码实现，不用xml--&gt;&lt;set xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot; android:ordering=&quot;sequentially&quot;&gt; &lt;!--repeatCount：默认是0，-1是无限循环--&gt; &lt;!--repeatMode：重复模式：restart-从头来一遍、reverse-反向来一遍--&gt; &lt;!--valueType：指定propertyName的类型可选intType、floatType--&gt; &lt;!--android:pathData=&quot;&quot; android:propertyXName=&quot;&quot; android:propertyYName=&quot;&quot;--&gt; &lt;objectAnimator android:propertyName=&quot;translationY&quot; android:duration=&quot;1000&quot; android:valueFrom=&quot;0&quot; android:valueTo=&quot;120&quot; android:startOffset=&quot;0&quot; android:repeatCount=&quot;0&quot; android:repeatMode=&quot;reverse&quot; android:valueType=&quot;floatType&quot; android:interpolator=&quot;@android:interpolator/accelerate_decelerate&quot; /&gt; &lt;!--animator对用vueAnimator，比objectAnimator少了propertyName--&gt; &lt;!--&lt;animator--&gt; &lt;!--android:duration=&quot;2000&quot;--&gt; &lt;!--android:valueFrom=&quot;&quot;--&gt; &lt;!--android:valueTo=&quot;&quot;--&gt; &lt;!--android:startOffset=&quot;&quot;--&gt; &lt;!--android:repeatCount=&quot;&quot;--&gt; &lt;!--android:repeatMode=&quot;&quot;--&gt; &lt;!--android:valueType=&quot;&quot;--&gt; &lt;!--android:interpolator=&quot;&quot;--&gt; &lt;!--android:pathData=&quot;&quot;--&gt; &lt;!--android:propertyXName=&quot;&quot;--&gt; &lt;!--android:propertyYName=&quot;&quot;/&gt;--&gt;&lt;/set&gt; translationX是实现横移，animatorUpAndDown是实现竖移、textColor是实现文字颜色变化。其中animatorUpAndDown是使用xml定义，标签含义也很好理解。 最后使用AnimatorSet的play、with、after 实现 先横移，然后 竖移和颜色变化 同时的动画集合效果。 注意点： 关于View动画和属性动画的平移，属性动画改变属性值setTranslationX 的视图效果像view动画的平移一样，都是view实际的layout位置没变，只改变了视图位置；不同点是属性动画 给触摸点生效区域增加了位移（而view动画仅改变了视图位置）。 插值器：Interpolator，根据 时间流逝的百分比，计算当前属性值改变的百分比。 例如duration是1000，start后过了200，那么时间百分比是0.2，那么如果差值器是LinearInterpolator线性差值器，那么属性值改变的百分比也是0.2 估值器：Evaluator，就是根据 差值器获取的 属性值百分比，计算改变后的属性值。 ofInt、onFloat内部会自动设置IntEvaluator、FloatEvaluator。如果使用ofInt且是颜色相关的属性，就要设置ArgbEvaluator。 上面例子中 文字颜色变化动画 设置了ArgbEvaluator：textColor.setEvaluator(new ArgbEvaluator())。 动画监听：主要是两个监听接口，AnimatorUpdateListener、AnimatorListenerAdapter。AnimatorUpdateListener的回调方法在每帧更新时都会调用一次；AnimatorListenerAdapter可以监听开始、结束、暂停、继续、重复、取消，重写你要关注的方法即可。 对任意属性做动画一个问题，针对下面的Button，如何实现 的宽度逐渐拉长的动画，即文字不变，仅拉长背景宽度？ 12345&lt;Button android:id=&quot;@+id/button_animator_test&quot; android:layout_width=&quot;180dp&quot; android:layout_height=&quot;wrap_content&quot; android:text=&quot;任意属性动画-宽度拉长&quot;/&gt; 首先，View动画的ScaleAnimation是无法实现的，因为view的scale是把view的视图放大，这样文字也会拉长变形。那么属性动画呢？试试~ 123ObjectAnimator width1 = ObjectAnimator.ofInt(button, &quot;width&quot;, 1000);width1.setDuration(2000);width1.start(); 但是发现，没有效果！这是为啥呢？解释如下. 对object 的任意属性做动画 要求两个条件： object有 对应属性 的set方法，动画中没设置初始值 还要有get方法，系统要去取初始值（不满足则会crash）。 set方法要对object有所改变，如UI的变化。不满足则会没有动画效果 上面Button没有动画效果，就是没有满足第二条。看下Button的setWidth方法： 123456public void setWidth(int pixels) { mMaxWidth = mMinWidth = pixels; mMaxWidthMode = mMinWidthMode = PIXELS; requestLayout(); invalidate();} 实际就是TextView的setWidth方法，看到设置进去的值仅影响了宽度最大值和最小值。按照官方注释和实测，发现只有当Button/TextView在xml中设置android:layout_width为”wrap_content”时，才会setWidth改变宽度；而当Button/TextView在xml中设置android:layout_width为固定dp值时，setWidth无效。 而我们上面给出的Button xml中确实是固定值180dp，所以是属性”width”的setWidth是无效的，即不满足第二条要求，就没有动画效果了。（当修改Button xml中设置android:layout_width为”wrap_content”时，上面执行的属性动画是生效的。） 那么，当不满足条件时，如何解决此问题呢？ 有如下处理方法： 给object添加set、get方法，如果有权限。（一般不行，如TextView是SDK里面的不能直接改） 给Object包装一层，在包装类中提供set、get方法。 使用ValueAnimator，监听Value变化过程，自己实现属性的改变。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162 private void testAnimatorAboutButtonWidth() { //Button width 属性动画：如果xml中宽度是wrap_content，那么动画有效。 // 如果设置button确切的dp值，那么无效，因为对应属性&quot;width&quot;的setWidth()方法就是 在wrap_content是才有效。 ObjectAnimator width1 = ObjectAnimator.ofInt(button, &quot;width&quot;, 1000); width1.setDuration(2000);// width1.start(); //那么，想要在button原本有确切dp值时，要能对width动画，怎么做呢？ //方法一，包一层，然后用layoutParams ViewWrapper wrapper = new ViewWrapper(button); ObjectAnimator width2 = ObjectAnimator.ofInt(wrapper, &quot;width&quot;, 1000); width2.setDuration(2000);// width2.start(); //方法二，使用ValueAnimator，每一帧自己显示宽度的变化 ValueAnimator valueAnimator = ValueAnimator.ofInt(button.getLayoutParams().width, 1000); valueAnimator.addUpdateListener(new ValueAnimator.AnimatorUpdateListener() { @Override public void onAnimationUpdate(ValueAnimator animation) { int animatedValue = (Integer) animation.getAnimatedValue(); Log.i(&quot;hfy&quot;, &quot;onAnimationUpdate: animatedValue=&quot; + animatedValue);// IntEvaluator intEvaluator = new IntEvaluator();//// 获取属性值改变比例、计算属性值// float animatedFraction = animation.getAnimatedFraction();// Integer evaluate = intEvaluator.evaluate(animatedFraction, 300, 600);// Log.i(&quot;hfy&quot;, &quot;onAnimationUpdate: evaluate=&quot;+evaluate); if (button != null) { button.getLayoutParams().width = animatedValue; button.requestLayout(); } } }); valueAnimator.setDuration(4000).start(); } /** * 包一层，提供对应属性的set、get方法 */ private class ViewWrapper { private final View mView; public ViewWrapper(View view) { mView = view; } public int getWidth() { return mView.getLayoutParams().width; } public void setWidth(int width) { ViewGroup.LayoutParams layoutParams = mView.getLayoutParams(); layoutParams.width = width; mView.setLayoutParams(layoutParams); mView.requestLayout(); } } 属性动画的原理属性动画，要求对象有这个属性的set方法，执行时会根据传入的 属性初始值、最终值，在每帧更新时调用set方法设置当前时刻的 属性值。随着时间推移，set的属性值会接近最终值，从而达到动画效果。如果没传入初始值，那么对象还要有get方法，用于获取初始值。 在获取初始值、set属性值时，都是使用 反射 的方式，进行 get、set方法的调用。 见PropertyValuesHolder的setupValue、setAnimatedValue方法： 1234567891011121314151617181920212223242526272829303132333435363738private void setupValue(Object target, Keyframe kf) { if (mProperty != null) { Object value = convertBack(mProperty.get(target)); kf.setValue(value); } else { try { if (mGetter == null) { Class targetClass = target.getClass(); setupGetter(targetClass); if (mGetter == null) { // Already logged the error - just return to avoid NPE return; } } Object value = convertBack(mGetter.invoke(target)); kf.setValue(value); } catch (InvocationTargetException e) { Log.e(&quot;PropertyValuesHolder&quot;, e.toString()); } catch (IllegalAccessException e) { Log.e(&quot;PropertyValuesHolder&quot;, e.toString()); } }}void setAnimatedValue(Object target) { if (mProperty != null) { mProperty.set(target, getAnimatedValue()); } if (mSetter != null) { try { mTmpValueArray[0] = getAnimatedValue(); mSetter.invoke(target, mTmpValueArray); } catch (InvocationTargetException e) { Log.e(&quot;PropertyValuesHolder&quot;, e.toString()); } catch (IllegalAccessException e) { Log.e(&quot;PropertyValuesHolder&quot;, e.toString()); } }} 以上效果图： 使用动画的注意事项 使用帧动画，避免OOM。因为图片多。 属性动画 如果有循环动画，在页面退出时要及时停止，避免内存泄漏。 使用View动画后，调用setVisibility(View.GONE)失效时，使用view.clearAnimation()可解决。 属性动画，可能会由于View属性变化导致频繁触发重新measure layout，注意性能","link":"/2023/10/26/Animation/"},{"title":"Binder","text":"为什么是Binder 具体见QA。 一次完整的 Binder IPC 通信过程通常是这样： 其内存流向是这样的： 首先 Binder 驱动在内核空间创建一个数据接收缓存区； 接着在内核空间开辟一块内核缓存区，建立内核缓存区和内核中数据接收缓存区之间的映射关系，以及内核中数据接收缓存区和接收进程用户空间地址的映射关系； 发送方进程通过系统调用 copy_from_user() 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在内存映射，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信。 如下图： Server创建Binder实例，并调用ServiceManager.addService(String name, IBinder service)向ServiceManager注册 ServiceManager根据传入的服务名与服务实体，在svclist中增加该服务对应的handle和name映射 Client发起通信，先向ServiceManager查询该服务名，命中后返回 Binder 结构图 要运作Binder，需要4个角色通力合作： 客户端：获取服务端在Binder驱动中对应的引用，然后调用它的transact方法即可向服务端发送消息。 服务端：指Binder实现类所在的进程，该对象一旦创建，内部则会启动一个隐藏线程，会接收客户端发送的数据，然后执行Binder对象中的onTransact()函数。 Binder驱动：当服务端Binder对象被创建时，会在Binder驱动中创建一个mRemote对象。 Service Manager:作用相当于DNS，就想平时我们通过网址，然后DNS帮助我们找到对应的IP地址一样，我们在Binder服务端创建的Binder，会注册到Service Manager，同理，当客户端需要该Binder的时候，也会去Service Manager查找。 所以以上4者的运作基本上是: 服务端创建对应Binder实例对象，然后开启隐藏Binder线程，接收来自客户端的请求，同时，将自身的Binder注册到Service Manager，在Binder驱动创建mRemote对象。 客户端想和服务端通信，通过Service Manager查找到服务端的Binder，然后Binder驱动将对应的mRemote对象返回 至此，整个通信连接建立完毕 在建立完毕通信之后，客户端可以通过获取到的mRemote对象发生消息给远程服务端了，客户端通过调用transact()方法，将要请求的内容发送到服务段，然后挂起自己当前的线程，等待回复，服务端收到数据后在自己的onTransact()方法进行处理，然后将对应的结果返回给客户端，客户端收到数据，重新拉起线程，至此进程间交互数据完毕。 Binder 通信模型介绍完 Binder IPC 的底层通信原理，接下来我们看看实现层面是如何设计的。 一次完整的进程间通信必然至少包含两个进程，通常我们称通信的双方分别为客户端进程（Client）和服务端进程（Server），由于进程隔离机制的存在，通信双方必然需要借助 Binder 来实现。 5.1 Client/Server/ServiceManager/驱动前面我们介绍过，Binder 是基于 C/S 架构的。由一系列的组件组成，包括 Client、Server、ServiceManager、Binder 驱动。其中 Client、Server、Service Manager 运行在用户空间，Binder 驱动运行在内核空间。其中 Service Manager 和 Binder 驱动由系统提供，而 Client、Server 由应用程序来实现。Client、Server 和 ServiceManager 均是通过系统调用 open、mmap 和 ioctl 来访问设备文件 /dev/binder，从而实现与 Binder 驱动的交互来间接的实现跨进程通信。 Client、Server、ServiceManager、Binder 驱动这几个组件在通信过程中扮演的角色就如同互联网中服务器（Server）、客户端（Client）、DNS域名服务器（ServiceManager）以及路由器（Binder 驱动）之前的关系。 通常我们访问一个网页的步骤是这样的：首先在浏览器输入一个地址，如 http://www.google.com 然后按下回车键。但是并没有办法通过域名地址直接找到我们要访问的服务器，因此需要首先访问 DNS 域名服务器，域名服务器中保存了 http://www.google.com 对应的 ip 地址 10.249.23.13，然后通过这个 ip 地址才能放到到 http://www.google.com 对应的服务器。 Android Binder 设计与实现一文中对 Client、Server、ServiceManager、Binder 驱动有很详细的描述，以下是部分摘录： Binder 驱动Binder 驱动就如同路由器一样，是整个通信的核心；驱动负责进程之间 Binder 通信的建立，Binder 在进程之间的传递，Binder 引用计数管理，数据包在进程之间的传递和交互等一系列底层支持。 ServiceManager 与实名 BinderServiceManager 和 DNS 类似，作用是将字符形式的 Binder 名字转化成 Client 中对该 Binder 的引用，使得 Client 能够通过 Binder 的名字获得对 Binder 实体的引用。注册了名字的 Binder 叫实名 Binder，就像网站一样除了除了有 IP 地址意外还有自己的网址。Server 创建了 Binder，并为它起一个字符形式，可读易记得名字，将这个 Binder 实体连同名字一起以数据包的形式通过 Binder 驱动发送给 ServiceManager ，通知 ServiceManager 注册一个名为“张三”的 Binder，它位于某个 Server 中。驱动为这个穿越进程边界的 Binder 创建位于内核中的实体节点以及 ServiceManager 对实体的引用，将名字以及新建的引用打包传给 ServiceManager。ServiceManger 收到数据后从中取出名字和引用填入查找表。 细心的读者可能会发现，ServierManager 是一个进程，Server 是另一个进程，Server 向 ServiceManager 中注册 Binder 必然涉及到进程间通信。当前实现进程间通信又要用到进程间通信，这就好像蛋可以孵出鸡的前提却是要先找只鸡下蛋！Binder 的实现比较巧妙，就是预先创造一只鸡来下蛋。ServiceManager 和其他进程同样采用 Bidner 通信，ServiceManager 是 Server 端，有自己的 Binder 实体，其他进程都是 Client，需要通过这个 Binder 的引用来实现 Binder 的注册，查询和获取。ServiceManager 提供的 Binder 比较特殊，它没有名字也不需要注册。当一个进程使用 BINDERSETCONTEXT_MGR 命令将自己注册成 ServiceManager 时 Binder 驱动会自动为它创建 Binder 实体（这就是那只预先造好的那只鸡）。其次这个 Binder 实体的引用在所有 Client 中都固定为 0 而无需通过其它手段获得。也就是说，一个 Server 想要向 ServiceManager 注册自己的 Binder 就必须通过这个 0 号引用和 ServiceManager 的 Binder 通信。类比互联网，0 号引用就好比是域名服务器的地址，你必须预先动态或者手工配置好。要注意的是，这里说的 Client 是相对于 ServiceManager 而言的，一个进程或者应用程序可能是提供服务的 Server，但对于 ServiceManager 来说它仍然是个 Client。 Client 获得实名 Binder 的引用Server 向 ServiceManager 中注册了 Binder 以后， Client 就能通过名字获得 Binder 的引用了。Client 也利用保留的 0 号引用向 ServiceManager 请求访问某个 Binder: 我申请访问名字叫张三的 Binder 引用。ServiceManager 收到这个请求后从请求数据包中取出 Binder 名称，在查找表里找到对应的条目，取出对应的 Binder 引用作为回复发送给发起请求的 Client。从面向对象的角度看，Server 中的 Binder 实体现在有两个引用：一个位于 ServiceManager 中，一个位于发起请求的 Client 中。如果接下来有更多的 Client 请求该 Binder，系统中就会有更多的引用指向该 Binder ，就像 Java 中一个对象有多个引用一样。 5.2 Binder 通信过程至此，我们大致能总结出 Binder 通信过程： 首先，一个进程使用 BINDERSETCONTEXT_MGR 命令通过 Binder 驱动将自己注册成为 ServiceManager； Server 通过驱动向 ServiceManager 中注册 Binder（Server 中的 Binder 实体），表明可以对外提供服务。驱动为这个 Binder 创建位于内核中的实体节点mRemote对象以及 ServiceManager 对mRemote的引用，将名字以及新建的引用打包传给 ServiceManager，ServiceManger 将其填入查找表。 Client 通过名字，在 Binder 驱动的帮助下从 ServiceManager 中获取到对 Binder 实体的引用，通过这个引用就能实现和 Server 进程的通信。 我们看到整个通信过程都需要 Binder 驱动的接入。下图能更加直观的展现整个通信过程(为了进一步抽象通信过程以及呈现上的方便，下图我们忽略了 Binder 实体及其引用的概念)： 5.3 Binder 通信中的代理模式我们已经解释清楚 Client、Server 借助 Binder 驱动完成跨进程通信的实现机制了，但是还有个问题会让我们困惑。A 进程想要 B 进程中某个对象（object）是如何实现的呢？毕竟它们分属不同的进程，A 进程 没法直接使用 B 进程中的 object。 前面我们介绍过跨进程通信的过程都有 Binder 驱动的参与，因此在数据流经 Binder 驱动的时候驱动会对数据做一层转换。当 A 进程想要获取 B 进程中的 object 时，驱动并不会真的把 object 返回给 A，而是返回了一个跟 object 看起来一模一样的代理对象 objectProxy，这个 objectProxy 具有和 object 一摸一样的方法，但是这些方法并没有 B 进程中 object 对象那些方法的能力，这些方法只需要把把请求参数交给驱动即可。对于 A 进程来说和直接调用 object 中的方法是一样的。 当 Binder 驱动接收到 A 进程的消息后，发现这是个 objectProxy 就去查询自己维护的表单，一查发现这是 B 进程 object 的代理对象。于是就会去通知 B 进程调用 object 的方法，并要求 B 进程把返回结果发给自己。当驱动拿到 B 进程的返回结果后就会转发给 A 进程，一次通信就完成了。 5.4 Binder 的完整定义现在我们可以对 Binder 做个更加全面的定义了： 从进程间通信的角度看，Binder 是一种进程间通信的机制； 从 Server 进程的角度看，Binder 指的是 Server 中的 Binder 实体对象； 从 Client 进程的角度看，Binder 指的是对 Binder 代理对象，是 Binder 实体对象的一个远程代理 从传输过程的角度看，Binder 是一个可以跨进程传输的对象；Binder 驱动会对这个跨越进程边界的对象对一点点特殊处理，自动完成代理对象和本地对象之间的转换。 Binder的死亡通知三种方式来检测远程对象是否存活： 调用远程方法的时候捕获RemoteException(DeadObjectException)； 调用IBinder的pingBinder()进行检测； 调用linkToDeath注册IBinder.DeathRecipient接口回调，接口会在Ibinder死亡时回调binderDied()； ServiceManager链接：https://juejin.cn/post/6855904885976924173 一个进程使用 BINDERSETCONTEXT_MGR 命令通过 Binder 驱动将自己注册成为 ServiceManager，同时想Binder驱动注册ServiceManager的Binder实体，此时其他相对于SM的Client可以通过0号引用获取SM的Binder引用。 ServiceManager的Binder引用：0号引用ServiceManager是安卓中一个重要的类，正如它的名字所表达的意思，用于管理所有的系统服务，维护着系统服务和客户端的binder通信。 那ServiceManager和Binder是什么样的关系呢？ 简单点说，ServiceManager作用是将字符形式的 Binder 名字转化成 Client 中对该 Binder 的引用，使得 Client 能够通过 Binder 的名字获得对 Binder 实体的引用。（这个注册了名字的 Binder 叫实名 Binder） 但现在就有个问题，Service Manager 是一个进程，Server 是一个进程，Server 向 Service Manager 中注册 Binder就涉及到进程间通信。但当前进程间通信又要用到进程间通信，这就好像蛋可以孵出鸡的前提却是要先找只鸡下蛋。那如何解决这个没有鸡生蛋的问题呢？ 巧妙的实现： 要打破这个问题，就要预先创造一只鸡去生蛋，这只鸡就是ServiceManager的Binder实体。ServiceManager 提供的 Binder 比较特殊，它没有名字也不需要注册。当一个进程使用 BINDER_SET_CONTEXT_MGR 命令就会将自己注册成 ServiceManager 时， Binder 驱动会自动为它创建 Binder 实体（这就是那只预先造好的那只鸡） Server端的注册方式这个 Binder 实体的引用在所有 Client 中都固定为 0 而无需通过其它手段获得。也就是说，一个 Server 想要向 ServiceManager 注册自己的 Binder 就必须通过这个 0 号引用和 ServiceManager 的 Binder 通信。 整个过程大致是： 当一个Binder Service创建后，它们就将自己的[名称、Binder句柄]对应关系告知SM进行备案，完成注册。 Client端获取Service的Binder引用Server 向 ServiceManager 中注册了 Binder 后， Client 就能通过名字获得 Binder 的引用了。由于 Client 和 SM 通信也需要Binder，所以Client 也是通过这个0号引用去向SM获取某个Service的Binder。 因为ServiceManager对于Client端来说Handle句柄是固定的，都是0，所以ServiceManager服务并不需要查询，可以直接使用。 整个过程大致是： Client发送数据包向SM请求某个名字的Binder引用 SM 收到这个请求后，从请求数据包中去找名称，在查找表里找到对应的Binder的引用 将找到的Binder 引用作为回复发送给请求的Client QA为什么内核空间里有两个缓存区，“内核缓存区”和“数据接收缓存区”https://blog.csdn.net/carson_ho/article/details/73560642?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165363401516782425141792%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=165363401516782425141792&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2 举个调用WindoManagerService的Binder例子？ 为什么是 Binder，具体说说Client-Server方式的广泛采用对进程间通信（IPC）机制是一个挑战。目前linux支持的IPC包括传统的管道，System V IPC，即消息队列/共享内存/信号量，以及socket中只有socket支持Client-Server的通信方式。当然也可以在这些底层机制上架设一套协议来实现Client-Server通信，但这样增加了系统的复杂性，在手机这种条件复杂，资源稀缺的环境下可靠性也难以保证。 另一方面是传输性能。socket作为一款通用接口，其传输效率低，开销大，主要用在跨网络的进程间通信和本机上进程间的低速通信。消息队列和管道采用存储-转发方式，即数据先从发送方缓存区拷贝到内核开辟的缓存区中，然后再从内核缓存区拷贝到接收方缓存区，至少有两次拷贝过程。共享内存虽然无需拷贝，但控制复杂，难以使用。 表 1 各种IPC方式数据拷贝次数 还有一点是出于安全性考虑。Android作为一个开放式，拥有众多开发者的的平台，应用程序的来源广泛，确保智能终端的安全是非常重要的。终端用户不希望从网上下载的程序在不知情的情况下偷窥隐私数据，连接无线网络，长期操作底层设备导致电池很快耗尽等等。传统IPC没有任何安全措施，完全依赖上层协议来确保。首先传统IPC的接收方无法获得对方进程可靠的UID/PID（用户ID/进程ID），从而无法鉴别对方身份。Android为每个安装好的应用程序分配了自己的UID，故进程的UID是鉴别进程身份的重要标志。使用传统IPC只能由用户在数据包里填入UID/PID，但这样不可靠，容易被恶意程序利用。可靠的身份标记只有由IPC机制本身在内核中添加。其次传统IPC访问接入点是开放的，无法建立私有通道。比如命名管道的名称，system V的键值，socket的ip地址或文件名都是开放的，只要知道这些接入点的程序都可以和对端建立连接，不管怎样都无法阻止恶意程序通过猜测接收方地址获得连接。 附录-Binder示例Server 12345678910111213141516171819202122232425262728293031323334353637383940414243public class GameService extends Service { private Binder mBinder = new Binder() { @Override protected boolean onTransact(int code, Parcel data, Parcel reply, int flags) throws RemoteException { if (code == 1) { String _arg0; _arg0 = data.readString(); int _result = getGamePrice(_arg0); reply.writeInt(_result); return true; } return super.onTransact(code, data, reply, flags); } public int getGamePrice(String name) { int price = -1; if (&quot;逃生2&quot;.equals(name)) { price = 88; } else if (&quot;饥荒&quot;.equals(name)) { price = 24; } return price; } }; @Nullable @Override public IBinder onBind(Intent intent) { return mBinder; } @Override public void onCreate() { super.onCreate(); // 在服务创建时，将Binder对象注册到ServiceManager try { ServiceManager.addService(&quot;my_service&quot;, mBinder); } catch (RemoteException e) { e.printStackTrace(); } }} Client 1234567891011121314151617181920212223242526272829303132333435363738394041private IBinder mRemote = null;private ServiceConnection mServiceConnection = new ServiceConnection() { @Override public void onServiceConnected(ComponentName name, IBinder service) { mRemote = service; Toast.makeText(MainActivity.this, &quot;绑定成功&quot;, Toast.LENGTH_SHORT).show(); service?.linkToDeath(object : IBinder.DeathRecipient{ override fun binderDied() { } }, 0) } @Override public void onServiceDisconnected(ComponentName name) { mRemote = null; Toast.makeText(MainActivity.this, &quot;远程服务链接已断&quot;, Toast.LENGTH_SHORT).show(); }};private void init() { String action = &quot;android.intent.action.bind.gameservice&quot;; Intent intent = new Intent(action); intent.setPackage(&quot;com.smartwork.bindertest&quot;); bindService(intent, mServiceConnection, BIND_AUTO_CREATE);}private int invokeRemoteService(String name) throws RemoteException { android.os.Parcel _data = android.os.Parcel.obtain(); android.os.Parcel _reply = android.os.Parcel.obtain(); int _result; try { _data.writeString(name); mRemote.transact(1, _data, _reply, 0); _result = _reply.readInt(); } finally { _reply.recycle(); _data.recycle(); } return _result;}","link":"/2022/08/08/Binder/"},{"title":"Coroutines_Principle","text":"Kotlin协程使用 Dispatchers协程调度器是用来指定协程体在哪个线程中执行，Kotlin提供了几个调度器： Default 默认选项，指定协程体在线程池中执行： 123456789101112GlobalScope.launch(Dispatchers.Default) { println(&quot;1: ${Thread.currentThread().name}&quot;) launch(Dispatchers.Default) { println(&quot;2: ${Thread.currentThread().name}&quot;) } println(&quot;3: ${Thread.currentThread().name}&quot;)}--&gt;output1: DefaultDispatcher-worker-13: DefaultDispatcher-worker-12: DefaultDispatcher-worker-2 Main 指定协程体在主线程中执行。 IO 基于 Default 调度器背后的线程池(designed for offloading blocking IO tasks)，因此从 Default 切换到 IO 不会触发线程切换： 123456789101112GlobalScope.launch(Dispatchers.Default) { println(&quot;1: ${Thread.currentThread().name}&quot;) launch(Dispatchers.IO) { println(&quot;2: ${Thread.currentThread().name}&quot;) } println(&quot;3: ${Thread.currentThread().name}&quot;)}--&gt;output1: DefaultDispatcher-worker-13: DefaultDispatcher-worker-12: DefaultDispatcher-worker-1 Unconfined 协程体运行在父协程所在的线程： 123456789101112GlobalScope.launch(Dispatchers.Default) { println(&quot;1: ${Thread.currentThread().name}&quot;) launch(Dispatchers.Unconfined) { println(&quot;2: ${Thread.currentThread().name}&quot;) } println(&quot;3: ${Thread.currentThread().name}&quot;)}--&gt;output1: DefaultDispatcher-worker-12: DefaultDispatcher-worker-13: DefaultDispatcher-worker-1 CoroutineScope1234public interface CoroutineScope { public val coroutineContext: CoroutineContext}复制代码 GlobeScope GlobeScope 启动的协程是一个单独的作用域，不会继承上层协程的作用域，其内部的子协程遵守默认的作用域规则。 coroutineScope coroutineScope 启动的协程 cancel 时会 cancel 所有子协程，也会 cancel 父协程，子协程未捕获的异常也会向上传递给父协程。 supervisorScope supervisorScope 启动的协程 cancel 和传递异常时，只会由父协程向子协程单向传播。MainScope 是 supervisorScope 作用域。 Android-Kotlin协程使用MainScopeAndroid 中一般不建议使用 GlobalScope, 因为它会创建一个顶层协程，需要保持所有对 GlobalScope 启动的协程的引用，然后在 Activity destory 等场景的时候 cancel 掉这些的协程，否则就会造成内存泄露等问题。可以使用 MainScope: 12345678910111213141516class CoroutineActivity : AppCompatActivity() { private val mainScope = MainScope() fun request1() { mainScope.launch { // ... } } // request2, 3, ... override fun onDestroy() { super.onDestroy() mainScope.cancel() }} MainScope 的定义： 1public fun MainScope(): CoroutineScope = ContextScope(SupervisorJob() + Dispatchers.Main) Lifecycle协程关于 Lifecycle 可以参考 Android-Jetpack组件之Lifecycle。 添加依赖： 1implementation &quot;androidx.lifecycle:lifecycle-runtime-ktx:2.2.0&quot; 源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940val LifecycleOwner.lifecycleScope: LifecycleCoroutineScope get() = lifecycle.coroutineScopeval Lifecycle.coroutineScope: LifecycleCoroutineScope get() { while (true) { val existing = mInternalScopeRef.get() as LifecycleCoroutineScopeImpl? if (existing != null) { return existing } val newScope = LifecycleCoroutineScopeImpl( this, SupervisorJob() + Dispatchers.Main.immediate ) if (mInternalScopeRef.compareAndSet(null, newScope)) { newScope.register() return newScope } } }abstract class LifecycleCoroutineScope internal constructor() : CoroutineScope { internal abstract val lifecycle: Lifecycle // 当 activity created 的时候执行协程体 fun launchWhenCreated(block: suspend CoroutineScope.() -&gt; Unit): Job = launch { lifecycle.whenCreated(block) } // // 当 activity started 的时候执行协程体 fun launchWhenStarted(block: suspend CoroutineScope.() -&gt; Unit): Job = launch { lifecycle.whenStarted(block) } // // 当 activity resumed 的时候执行协程体 fun launchWhenResumed(block: suspend CoroutineScope.() -&gt; Unit): Job = launch { lifecycle.whenResumed(block) }}复制代码 使用： 12345678910// AppCompatActivity 实现了 LifecycleOwner 接口class MainActivity : AppCompatActivity() { fun test() { lifecycleScope.launchWhenCreated { // ... } }}复制代码 LiveData协程关于 LiveData 可以参考 Android-Jetpack组件之LiveData-ViewModel。 添加依赖： 1implementation &quot;androidx.lifecycle:lifecycle-livedata-ktx:2.2.0&quot; 源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051fun &lt;T&gt; liveData( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, @BuilderInference block: suspend LiveDataScope&lt;T&gt;.() -&gt; Unit): LiveData&lt;T&gt; = CoroutineLiveData(context, timeoutInMs, block)internal class CoroutineLiveData&lt;T&gt;( context: CoroutineContext = EmptyCoroutineContext, timeoutInMs: Long = DEFAULT_TIMEOUT, block: Block&lt;T&gt;) : MediatorLiveData&lt;T&gt;() { private var blockRunner: BlockRunner&lt;T&gt;? private var emittedSource: EmittedSource? = null init { val supervisorJob = SupervisorJob(context[Job]) val scope = CoroutineScope(Dispatchers.Main.immediate + context + supervisorJob) blockRunner = BlockRunner( liveData = this, block = block, timeoutInMs = timeoutInMs, scope = scope ) { blockRunner = null } } internal suspend fun emitSource(source: LiveData&lt;T&gt;): DisposableHandle { clearSource() val newSource = addDisposableSource(source) emittedSource = newSource return newSource } internal suspend fun clearSource() { emittedSource?.disposeNow() emittedSource = null } // 启动协程 override fun onActive() { super.onActive() blockRunner?.maybeRun() } // 取消协程 override fun onInactive() { super.onInactive() blockRunner?.cancel() }} 使用： 12345678910111213141516// AppCompatActivity 实现了 LifecycleOwner 接口class MainActivity : AppCompatActivity() { fun test() { liveData { try { // ... emit(&quot;success&quot;) } catch(e: Exception) { emit(&quot;error&quot;) } }.observe(this, Observer { Log.d(&quot;LLL&quot;, it) }) }} ViewModel协程关于 ViewModel 可以参考 Android-Jetpack组件之LiveData-ViewModel。 添加依赖： 1implementation &quot;androidx.lifecycle:lifecycle-viewmodel-ktx:2.2.0&quot; 源码如下： 1234567891011121314151617val ViewModel.viewModelScope: CoroutineScope get() { val scope: CoroutineScope? = this.getTag(JOB_KEY) if (scope != null) { return scope } return setTagIfAbsent(JOB_KEY, CloseableCoroutineScope(SupervisorJob() + Dispatchers.Main.immediate)) }internal class CloseableCoroutineScope(context: CoroutineContext) : Closeable, CoroutineScope { override val coroutineContext: CoroutineContext = context override fun close() { coroutineContext.cancel() }} 协程原理suspend 的原理简述：suspend其实也是回调，实现suspend的方法会被编译器替换为 多一个Continuation参数 的方法，Continuation实现了一个状态机，其中每个挂起点(suspend方法)都是一个状态，保存了下一步执行的CoroutineContext。 具体而言， 比如main中调用了suspend a(), suspend b()，那么实际上编译器会构造这么一个状态机：invokeSuspend() 中根据每个方法的执行结果，如a()如果耗时【即withContext(Dispatchers)/runBlocking之类的】则会return COROUTINE_SUSPENDED (即后续操作先不执行，也就是挂起了)，等耗时执行完成后invokeSuspend()再被调用，此时状态改变，break走下一步b()；如果a()不耗时则立即break，走到下一步b()； 如此往复，直到所有suspend方法执行完成，后正常执行其他代码 suspend 是回调（Callback）理解 suspend 其实不需要纠结神奇的「挂起」是什么意思或者拘泥于线程是怎么切换的。实际上 suspend 的背后是大家非常熟悉的回调。 假设 postItem 由三个有依赖关系的异步子任务组成： requestToken，createPost 和 processPost ，这三个函数都是基于回调的 API： 12345678910111213141516// 三个基于回调的 APIfun requestToken(block: (String) -&gt; Unit)fun createPost( token: String, item: Item, block: (Post) -&gt; Unit))fun processPost(post: Post)fun postItem(item: Item) { requestToken { token -&gt; createPost(token, item) { post -&gt; processPost(post) } }} 可以看到基于回调的 API 很容易造成大量缩进。如果代码中再加上一些条件、循环的逻辑，那么代码可读性会大大降低。Promise (Future) 等 API 以及 Android 社区很流行的 RxJava 通过链式调用在一定程度上消除了嵌套的问题。比如上面这个例子用 RxJava 实现的话： 1234567fun requestToken(): Observable&lt;String&gt;fun createPost(token: String, item: Item): Observable&lt;Post&gt;fun processPost(post: Post)fun postItem(item: Item) = requestToken() .flatMap { createPost(it, item) } .flatMap { processPost(it) } 但是 RxJava 这样的方案需要使用者掌握大量操作符，写复杂逻辑也很麻烦，会有一种被「困在」这个调用链里面的感觉。 kotlin 的 suspend 关键字可以帮助我们消除回调，用同步的写法写异步： 🏹代表挂起点（suspension point） 123456789suspend fun requestToken(): Stringsuspend fun createPost(token: String, item: Item): Postsuspend fun processPost(post)suspend fun postItem(item: Item) { val token = 🏹 requestToken() val post = 🏹 createPost(token, item) 🏹 processPost(post)} 由于 createPost 这些方法实际上是耗时的 IO 异步操作，需要等到拿到返回值才能执行后面的逻辑，但我们又不希望阻塞当前线程（通常是主线程），因此最终必须实现某种消息传递的机制，让后台线程做完耗时操作以后把结果传给主线程。 假设我们有了前面提到的三个基于回调的 API，实现 suspend 可以在编译的时候把每个挂起点 🏹 后面的逻辑包在一个 lambda 里面，然后去调用回调 API，最终生成类似嵌套的代码。但这样每一个挂起点在运行时都需要开销一个 lambda 对象。Kotlin 和许多其他语言都采用生成状态机的方式，性能更好。 具体来说，编译器看到 suspend 关键字会去掉 suspend ，给函数添加一个额外的 Continuation 参数。这个 Continuation 就代表了一个回调： 12345public interface Continuation&lt;in T&gt; { public val context: CoroutineContext // 用来回调的方法 public fun resumeWith(result: Result&lt;T&gt;)} Kotlin 编译器会给每个 suspend 的块生成一个 Continuation 的实现类，这个实现类是一个状态机，其中的状态对应于每个挂起点，保存了需要下一步继续执行所需要的上下文（即依赖的局部变量），类似下面的伪代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748suspend fun postItem(item: Item) { val token = 🏹 requestToken() val post = 🏹 createPost(token, item) 🏹 processPost(post)}// 编译器变换后的伪代码// 1.脱掉了 suspend 关键字// 2.增加了一个 Continuation 对象fun postItem(item: Item, cont: Continuation) { // 判断传入的是否是 postItem 的 `ContiuationImpl` // * false: 初始化一个对应本次调用 postItem 的状态机 // * true: 对应 postItem 内其他 suspend 函数回调回来情况 // 其中 ThisSM 指的 object: ContinuationImpl 这个匿名类 val sm = (cont as? ThisSM) ?: object: ContinuationImpl { // 实际源码中 override 的是 // kotlin.coroutine.jvm.internal.BaseContinuationImpl // 的 invokeSuspend 方法 override fun resume(..) { // 通过 ContinuationImpl.resume // 重新回调回这个方法 postItem(null, this) } } switch (sm.label) { case 0: // 捕获后续步骤需要的局部变量 sm.item = item // 设置下一步的 label sm.label = 1 // 当 requestToken 里的耗时操作完成后会更新状态机 // 并通过 sm.resume 再次调用这个 postItem 函数 // 「我们在前面提供了 sm.resume 的实现，即再次调用 postItem」 requestToken(sm) case 1: val item = sm.item // 前一个异步操作的结果 val token = sm.result as Token sm.label = 2 createPost(token, item, sm) case 2: procesPost(post) // ... }} 编译器将 suspend 编译成带有 continuation 参数的方法叫做 CPS (Continuation-Passing-Style) 变换。 使用 suspend 函数无须关心线程切换suspend 提供了这样一个**约定(Convention)**：调用这个函数不会阻塞当前调用的线程。 但前提是这个 suspend 函数实现正确，真正做到了不阻塞当前线程。单纯地给函数加上 suspend 关键字并不会神奇地让函数变成非阻塞的 这对 UI 编程是非常有用的，因为 UI 的主线程需要不断相应各种图形绘制、用户操作的请求，如果主线程上有耗时操作会让其他请求无法及时响应，造成 UI 卡顿。 Android 社区流行的网络请求库 Retrofit、官方出品的数据库 ORM Room 都已经通过提供 suspend API 的形式支持了协程。Android 官方也利用 Kotlin 扩展属性的方式给 Activity 等具有生命周期的组件提供了开启协程所需的 CoroutineScope ，其中的 context 指定了使用 Dispatchers.Main ，即通过 lifecycleScope 开启的协程都会被调度到主线程执行。因此我们可以在调用 suspend 函数，拿到结果后直接更新 UI，无须做任何线程切换的动作。这样的 suspend 函数叫作「main 安全」的。 1234lifecycleScope.launch { val posts = 🏹 retrofit.get&lt;PostService&gt;().fetchPosts(); // 由于在主线程，可以拿着 posts 更新 UI} 这相比 callback 和 RxJava 的 API 是要好很多的。这些异步的 API 最终都得依靠回调，但回调回来在哪个线程需要调用方自己搞清楚，得看这些函数里面是怎么实现的。而有了 suspend 不阻塞当前线程的约定，调用方其实无须关心这个函数内部是在哪个线程执行的。 12lifecycleScope.launch(Dispatchers.Main) { 🏹 foo()} 比如上面这个代码块，我们指定这个协程块调度到主线程执行，里面调用了一个不知道哪里来的 suspend foo 方法。这个方法内部可能是耗时的 CPU 计算，可能是耗时的 IO 请求，但是我在写这个协程块的时候，其实并不需要关心这里面到底是怎么回事，运行在哪个线程。类似地，在阅读这段协程块的时候，我们可以清楚地知道眼前的这段代码会在主线程执行，suspend foo 里面的代码是一个潜在的耗时操作，具体在哪个线程执行是这个函数的实现细节，对于当前代码的逻辑是「透明」的。 但前提是这个 suspend 函数实现正确，真正做到了不阻塞当前线程。单纯地给函数加上 suspend 关键字并不会神奇地让函数变成非阻塞的，比如假设 suspend foo 里面的实现是这样的： 12// 😖suspend fun foo() = BigInteger.probablePrime(4096, Random()) 这里这个 suspend 函数的内部实现是一段耗时的 CPU 操作，类似地也可以想象成是一段时间复杂度特别高的代码。我们如果在主线程调用这个函数还是会阻塞 UI。问题出在这个 foo 函数的实现没有遵守 suspend 的语义，是错误的。正确的做法应该修改这个 foo 函数： 123suspend fun findBigPrime(): BigInteger = withContext(Dispatchers.Default) { BigInteger.probablePrime(4096, Random()) } 借助 withContext 我们把耗时操作从当前主线程挪到了一个默认的后台线程池。因此有人说，即使是用了协程，最终还是会「阻塞」某个线程，「所有的代码本质上都是阻塞式的」。这种理解可以帮助我们认识到 Android / JVM 上最终需要线程作为执行协程的载体，但忽略了阻塞和非阻塞 IO 之分。CPU 执行线程，而上面 BigInteger.probablePrime 是一个耗时的 CPU 计算，只能等待 CPU 把结果算出来，但 IO 造成的等待并不一定要阻塞 CPU。 链接抽丝剥茧kotlin-协程 Kotlin笔记之协程工作原理 理解 Kotlin 的 suspend 函数 https://blog.yujinyan.me/posts/understanding-kotlin-suspend-functions/ Other以GlobalScope.launch{ … } 为例，编译期通过编译时插入代码，将”…”协程体包裹封装成一个继承与SuspendLambda,而SuspendLambda是一个抽象类，继承于ContinuationImpl。 ContinuationImpl就是核心协程类Continuation接口的实现（一个Continuation就代表了一个协程）\\ 协程的启动是通过 BaseContinuationImpl.resumeWith 方法调用到了子类 SuspendLambda.invokeSuspend 方法，然后通过状态机来控制顺序运行。 Kotlin 编译器会为 协程体 生成继承自 SuspendLambda 的子类，协程的真正运算逻辑都在其 invokeSuspend 方法中。","link":"/2021/11/02/Coroutines-Principle/"},{"title":"ActivityStart","text":"当手指点击了桌面的App图标时发生了什么 - ProcessOn AIDL： frameworks/base/core/java/android/app/IActivityManager.aidl -&gt; 本地进程获取system_server进程中的AMS服务 frameworks/base/core/java/android/app/IApplicationThread.aidl -&gt; system_server进程调用本地进程ActivtyThread执行 (如LaunchActivityItem创建Activity与ResumeActivityItem走onResume生命周期) 事务发送Handler消息 0x01: 从activity.startActivity到onPuase() 1234567891011121314151617181920212223242526272829android.app.Activity#startActivity(android.content.Intent)-&gt;android.app.Activity#startActivityForResult(android.content.Intent, int, android.os.Bundle)... Instrumentation.ActivityResult ar = mInstrumentation.execStartActivity( this, mMainThread.getApplicationThread(), mToken, this, intent, requestCode, options);...-&gt;android.app.Instrumentation#execStartActivity(android.content.Context, android.os.IBinder, android.os.IBinder, android.app.Activity, android.content.Intent, int, android.os.Bundle)// Instrumentation#execStartActivity各个版本实现区别较大，Android8之前（不含）是用ActivityManagerProxy代理AMS，Android8及之后替换为直接以AIDL方法获取调用AMS服务，Android10及之后又将将该过程交给ActivityTaskMangerService(ATMS)执行startActivity流程 int result = ActivityManager.getService() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target, requestCode, 0, null, options); checkStartActivityResult(result, intent);-&gt; com.android.server.am.ActivityManagerService#startActivity(IApplicationThread caller, String callingPackage,Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode,int startFlags, ProfilerInfo profilerInfo, Bundle bOptions)//Android9.0即API28为例：经过上述IPC过程后，进入system_server进程，接下来在ActivityManagerService中执行startActivity ————— 应用进程与system_server进程切换的分割线 —————-切换到system_server进程，由于system_server是隐藏的，故难以debug 一、ActivityManagerService12345678910111213141516171819202122232425262728293031323334353637383940414243//以下为system_server中进行的AMS startActivity的流程com.android.server.am.ActivityManagerService#startActivity(IApplicationThread caller, String callingPackage,Intent intent, String resolvedType, IBinder resultTo, String resultWho, int requestCode,int startFlags, ProfilerInfo profilerInfo, Bundle bOptions)-&gt; com.android.server.am.ActivityManagerService#startActivityreturn startActivityAsUser(... , UserHandle.getCallingUserId());-&gt;com.android.server.am.ActivityManagerService#startActivityAsUser(IApplicationThread, java.lang.String, android.content.Intent, java.lang.String, android.os.IBinder, java.lang.String, int, int, ProfilerInfo, android.os.Bundle, int)-&gt;com.android.server.am.ActivityManagerService#startActivityAsUser(IApplicationThread, java.lang.String, android.content.Intent, java.lang.String, android.os.IBinder, java.lang.String, int, int, ProfilerInfo, android.os.Bundle, int, boolean)... // TODO: Switch to user app stacks here. return mActivityStartController.obtainStarter(intent, &quot;startActivityAsUser&quot;) .setCaller(caller) .setCallingPackage(callingPackage) .setResolvedType(resolvedType) .setResultTo(resultTo) .setResultWho(resultWho) .setRequestCode(requestCode) .setStartFlags(startFlags) .setProfilerInfo(profilerInfo) .setActivityOptions(bOptions) .setMayWait(userId) .execute();...-&gt;com.android.server.am.ActivityStartController#obtainStarter//工厂模式，制造一个核心启动类ActivityStarter，赋值startActivityAsUser入参给ActivityStarter，并叼调用其execute-&gt; 二、ActivityStarter1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//ActivityStarter.java com.android.server.am.ActivityStarter#execute() { ...//mRequest.mayWait == truereturn startActivityMayWait(mRequest.caller, mRequest.callingUid, mRequest.callingPackage, mRequest.intent, mRequest.resolvedType, mRequest.voiceSession, mRequest.voiceInteractor, mRequest.resultTo, mRequest.resultWho, mRequest.requestCode, mRequest.startFlags, mRequest.profilerInfo, mRequest.waitResult, mRequest.globalConfig, mRequest.activityOptions, mRequest.ignoreTargetSecurity, mRequest.userId, mRequest.inTask, mRequest.reason, mRequest.allowPendingRemoteAnimationRegistryLookup); ...}//ActivityStarter#startActivityMayWait 中new 一个ActivityRecord， ActivityRecord 为Activity 在AMS中的信息，然后在下面的startActivity中赋值。并且找到Activity 所在的ActivityStack.private int startActivityMayWait(IApplicationThread caller, int callingUid, String callingPackage, Intent intent, String resolvedType, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, IBinder resultTo, String resultWho, int requestCode, int startFlags, ProfilerInfo profilerInfo, WaitResult outResult, Configuration globalConfig, SafeActivityOptions options, boolean ignoreTargetSecurity, int userId, TaskRecord inTask, String reason, boolean allowPendingRemoteAnimationRegistryLookup) { //... synchronized (mService) { final ActivityStack stack = mSupervisor.mFocusedStack; //... final ActivityRecord[] outRecord = new ActivityRecord[1]; int res = startActivity(caller, intent, ephemeralIntent, resolvedType, aInfo, rInfo, voiceSession, voiceInteractor, resultTo, resultWho, requestCode, callingPid, callingUid, callingPackage, realCallingPid, realCallingUid, startFlags, options, ignoreTargetSecurity, componentSpecified, outRecord, inTask, reason, allowPendingRemoteAnimationRegistryLookup); } -&gt; startActivity -&gt; startActivity -&gt; startActivity -&gt; //经过多个startACtivity重载方法套娃式调用（主要是Activity信息的组装）后，走到startActivityUnchecked //startActivityUnchecked 中调用ActivityStack#startActivityLocked 找到Activity 所在的TaskRecord, 把Activity 插入TaskRecord 合适的位置。调用ActivityStackSupervisor#resumeFocusedStackTopActivityLocked private int startActivityUnchecked(final ActivityRecord r, ActivityRecord sourceRecord, IVoiceInteractionSession voiceSession, IVoiceInteractor voiceInteractor, int startFlags, boolean doResume, ActivityOptions options, TaskRecord inTask, ActivityRecord[] outActivity) { //... mTargetStack.startActivityLocked(mStartActivity, topFocused, newTask, mKeepCurTransition,mOptions); //... if (mDoResume) { if (!mTargetStack.isFocusable() || (topTaskActivity != null &amp;&amp; topTaskActivity.mTaskOverlay &amp;&amp; mStartActivity != topTaskActivity)) { } else { mSupervisor.resumeFocusedStackTopActivityLocked(mTargetStack, mStartActivity, mOptions); } } else if (mStartActivity != null) { } //... return START_SUCCESS; } 三、ActivityStackSupervisor123456789101112131415//ActivityStackSupervisor.java//Activity 已经在进入ActivityStack， 然后从Activity 中查找这个Activity 然后调状态设置为resume. boolean resumeFocusedStackTopActivityLocked( ActivityStack targetStack, ActivityRecord target, ActivityOptions targetOptions) { if (!readyToResume()) { return false; } if (targetStack != null &amp;&amp; isFocusedStack(targetStack)) { return targetStack.resumeTopActivityUncheckedLocked(target, targetOptions); } return false; } 四、ActivityStack123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//ActivityStack.java//继续回到 ActivityStack resume Activity.在resumeTopActivityInnerLocked 中先检查桌面的Activity 状态，桌面Activity 状态需要设置为pause, startPausingLocked 把桌面Activity设置为paused。 由于新的Activity 在另外一个进程中，另外一个进程还没有启动，mStackSupervisor.startSpecificActivityLocked 启动新的Activity 进程。boolean resumeTopActivityUncheckedLocked(ActivityRecord prev, ActivityOptions options) { //... try { // Protect against recursion. mStackSupervisor.inResumeTopActivity = true; result = resumeTopActivityInnerLocked(prev, options); //... return result; } private boolean resumeTopActivityInnerLocked(ActivityRecord prev,ActivityOptions options) { //... boolean pausing = mStackSupervisor.pauseBackStacks(userLeaving, next, false); if (mResumedActivity != null) { if (DEBUG_STATES) Slog.d(TAG_STATES, &quot;resumeTopActivityLocked: Pausing &quot; + mResumedActivity); //启动方Activity 状态需要设置为pause pausing |= startPausingLocked(userLeaving, false, next, false); } //... if (next.app != null &amp;&amp; next.app.thread != null) { //... } else { //... mStackSupervisor.startSpecificActivityLocked(next, true, true); } return true;}//关于PauseActivityItem事务执行流程可参见//@0x02——一、releaseStartActivityLocked——1、创建添加activity事务并通过binder将事务交予应用进程执行final boolean startPausingLocked(boolean userLeaving, boolean uiSleeping, ActivityRecord resuming, boolean pauseImmediately) { //... if (prev.app != null &amp;&amp; prev.app.thread != null) { mService.getLifecycleManager().scheduleTransaction(prev.app.thread, prev.appToken,PauseActivityItem.obtain(prev.finishing, userLeaving, prev.configChangeFlags, pauseImmediately)); } catch (Exception e) { } } else { }} 小结:从activity.startActivity()到Instrunmentaion中以Binder机制通过ActivityManager.getService().startActivity切换到system_server进程中的ActivityMangerService服务，再到ActivityMangerService中ActivityStarter、ActivityStatckSuperVisor、ActivityStack执行解析生成ActivityRecord(包含AMS、activityInfo、Configuration等信息)，最后由ActivityStack通过binder将”pause事务”从AMS传递到应用进程，应用进程handler机制处理该事务，旧Activity pause成功。开始AMS启动新Activity。 1234567891011121314151617至此的链路简述Activity.startActivity-&gt;Instrumentation.execStartActivity-&gt;ActivityManager.getService().startActivity-&gt;ActivityManagerService.startActivityAsUser-&gt;ActivityStarter.execute-&gt;ActivityStarter.startActivityMayWait -&gt;ActivityStarter.startActivity-&gt;ActivityStarter.startActivity重载套娃-&gt;ActivityStarter.startActivityUnchecked-&gt;ActivityStackSupervisor.resumeFocusedStackTopActivityLocked-&gt;ActivityStack.resumeTopActivityUncheckedLocked-&gt; ActivityStack.resumeTopActivityInnerLocked{ //startPausingLocked() //startSpecificActivityLocked(next, true, false);} 至此，新Activity的ActivityRecord（AMS中的Activity信息，包括不限于ActivityInfo、ProcessRecord、Configuration，ActivityStackSupervisor、发起跳转的Activity的ActivityRecord和resultTo的ActivityRecord）创建解析完成，旧Activity的pause生命周期被调用执行（见附录ActivityStack#startPausingLocked），接下来就是通过AMS启动新的Activity 0x02: AMS启动新的Activity1234567891011121314151617181920212223242526272829com.android.server.am.ActivityStackSupervisor#startSpecificActivityLocked (...) { ProcessRecord app = mService.getProcessRecordLocked(r.processName, r.info.applicationInfo.uid, true); getLaunchTimeTracker().setLaunchTime(r); if (app != null &amp;&amp; app.thread != null) { try { // !!! 看这里，如果没有另开进程的标识，就走realStartActivityLocked，直接走普通Activity启动流程，然后retrun !!! if ((r.info.flags&amp;ActivityInfo.FLAG_MULTIPROCESS) == 0 || !&quot;android&quot;.equals(r.info.packageName)) { // Don't add this if it is a platform co mponent that is marked // to run in multiple processes, because this is actually // part of the framework so doesn't make sense to track as a // separate apk in the process. app.addPackage(r.info.packageName,r.info.applicationInfo.longVersionCode, mService.mProcessStats); } realStartActivityLocked(r, app, andResume, checkConfig); return; } catch (RemoteException e) { Slog.w(TAG, &quot;Exception when starting activity &quot; + r.intent.getComponent().flattenToShortString(), e); } // If a dead object exception was thrown -- fall through to // restart the application. } // !!!看这里，如果没有在前面被return掉，就会走新开进程启动Activity的流程 mService.startProcessLocked(r.processName, r.info.applicationInfo, true, 0, &quot;activity&quot;, r.intent.getComponent(), false, false, true);} 一、startProcessLocked简述：启动新的进程，即Zygote进程Process.start() fork出新的进程并反射调用其mian方法，走到ActivityThread.main，main方法中主要是初始化looper并启动循环，接着调用ActivityThread.attach()在该方法中初始化Application单例。接下来就是二、实质性启动Activity。 启动新进程承载新Activity，之后继续走realStartActivityLocked常见同进程Activity启动的流程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189com.android.server.am.ActivityManagerService#startProcessLocked(java.lang.String, android.content.pm.ApplicationInfo, boolean, int, java.lang.String, android.content.ComponentName, boolean, boolean, boolean) -&gt; com.android.server.am.ActivityManagerService#startProcessLocked(java.lang.String, java.lang.String, java.lang.String, com.android.server.am.ProcessRecord, int, int[], int, int, java.lang.String, java.lang.String, java.lang.String, java.lang.String, long) -&gt; com.android.server.am.ActivityManagerService#startProcess(...) { if (hostingType.equals(&quot;webview_service&quot;)) { startResult = startWebView(entryPoint, app.processName, uid, uid, gids, runtimeFlags, mountExternal, app.info.targetSdkVersion, seInfo, requiredAbi, instructionSet, app.info.dataDir, null, new String[] {PROC_START_SEQ_IDENT + app.startSeq}); } else { startResult = Process.start(entryPoint, app.processName, uid, uid, gids, runtimeFlags, mountExternal, app.info.targetSdkVersion, seInfo, requiredAbi, instructionSet, app.info.dataDir, invokeWith, new String[] {PROC_START_SEQ_IDENT + app.startSeq}); }} -&gt;//android.os.Process.java public static final ZygoteProcess zygoteProcess = new ZygoteProcess(ZYGOTE_SOCKET, SECONDARY_ZYGOTE_SOCKET);public static final ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { return zygoteProcess.start(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, zygoteArgs);}public final Process.ProcessStartResult start(final String processClass, final String niceName, int uid, int gid, int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, String[] zygoteArgs) { try { return startViaZygote(processClass, niceName, uid, gid, gids, runtimeFlags, mountExternal, targetSdkVersion, seInfo, abi, instructionSet, appDataDir, invokeWith, false /* startChildZygote */, zygoteArgs); } catch (ZygoteStartFailedEx ex) { Log.e(LOG_TAG, &quot;Starting VM process through Zygote failed&quot;); throw new RuntimeException( &quot;Starting VM process through Zygote failed&quot;, ex); }}private Process.ProcessStartResult startViaZygote(final String processClass, final String niceName, final int uid, final int gid, final int[] gids, int runtimeFlags, int mountExternal, int targetSdkVersion, String seInfo, String abi, String instructionSet, String appDataDir, String invokeWith, boolean startChildZygote, String[] extraArgs) throws ZygoteStartFailedEx { ArrayList&lt;String&gt; argsForZygote = new ArrayList&lt;String&gt;(); // --runtime-args, --setuid=, --setgid=, // and --setgroups= must go first argsForZygote.add(&quot;--runtime-args&quot;); argsForZygote.add(&quot;--setuid=&quot; + uid); argsForZygote.add(&quot;--setgid=&quot; + gid); argsForZygote.add(&quot;--runtime-flags=&quot; + runtimeFlags); if (mountExternal == Zygote.MOUNT_EXTERNAL_DEFAULT) { argsForZygote.add(&quot;--mount-external-default&quot;); } else if (mountExternal == Zygote.MOUNT_EXTERNAL_READ) { argsForZygote.add(&quot;--mount-external-read&quot;); } else if (mountExternal == Zygote.MOUNT_EXTERNAL_WRITE) { argsForZygote.add(&quot;--mount-external-write&quot;); } argsForZygote.add(&quot;--target-sdk-version=&quot; + targetSdkVersion); // --setgroups is a comma-separated list if (gids != null &amp;&amp; gids.length &gt; 0) { StringBuilder sb = new StringBuilder(); sb.append(&quot;--setgroups=&quot;); int sz = gids.length; for (int i = 0; i &lt; sz; i++) { if (i != 0) { sb.append(','); } sb.append(gids[i]); } argsForZygote.add(sb.toString()); } if (niceName != null) { argsForZygote.add(&quot;--nice-name=&quot; + niceName); } if (seInfo != null) { argsForZygote.add(&quot;--seinfo=&quot; + seInfo); } if (instructionSet != null) { argsForZygote.add(&quot;--instruction-set=&quot; + instructionSet); } if (appDataDir != null) { argsForZygote.add(&quot;--app-data-dir=&quot; + appDataDir); } if (invokeWith != null) { argsForZygote.add(&quot;--invoke-with&quot;); argsForZygote.add(invokeWith); } if (startChildZygote) { argsForZygote.add(&quot;--start-child-zygote&quot;); } argsForZygote.add(processClass); if (extraArgs != null) { for (String arg : extraArgs) { argsForZygote.add(arg); } } synchronized(mLock) { return zygoteSendArgsAndGetResult(openZygoteSocketIfNeeded(abi), argsForZygote); }}// 通过socket 检查新进程的启动情况private static Process.ProcessStartResult zygoteSendArgsAndGetResult( ZygoteState zygoteState, ArrayList&lt;String&gt; args) throws ZygoteStartFailedEx { try { final BufferedWriter writer = zygoteState.writer; final DataInputStream inputStream = zygoteState.inputStream; writer.write(Integer.toString(args.size())); writer.newLine(); for (int i = 0; i &lt; sz; i++) { String arg = args.get(i); writer.write(arg); writer.newLine(); } writer.flush(); // Should there be a timeout on this? Process.ProcessStartResult result = new Process.ProcessStartResult(); // Always read the entire result from the input stream to avoid leaving // bytes in the stream for future process starts to accidentally stumble // upon. result.pid = inputStream.readInt(); result.usingWrapper = inputStream.readBoolean(); if (result.pid &lt; 0) { throw new ZygoteStartFailedEx(&quot;fork() failed&quot;); } return result; } catch (IOException ex) { zygoteState.close(); throw new ZygoteStartFailedEx(ex); }} 1、 Zygote 进程forkZygote 的fork 过程参考SystemService 的启动流程。Zygote fork 后也是通过反射的方法找到一个main 函数，这时候因为启动的是App 进程。所以这个main 函数为ActivityThread 的main函数。 App发起进程：当从桌面启动应用，则发起进程便是Launcher所在进程；当从某App内启动远程进程，则发送进程便是该App所在进程。发起进程先通过binder发送消息给system_server进程； system_server进程：调用Process.start()方法，通过socket向zygote进程发送创建新进程的请求； zygote进程：在执行ZygoteInit.main()后便进入runSelectLoop()循环体内，当有客户端连接时便会执行ZygoteConnection.runOnce()方法，再经过层层调用后fork出新的应用进程； 新进程：执行handleChildProc方法，最后调用ActivityThread.main()方法。 2、 fork 后的新进程的 ActivityThreadfork 以后启动ActivityThread 的main 函数，在Main 函数中完成Looper的初始化，最重要的一个调用就是 attach 123456789101112131415161718192021222324252627282930313233343536public static void main(String[] args) { Process.setArgV0(&quot;&lt;pre-initialized&gt;&quot;); Looper.prepareMainLooper(); ActivityThread thread = new ActivityThread(); thread.attach(false, startSeq); if (sMainThreadHandler == null) { sMainThreadHandler = thread.getHandler(); } Looper.loop(); throw new RuntimeException(&quot;Main thread loop unexpectedly exited&quot;);}private void attach(boolean system, long startSeq) { sCurrentActivityThread = this; mSystemThread = system; if (!system) { android.ddm.DdmHandleAppName.setAppName(&quot;&lt;pre-initialized&gt;&quot;, UserHandle.myUserId()); RuntimeInit.setApplicationObject(mAppThread.asBinder()); final IActivityManager mgr = ActivityManager.getService(); try { mgr.attachApplication(mAppThread, startSeq); } catch (RemoteException ex) { throw ex.rethrowFromSystemServer(); } } else { }} AMS 的 attachApplication12IActivityManager mgr = ActivityManager.getService();mgr.attachApplication(mAppThread, startSeq); AMS 的attachApplication 依次调用了ApplicationThread 的 bindApplication // 创建Application scheduleTransaction(clientTransaction); // Resume Activity 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091ActivityMangerService.class:@Overridepublic final void attachApplication(IApplicationThread thread, long startSeq) { synchronized (this) { attachApplicationLocked(thread, callingPid, callingUid, startSeq); }}@GuardedBy(&quot;this&quot;)private final boolean attachApplicationLocked(IApplicationThread thread, int pid, int callingUid, long startSeq) { // It's possible that process called attachApplication before we got a chance to // update the internal state. try { if (app.isolatedEntryPoint != null) { } else if (app.instr != null) { thread.bindApplication(processName, appInfo, providers, app.instr.mClass, profilerInfo, app.instr.mArguments, app.instr.mWatcher, app.instr.mUiAutomationConnection, testMode, mBinderTransactionTrackingEnabled, enableTrackAllocation, isRestrictedBackupMode || !normalMode, app.persistent, new Configuration(getGlobalConfiguration()), app.compat, getCommonServicesLocked(app.isolated), mCoreSettingsObserver.getCoreSettingsLocked(), buildSerial, isAutofillCompatEnabled); } else { thread.bindApplication(processName, appInfo, providers, null, profilerInfo, null, null, null, testMode, mBinderTransactionTrackingEnabled, enableTrackAllocation, isRestrictedBackupMode || !normalMode, app.persistent, new Configuration(getGlobalConfiguration()), app.compat, getCommonServicesLocked(app.isolated), mCoreSettingsObserver.getCoreSettingsLocked(), buildSerial, isAutofillCompatEnabled); } } catch (Exception e) { } // See if the top visible activity is waiting to run in this process... if (normalMode) { try { if (mStackSupervisor.attachApplicationLocked(app)) { didSomething = true; } } catch (Exception e) { } } return true;}boolean attachApplicationLocked(ProcessRecord app) throws RemoteException { final String processName = app.processName; boolean didSomething = false; for (int displayNdx = mActivityDisplays.size() - 1; displayNdx &gt;= 0; --displayNdx) { final ActivityDisplay display = mActivityDisplays.valueAt(displayNdx); for (int stackNdx = display.getChildCount() - 1; stackNdx &gt;= 0; --stackNdx) { final ActivityStack stack = display.getChildAt(stackNdx); if (!isFocusedStack(stack)) { continue; } stack.getAllRunningVisibleActivitiesLocked(mTmpActivityList); final ActivityRecord top = stack.topRunningActivityLocked(); final int size = mTmpActivityList.size(); for (int i = 0; i &lt; size; i++) { final ActivityRecord activity = mTmpActivityList.get(i); if (activity.app == null &amp;&amp; app.uid == activity.info.applicationInfo.uid &amp;&amp; processName.equals(activity.processName)) { try { if (realStartActivityLocked(activity, app, top == activity /* andResume */, true /* checkConfig */)) { didSomething = true; } } catch (RemoteException e) { throw e; } } } } } return didSomething;} realStartActivityLocked 见下二、realStartActivityLocked简述：实质性启动Activity，首先AMS推动包含Launch事务和Resume生命周期事务的ClientTransaction，App进程在ActivityThread的handler中接受并处理，调用handleLaunchActivity()-&gt;perfomLaunchActivity()，此方法中，首先反射创建了Activity对象，并调用了activity.attach()，之后执行onCreate。 1、创建添加activity事务并通过binder将事务交予应用进程执行1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859//com.android.server.am.ActivityStackSupervisor#realStartActivityLocked//主要创建事务交给本地执行final boolean realStartActivityLocked(ActivityRecord r, ProcessRecord app, boolean andResume, boolean checkConfig) throws RemoteException { ... //创建启动activity的事务ClientTransaction对象 // Create activity launch transaction. final ClientTransaction clientTransaction = ClientTransaction.obtain(app.thread, r.appToken); // 添加LaunchActivityItem，该类obtain入参都是应用进程中创建Activity需要的所有信息，到时候会将这些信息组装成ActivityClientRecord交给ActivityThread的performLaunchActivity使用 clientTransaction.addCallback(LaunchActivityItem.obtain(new Intent(r.intent), System.identityHashCode(r), r.info, mergedConfiguration.getGlobalConfiguration(), mergedConfiguration.getOverrideConfiguration(), r.compat, r.launchedFromPackage, task.voiceInteractor, app.repProcState, r.icicle, r.persistentState, results, newIntents, mService.isNextTransitionForward(), profilerInfo)); // Set desired final state. //添加执行Resume事务ResumeActivityItem,后续会在本地被执行 final ActivityLifecycleItem lifecycleItem; if (andResume) { lifecycleItem = ResumeActivityItem.obtain(mService.isNextTransitionForward()); } else { lifecycleItem = PauseActivityItem.obtain(); } clientTransaction.setLifecycleStateRequest(lifecycleItem); // ClientLifecycleManager.scheduleTransaction就是调用clientTransaction的schedule启动事务然后回收clientTransaction // 这里的mService就是AMS // 记住上面两个item：LaunchActivityItem和ResumeActivityItem，这是事务的执行单位 mService.getLifecycleManager().scheduleTransaction(clientTransaction);} -&gt;com.android.server.am.ClientLifecycleManager#scheduleTransaction(ClientTransaction) { //把事务交给本地ActivityThread执行。这里通过本地ApplicationThread在服务端的接口IApplicationThread来进行跨进程通信。后面的逻辑就回到了应用程序进程了。 void scheduleTransaction(ClientTransaction transaction) throws RemoteException { final IApplicationThread client = transaction.getClient(); transaction.schedule(); if (!(client instanceof Binder)) { transaction.recycle(); } }} -&gt;//这里的IApplicationThread是要启动进程的 IBinder 接口//ApplicationThread是ActivityThread的内部类，IApplicationThread是IBinder代理接口//这里将逻辑转到应用进程中执行private IApplicationThread mClient;public void schedule() throws RemoteException { mClient.scheduleTransaction(this);} ————— system_server进程与应用进程切换的分割线 —————-通过AIDL方式又回到应用进程了，调用了IApplicationThread.scheduleTransaction() 2、回到应用进程后ActivityThread执行事务创建Activity ApplicationThread.class是 “AIDL接口—— IApplicationThread接口具体实现”，是ActivityThread的内部类，其定义了服务的远程过程调用 (RPC) 接口，即本地进程提供给其他进程通过IPC机制调用的接口：如更新进程状态updateProcessState，scheduleTransaction System private API for communicating with the application. This is given to the activity manager by an application when it starts up, for the activity manager to tell the application about things it needs to do. 用于与应用程序通信的系统私有API。 这是应用程序在启动时给AMS的，以便AMS告诉应用程序它需要做的事情。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//ActivityThread#ApplicationThread.class//ApplicationThread extends IApplicationThread.Stubpublic void scheduleTransaction(ClientTransaction transaction) throws RemoteException { //ActivityThread 继承 ClientTransactionHandler 的scheduleTransaction方法 ActivityThread.this.scheduleTransaction(transaction);}//abstract ClientTransactionHandler.classvoid scheduleTransaction(ClientTransaction transaction) { //主要是更新应用进程状态see@ LaunchActivityItem、ResumeActivityItem preExecute transaction.preExecute(this); //通过Handler发送what为EXECUTE_TRANSACTION，obj为transaction的消息，即ActivityThread中Hanlder实现H.class处理 sendMessage(ActivityThread.H.EXECUTE_TRANSACTION, transaction);}abstract void sendMessage(int what, Object obj);//ActivityThread.class/* */final H mH = new H();private final TransactionExecutor mTransactionExecutor = new TransactionExecutor(this);void sendMessage(int what, Object obj) { sendMessage(what, obj, 0, 0, false);}private void sendMessage(int what, Object obj, int arg1, int arg2, boolean async) { if (DEBUG_MESSAGES) Slog.v( TAG, &quot;SCHEDULE &quot; + what + &quot; &quot; + mH.codeToString(what) + &quot;: &quot; + arg1 + &quot; / &quot; + obj); Message msg = Message.obtain(); msg.what = what; msg.obj = obj; msg.arg1 = arg1; msg.arg2 = arg2; if (async) { msg.setAsynchronous(true); } mH.sendMessage(msg);}//class H extends Handler public static final int EXECUTE_TRANSACTION = 159;public void handleMessage(Message msg) { if (DEBUG_MESSAGES) Slog.v(TAG, &quot;&gt;&gt;&gt; handling: &quot; + codeToString(msg.what)); switch (msg.what) { case EXECUTE_TRANSACTION: final ClientTransaction transaction = (ClientTransaction) msg.obj; mTransactionExecutor.execute(transaction); if (isSystem()) { transaction.recycle(); } break; }}//其实还是那句话，事务(LaunchActivityItem与ResumeActivityItem)从system_server中通过AIDL的IPC方式，丢到应用进程中的ActivityThread的handler中执行事务的execute方法。 a. LaunchActivityItem/ResumeActivityItem preExecute/execute123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/* 见上 ActivityStackSupervisor.realStartActivityLocked()中 { ClientTransaction.addCallback(LaunchActivityItem...) clientTransaction.setLifecycleStateRequest(ResumeActivityItem实例lifecycleItem); } //ClientTransaction.class public void setLifecycleStateRequest(ActivityLifecycleItem stateRequest) { mLifecycleStateRequest = stateRequest; } public void addCallback(ClientTransactionItem activityCallback) { if (mActivityCallbacks == null) { mActivityCallbacks = new ArrayList&lt;&gt;(); } mActivityCallbacks.add(activityCallback); }*///ClientTransaction.java;public void preExecute(android.app.ClientTransactionHandler clientTransactionHandler) { if (mActivityCallbacks != null) { final int size = mActivityCallbacks.size(); for (int i = 0; i &lt; size; ++i) {mActivityCallbacks.get(i).preExecute(clientTransactionHandler, mActivityToken); } } if (mLifecycleStateRequest != null) { mLifecycleStateRequest.preExecute(clientTransactionHandler, mActivityToken); }}//TransactionExecutor.class//(其实就是ActivityThread，依赖倒置)private ClientTransactionHandler mTransactionHandler;public TransactionExecutor(ClientTransactionHandler clientTransactionHandler) { mTransactionHandler = clientTransactionHandler;}public void execute(ClientTransaction transaction) { final IBinder token = transaction.getActivityToken(); log(&quot;Start resolving transaction for client: &quot; + mTransactionHandler + &quot;, token: &quot; + token); executeCallbacks(transaction); executeLifecycleState(transaction); mPendingActions.clear(); log(&quot;End resolving transaction&quot;);} -&gt; public void executeCallbacks(ClientTransaction transaction) { final int size = callbacks.size(); for (int i = 0; i &lt; size; ++i) { final ClientTransactionItem item = callbacks.get(i); item.execute(mTransactionHandler, token, mPendingActions); item.postExecute(mTransactionHandler, token, mPendingActions); }} private void executeLifecycleState(ClientTransaction transaction) { final ActivityLifecycleItem lifecycleItem = transaction.getLifecycleStateRequest(); lifecycleItem.execute(mTransactionHandler, token, mPendingActions); lifecycleItem.postExecute(mTransactionHandler, token, mPendingActions);}//preExecute在execute前准备客户端请求。这方面的一个例子可能是通知某些值的挂起更新。ps:更新进程状态//execute执行请求//postExecute执行execute后需要执行的所有操作，例如将结果报告给服务器。 //LaunchActivityItem.class extends ClientTransactionItem (Parcelable implementation) @Overridepublic void preExecute(ClientTransactionHandler client, IBinder token) { // client.updateProcessState(mProcState, false); client.updatePendingConfiguration(mCurConfig);} public void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { Trace.traceBegin(TRACE_TAG_ACTIVITY_MANAGER, &quot;activityStart&quot;); //ActivityClientRecord就是应用进程中的Activity信息，与之对应的是system_server中ActivityRecord类，是系统进程中的Activity信息 ActivityClientRecord r = new ActivityClientRecord(token, mIntent, mIdent, mInfo, mOverrideConfig, mCompatInfo, mReferrer, mVoiceInteractor, mState, mPersistentState,mPendingResults, mPendingNewIntents, mIsForward,mProfilerInfo, client); //这里的client其实ActivityThread client.handleLaunchActivity(r, pendingActions, null /* customIntent */); Trace.traceEnd(TRACE_TAG_ACTIVITY_MANAGER);}//ResumeActivityItem.class extends ClientTransactionItem ActivityLifecycleItem extends ClientTransactionItem (Parcelable implementation)@Overridepublic void preExecute(ClientTransactionHandler client, IBinder token) { if (mUpdateProcState) { client.updateProcessState(mProcState, false); }}@Overridepublic void execute(ClientTransactionHandler client, IBinder token, PendingTransactionActions pendingActions) { Trace.traceBegin(TRACE_TAG_ACTIVITY_MANAGER, &quot;activityResume&quot;); client.handleResumeActivity(token, true /* finalStateRequest */, mIsForward, &quot;RESUME_ACTIVITY&quot;); Trace.traceEnd(TRACE_TAG_ACTIVITY_MANAGER);} 以启动activity的LaunchActivityItem.execute()中client.handleLaunchActivity(r, pendingActions, null /* customIntent */);为核心分析应用进程中ActivityThread中启动Activity的流程。 b. handleLaunchActivity()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117//ActivityThread.class@Overridepublic Activity handleLaunchActivity(ActivityClientRecord r, PendingTransactionActions pendingActions, Intent customIntent) { // Initialize before creating the activity if (!ThreadedRenderer.sRendererDisabled) { //非系统进程才能渲染 GraphicsEnvironment.earlyInitEGL(); } WindowManagerGlobal.initialize(); final Activity a = performLaunchActivity(r, customIntent);} -&gt; private Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) { //package信息 ActivityInfo aInfo = r.activityInfo; if (r.packageInfo == null) { r.packageInfo = getPackageInfo(aInfo.applicationInfo, r.compatInfo, Context.CONTEXT_INCLUDE_CODE); } // 获取activity的包名类型信息 ComponentName component = r.intent.getComponent(); if (component == null) { component = r.intent.resolveActivity( mInitialApplication.getPackageManager()); r.intent.setComponent(component); } if (r.activityInfo.targetActivity != null) { component = new ComponentName(r.activityInfo.packageName, r.activityInfo.targetActivity); } // 创建context上下文 ContextImpl appContext = createBaseContextForActivity(r); // 反射创建Activity对象(工厂模式) Activity activity = null; try { java.lang.ClassLoader cl = appContext.getClassLoader(); activity = mInstrumentation.newActivity( cl, component.getClassName(), r.intent); StrictMode.incrementExpectedActivityCount(activity.getClass()); r.intent.setExtrasClassLoader(cl); r.intent.prepareToEnterProcess(); if (r.state != null) { r.state.setClassLoader(cl); } } catch (Exception e) { if (!mInstrumentation.onException(activity, e)) { throw new RuntimeException( &quot;Unable to instantiate activity &quot; + component + &quot;: &quot; + e.toString(), e); } try { //获取Application单例（在ActivityThread.attach时创建） Application app = r.packageInfo.makeApplication(false, mInstrumentation); if(activity != null) { // 为Activity添加window,之后移除对象 Window window = null; if (r.mPendingRemoveWindow != null &amp;&amp; r.mPreserveWindow) { window = r.mPendingRemoveWindow; r.mPendingRemoveWindow = null; r.mPendingRemoveWindowManager = null; } //onAttach activity.attach(appContext, this, getInstrumentation(), r.token, r.ident, app, r.intent, r.activityInfo, title, r.parent, r.embeddedID, r.lastNonConfigurationInstances, config, r.referrer, r.voiceInteractor, window, r.configCallback); //onCreate mInstrumentation.callActivityOnCreate(activity, r.state); } }}//LoadedApk.class public Application makeApplication(boolean forceDefaultAppClass,Instrumentation instrumentation) { //只有一个application，在应用初始化时才会走到此方法后面的流程 if (mApplication != null) { return mApplication; } Application app = null; try { java.lang.ClassLoader cl = getClassLoader(); ContextImpl appContext = ContextImpl.createAppContext(mActivityThread, this); //newApplication反射创建Application(工厂模式)后会顺手调一下app.attach(context); app = mActivityThread.mInstrumentation.newApplication(cl, appClass, appContext); appContext.setOuterContext(app); } catch (Exception e) { //... } if (instrumentation != null) { try { //具体实现就app.onCreate(); instrumentation.callApplicationOnCreate(app); } catch (Exception e) { if (!instrumentation.onException(app, e)) { Trace.traceEnd(Trace.TRACE_TAG_ACTIVITY_MANAGER); throw new RuntimeException( &quot;Unable to create application &quot; + app.getClass().getName() + &quot;: &quot; + e.toString(), e); } } }} 003：Activity.Attach()简述：首先初始化Window，具体实现类是PhoneWindow。为其设置WindowManger（具体实现类为WindowManagerImpl） 在Activity的attach方法中，很关键的一点就是初始化Window，从这里就能看到，Window的实现类，是PhoneWindow。PhoneWindow的创建对于我们后面的操作很重要。 mWindow是一个Window类型的变量，但实际上它是一个PhoneWindow对象，与Activity的内容显示相关。 123456789101112131415161718192021222324final void attach(Context context, ActivityThread aThread, Instrumentation instr, IBinder token, int ident, Application application, Intent intent, ActivityInfo info, CharSequence title, Activity parent, String id, NonConfigurationInstances lastNonConfigurationInstances, Configuration config) { attachBaseContext(context); mFragments.attachActivity(this, mContainer, null); mWindow = PolicyManager.makeNewWindow(this); ... //将各种参数赋给Activity的成员变量 mWindow.setWindowManager( (WindowManager)context.getSystemService(Context.WINDOW_SERVICE), mToken, mComponent.flattenToString(), (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != 0); if (mParent != null) { mWindow.setContainer(mParent.getWindow()); } mWindowManager = mWindow.getWindowManager(); mCurrentConfig = config;} 004：Activity.onCreate()简述：onCreate()-&gt;setContentView()-&gt;PhoneWindow.setContentView()，在这里初始化了最顶层View（FrameLayout）DecorView；并将layoutResID通过LayoutInflate填充后添加到DecorView中。 123456789101112public void setContentView(View view, ViewGroup.LayoutParams params) { if (mContentParent == null) { installDecor(); } else { mContentParent.removeAllViews(); } mContentParent.addView(view, params); final Callback cb = getCallback(); if (cb != null &amp;&amp; !isDestroyed()) { cb.onContentChanged(); }} 005：ActivityThread.handleResumeActivity()简述： 核心就是先调用onResume()， 然后再调用Window#addView(Window也就是上面activity.attach()中初始化的PhoneWindow)。接下来就是走到WindowManager（具体实现在WindowManagerGlobal中）的addView()。首先创建ViewRootImpl然后调用它的setView，setView中最关键的就是就是调用了requestLayout()然后注册Vsync回调回来后ViewRootImpl.performTraversals()，其中先执行了dispatchAttachToWindow（View.post的缓存action执行），后走了performMeasure、performLayout、performDraw测绘三大流程 performResumeActivity Window#addView new ViewRootImpl() ViewRootImpl.setView() ViewRootImpl.requestLayout() ViewRootImpl.scheduleTraversals() ViewRootImpl.doTraversal(); ViewRootImpl.performTraversals(); 0xFF: 附录附录一 execStartActivityAndroid 6.0/9.0/10.0 Instrumentation#execStartActivity123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566...//Android 6 //ActivityManagerNative.getDefault()拿到的对象是ActivityManagerProxy，这个类初始化时即构造传入AMS（ServiceManager.getService(&quot;activity&quot;)），由ActivityManagerProxy代理AMS执行startActivity方法 ActivityManagerNative.getDefault() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target != null ? target.mEmbeddedID : null, requestCode, 0, null, options); /** * Retrieve the system's default/global activity manager. */static public IActivityManager getDefault() { return gDefault.get();} private static final Singleton&lt;IActivityManager&gt; gDefault = new Singleton&lt;IActivityManager&gt;() { protected IActivityManager create() { IBinder b = ServiceManager.getService(&quot;activity&quot;); ... IActivityManager am = asInterface(b); ... return am; } }; //Android 9 ActivityManagerProxy类已经被去掉了， ActivityManger.getService 获取 AMS 的单例实例，然后调用其 startActivity 方法，实际上这里就是通过 AIDL 来调用 AMS 的 startActivity 方法。ActivityManager.getService() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target != null ? target.mEmbeddedID : null, requestCode, 0, null, options); public static IActivityManager getService() { return IActivityManagerSingleton.get(); }private static final Singleton&lt;IActivityManager&gt; IActivityManagerSingleton = new Singleton&lt;IActivityManager&gt;() { @Override protected IActivityManager create() { final IBinder b = ServiceManager.getService(Context.ACTIVITY_SERVICE); final IActivityManager am = IActivityManager.Stub.asInterface(b); return am; } }; //Andorid 10 新增了一层ActivityTaskManager来管理activity任务，AIDL方式向ServiceManager获取ACTIVITY_TASK_SERVICE服务单例，其具有IActivityTaskManager的方法实现（包括startActivity）int result = ActivityTaskManager.getService() .startActivity(whoThread, who.getBasePackageName(), intent, intent.resolveTypeIfNeeded(who.getContentResolver()), token, target != null ? target.mEmbeddedID : null, requestCode, 0, null, options);android.app.ActivityTaskManager#getService... @UnsupportedAppUsage(trackingBug = 129726065) private static final Singleton&lt;IActivityTaskManager&gt; IActivityTaskManagerSingleton = new Singleton&lt;IActivityTaskManager&gt;() { @Override protected IActivityTaskManager create() { final IBinder b = ServiceManager.getService(Context.ACTIVITY_TASK_SERVICE); return IActivityTaskManager.Stub.asInterface(b); } }; 附录二 startPausingLockedActivityStack#startPausingLocked1234567891011ActivityStack#startPausingLocked{//...//PauseActivityItem继承于ActivityLifecycleItem，又继承于ClientTransactionItem,是Activity负责暂停的事务类。同样继承于ActivityLifecycleItem的负责Activity生命周期的类还有ResumeActivityItem、StopActivityItem等。ActivityLifecycleItem相比其父类多了状态的请求（事务执行后客户端活动应该处于的最后生命周期状态）mService.getLifecycleManager().scheduleTransaction(prev.app.thread, prev.appToken, PauseActivityItem.obtain(prev.finishing, userLeaving, prev.configChangeFlags, pauseImmediately));//...}-&gt; ActivityManager : DisplayActivityManager : Display / startActivity Android6/7 简单结论：display 只统计A onPause之后 AMS 启动新ActivityB 并 执行 B的onCreate、onstart、onresume 与 B向WMS注册窗口到编舞者发起的第一次测绘 完成 Activity的启动可以分为三个步骤，以ActivityA启动ActivityB为例，三步骤分别为： 以ActivityA调用startActivity，到ActivityA成功pause为止 displayTimeStart ActivityB成功初始化，到执行完resume为止 ActivityB向WSM注册窗口，到第一帧绘制完成为止displayTimeEnd ActiivtyA Pause流程当ActivityA使用startActivity方法启动ActivityB时，执行函数链路如下 1234567891011121314151617181920212223242526//Android 6.0/7.0ActivityA.startActivity-&gt;Instrumentation.execStartActivity-&gt;ActivityManagerNative.getDefault.startActivity-&gt;ActivityManagerService.startActivityAsUser-&gt;ActivityStarter.startActivityMayWait -&gt;ActivityStarter.startActivityLocked -&gt;ActivityStarter.startActivityUnchecked-&gt;ActivityStackSupervisor.resumeFocusedStackTopActivityLocked-&gt;ActivityStack.resumeTopActivityUncheckedLocked -&gt; ActivityStack.resumeTopActivityInnerLocked{ //startPausingLocked() 暂停旧Activity //startSpecificActivityLocked(next, true, false);} -&gt; ActivityStack.startPausingLocked -&gt; ActivityThread#ApplicationThread.schedulePauseActivity-&gt;ActivityThread.handlePauseActivity-&gt; └ActivityA.onPauseActivityManagerNative.getDefault().activityPaused 当App请求AMS要启动一个新页面的时候，AMS首先会pause掉当前正在显示的Activity，当然，这个Activity可能与请求要开启的Activity不在一个进程，比如点击桌面图标启动App,当前要暂停的Activity就是桌面程序Launcher。在onPause内执行耗时操作是一种很不推荐的做法，从上述调用链路可以看出，如果在onPause内执行了耗时操作，会直接影响到ActivityManagerNative.getDefault().activityPaused()方法的执行，而这个方法的作用就是通知AMS，“当前Activity已经已经成功暂停，可以启动新Activity了”。 ActivityB Launch流程在AMS接收到App进程对于activityPaused方法的调用后，执行函数链路如下 12345678910111213141516//ActivityStack.resumeTopActivityInnerLocked -&gt;ActivityStackSupervisor.startSpecificActivityLocked-&gt; -&gt; //displayStartTime └1.启动新进程：ActivityManagerService.startProcessLocked 暂不展开 └2.当前进程：ActivityStackSupervisor.realStartActivityLocked-&gt;ActivityThread?ApplicationThread.scheduleLaunchActivity-&gt;Activity.handleLaunchActivity-&gt; └Activity.onCreate └Activity.onRestoreInstanceState └handleResumeActivity └Activity.onStart-&gt; └Activity.onResume-&gt; └WindowManager.addView-&gt; AMS在经过一系列方法调用后，通知App进程正式启动一个Actviity，注意如果要启动Activity所在进程不存在，比如点击桌面图标第一次打开应用，或者App本身就是多进程的，要启动的新页面处于另外一个进程，那就需要走到ActivityManagerService.startProcessLocked流程，等新进程启动完毕后再通知AMS，这里不展开。按照正常流程，会依次走过Activity生命周期内的onCreate、onRestoreInstanceState、onStart、onResume方法，这一步的耗时基本也可以看成就是这四个方法的耗时，由于这四个方法是同步调用的，所以可以通过以onCreate方法为起点，onResume方法为终点，统计出这一步骤的总耗时。 ActivityB Render流程在ActivityB执行完onResume方法后，就可以显示该Activity了，调用流程如下 1234567WindowManager.addView-&gt;WindowManagerImpl.addView-&gt;ViewRootImpl.setView-&gt;ViewRootImpl.requestLayout-&gt; └ViewRootImpl.scheduleTraversals-&gt; └Choreographer.postCallback-&gt;WindowManagerSerivce.add 这一步的核心实际上是Choreographer.postCallback，向Choreographer注册了一个回调，当Vsync事件到来时，就会执行下面的回调进行ui的渲染 123456789ViewRootImpl.doTraversal-&gt;ViewRootImpl.performTraversals-&gt; └ViewRootImpl.relayoutWindow └ViewRootImpl.performMeasure └ViewRootImpl.performLayout └ViewRootImpl.performDrawViewRootImpl.reportDrawFinished...reportLaunchTimeLocked 这里分别执行了performMeasure、performLayout、performDraw，实际上就是对应到DecorView的测量、布局、绘制三个流程。由于Android的UI是个树状结构，作为根View的DecorView的测量、布局、绘制，会调用到所有子View相应的方法，因此，这一步的总耗时就是所有子View在测量、布局、绘制中的耗时之和，如果某个子View在这三个方法中如果进行了耗时操作，就会拖慢整个UI的渲染，进而影响Activity第一帧的渲染速度。 从Window视角看ActivityStart当从Window的角度看待Activity的启动过程时，可以看到以下流程： 在目标进程中，执行Activity.handleLaunchActivity方法，会先获取AMS服务，之后调用Activity.performLaunchActivity 回调目标Activity的onAttach方法，初始化Window及Window相关对象，如PhoneWindow、Token等。 mWindow = new PhoneWindow(this, window, activityConfigCallback); 之后回调目标Activity的onCreate方法，然后通过setContentView方法创建一个DecorView对象； 在目标进程中，执行Activity.handleResumeActivity方法，会回调目标Activity的onResume方法，然后调用目标Activity的makeVisible方法；在makeVisible方法中，会调用WindowManagerImpl.addView方法绘制View，并通过Binder远程调用WMS添加Window。ViewManager wm = getWindowManager();wm.addView(mDecor, getWindow().getAttributes());","link":"/2021/07/30/ActivityStart/"},{"title":"CodeOptimization","text":"# 代码优化1：纯函数纯函数是函数编程中的一个概念，指的是一个方法函数，就像一个数学的函数式一样，同样的参数输入会得到同样的输出。可以近似理解为函数内部不依赖任何的外部状态，外部变量。 2：空安全java是强对象类型语言，故对于java来说我们很容易关注到类型强转的错误 这里引进一个概念，程序其实是一个由函数组成的树型或者图型结构，这其实意味着我们需要在接近根节点的地方，对传入的 不应为空的参数或变量进行校验，从而避免参数往后传递而造成在后面叶子节点进行空判断的现象。这一行为通常可以通过对函数入参加入注解：@Nullable/@NonNull 在java中，要尽量保证代码质量，排除空安全而所谓的空安全的语言，实际上也没有解决空安全的问题，因为空这个概念是被需要的，所以如kotlin之类的空安全语言只是把空校验从运行时提前到编译时 3：控制逻辑对于 嵌套循环或if 是否要通过continue/break/return等操作，简化嵌套的问题。其实是存在分歧的，分歧点在于：continue/break/return操作虽然可以简化嵌套但同时也会增加代码复杂度，直观度。 所以，嵌套是否要continue/break/retrun，还是需要根据具体的业务情况才能决定，大致上有这么几种考虑： 对于异常情况引起的if嵌套，可以通过在提前return的方式，减低嵌套 如果业务确实需要，不需为你的 嵌套的控制逻辑 感到不好意思。如果嵌套确实能达到直观的业务表达效果，那就用它 continue/break/return操作，尽量不要在控制逻辑的中或者尾逻辑出现，这会很大程度的使逻辑可读性降低。如果要用，尽量提前使用它们。","link":"/2024/03/25/CodeOptimization/"},{"title":"CpuArch","text":"‘armeabi-v7a’表示32位cpu架构, ‘arm64-v8a’表示64位, ‘x86’是只模拟器或特定rom。 桌面端处理器架构（Intel 酷睿core i3 - i9/Xeon E、Amd 锐龙ryzen/霄龙epyc）都是x86架构。基于复杂指令集（CISC）。高功耗，高性能 可分为：x86-32(又名x86);x86-64(又名x64)； 关于x86的32位架构（常被称为i386、x86），请见“**IA-32**”。 关于基于x86的64位处理器（x64）架构（向前兼容于16位及32位的x86架构，常称AMD64或 Intel 64），请见“**x86-64**”。 移动端处理器架构（ios Axx，骁龙，麒麟，三星Exynos）则是基于ARM架构的。基于精简指令集(RISC) 低功耗，性能上限不如复杂指令集的x86架构 可分为v7版本及以前，为32位；v8及以后，为64位； 架构支持Android系统目前支持以下七种不同的CPU架构： 每一个CPU架构对应一个ABI： CPU架构： ARMv5 ARMv7 (从2010年起) x86 (从2011年起) MIPS (从2012年起) ARMv8 MIPS64 x86_64 (从2014年起) ABI： armeabi armeabi-v7a x86 mips arm64-v8a mips64 x86_64 所有的x86、x8664、armeabi-v7a、arm64-v8a设备都支持armeabi架构的.so文件，x86设备能够很好的运行ARM类型函数库，但并不保证100%不发生crash，特别是对旧设备。 64位设备（arm64-v8a, x8664, mips64）能够运行32位的函数库，但是以32位模式运行，在64位平台上运行32位版本的ART和Android组件，将丢失专为64位优化过的性能（ART，webview，media等等），并只能最大使用4G虚拟内存 阿里Patron 。 目前国内的 Android App 大多数还是32位架构，仅提供了 arm-v7a 的动态链接库(包大小、维护成本等等)，市面上大多数手机都是64位的 CPU，App 通常都运行在兼容模式下，只可以使用完整的 4GB 虚拟内存，且丢失专为64位优化性能。 可以通过gradle配置 1234567android { defaultconfig { ndk { abiFilters &quot;armeabi-v7a&quot; } }} 比如：国内拼多多、京喜都是只保留了 armeabi_v7a，微信 arm64_v8a， 国外facebook、instagram等则已是 arm64_v8a了","link":"/2021/06/15/CpuArch/"},{"title":"CustomView","text":"Measure public void onMeasure(int widthMeasureSpec, int heightMeasureSpec) 简述：测量是从ViewRootImpl调用performMeasure之后，由DecorView（Framelayout）的onMeasure开始，往子View一层一层递归调用其onMeasure测量宽高，如遇子View为ViewGroup，则分发测量给下一级直到非ViewGroup，最后再从最低层View确定宽高一层层返回确定上一级的宽高。 MeasureSpec MeasureSpec 的完整英文是 Measure Specification测量规范，其中 Measure 表示测量，Specification 表示规范 MeasureSpec 就用来封装 View 的 size 和 mode 这两个属性，它是 View 的一个静态内部类，用一个 int 类型的三十二位整数来表示这两个属性，前两位表示 mode，后三十位表示 size。两个二进制位足够表示四种可能值，实际上 View 只用到了三种：UNSPECIFIED、EXACTLY、AT_MOST。makeMeasureSpec 方法就用于打包封装 size 和 mode 这两个属性值来生成 MeasureSpec mode 含义 UNSPECIFIED（少见） ViewGroup 对于 View 没有任何限制，View 可以拿到任意想要的 size EXACTLY View 本身设定了确切大小的 size。例如，View 的宽度设置为了 match_parent 或者具体的 dp 值，match_parent 即占满父容器，对于 View 来说也属于精准值 AT_MOST size 是 View 能够占据的最大空间，View 的最终大小不能超出该范围。对应 wrap_content，View 可以在父容器可以容纳的范围内申请空间 一般情况下，MeasureSpecMode 的取值由 View 的父容器决定，当父容器希望子 View 按照固定的大小来测量时，MeasureSpecMode 取 EXACTLY；当父容器希望子 View 不超过一定的大小时，MeasureSpecMode 取 AT_MOST。 UNSPECIFIED 模式相对较少用到，它表示 View 可以任意大小，一般用于一些特殊的场景，例如 ListView 中的子项，由于 ListView 的高度可以根据子项的数量动态调整，所以 ListView 在测量子项时，会将 MeasureSpecMode 设置为 UNSPECIFIED。当 MeasureSpecMode 为 UNSPECIFIED 时，MeasureSpecSize 的值通常是 0，但这并不影响 View 的测量，因为 View 可以根据自身的需要自由调整大小。 getChildMeasureSpec 方法是 View 的 MeasureSpec 是由其父容器 ViewGroup 的 MeasureSpec 和 View 自身的 LayoutParams 来共同决定的 这句话最直接的体现。（见附录代码getChildMeasureSpec） 测量过程对于 View 来说，其 MeasureSpec 是由其父容器 ViewGroup 的 MeasureSpec 和 View 自身的 LayoutParams 来共同决定的。此处所说的 View 也包含 ViewGroup 类型，因为父容器 ViewGroup 在测量 childView 的时候并不关心下一级的具体类型，而只是负责下发测量要求并接收测量结果，下一级如果是 View 类型那么就只需要测量自身并返回结果，下一级如果是 ViewGroup 类型那么就重复以上步骤并返回结果，整个视图树的绘制流程就通过这种层层递归调用的方式来完成测量，和 View 的事件分发机制非常相似 View通过重写 public void onMeasure(int widthMeasureSpec, int heightMeasureSpec)方法来返回自身的测量宽高结果，widthMeasureSpec、heightMeasureSpec这两个参数的值由 View 的父容器传递进来，因此它们实际上是父容器传递给子 View 的规格要求。在 onMeasure() 方法中，子 View 需要根据这两个参数计算出自己的测量宽度和测量高度，并将它们保存起来(setMeasuredDimension)，以便后续的布局和绘制过程使用(getMeasureHeight/getMeasureWidth)。 Layoutprotected abstract void onLayout(boolean changed,int l, int t, int r, int b); 简述：继performMeasure执行完成之后，每个View有了自己的测量宽高(getMeasureWidth)，接下来就由ViewRootImpl执行performLayout后走到DecorView的layout方法，决定自身的left,top,right,buttom等属性，定下来自身的位置。 View 的 layout 起始点也是从 ViewRootImpl 开始的，ViewRootImpl 的 performLayout 方法会调用 DecorView 的 layout 方法来启动 layout 流程，传入的后两个参数即屏幕的宽高大小 12345678910111213private void performLayout(WindowManager.LayoutParams lp, int desiredWindowWidth, int desiredWindowHeight) { //... Trace.traceBegin(Trace.TRACE_TAG_VIEW, &quot;layout&quot;); try { //启动 layout 流程 host此时为DecorView host.layout(0, 0, host.getMeasuredWidth(), host.getMeasuredHeight()); ··· } finally { Trace.traceEnd(Trace.TRACE_TAG_VIEW); } mInLayout = false; } layout(int l, int t, int r, int b) 是 View 类中的方法，传入的四个参数即我们熟知的 left、top、right、bottom，这四个值都是 View 相对父容器 ViewGroup 的坐标值。对于 DecorView 来说这四个值就分别是 0、0、screenWidth、screenHeight 123456789101112131415public void layout(int l, int t, int r, int b) { ··· //重点 boolean changed = isLayoutModeOptical(mParent) ? setOpticalFrame(l, t, r, b) : setFrame(l, t, r, b); if (changed || (mPrivateFlags &amp; PFLAG_LAYOUT_REQUIRED) == PFLAG_LAYOUT_REQUIRED) { //重点 onLayout(changed, l, t, r, b); ··· } ···}protected void onLayout(boolean changed, int left, int top, int right, int bottom) {} setFrame 方法又会将 left、top、right、bottom 等四个值保存到 View 相应的几个全局变量上，至此 View 的 width 和 height 才真正确定下来，View 的 getWidth() 和 getHeight()方法都是依靠这四个值做减法运算得到的。此外，这里也会回调 onSizeChanged 方法，在自定义 View 时我们往往就通过该方法来得到 View 的准确宽高大小，并在这里接收宽高大小变化的通知 123456789101112131415161718192021protected boolean setFrame(int left, int top, int right, int bottom) { ··· if (mLeft != left || mRight != right || mTop != top || mBottom != bottom) { changed = true; ··· mLeft = left; mTop = top; mRight = right; mBottom = bottom; mRenderNode.setLeftTopRightBottom(mLeft, mTop, mRight, mBottom); mPrivateFlags |= PFLAG_HAS_BOUNDS; if (sizeChanged) { sizeChange(newWidth, newHeight, oldWidth, oldHeight); } ··· } return changed; } e.g FrameLayout详见代码(FrameLayout.onLayout) layout 方法又会调用自身的 onLayout 方法。onLayout 方法在 View 类中是空实现，大部分情况下 View 都无需重写该方法。而 ViewGroup 又将其改为了抽象方法，即每个 ViewGroup 子类都需要通过实现该方法来管理自己的所有 childView 的摆放位置，FrameLayout 和 LinearLayout 等容器类就通过实现该方法来实现不同的布局效果 还是以 FrameLayout 为例子。FrameLayout 的布局特点就是会将所有的 childView 进行叠加覆盖显示，每个 childView 之间并不会形成相互约束，childView 主要是通过 layout_gravity 和 layout_margin 来声明自己在 FrameLayout 中的位置。FrameLayout 的 padding 也会占据一部分空间，从而影响 childView 的可用空间 FrameLayout 的 layoutChildren 方法就需要考虑以上因素，计算得出 childView 相对 FrameLayout 的 left、top、right、bottom 等值的大小，然后调用 childView 的 layout 方法，使得 childView 能够得到自己的真实宽高。如果 childView 也属于 ViewGroup 类型的话，就又会层层调用重复以上步骤完成整个视图树的 layout 操作 Draw简述：继performMeasure、performLayout相继执行完成之后，每个View有了自己的确定宽高(getWidth)、位置(getLeft，这时候由ViewRootImpl的performDraw开始，走到DecordView的Draw开始，viewGroup dispatchDraw向下分发，View 操作canvas进行绘制。 draw 代表的是绘制视图的过程，在这个过程中 View 需要通过操作 Canvas 来实现自己 UI 效果 View 的 draw 起始点也是从 ViewRootImpl 开始的，ViewRootImpl 的 performDraw 方法会调用 drawSoftware 方法，再通过调用 DecorView 的 draw 方法来启动 draw 流程 12345678private boolean drawSoftware(Surface surface, AttachInfo attachInfo, int xoff, int yoff, boolean scalingRequired, Rect dirty, Rect surfaceInsets) { // Draw with software renderer. final Canvas canvas; ··· mView.draw(canvas); ···} View 的draw方法的重点看其调用的 onDraw 和 dispatchDraw 这两个方法即可，这两个方法在 View 类中都是空实现 对于自定义 View，我们需要重写onDraw方法来实现自己的特定 UI，无需关心dispatchDraw方法 对于 ViewGroup，除了需要绘制背景色前景色等外，无需绘制自身，所以 ViewGroup 无需重写onDraw方法。而 dispatchDraw方法就是为 ViewGroup 准备的，用于向所有 childView 下发 draw 请求 123456789 public void draw(Canvas canvas) { ··· // Step 3, draw the content onDraw(canvas); // Step 4, draw the children dispatchDraw(canvas); ··· }复制代码 ViewGroup 的 dispatchDraw 方法会循环遍历所有 childView，使用同个 Canvas 对象来调用每个 childView 的 draw方法，层层调用完成整个视图树的绘制 12345678910111213141516171819202122232425262728293031 @Override protected void dispatchDraw(Canvas canvas) { ··· for (int i = 0; i &lt; childrenCount; i++) { while (transientIndex &gt;= 0 &amp;&amp; mTransientIndices.get(transientIndex) == i) { final View transientChild = mTransientViews.get(transientIndex); if ((transientChild.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || transientChild.getAnimation() != null) { //重点 more |= drawChild(canvas, transientChild, drawingTime); } transientIndex++; if (transientIndex &gt;= transientCount) { transientIndex = -1; } } final int childIndex = getAndVerifyPreorderedIndex(childrenCount, i, customOrder); final View child = getAndVerifyPreorderedView(preorderedList, children, childIndex); if ((child.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) { //重点 more |= drawChild(canvas, child, drawingTime); } } ··· } protected boolean drawChild(Canvas canvas, View child, long drawingTime) { return child.draw(canvas, this, drawingTime); }复制代码 附录getChildMeasureSpecspec 即 Parent 的 MeasureSpec childDimension 是 子View（自身） 在布局文件中声明的尺寸值，&gt;= 0时为像素值，-1为MATCH_PARENT，-2为WRAP_CONTENT 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public static int getChildMeasureSpec(int spec, int padding, int childDimension) { int specMode = MeasureSpec.getMode(spec); int specSize = MeasureSpec.getSize(spec); int size = Math.max(0, specSize - padding); int resultSize = 0; int resultMode = 0; switch (specMode) { // Parent has imposed an exact size on us case MeasureSpec.EXACTLY: if (childDimension &gt;= 0) { resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size. So be it. resultSize = size; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can't be // bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } break; // Parent has imposed a maximum size on us case MeasureSpec.AT_MOST: if (childDimension &gt;= 0) { // Child wants a specific size... so be it resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size, but our size is not fixed. // Constrain child to not be bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size. It can't be // bigger than us. resultSize = size; resultMode = MeasureSpec.AT_MOST; } break; // Parent asked to see how big we want to be case MeasureSpec.UNSPECIFIED: if (childDimension &gt;= 0) { // Child wants a specific size... let him have it resultSize = childDimension; resultMode = MeasureSpec.EXACTLY; } else if (childDimension == LayoutParams.MATCH_PARENT) { // Child wants to be our size... find out how big it should // be resultSize = View.sUseZeroUnspecifiedMeasureSpec ? 0 : size; resultMode = MeasureSpec.UNSPECIFIED; } else if (childDimension == LayoutParams.WRAP_CONTENT) { // Child wants to determine its own size.... find out how // big it should be resultSize = View.sUseZeroUnspecifiedMeasureSpec ? 0 : size; resultMode = MeasureSpec.UNSPECIFIED; } break; } //noinspection ResourceType return MeasureSpec.makeMeasureSpec(resultSize, resultMode);} FrameLayout.onLayout()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Override protected void onLayout(boolean changed, int left, int top, int right, int bottom) { layoutChildren(left, top, right, bottom, false /* no force left gravity */); } void layoutChildren(int left, int top, int right, int bottom, boolean forceLeftGravity) { final int count = getChildCount(); final int parentLeft = getPaddingLeftWithForeground(); final int parentRight = right - left - getPaddingRightWithForeground(); final int parentTop = getPaddingTopWithForeground(); final int parentBottom = bottom - top - getPaddingBottomWithForeground(); for (int i = 0; i &lt; count; i++) { final View child = getChildAt(i); if (child.getVisibility() != GONE) { final LayoutParams lp = (LayoutParams) child.getLayoutParams(); final int width = child.getMeasuredWidth(); final int height = child.getMeasuredHeight(); int childLeft; int childTop; int gravity = lp.gravity; if (gravity == -1) { gravity = DEFAULT_CHILD_GRAVITY; } final int layoutDirection = getLayoutDirection(); final int absoluteGravity = Gravity.getAbsoluteGravity(gravity, layoutDirection); final int verticalGravity = gravity &amp; Gravity.VERTICAL_GRAVITY_MASK; //考虑水平方向上的约束条件 switch (absoluteGravity &amp; Gravity.HORIZONTAL_GRAVITY_MASK) { case Gravity.CENTER_HORIZONTAL: childLeft = parentLeft + (parentRight - parentLeft - width) / 2 + lp.leftMargin - lp.rightMargin; break; case Gravity.RIGHT: if (!forceLeftGravity) { childLeft = parentRight - width - lp.rightMargin; break; } case Gravity.LEFT: default: childLeft = parentLeft + lp.leftMargin; } //考虑竖直方向上的约束条件 switch (verticalGravity) { case Gravity.TOP: childTop = parentTop + lp.topMargin; break; case Gravity.CENTER_VERTICAL: childTop = parentTop + (parentBottom - parentTop - height) / 2 + lp.topMargin - lp.bottomMargin; break; case Gravity.BOTTOM: childTop = parentBottom - height - lp.bottomMargin; break; default: childTop = parentTop + lp.topMargin; } child.layout(childLeft, childTop, childLeft + width, childTop + height); } } }","link":"/2023/03/06/CustomView/"},{"title":"DNS","text":"简述： 浏览器中访问一个www.baidu.com，首先会访问浏览器缓存，如未命中则进一步访问操作系统缓存，如未命中则访问hosts文件。如未命中，则客户端想本地DNS服务器发起递归查询（本地DNS会将结果也就是ip直接返回），如本地DNS解析服务器未命中，则由本地DNS解析服务器向根域名服务器、顶级域名服务器、管理方域名服务器等依次进行迭代查询（每有一个未命中则返回下一个域名服务器地址给本地域名服务器，比如local dns server向根域名服务器查询未命中，则根域名服务器返回顶级域名服务器地址给local dns server，然后local dns server向收到的这个地址迭代发起查询） 迭代与递归查询区别：客户端向本地dns服务器发起的是递归查询，客户端拿到的ip是由本地dns服务器直接返回；本地dns服务器向外网查询时是用的迭代查询，即向根域名服务器查询未命中返回给本地dns服务器的是下一个域名服务器的地址而非根域名去访问下一个域名服务器返回结果ip。 这里还有一个权威性的问题：如果客户端向本地dns服务器发起递归查询时，本地dns存在缓存，并将结果返回客户端，则该结果不具权威性（即缓存可能已经失效）；反之如果由本地dns服务器解析命中后返回，则具有权威性 域名的级别： .代表根域名， .com这种是顶级域名，也叫一级域名，baidu.com这种叫二级域名， www.baidu.com这种叫三级域名，依次类推。 注：也有其他叫法的，反正你知道这个意思就可以了。 再介绍一下最常见的两种域名服务器： 权威DNS：负责对请求作出权威的回答。权威DNS中存储着记录，最常见的3种：A记录（记录某域名和其IP的对应），NS记录（记录某域名和负责解析该域的权威DNS），CNAME记录（负责记录某域名及其别名）。权威能直接回答的，就回A记录；需要其他权威DNS回答的，就回NS记录，然后LDNS再去找其他权威DNS问；如果该记录是别名类型的，就回CNAME，LDNS就会再去解析别名。 递归DNS：通常就是LDNS，它接受终端的域名查询请求，负责在网上问一圈后，将答案返回终端。 现在举一个具体的例子：比如终端请求www.baidu.com这个域名的IP。 在没有缓存时，LDNS会从根DNS问起： 1、LDNS问根DNS说：“www.baidu.com的IP是多少啊？”。 2、根DNS说：“我哪有时间管你这么细的问题，你去问com顶级域的DNS吧，我只管到顶级域，喏，这些是com顶级域DNS的名字和IP，你去问它们吧”。（以NS记录回应） 3、LDNS又忙问com的权威DNS，com权威DNS说：“你问的这是三级域名，我不管这么多，你去问baidu.com的权威DNS吧，它的名字是ns.baidu.com，他的IP是XXX（这里可能给出多个权威DNS）”。 4、LDNS继续问baidu.com的权威DNS，这次痛快，因为www.baidu.com正是它管的，它可能直接给出A记录，也可能给出CNAME记录，如果是前者，就直接得到IP，如果是后者，就需要对别名再做查询。 5、最终，LDNS得到www.baidu.com的IP，并将其返回给终端。 细心的人会问，在第1步中，LDNS问根DNS的时候，他是怎么知道根DNS的IP的？ 这13个IP通常是预先配置在LDNS里面的。在LDNS初始化DNS缓存或者缓存失效的时候，LDNS向自己被预先配置的这些IP中的一个，发起对根的查询（也即询问.的NS记录），获得最新的根DNS的信息_（6）_。 对于DNS服务器软件而言，这13个IP，配置在根提示文件（root hints file）中，可能是named.cache或root.ca或root.hints等等之类的文件。 上面就是各种教科书中都会讲到的DNS查询过程，但实际上，没有这么麻烦，因为各个层面都是有缓存的。 实际DNS查询的过程，是这样的： 举个例子，比如用户在浏览器中输入这个域名：123.abc.qq.com.cn 1、浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去hosts文件看，也没有，才会去问LDNS。 2、LDNS会去先看看自己有没有123.abc.qq.com.cn的A记录，要有就直接返回，要没有，就去看有没有abc.qq.com.cn的NS记录，如果有，就去问它要答案，如果没有，就去看有无qq.com.cn的NS的记录，如果有，就去问它，没有就去看有无com.cn的DNS，还没有就去看有无cn的DNS，如果连cn的NS记录都没有，才去问根。 所以，有了缓存以后，教科书上那种从根问起的情况，实际上很少发生。 只有在各处都没有缓存的时候，我们才会问根。 基础知识1.域名系统 2.域名服务器 域名解析过程1.在浏览器中输入www.qq.com域名，会优先访问浏览器缓存，如果未命中则访问OS缓存，则访问本地hosts文件 2.如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 3.如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器， 此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 4.如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 5.如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询， 如果未用转发模式，本地DNS就把请求发至 “根DNS服务器”，“根DNS服务器”收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。 本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析， 它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 6.如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。 不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 递归查询与迭代查询 一、主机向本地域名服务器的查询一般都是采用递归查询。 ​ 所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那么本地域名服务器就以DNS客户的身份， ​ 向其它根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。 ​ 因此，递归查询返回的查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。 二、本地域名服务器向根域名服务器的查询的迭代查询。 ​ 迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。 ​ 然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。 ​ 顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。 ​ 最后，知道了所要解析的IP地址或报错，然后把这个结果返回给发起查询的主机 递归：客户端只发一次请求，要求对方给出最终结果。 迭代：客户端发出一次请求，对方如果没有授权回答，它就会返回一个能解答这个查询的其它名称服务器列表， ​ 客户端会再向返回的列表中发出请求，直到找到最终负责所查域名的名称服务器，从它得到最终结果。 授权回答：向dns服务器查询一个域名，刚好这个域名是本服务器负责，返回的结果就是授权回答。 从递归和迭代查询可以看出： 客户端-本地dns服务端：这部分属于递归查询。 本地dns服务端—外网：这部分属于迭代查询。 递归查询时，返回的结果只有两种:查询成功或查询失败. 迭代查询，又称作重指引,返回的是最佳的查询点或者主机地址. DNS缓存机制关于DNS缓存的机制，有一篇非常详细的文章What really happens when you navigate to a URL。 简单来说，一条域名的DNS记录会在本地有两种缓存：浏览器缓存和操作系统(OS)缓存。在浏览器中访问的时候，会优先访问浏览器缓存， 如果未命中则访问OS缓存，则访问本地hosts文件，若未命中最后再访问DNS服务器(一般是ISP提供)，然后DNS服务器会递归式的查找域名记录，然后返回。 DNS记录会有一个ttl值(time to live)，单位是秒，意思是这个记录最大有效期是多少。经过实验，OS缓存会参考ttl值，但是不完全等于ttl值， 而浏览器DNS缓存的时间跟ttl值无关，每种浏览器都使用一个固定值。 这里有一篇文章，做过详细的测试Why Web Browser DNS Caching Can Be A Bad Thing： Windows访问DNS后会把记录保存一段短暂的时间， 可通过ipconfig /displaydns 查看windows的DNS缓存、通过ipconfig /flushdns来清除。 工具和命令相关的工具和命令: dig,nslookup,host等.其中以dig命令的功能最为强大和灵活. dig命令典型应用形如： dig @server name type @server: 指定域名服务器 **name:**指定查询请求资源的域名 **type:**指定查询类型，如A、CNAME、SRV、MX、SIG等，如果不指定type，默认为A 查询某个域名解析的全过程:(此时为迭代查询) 1$ dig @8.8.8.8 163.com +trace 参考资料： DNS递归查询与迭代查询 - 皈依之路 - 博客园 (cnblogs.com) http://blog.csdn.net/wyq_tc25/article/details/51679520 http://blog.csdn.net/wytheonly/article/details/37925067 http://www.cnblogs.com/Juntaran/p/5827110.html http://magic3.blog.51cto.com/1146917/1354084 http://blog.csdn.net/realmeh/article/details/22663807","link":"/2022/01/06/DNS/"},{"title":"Design Pattrens","text":"设计模式的六个原则 单一原则每个类或方法都应该只被一个原因影响 开闭原则类或方法应该对扩展开放, 对修改封闭 里氏替换原则子类出现的地方一定可以被父类替换 接口隔离原则接口的粒度要尽量的小 依赖倒置原则抽象依赖抽象, 具体依赖抽象 迪米特原则尽量无知, 朋友的朋友不是我的朋友 二十三种设计模式共有三类23种设计模式 首先，简单工厂不是标准的GoF设计模式，但依然是常见的创建对象方式。 简单工厂模式： 关注点： 简单工厂模式关注于通过一个统一的工厂类创建不同的对象。 简单工厂通常没有子类。 但当从一个简单工厂中抽取出子类后， 它看上去就会更像经典的工厂方法模式了。 顺便提一句， 如果你将一个简单工厂声明为 abstract类型， 它并不会神奇地变成抽象工厂模式。 e.g: ChoiceBarFactory 第一类是创建型: 工厂方法模式（虚拟构造函数、Factory Method）关注点： 工厂方法模式侧重于单个对象的创建，每个具体工厂负责创建一个具体产品。 如果在基类及其扩展的子类中都有一个构建方法的话， 那它可能就是工厂方法。 e.g NumberFormat.getInstance() 抽象工厂模式（Abstract Factory）关注点： 抽象工厂模式关注一组相关对象的创建，每个具体工厂负责创建一组相关的产品对象。 如果你的程序中并不涉及产品系列的话， 那就不需要抽象工厂。 再次重申， 许多人分不清抽象工厂模式和声明为 abstract的简单工厂。 不要犯这个错误！ 生成器模式（构建者模式、Buider模式）生成器关注于如何分步生成对象，通常支持方法链e.g： StringBuilder OkHttp的Request.Builder() 原型模式（克隆模式、ProtoType）由被复制方自己提供clone() or copy()方法，故而调用方可不感知内部实现的情况下获取其备份 原型可以简单地通过 clone或 copy等方法来识别。 e.g：Java 的 Cloneable （可克隆） 接口就是立即可用的原型模式。 单例模式（Singleton）单例模式让你能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点。 e.g kotlin的object class，饿汉式单例模式是一种在类加载时就创建实例的单例模式。在 Kotlin 中，使用 object 关键字声明的对象在首次被访问时就会被创建，因此它是一种线程安全的单例实现方式。 第二类是结构型模式 适配器模式（Adapt）使不兼容的对象能相互合作，接收一个对象的调用，将其转化为另一个对象可识别的格式和接口e.g： RecyclerView.Adapter java.util.Arrays#asList() 代理模式 （Proxy）关注将 重量级/远程/缓存 用代理的方式，为其提供占位符或替代品 代理与其服务对象遵循同一接口， 使得自己和服务对象可以互换 e.g： binderProxy Binder 和 BinderProxy 在 Android 中可以被视为代理模式的一种实现。 在 Android 中，Binder 是用于实现进程间通信（IPC，Inter-Process Communication）的机制。每个进程都有一个自己的 Binder 实例，用于处理本地进程内部的通信，以及与其他进程之间的通信。BinderProxy 则是用于在客户端进程中代理服务端进程中的 Binder 对象。 这种情况下，BinderProxy 可以被看作是一种代理，用于代表服务端进程中的 Binder 对象。客户端进程通过调用 BinderProxy 的方法，实际上是在发起跨进程调用，这个调用会被传送到服务端进程中的对应 Binder 对象。这个过程符合代理模式的基本思想，一个对象（BinderProxy）代理另一个对象（服务端进程中的 Binder 对象）执行一些操作。 总之，Binder 和 BinderProxy 在 Android 中可以被视为代理模式的一种应用，用于实现进程间通信。 Retrofit动态代理 享元模式（缓存模式）利用如Integer缓存池的技术般，将可复用的对象通过共享的方式，让有限的内存可容纳更多的对象e.g： 缓存了[-128, 127]的Integer类， 外观模式 装饰模式 桥接模式与适配器模式很像，区分于适配器模式的可能就是桥接模式更多用于前期设计，有预谋。 桥接模式通常会于开发前期进行设计， 使你能够将程序的各个部分独立开来以便开发。 另一方面， 适配器模式通常在已有程序中使用， 让相互不兼容的类能很好地合作。 e.g：如okhttp3.internal.http.BridgeInterceptor，涉及了header，请求和响应的转换、处理和传输，但并不是标准的桥接模式，桥接模式更多地涉及到将抽象和实现分离，以便它们可以独立地变化。BridgeInterceptor 更多地关注在请求和响应之间进行数据的转换和协调，以便进行有效的网络通信。 组合模式 第三类是行为模式 责任链模式允许你将请求沿着处理者链进行发送。收到请求后，每个处理者均可对请求进行处理，或将其传递给链上的下个处理者。 每个处理者都可处理或结束请求，由于每个处理者都持有下一个处理节点，故而请求将按顺序沿着链条传递。（可能会有处理者因为前面节点的提前返回而没有处理） e.g： OkHttp中RealCall.getResponseWithInterceptorChain()即是一个责任链模式，每个节点都可都会追加对请求或响应的处理； Android的事件分发机制也是一种责任链，事件分发中，如果事件被处理了就会直接返回； 这些其实都是责任链，无论请求是否可被所有处理者处理过。 命令模式将请求转换为一个包含与请求相关的所有信息的独立对象。 该转换让你能根据不同的请求将方法参数化、 延迟请求执行或将其放入队列中， 且能实现可撤销操作。 迭代器模式 中介者模式 备忘录模式 观察者模式（ 事件订阅者、监听者、Event-Subscriber、Listener、Observer）发布者内部维护了一个订阅者对象列表 e.g： Animator.addListener() View.setOnClickListener 状态模式e.g：kotlin的协程状态机 策略模式有一种说法：（尤其针对策略模式）一种针对不完善编程语言的蹩脚解决方案通常当所选编程语言或技术缺少必要的抽象功能时， 人们才需要设计模式。 在这种情况下， 模式是一种可为语言提供更优功能的蹩脚解决方案。 例如， 策略模式在绝大部分现代编程语言中可以简单地使用匿名 （lambda） 函数来实现。 e.g： Collections.sort()：Collections.sort()最终调用的List（策略基类）的子类(ArrayList/Vector).sort； lambda 模板访问模式 访问者模式 解释器模式","link":"/2023/08/17/Design-Pattrens/"},{"title":"Concurrent","text":"https://www.wwwbuild.net/JavaAmazing/112187.html 并发操作：原子性、可见性、有序性1、原子性即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 如java.util.concurrent.atomic包下的原子类，就是用CAS(Compare And Swap)保证原子性和可见性（内存屏障） 虽然 java.util.concurrent.atomic 提供了原子操作，但这些解决方案主要针对单一变量。对于涉及多个变量时的原子性操作，仍然需要使用高级同步机制（如 synchronized 块或 ReentrantLock）。 Java 内存模型（JMM）确保在使用原子类和 CAS 操作时，数值的更新对其他线程是可见的。这是通过内存屏障来实现的。 2、可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 如volatile能保证被修饰变量的可见性、有序性；原子类可以保证原子性和可见性； 可见性：volatile 关键字确保变量的更新对所有线程立即可见，避免线程读取到变量的过期值。 禁止指令重排序优化：编译器和运行时不会把 volatile 变量的写操作与之前的内存操作重排序，也不会把 volatile 变量的读操作与之后的内存操作重排序。 3、有序性即程序执行的顺序按照代码的先后顺序执行。（指令编排可能会导致多线程下执行结果不一致） 如volatile能保证被修饰变量的可见性、有序性 synchronized关键字三者都能保证。 Volatile 和synchronized的区别：java.util.concurrent.atomic包的原子类可以保证数据的原子性、可见性；volatile关键字能保证数据的可见性、有序性，但不能保证数据的原子性。synchronized关键字三者都能保证。 1：并发特性比较：volatile关键字能保证数据的可见性、有序性，但不能保证数据的原子性（即volatile int x; x++ 是三步操作：一取x值，二加一，三赋值回x）。synchronized关键字两者都能保证。 有序性则volatile和synchronized都能保证，volatile关键字禁止JVM编译器已及处理器对其进行重排序, synchronized保证顺序性是串行化的结果，但同步块里的语句是会发生指令从排。 2：volatile 的原理 1). 修改volatile变量时会强制将修改后的值刷新的主内存中。 2). 修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。 3). 禁止指令重排序优化：编译器和运行时不会把 volatile 变量的写操作与之前的内存操作重排序，也不会把 volatile 变量的读操作与之后的内存操作重排序。 （Intel 的MESI协议：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的高速缓存置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取重新加载到高速缓存。） 3：阻塞与否多线程访问volatile关键字不会发生阻塞（2所述原理），而synchronized关键字可能会发生阻塞(重量级锁时会阻塞) 4：性能volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用synchronized关键字的场景还是更多一些。 可重入锁和不可重入的区别可重入锁也叫递归锁，是在一个线程获取锁后，内部如果还需要获取锁，可以直接获取的锁（前提锁对象得是同一个对象或者class）。不可重入锁也就是相反，线程获取锁后，内部不能再获取锁，由于之前已经获取过还没释放而阻塞，会导致线程死锁。所以可重入锁的一个优点是可一定程度避免死锁。可重入锁有ReentrantLock和synchronized。非可重入锁有NonReentrantLock（Netty框架）。 可重入锁的实现原理：二者类似 synchronized：synchronized底层的实现原理是利用计算机系统的mutex Lock实现。每一个可重入锁都会关联一个线程ID和一个锁状态status。当一个线程请求方法时，会去检查锁状态，如果锁状态是0，代表该锁没有被占用，直接进行CAS操作获取锁，将线程ID替换成自己的线程ID。如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法。如果是非重入锁，就会进入阻塞队列等待。释放锁时，可重入锁，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。释放锁时，非可重入锁，线程退出方法，直接就会释放该锁。 ReentrantLock：ReentrantLock的可重入功能基于AQS的同步状态：state。 其原理大致为：当某一线程获取锁后，将state值+1，并记录下当前持有锁的线程，再有线程来获取锁时，判断这个线程与持有锁的线程是否是同一个线程，如果是，将state值再+1，如果不是，阻塞线程。 当线程释放锁时，将state值-1，当state值减为0时，表示当前线程彻底释放了锁，然后将记录当前持有锁的线程的那个字段设置为null，并唤醒其他线程，使其重新竞争锁。 原子类&amp;CAS算法&amp;乐观锁&amp;悲观锁简述： 乐观锁是无锁的，因为它认为自己使用数据时不会有别的线程来修改数据，所以不会对资源加锁。实现乐观锁的代表是原子类（java.util.concurrent.atomic包），原子类中的递增操作就是由CAS自旋实现的。 悲观锁则是在使用数据前悲观的认为一定会有别的线程来修改数据，所以在每次使用数据时都会对资源加锁，未拿到锁的都需要排队阻塞等候。 乐观锁&amp;悲观锁对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 CAS原理CAS算法全程 Compare And Swap，在不加锁的请况下实现多线程变量同步： 简述：当且仅当内存值（内存地址）等于预估值（备份的旧数据）时，将更新值（新数据）写入内存，否则什么都不做 CAS 包含了三个操作数： 内存值 V 预估值 A 更新值 B 当且仅当 V == A 时，V 将被赋值为 B，否则什么都不做， 自旋锁：循环的CAS算法：当然如果需要的话，可以设计成自旋锁的模式,循环着不断进行判断 V 与 A 是否相等。 CAS比较与交换的伪代码可以表示为： 1234do{ 备份旧数据； 基于旧数据构造新数据；}while(!CAS( 内存地址，备份的旧数据，新数据 )) CAS存在的问题CAS虽然很高效，但是它也存在三大问题: ABA问题 CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。 JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。 只能保证一个共享变量的原子操作 对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。 Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 synchronized原理及锁升级过程简述： 无锁&amp;偏向锁：对象头中的MarkWord的标志位都是01，偏向模式位 为0则无锁，为1则偏向锁；无锁也就是CAS原理及应用，不加锁，对修改资源进行循环的CAS操作。偏向锁则是因为同步代码一直被一个线程所访问，那么该线程会自动获取偏向锁，获取锁的线程的id被对象MarkWord记录，后不再通过CAS加解偏向锁，而是通过检测id是否相符（也就是不释放偏向锁直到有其他线程尝试竞争锁时升级轻量级锁） 轻量级锁：MarkWord的标志位00，一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁），其他线程通过自旋CAS操作尝试获取轻量级锁 重量级锁：MarkWord的标志位10，一旦尝试超过10次不成功或有三个线程同时竞争，升级重量级锁。此时，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。加锁的过程其实就是竞争 monitor 的过程，当线程进入字节码 monitorenter 指令（sychronized前后插入monitorenter&amp;monitorentexit）之后，线程将持有 monitor 对象， 执行 monitorexit 时释放 monitor 对象，当其他线程没有拿到 monitor 对象时，则需要阻塞 等待获取该对象，阻塞由于涉及用户态和内核态的切换，线程的阻塞和恢复，故较为耗时 四种锁状态对应的的Mark Word内容： 锁状态 存储内容 存储内容 无锁 对象的hashCode、 对象分代年龄、是否是偏向锁（0） 01 偏向锁 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） 01 轻量级锁 指向栈中锁记录(lock_record)的指针 00 重量级锁 指向Monitor的指针 10 对象头 对象头中的markWordMark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 32位标记字段详情12345678910111213|-------------------------------------------------------|--------------------|| Mark Word (32 bits) | State ||-------------------------------------------------------|--------------------|| identity_hashcode:25 | age:4 | biased_lock:1 | lock:2 | Normal ||-------------------------------------------------------|--------------------|| thread:23 | epoch:2 | age:4 | biased_lock:1 | lock:2 | Biased ||-------------------------------------------------------|--------------------|| ptr_to_lock_record:30 | lock:2 | Lightweight Locked ||-------------------------------------------------------|--------------------|| ptr_to_heavyweight_monitor:30 | lock:2 | Heavyweight Locked ||-------------------------------------------------------|--------------------|| | lock:2 | Marked for GC ||-------------------------------------------------------|--------------------| lock:2位的锁状态标记位，由于希望用尽可能少的二进制位表示尽可能多的信息，所以设置了lock标记。 biased_lock：对象是否启用偏向锁标记，只占1个二进制位。为1时表示对象启用偏向锁，为0时表示对象没有偏向锁。 age：4位的Java对象年龄。在GC中，如果对象在Survivor区复制一次，年龄增加1。当对象达到设定的阈值时，将会晋升到老年代。默认情况下，并行GC的年龄阈值为15，并发GC的年龄阈值为6。由于age只有4位，所以最大值为15，这就是-XX:MaxTenuringThreshold选项最大值为15的原因。 identity_hashcode：25位的对象标识Hash码，采用延迟加载技术。调用方法System.identityHashCode()计算，并会将结果写到该对象头中。当对象被锁定时，该值会移动到管程Monitor中。 thread：持有偏向锁的线程ID。 epoch：偏向时间戳。 ptr_to_lock_record：指向栈中锁记录的指针。 ptr_to_heavyweight_monitor：指向管程Monitor的指针。 对象头中的Klass PointKlass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 MonitorMonitor实现在Java虚拟机(HotSpot)中，Monitor是基于C++实现的，由ObjectMonitor实现的，其主要数据结构如下： 123456789101112131415161718ObjectMonitor() { _header = NULL; _count = 0; _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ;} 源码地址：objectMonitor.hpp ObjectMonitor中有几个关键属性： _owner：指向持有ObjectMonitor对象的线程_WaitSet：存放处于wait状态的线程队列_EntryList：存放处于等待锁block状态的线程队列_recursions：锁的重入次数_count：用来记录该线程获取锁的次数 当多个线程同时访问一段同步代码时，首先会进入_EntryList队列中，当某个线程获取到对象的monitor后进入_Owner区域并把monitor中的_owner变量设置为当前线程，同时monitor中的计数器_count加1。即获得对象锁。 Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 synchronized锁升级过程无锁也就是CAS原理及应用，不加锁，对修改资源进行循环的CAS操作 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁同步代码一直被一个线程所访问，那么该线程会自动获取锁，获取锁的线程的id被对象MarkWord记录，后不再通过CAS加解锁（也就是不释放锁直到有其他线程尝试竞争锁时升级轻量级锁），而是通过检测id是否相符 偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁一旦有第二个线程加入锁竞争，偏向锁就升级为轻量级锁（自旋锁），其他线程通过自旋CAS操作尝试获取锁。一旦尝试超过10次不成功或者有三个及以上的锁竞争，升级重量级锁 是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁等待锁的线程都进入阻塞状态，直到锁被释放后线程唤醒竞争锁 ，过程涉及用户态和内核态的切换，较耗时 升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 整体的锁状态升级流程如下： 综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 总结 synchronized特点：保证内存可见性、操作原子性 synchronized影响性能的原因： 1、加锁解锁操作需要额外操作； 2、互斥同步对性能最大的影响是阻塞的实现，因为阻塞涉及到的挂起线程和恢复线程的操作都需要转入内核态中完成（用户态与内核态的切换的性能代价是比较大的） synchronized锁：对象头中的Mark Word根据锁标志位的不同而被复用 偏向锁：在只有一个线程执行同步块时提高性能。Mark Word存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单比较ThreadID。特点：只有等到线程竞争出现才释放偏向锁，持有偏向锁的线程不会主动释放偏向锁。之后的线程竞争偏向锁，会先检查持有偏向锁的线程是否存活，如果不存货，则对象变为无锁状态，重新偏向；如果仍存活，则偏向锁升级为轻量级锁，此时轻量级锁由原持有偏向锁的线程持有，继续执行其同步代码，而正在竞争的线程会进入自旋等待获得该轻量级锁 轻量级锁：在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，尝试拷贝锁对象目前的Mark Word到栈帧的Lock Record，若拷贝成功：虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向对象的Mark Word。若拷贝失败：若当前只有一个等待线程，则可通过自旋稍微等待一下，可能持有轻量级锁的线程很快就会释放锁。 但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁 重量级锁：指向互斥量（mutex），底层通过操作系统的mutex lock实现。等待锁的线程会被阻塞，由于Linux下Java线程与操作系统内核态线程一一映射，所以涉及到用户态和内核态的切换、操作系统内核态中的线程的阻塞和恢复。 synchonized的无锁和其他状态下调用 hashcode区别 无锁状态：调用 hashCode 直接返回哈希值，没有额外开销（已存过hashCode的情况）。 偏向锁状态：调用 hashCode 会导致锁升级为轻量级锁，生成并存储哈希码。 轻量级锁和重量级锁状态：调用 hashCode 会导致额外的开销，锁升级为重量级锁，并且可能需要额外的内存空间来存储哈希码。 HotSpot VM 的锁实现机制是： 当一个对象已经调用默认 hashCode() 或者 System.identityHashCode()，即计算过 identity hash code 后，它就无法进入偏向锁状态。这意味着，如果要在不发生争用的对象上进行同步，则最好覆盖默认hashCode()实现，否则JVM不会优化。 当一个对象当前正处于偏向锁状态，并且需要计算其 identity hash code 的话，则它的偏向锁会被撤销，并且锁会膨胀为轻量级锁或者重量锁； 轻量级锁的实现中，会通过线程栈帧的锁记录存储 Displaced Mark Word； 重量锁的实现中，ObjectMonitor 类里有字段可以记录非加锁状态下的 mark word，其中可以存储 identity hash code 的值。 synchronized关键字可以实现什么类型的锁 悲观锁：synchronized关键字实现的是悲观锁，每次访问共享资源时都会上锁。 非公平锁：synchronized关键字实现的是非公平锁，即线程获取锁的顺序并不一定是按照线程阻塞的顺序。 可重入锁：synchronized关键字实现的是可重入锁，即已经获取锁的线程可以再次获取锁。 独占锁或者排他锁：synchronized关键字实现的是独占锁，即该锁只能被一个线程所持有，其他线程均被阻塞。 Lock与ReentrantLockLock 接是 java并发包的顶层接口。 可重入锁 ReentrantLock 是 Lock 最常见的实现，与 synchronized 一样可重入。ReentrantLock 在默认情况下是非公平的，可以通过构造方法指定公平锁。一旦使用了公平锁，性能会下降。 Synchronized 和 Lock 的主要区别存在层面：Syncronized 是Java 中的一个关键字，存在于 JVM 层面，Lock 是 Java 中的一个接口锁的释放条件：1. 获取锁的线程执行完同步代码后，自动释放；2. 线程发生异常时，JVM会让线程释放锁；Lock 必须在 finally 关键字中释放锁，不然容易造成线程死锁锁的获取: 在 Syncronized 中，假设线程 A 获得锁，B 线程等待。如果 A 发生阻塞，那么 B 会一直等待。在 Lock 中，会分情况而定，Lock 中有尝试获取锁的方法，如果尝试获取到锁，则不用一直等待锁的状态：Synchronized 无法判断锁的状态，Lock 则可以判断锁的类型：Synchronized 是可重入，不可中断，非公平锁；Lock 锁则是 可重入，可判断，可公平锁锁的性能：Synchronized 适用于少量同步的情况下，性能开销比较大。Lock 锁适用于大量同步阶段：Lock 锁可以提高多个线程进行读的效率(使用 readWriteLock)在竞争不是很激烈的情况下，Synchronized的性能要优于ReetrantLock，但是在资源竞争很激烈的情况下，Synchronized的性能会下降几十倍，但是ReetrantLock的性能能维持常态；ReetrantLock 提供了多样化的同步，比如有时间限制的同步，可以被Interrupt的同步（synchronized的同步是不能Interrupt的）等。 ReentrantLock与synchronized的区别 「锁的实现：」 synchronized是Java语言的关键字，基于JVM实现。而ReentrantLock是基于JDK的API层面实现的（一般是lock()和unlock()方法配合try/finally 语句块来完成。） 「性能：」 在JDK1.6锁优化以前，synchronized的性能比ReenTrantLock差很多。但是JDK6开始，增加了适应性自旋、锁消除等，两者性能就差不多了。 「功能特点：」 ReentrantLock 比 synchronized 增加了一些高级功能，如等待可中断、可实现公平锁、可实现选择性通知。 ❝ ReentrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。 ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 synchronized与wait()和notify()/notifyAll()方法结合实现等待/通知机制，ReentrantLock类借助Condition接口与newCondition()方法实现。 ReentrantLock需要手工声明来加锁和释放锁，一般跟finally配合释放锁。而synchronized不用手动释放锁。 ❞ ReentrantLock 有如下特点： 相同点： 可重入： 可重入锁 ReentrantLock 是 Lock 最常见的实现，与 synchronized 一样可重入。 不过两者实现原理稍有差 别， RetrantLock 利用 AQS 的的 state 状态来判断资源是否已锁，同一线程重入加锁， state 的状态 +1 ; 同一线程重入解锁, state 状态 -1 (解锁必须为当前独占线程，否则异 常); 当 state 为 0 时解锁成功。 不同点： 需要手动加锁、解锁，而 synchronized 关键字是自动进行加锁、解锁的。而 ReentrantLock 需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成，来手动加锁、解锁。 支持设置锁的超时时间，而 synchronized 关键字无法设置锁的超时时间。如果一个获得锁的线程内部发生死锁，那 么其他线程就会一直进入阻塞状态，而 ReentrantLock 提供 tryLock 方法，允许设置线 程获取锁的超时时间，如果超时，则跳过，不进行任何操作，避免死锁的发生。 支持公平/非公平锁（默认非公平），而 synchronized 关键字是一种非公平锁。先抢到锁的线程先执行。而 ReentrantLock 的 构造方法中允许设置 true/false 来实现公平、非公平锁，如果设置为 true ，则线程获取 锁要遵循”先来后到”的规则，每次都会构造一个线程 Node ，然后到双向链表的”尾 巴”后面排队，等待前面的 Node 释放锁资源。 可中断锁， ReentrantLock 中的 lockInterruptibly() 方法使得线程可以在被阻塞时响应中断。比 如一个线程 t1 通过 lockInterruptibly() 方法获取到一个可重入锁，并执行一个长时间 的任务，另一个线程通过 interrupt() 方法就可以立刻打断 t1 线程的执行，来获取t1持 有的那个可重入锁。而通过 ReentrantLock 的 lock() 方法或者 Synchronized 持有锁 的线程是不会响应其他线程的 interrupt() 方法的，直到该方法主动释放锁之后才会响应 interrupt() 方法。 可重入锁和不可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析： 12345678910public class Widget { public synchronized void doSomething() { System.out.println(&quot;方法1执行...&quot;); doOthers(); } public synchronized void doOthers() { System.out.println(&quot;方法2执行...&quot;); }} 在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。 如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁","link":"/2021/11/11/Concurrent/"},{"title":"EventAndNestedScroll","text":"原理&amp;流程一. ns child会在收到DOWN事件时，找到自己祖上中最近的能与自己匹配的ns parent，与它进行绑定并关闭它的事件拦截机制 二. 然后ns child会在接下来的MOVE事件中判定出用户触发了滑动手势，并把事件流拦截下来给自己消费 三. 消费事件流时，对于每一次MOVE事件增加的滑动距离： ns child并不是直接自己消费，而是先把它交给ns parent，让ns parent可以在ns child之前消费滑动dispatch/onNestedPreScroll() 如果ns parent没有消费或是没有消费完，ns child再自己消费剩下的滑动dispatchNestedScroll() 如果ns child自己还是没有消费完这个滑动，会再把剩下的滑动交给ns parent消费onNestedScroll() 最后如果滑动还有剩余，ns child可以做最终的处理dispatchNestedScroll() 四. 同时在ns child的computeScroll()方法中，ns child也会把自己因为用户fling操作引发的滑动，与上一条中用户滑动屏幕触发的滑动一样，使用「parent -&gt; child -&gt; parent -&gt; child」的顺序进行消费 ns child使用更灵活的方式找到和绑定自己的ns parent，而不是直接找自己的上一级结点 ns child在DOWN事件时关闭ns parent的事件拦截机制单独用了一个 Flag 进行关闭，这就不会关闭ns parent对其他手势的拦截，也不会递归往上关闭祖上们的事件拦截机制。ns child直到在MOVE事件中确定自己要开始滑动后，才会调用requestDisallowInterceptTouchEvent(true)递归关闭祖上们全部的事件拦截 对每一次MOVE事件传递来的滑动，都使用「parent -&gt; child -&gt; parent -&gt; child」机制进行消费，让ns child在消费滑动时与ns parent配合更加细致、紧密和灵活 对于因为用户fling操作引发的滑动，与用户滑动屏幕触发的滑动使用同样的机制进行消费，实现了完美的惯性连续效果 DOWN事件来时，NSCstartNestedScroll()找到自己祖上匹配的NSP进行绑定并关闭NSP的拦截； MOVE事件来时： 「parent -&gt; child -&gt; parent -&gt; child」的顺序进行消费 NSCdispatchNestedPreScroll()中触发NSPonNestedPreScroll()预先进行滑动事件的消费，之后将剩余事件返回；接着NSC消费剩余事件； NSC消费事件后再dispatchNestedScroll()去将剩余事件传递给NSPonNestedScroll()消费。 NSP消费完剩余事件返回NSC，NSC此时可以做最后的处理，比如overScroll效果比如在 fling 的时候停止scroller 与MOVE事件中处理滑动按照这个顺序进行消费：「dispatchNestedPreScroll()到Parent -&gt; 自己 -&gt; dispatchNestedScroll() -&gt; 自己」一样，惯性滑动按照上面的顺序。 Case分析ScrollView嵌套ScrollView默认情况：外部ScrollView优先获取上下滑动的权力，在蓝色区域上下滑动，内部ScrollView并不会上下滑动 简述： 默认内部ScrollView会消费DOWN事件 默认外部ScrollView优先获取MOVE事件处理机会，并且当yDiff &gt; mTouchSlop时，外部ScrollView会拦截掉MOVE事件并给内部ScrollView发CANCEL事件。 表现：（不考虑后来 Google 给它加的NestedScroll开关），嵌套ScrollView同向滑动的效果如上，内部ScrollView优先获得DOWN事件的处理机会，外部的ScrollView优先获得MOVE事件的处理机会并且拦截（yDiff &gt; mTouchSlop（8，可配置常量）)。 分析: 当外部ScrollView嵌套内部ScrollView时,DOWN事件在内部ScrollView的onTouchEvent中返回true，内部ScrollView处理了DOWN事件。MOVE事件首先到达外部ScrollView的onInterceptTouchEvent方法，当滑动距离大于mTouchSlop时，会拦截掉MOVE事件，给内部ScrollView发出CANCEL事件，从而外部ScrollView获得了事件的处理权，内部ScrollView失去了事件的处理权。 ScrollView 实现了ViewParent接口，而ViewParent接口声明了和NestedScrollParent一样的接口方法 ScrollView 继承于View，而View实现了NestedScrollChild接口方法。 (看这就知道了，整体滑动嵌套的思路是NSC先获取事件处理优先权，也许是通过禁止外部拦截的方法获取的，自身的滑动事件消费剩余的滑动距离再由NSC在自身的dispatchNestedXXX中，通知NSP的onNestesXXScroll方法承接，所以内部是主动，外部是被动。至于惯性扔动事件类似？) 如果要达到外层ScrollView可以消费内部溢出的滑动和Fling事件的话，需要外层实现NestedScrollingParent，内层实现NestedScrollingChild协作事件处理。 ???： 1、ScrollView覆盖了View的onTouchEvent并默认返回true；所以如果一个ScrollView外部还嵌套了其他ViewGroup了，则Down事件不会返回到外部，也同时MOVE、UP事件也随DOWN事件被ScrollView或其子类内部消费。 2、外ScrollView嵌套内ScrollView，内ScrollView包裹一个内部View的话，不打开（残缺的）嵌套滑动开关setNestedScrollingEnabled(true)的话，点击内部View拖动： 那么DOWN事件会由外ScrollView传到内ScrollView再传到内部View，内部View不消费，回传到内ScrollView消费； MOVE事件diff超过touchSlop的话会被外ScrollView拦截处理，并产生一个CANCEL事件交给内SCrollView，因为DOWN已经被内ScrollView消费了，所以CANCEL事件也交给了内ScrollView消费，而不会再给到内部View。 UP事件只被外ScrollView分发并传递给外ScrollView的onTouchEvent消费，是的没有拦截。原因未知（理论上应该跟CANCEL一样才对…….） 3、不用小心翼翼地让改动尽量小，既然内部优先，完全可以让内部的ScrollView在DOWN事件的时候就申请外部不拦截，然后在滑动一段距离后，如果判断自己在该滑动方向无法滑动，再取消对外部的拦截限制，像这样也只能实现滑动事件，对于惯性事件的处理是不到位的。 1234567891011121314151617class SimpleNestedScrollView(context: Context, attrs: AttributeSet) : ScrollView(context, attrs) { override fun dispatchTouchEvent(ev: MotionEvent): Boolean { if (ev.actionMasked == MotionEvent.ACTION_DOWN) parent.requestDisallowInterceptTouchEvent(true) if (ev.actionMasked == MotionEvent.ACTION_MOVE) { val offsetY = ev.y.toInt() - getInt(&quot;mLastMotionY&quot;) if (Math.abs(offsetY) &gt; getInt(&quot;mTouchSlop&quot;)) { if ((offsetY &gt; 0 &amp;&amp; isScrollToTop()) || (offsetY &lt; 0 &amp;&amp; isScrollToBottom())) { parent.requestDisallowInterceptTouchEvent(false) } } } return super.dispatchTouchEvent(ev) }} ScrollView的真实源码实际上是直接在DOWN事件中请求了parent禁止拦截，然后自身先处理消耗MOVE事件直到达到自身的滑动边界之后再找自己的parent处理剩余滑动距离。对于惯性事件也是处理不到位的。 浅析NestedScrolling嵌套滑动机制之基础篇 - 掘金 (juejin.cn) 事件分发四部曲之二《嵌套滑动事件分析》 - 掘金 (juejin.cn)","link":"/2022/01/12/EventAndNestedScroll/"},{"title":"ClassLoading","text":"类的生命周期： 简述：加载是字节码(.class)文件被ClassLoader装载进方法区并在堆中生成一个class对象引用；链接包括：校验二进制流是否符合JVM规范的验证、为各个变量分配内存赋值默认值的准备、将字符串表示的符号引用解析成直接将引用的解析；初始化则是static块、static变量初始化、类构造器执行的过程。 类加载过程(ClassLoading)这里的类加载不是指类加载阶段，而是指整个类加载过程，即类加载阶段到初始化完成。 隐式加载 创建类对象 使用类的静态域 创建子类对象 使用子类的静态域 在JVM启动时，BootStrapLoader会加载一些JVM自身运行所需的class 在JVM启动时，ExtClassLoader会加载指定目录下一些特殊的class 在JVM启动时，AppClassLoader会加载classpath路径下的class，以及main函数所在的类的class文件 显式加载 ClassLoader.loadClass(className)，只加载和连接、不会进行初始化 Class.forName(String name, boolean initialize,ClassLoader loader); 使用loader进行加载和连接，根据参数initialize决定是否初始化。 动态加载： 不管使用什么样的类加载器，类，都是在第一次被用到时，动态加载到JVM的。这句话有两层含义： Java程序在运行时并不一定被完整加载，只有当发现该类还没有加载时，才去本地或远程查找类的.class文件并验证和加载； 当程序创建了第一个对类的静态成员的引用（如类的静态变量、静态方法、构造方法——构造方法也是静态的）时，才会加载该类。 包括3个步骤： 一、加载（Loading）简述：加载是将.class文件从各个来源通过ClassLoader装载到方法区内存，并在堆内存中生成该类的class对象引用 时机：类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它 这里有两个重点： 字节码来源。一般的加载来源包括从本地路径下编译生成的.class文件，从jar包中的.class文件，从远程网络，以及动态代理实时编译 类加载器。一般包括启动类加载器，扩展类加载器，应用类加载器，以及用户的自定义类加载器。(Android中是系统用PathClassLoader，插件化热修复方案用的DexClassLoader和所有classLoader的父ClassLoader——BaseClassLoader) 二、链接（Linking）验证字节码、为类变量分配内存并赋default值，解析该类创建所需要直接引用； Java在加载了类之后，需要进行链接的步骤，链接简单地说，就是将已经加载的java二进制代码组合到JVM运行状态中去。它包括3个步骤： 验证（Verification）​ 简述：保证二进制字节码符合虚拟机规范：包括类型正确、访问权限、final类是否错误继承等； ​ 验证是保证二进制字节码在结构上的正确性，具体来说，工作包括检测类型正确性，接入属性正确性（public、private），检查final class 没有被继承，检查静态变量的正确性等。 准备（Preparation）​ 简述：不执行任何代码，仅为类变量(static)分配内存并赋零值：基本类型为0，引用类型为null； ​ 准备阶段主要是创建静态域，分配空间，给这些域设默认值，需要注意的是两点：一个是在准备阶段不会执行任何代码，仅仅是设置默认值，二个是这些默认值是这样分配的，原生类型全部设为0，如：float:0f,int 0, long 0L, boolean:0（布尔类型也是0），其它引用类型为null。 解析（Resolution）​ 简述：将符号引用解析成直接饮用（即字符串解析成具体地址）直接引用指的是存于方法区-运行时常量池中的方法引用 ​ 解析的过程就是对类中的接口、类、方法、变量的符号引用（处于方法区的类信息）进行解析并定位，解析成直接引用（符号引用就是编码，是用字符串表示某个变量、接口的位置；直接引用就是根据符号引用翻译出来的地址），并保证这些类被正确的找到。解析的过程可能导致其它的类被加载。 三、初始化（Initialization）类与接口的初始化不同，如果一个类被初始化，则其父类或父接口也会被初始化，但如果一个接口初始化，则不会引起其父接口的初始化。 类的初始化时机:类的初始化即java虚拟机为类的static静态变量赋予初始值(这和准备阶段设置默认初始值为0是不一样的)。只有类的主动使用才会初始化类。 1.类的主动使用(6种): 创建类的实例：用new语句创建实例 Person ps=new Person(); 调用类的静态变量或对静态变量赋值： 调用类的静态方法 调用java API中的反射方法：Class.forName(“Person”); 初始化子类的时候会先初始化父类(但”父类”是接口的时候，不会先初始化它所实现的接口的，只有在程序在使用接口的静态变量时才会使静态接口初始化) java虚拟机启动时被标明为启动类的类 2.类的被动使用: final类型的静态变量在编译的时候能计算出值（即编译时常量，在编译的时候将这个值就放入到常量池中了）：注： final类型的静态变量在编译的时候不能计算出变量的值(即运行时常量)的时候是会被初始化的 12final static int a=2*3; //变量a是编译时常量final static int a=(int)Math.random(); //变量a不是是编译时常量（即运行时常量） “父类”是接口的时候，不会先初始化它所实现的接口的，只有在程序在使用接口的静态变量时才会使静态接口初始化 **ClassLoader类的loadClass(“Person”)**方法的时候，只是对类的加载，不是初始化。Class.forName(“Person”);才会初始化 Other 变量赋值： “二.1准备阶段”，是jvm赋static变量初值：包括基本类型赋值默认值0、引用类型赋值null ”三、初始化阶段“，则根据程序员自己设置的变量赋值。 ————final变量 在运行时初始化、static变量在“三、初始化阶段”初始化，至于默认值则都是在“二.1准备阶段”赋予了——— 类加载器 在了解Java的机制之前，需要先了解类在JVM（Java虚拟机）中是如何加载的，这对后面理解java其它机制将有重要作用。 每个类编译后产生一个Class对象，存储在.class文件中，JVM使用类加载器（Class Loader）来加载类的字节码文件（.class），类加载器实质上是一条类加载器链，一般的，我们只会用到一个原生的类加载器，它只加载Java API等可信类，通常只是在本地磁盘中加载，这些类一般就够我们使用了。如果我们需要从远程网络或数据库中下载.class字节码文件，那就需要我们来挂载额外的类加载器。 一般来说，类加载器是按照树形的层次结构组织的，每个加载器都有一个父类加载器。另外，每个类加载器都支持代理模式，即可以自己完成Java类的加载工作，也可以代理给其它类加载器。 类加载器的加载顺序有两种，一种是父类优先策略，一种是是自己优先策略，父类优先策略是比较一般的情况（如JDK采用的就是这种方式），在这种策略下，类在加载某个Java类之前，会尝试代理给其父类加载器，只有当父类加载器找不到时，才尝试自己去加载。自己优先的策略与父类优先相反，它会首先尝试子经济加载，找不到的时候才要父类加载器去加载，这种在web容器（如tomcat）中比较常见。","link":"/2021/10/26/ClassLoading/"},{"title":"EventDispatch","text":"Core事件分发中有一个重要的规则：一个触控点的一个事件序列只能给一个view处理 分析：以DOWN事件为序列分发判定，ViewGroup为消费DOWN事件的View生成一个TouchTarget（这个TouchTarget就包含了该view的实例与触控id，id可以是多个以应对多指触控），后续MOVE、UP都会交给这个TouchTarget。如果TouchTarget为空则ViewGroup自己处理。如果viewGroup消费了down事件，那么子view将无法收到任何事件。 除非异常情况： 1、比如ScrollView嵌套ScrollView情况下DOWN事件虽然MOVE事件被外ScrollView拦截而生成CANCEL事件分发给内ScrollView)。 2、界面跳转等情况。 此时View需要对CANCEL事件做一些状态的恢复工作，如终止动画，恢复view大小等等。 viewGroup是如何分发(dispatch)事件的？ viewGroup分发事件信息分为三个步骤：拦截、寻找子控件、派发事件。 第一步会判断当前ViewGroup是否disallowIntercept，如果不是（也就是允许拦截）则调用onInterceptTouchEvent方法判断是否要进行拦截。（如果拦截则直接走自身的onTouchEvent()）第二步是如果这个事件是down事件并且没有拦截或取消，那么需要为他寻找一个消费此事件的子控件，如果找到则为他创建一个TouchTarget。第三步是派发事件，如果存在TouchTarget，说明找到了消费事件序列的子view，直接分发给他。如果没有则交给自己处理。 View的enable属性不影响onTouchEvent的默认返回值, 哪怕一个View是disable状态. 只要它的clickable或者longClickable有一个为true. 那么它的onTouchEvent()就返回true. 简述：当手指触碰到屏幕时，屏幕硬件底层产生中断上报并通过native层传到Activity开始事件分发。Down事件会使Activity先调用onUserInteration，之后由PhoneWindow（ViewGroup）调用superDispatchTouchEvent将事件分发给DecorView，如果DecorView的View树没有处理则再调用到Activity的onTouchEvent消费。 DecorView事实上是一个最顶层存在的一个FrameLayout，以DecorView开始从顶向下的开始ViewGroup的分发过程：首先判断ViewGroup是否被禁止拦截（ViewGroup.requestDisallowInterceptTouchEvent可使当前ViewGroup及其父至顶都不可拦截事件），没有禁止则先由ViewGroup.onInterceptTouchEvent返回true/false判断是否拦截事件，if true，则事件不再往下传递而是调用拦截者的ViewGroup.onTouchEvent，else 继续往下传递，ViewGroup往其child ViewGroup/View传递。ViewGroup则重复此过程。直到最底的View。 View在View.dispathTouchEvent中分发：先判断本身是否有OnTouchListener且本身状态为enable，由该OnTouchListener.onTouch先处理，由其返回值为true/false，if true 则OnTouchListener已经消费了事件，else 调用View.onTouchEvent进行处理，同样返回true则为View消费了事件，返回false则由其父ViewGroup的onTouchEvent ps:如果View没有消费ACTION_DOWN事件，则之后的ACTION_MOVE等事件都不会再接收。 经典伪代码viewGroup是如何分发(dispatch)事件的？ viewGroup分发事件信息分为三个步骤：拦截、寻找子控件、派发事件。 第一步会判断当前ViewGroup是否disallowIntercept，如果不是（也就是允许拦截）则调用onInterceptTouchEvent方法判断是否要进行拦截。（如果拦截则直接走自身的onTouchEvent()）第二步是如果这个事件是down事件并且没有拦截或取消，那么需要为他寻找一个消费此事件的子控件，如果找到则为他创建一个TouchTarget。第三步是派发事件，如果存在TouchTarget，说明找到了消费事件序列的子view，直接分发给他。如果没有则交给自己处理。 具体： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class MViewGroup extends MView implements ViewParent { private MView child; private boolean isChildNeedEvent = false; private boolean isSelfNeedEvent = false; private boolean isDisallowIntercept = false; public MViewGroup(MView child) { this.child = child; // 这里只是示意，实际中不建议这么写，会造成提前发布未构造完成的实例 child.parent = this; } @Override public boolean dispatch(MotionEvent ev) { boolean handled = false; if (ev.getActionMasked() == MotionEvent.ACTION_DOWN) { clearStatus(); if (!isDisallowIntercept &amp;&amp; onIntercept(ev)) { isSelfNeedEvent = true; handled = onTouch(ev); }else{ handled = child.dispatch(ev); if (handled) isChildNeedEvent = true; if (!handled) { // 这里没有用 if else 是因为这样写上下一致，更清晰 handled = onTouch(ev); if (handled) isSelfNeedEvent = true; // 这一步有没有必要呢？还是有的，会更清晰，否则下面的else要多写一个不太清晰的else } } } else { // 这里 isSelfNeedEvent 条件判断应该放在 isChildNeedEvent 前面 // 因为两个都为真的情况只能是自己之后通过 onIntercept 抢了控制权，那这之后的控制权就不会去 child 那儿了 // 真实源码中 mFirstTouchTarget（TouchTarget类）用来记录消费了DOWN事件的子View，即如果为空也就意味着DOWN事件会由自身处理。 // if (mFirstTouchTarget == null) isSelfNeedEvent = true 相当于 isChildNeedEvent = false, if (isSelfNeedEvent) { handled = onTouch(ev); } else if (isChildNeedEvent) { if (!isDisallowIntercept &amp;&amp; onIntercept(ev)) { isSelfNeedEvent = true; MotionEvent cancel = MotionEvent.obtain(ev); cancel.setAction(MotionEvent.ACTION_CANCEL); handled = child.dispatch(cancel); cancel.recycle(); } else { handled = child.dispatch(ev); } } // 这里不用再 else 了，因为如果 isSelfNeedEvent 和 isChildNeedEvent 都不为 true，上面不会再发事件下来了 } if (ev.getActionMasked() == MotionEvent.ACTION_UP || ev.getActionMasked() == MotionEvent.ACTION_CANCEL) { this.clearStatus(); } return handled; } private void clearStatus() { isChildNeedEvent = false; isSelfNeedEvent = false; isDisallowIntercept = false; } public boolean onIntercept(MotionEvent ev) { return false; } @Override public boolean onTouch(MotionEvent ev) { return false; } @Override public void requestDisallowInterceptTouchEvent(boolean isDisallowIntercept) { this.isDisallowIntercept = isDisallowIntercept; if (parent != null) { parent.requestDisallowInterceptTouchEvent(isDisallowIntercept); } }} 简单： 12345678910111213public boolean dispatchTouchEvent(MotionEvent event) { boolean consume = false; //表示这个事件最终的处理结果 if (onInterceptTouchEvent(event)){ //事件被拦截自己处理 consume = onTouchEvent(event); }else{ //事件被分发到子view的dispatchTouchEvent()中 consume = child.dispatchTouchEvent(event); } return consume;} 流程图 onInterceptTouchEvent返回值true表示事件拦截， onTouch/onTouchEvent 返回值true表示事件消费。 触摸事件先交由Activity.dispatchTouchEvent。再一层层往下分发，当中间的ViewGroup都不拦截时，进入最底层的View后，开始由最底层的OnTouchEvent来处理，如果一直不消费，则最后返回到Activity.OnTouchEvent。 ViewGroup才有onInterceptTouchEvent拦截方法。在分发过程中，中间任何一层ViewGroup都可以直接拦截，则不再往下分发，而是交由发生拦截操作的ViewGroup的OnTouchEvent来处理。 子View可调用requestDisallowInterceptTouchEvent方法，来设置disallowIntercept=true，从而阻止父ViewGroup的onInterceptTouchEvent拦截操作。 OnTouchEvent由下往上冒泡时，当中间任何一层的OnTouchEvent消费该事件，则不再往上传递，表示事件已处理。 如果View没有消费ACTION_DOWN事件，则之后的ACTION_MOVE等事件都不会再接收。 只要View.onTouchEvent是可点击或可长按，则消费该事件. onTouch优先于onTouchEvent执行，上面流程图中省略，onTouch的位置在onTouchEvent前面。当onTouch返回true,则不执行onTouchEvent,否则会执行onTouchEvent。onTouch只有View设置了OnTouchListener，且是enable的才执行该方法。 那主要的分发流程是什么： 在程序的主界面情况下，布局的顶层view是DecorView，他会先把事件交给Activity，Activity调用PhoneWindow的方法进行分发，PhoneWindow会调用DecorView的父类ViewGroup的dispatchTouchEvent方法进行分发。也就是Activity-&gt;Window-&gt;ViewGroup的流程。ViewGroup则会向下去寻找合适的控件并把事件分发给他。 事件一定会经过Activity吗？ 不是的。我们的程序界面的顶层viewGroup，也就是decorView中注册了Activity这个callBack，所以当程序的主界面接收到事件之后会先交给Activity。但是，如果是另外的控件树，如dialog、popupWindow等事件流是不会经过Activity的。只有自己界面的事件才会经Activity。 Activity的分发方法中调用了onUserInteraction()方法，你能说说这个方法有什么作用吗？ 好的。这个方法在Activity接收到down的时候会被调用，本身是个空方法，需要开发者自己去重写。通过官方的注释可以知道，这个方法会在我们以任意的方式开始与Activity进行交互的时候被调用。比较常见的场景就是屏保：当我们一段时间没有操作会显示一张图片，当我们开始与Activity交互的时候可在这个方法中取消屏保；另外还有没有操作自动隐藏工具栏，可以在这个方法中让工具栏重新显示。 前面你讲到最后会分发到viewGroup，那么viewGroup是如何分发事件的？ viewGroup处理事件信息分为三个步骤：拦截、寻找子控件、派发事件。 事件分发中有一个重要的规则：一个触控点的一个事件序列只能给一个view处理，除非异常情况。所以如果viewGroup消费了down事件，那么子view将无法收到任何事件。 viewGroup第一步会判读这个事件是否需要分发给子view，如果是则调用onInterceptTouchEvent方法判断是否要进行拦截。第二步是如果这个事件是down事件，那么需要为他寻找一个消费此事件的子控件，如果找到则为他创建一个TouchTarget。第三步是派发事件，如果存在TouchTarget，说明找到了消费事件序列的子view，直接分发给他。如果没有则交给自己处理。 你前面讲到“一个触控点的一个事件序列只能给一个view处理，除非异常情况”,这里有什么异常情况呢？如果发生异常情况该如何处理？ 这里的异常情况主要有两点：1.被viewGroup拦截，2.出现界面跳转等其他情况。 当事件流中断时，viewGroup会发送一个ACTION_CANCEL事件给到view，此时需要做一些状态的恢复工作，如终止动画，恢复view大小等等。 哦？说到多指，那你知道ViewGroup是如何将多个手指产生的事件准确分发给不同的子view吗 这个问题的关键在于MotionEvent以及ViewGroup内部的TouchTarget。 每个MotionEvent中都包含了当前屏幕所有触控点的信息，他的内部用了一个数组来存储不同的触控id所对应的坐标数值。 当一个子view消费了down事件之后，ViewGroup会为该view创建一个TouchTarget，这个TouchTarget就包含了该view的实例与触控id。这里的触控id可以是多个，也就是一个view可接受多个触控点的事件序列。 当一个MotionEvent到来之时，ViewGroup会将其中的触控点信息拆开，再分别发送给感兴趣的子view。从而达到精准发送触控点信息的目的。 那view支持处理多指信息吗？ View默认是不支持的。他在获取触控点信息的时候并没有传入触控点索引，也就是获取的是MotionEvent内部数组中的第一个触控点的信息。多指需要我们自己去重写方法支持他。 嗯嗯…那View是如何处理触摸事件的？ 首先，他会判断是否存在onTouchListener，存在则会调用他的onTouch方法来处理事件。如果该方法返回true那么就分发结束直接返回。而如果该监听器为null或者onTouch方法返回了false，则会调用onTouchEvent方法来处理事件。 onTouchEvent方法中支持了两种监听器：onClickListener和onLongClickListener。View会根据不同的触摸情况来调用这两个监听器。同时进入到onTouchEvent方法中，无论该view是否是enable，只要是clickable，他的分发方法都是返回true。 总结一下就是：先调用onTouchListener，再调用onClickListener和onLongClickListener。 View 是最后一个处理事件分发的节点了为什么了还会有dispatchTouchEvent呢？ 是因为,在该方法中,要对view的长按事件,触摸事件,点击事件进行调度处理 整理自：Android事件分发机制 - Gityuan博客 | 袁辉辉的技术博客 (32条消息) Android事件分发机制五：面试官你坐啊_一只修仙的猿-CSDN博客_android事件分发机制面试 相关源码Activity和PhoneWindow相关Activity是Android四大基本组件之一，当手指触摸到屏幕时，屏幕硬件一行行不断地扫描每个像素点，获取到触摸事件后，从底层产生中断上报。再通过native层调用Java层InputEventReceiver中的dispatchInputEvent方法。经过层层调用，交由Activity的dispatchTouchEvent方法来处理。 1234567891011121314151617181920212223242526#Activity.javaclass Activity extends...implement ... { public boolean dispatchTouchEvent(MotionEvent ev) { if (ev.getAction() == MotionEvent.ACTION_DOWN) { //第一次按下操作时，用户希望能与设备进行交互，可通过实现该方法 onUserInteraction(); } //获取当前Activity的顶层窗口是PhoneWindow [见PhoneWindow] if (getWindow().superDispatchTouchEvent(ev)) { return true; } //当没有任何view处理时，交由activity的onTouchEvent处理 return onTouchEvent(ev); // [见小节2.2.1] } public boolean onTouchEvent(MotionEvent event) { //当窗口需要关闭时，消费掉当前event if (mWindow.shouldCloseOnTouch(this, event)) { finish(); return true; } return false; } } PhoneWindow的最顶View是DecorView，再交由DecorView处理。而DecorView的父类的父类是ViewGroup,接着调用 ViewGroup.dispatchTouchEvent()方法。 123456#PhoneWindow.javaPhoneWindow implement Window { public boolean superDispatchTouchEvent(KeyEvent event) { return mDecor.superDispatcTouchEvent(event); // [见小节2.4] }} ViewGroup首先判断ViewGroup是否被禁止拦截（ViewGroup.requestDisallowInterceptTouchEvent可使当前ViewGroup及其父至顶都不可拦截事件），没有禁止则先由ViewGroup.onInterceptTouchEvent返回true/false判断是否拦截事件，if true，则事件不再往下传递而是调用拦截者的ViewGroup.onTouchEvent，else 继续往下传递。 dispatchTransformedTouchEvent是真正处理ViewGroup事件的方法，其中会判断是否当前ViewGroup如果已经没有child ViewGroup/View了，则由自身的onTouchEvent处理；有的话ViewGroup 遍历child传入该方法中判断点击坐标是否在child区域中，是则调用对应child ViewGroup/View的dispatchTouchEvent分发。 ViewGroup则重复此过程。直到最底的View。 只有当Down事件被dispatchTouchEvent接受时才会继续处理其系列MOVE、UP等事件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154public boolean dispatchTouchEvent(MotionEvent ev) { ... boolean handled = false; //根据隐私策略而来决定是否过滤本次触摸事件, if (onFilterTouchEventForSecurity(ev)) { // [见小节2.4.1] final int action = ev.getAction(); final int actionMasked = action &amp; MotionEvent.ACTION_MASK; if (actionMasked == MotionEvent.ACTION_DOWN) { // 发生ACTION_DOWN事件, 则取消并清除之前所有的触摸targets cancelAndClearTouchTargets(ev); resetTouchState(); // 重置触摸状态 } // 发生ACTION_DOWN事件或者已经发生过ACTION_DOWN;才进入此区域，主要功能是拦截器 //只有发生过ACTION_DOWN事件，则mFirstTouchTarget != null; final boolean intercepted; if (actionMasked == MotionEvent.ACTION_DOWN || mFirstTouchTarget != null) { //可通过调用requestDisallowInterceptTouchEvent，当前ViewGroup及其到顶的父ViewGroup禁止拦截事件 final boolean disallowIntercept = (mGroupFlags &amp; FLAG_DISALLOW_INTERCEPT) != 0; //判断是否允许调用拦截器 if (!disallowIntercept) { //调用拦截方法 intercepted = onInterceptTouchEvent(ev); // [见小节2.4.2] ev.setAction(action); } else { intercepted = false; } } else { // 当没有触摸targets，且不是down事件时，开始持续拦截触摸。 intercepted = true; } ... //不取消事件，同时不拦截事件, 并且是Down事件才进入该区域 if (!canceled &amp;&amp; !intercepted) { //把事件分发给所有的子视图，寻找可以获取焦点的视图。 View childWithAccessibilityFocus = ev.isTargetAccessibilityFocus() ? findChildWithAccessibilityFocus() : null; if (actionMasked == MotionEvent.ACTION_DOWN || (split &amp;&amp; actionMasked == MotionEvent.ACTION_POINTER_DOWN) || actionMasked == MotionEvent.ACTION_HOVER_MOVE) { //...... if (newTouchTarget == null &amp;&amp; childrenCount != 0) { //...... for (int i = childrenCount - 1; i &gt;= 0; i--) { //...... 省略若干代码...... //重置取消或抬起标志位 //如果触摸位置在child的区域内，则把事件分发给子View或ViewGroup //================ &lt;mark&gt; dispatchTransformedTouchEvent &lt;!mark&gt;================ if (dispatchTransformedTouchEvent(ev, false, child, idBitsToAssign)) { // [见小节2.4.4] // 获取TouchDown的时间点 mLastTouchDownTime = ev.getDownTime(); // 获取TouchDown的Index if (preorderedList != null) { for (int j = 0; j &lt; childrenCount; j++) { if (children[childIndex] == mChildren[j]) { mLastTouchDownIndex = j; break; } } } else { mLastTouchDownIndex = childIndex; } //获取TouchDown的x,y坐标 mLastTouchDownX = ev.getX(); mLastTouchDownY = ev.getY(); //添加TouchTarget,则mFirstTouchTarget != null。 [见小节2.4.5] //=========================！addTouchTarget！========================== newTouchTarget = addTouchTarget(child, idBitsToAssign); //表示已经分发给NewTouchTarget alreadyDispatchedToNewTouchTarget = true; break; } ev.setTargetAccessibilityFocus(false); } // 清除视图列表 if (preorderedList != null) preorderedList.clear(); } if (newTouchTarget == null &amp;&amp; mFirstTouchTarget != null) { //将mFirstTouchTarget的链表最后的touchTarget赋给newTouchTarget newTouchTarget = mFirstTouchTarget; while (newTouchTarget.next != null) { newTouchTarget = newTouchTarget.next; } newTouchTarget.pointerIdBits |= idBitsToAssign; } } } // mFirstTouchTarget赋值是在通过addTouchTarget方法获取的； // 只有处理ACTION_DOWN事件，才会进入addTouchTarget方法。 // 这也正是当View没有消费ACTION_DOWN事件，则不会接收其他MOVE,UP等事件的原因 if (mFirstTouchTarget == null) { //没有触摸target,则由当前ViewGroup来处理。 //================&lt;mark&gt; dispatchTransformedTouchEvent &lt;!mark&gt;================ handled = dispatchTransformedTouchEvent(ev, canceled, null, TouchTarget.ALL_POINTER_IDS); } else { //如果View消费ACTION_DOWN事件，那么MOVE,UP等事件相继开始执行 TouchTarget predecessor = null; TouchTarget target = mFirstTouchTarget; while (target != null) { final TouchTarget next = target.next; if (alreadyDispatchedToNewTouchTarget &amp;&amp; target == newTouchTarget) { handled = true; } else { final boolean cancelChild = resetCancelNextUpFlag(target.child) || intercepted; if (dispatchTransformedTouchEvent(ev, cancelChild, target.child, target.pointerIdBits)) { handled = true; } if (cancelChild) { if (predecessor == null) { mFirstTouchTarget = next; } else { predecessor.next = next; } target.recycle(); target = next; continue; } } predecessor = target; target = next; } } //当发生抬起或取消事件，更新触摸targets if (canceled || actionMasked == MotionEvent.ACTION_UP || actionMasked == MotionEvent.ACTION_HOVER_MOVE) { resetTouchState(); } else if (split &amp;&amp; actionMasked == MotionEvent.ACTION_POINTER_UP) { final int actionIndex = ev.getActionIndex(); final int idBitsToRemove = 1 &lt;&lt; ev.getPointerId(actionIndex); removePointersFromTouchTargets(idBitsToRemove); } } //此处大括号，是if (onFilterTouchEventForSecurity(ev))的结尾 //通知verifier由于当前时间未处理，那么该事件其余的都将被忽略 if (!handled &amp;&amp; mInputEventConsistencyVerifier != null) { mInputEventConsistencyVerifier.onUnhandledEvent(ev, 1); } return handled;} 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071private boolean dispatchTransformedTouchEvent(MotionEvent event, boolean cancel, View child, int desiredPointerIdBits) { final boolean handled; // 发生取消操作时，不再执行后续的任何操作 final int oldAction = event.getAction(); if (cancel || oldAction == MotionEvent.ACTION_CANCEL) { event.setAction(MotionEvent.ACTION_CANCEL); if (child == null) { handled = super.dispatchTouchEvent(event); } else { handled = child.dispatchTouchEvent(event); } event.setAction(oldAction); return handled; } final int oldPointerIdBits = event.getPointerIdBits(); final int newPointerIdBits = oldPointerIdBits &amp; desiredPointerIdBits; //由于某些原因，发生不一致的操作，那么将抛弃该事件 if (newPointerIdBits == 0) { return false; } //分发的主要区域 final MotionEvent transformedEvent; //判断预期的pointer id与事件的pointer id是否相等 if (newPointerIdBits == oldPointerIdBits) { if (child == null || child.hasIdentityMatrix()) { if (child == null) { //不存在子视图时，ViewGroup调用View.dispatchTouchEvent分发事件，再调用ViewGroup.onTouchEvent来处理事件 handled = super.dispatchTouchEvent(event); // [见小节2.4] } else { final float offsetX = mScrollX - child.mLeft; final float offsetY = mScrollY - child.mTop; event.offsetLocation(offsetX, offsetY); //将触摸事件分发给子ViewGroup或View; //如果是ViewGroup，则调用代码(2.1)； //如果是View，则调用代码(3.1)； handled = child.dispatchTouchEvent(event); event.offsetLocation(-offsetX, -offsetY); //调整该事件的位置 } return handled; } transformedEvent = MotionEvent.obtain(event); //拷贝该事件，来创建一个新的MotionEvent } else { //分离事件，获取包含newPointerIdBits的MotionEvent transformedEvent = event.split(newPointerIdBits); } if (child == null) { //不存在子视图时，ViewGroup调用View.dispatchTouchEvent分发事件，再调用ViewGroup.onTouchEvent来处理事件 handled = super.dispatchTouchEvent(transformedEvent); // [见小节2.4] } else { final float offsetX = mScrollX - child.mLeft; final float offsetY = mScrollY - child.mTop; transformedEvent.offsetLocation(offsetX, offsetY); if (! child.hasIdentityMatrix()) { //将该视图的矩阵进行转换 transformedEvent.transform(child.getInverseMatrix()); } //将触摸事件分发给子ViewGroup或View; //如果是ViewGroup，则 [见小节2.4]; 如果是View，则[见小节2.5]; handled = child.dispatchTouchEvent(transformedEvent); } //回收transformedEvent transformedEvent.recycle(); return handled;} 123456private TouchTarget addTouchTarget(View child, int pointerIdBits) { TouchTarget target = TouchTarget.obtain(child, pointerIdBits); target.next = mFirstTouchTarget; mFirstTouchTarget = target; return target;} View12345678910111213141516171819202122232425262728293031323334353637public boolean dispatchTouchEvent(MotionEvent event) { ... final int actionMasked = event.getActionMasked(); if (actionMasked == MotionEvent.ACTION_DOWN) { //在Down事件之前，如果存在滚动操作则停止。不存在则不进行操作 stopNestedScroll(); } // mOnTouchListener.onTouch优先于onTouchEvent。 if (onFilterTouchEventForSecurity(event)) { //当存在OnTouchListener，且视图状态为ENABLED时，调用onTouch()方法 ListenerInfo li = mListenerInfo; if (li != null &amp;&amp; li.mOnTouchListener != null &amp;&amp; (mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; li.mOnTouchListener.onTouch(this, event)) { result = true; //如果已经消费事件，则返回True } //如果OnTouch（)没有消费Touch事件则调用OnTouchEvent() if (!result &amp;&amp; onTouchEvent(event)) { // [见小节2.5.1] result = true; //如果已经消费事件，则返回True } } if (!result &amp;&amp; mInputEventConsistencyVerifier != null) { mInputEventConsistencyVerifier.onUnhandledEvent(event, 0); } // 处理取消或抬起操作 if (actionMasked == MotionEvent.ACTION_UP || actionMasked == MotionEvent.ACTION_CANCEL || (actionMasked == MotionEvent.ACTION_DOWN &amp;&amp; !result)) { stopNestedScroll(); } return result;}","link":"/2021/04/10/EventDispatch/"},{"title":"FirstScreenCost.md","text":"Activity启动耗时首先：测试方法： AMS会打印启动Activity的耗时，Android 10之后打印tag为ActivityTaskManager，Android10之前打印ActivityManager; 在Android 10（Q）版本中，Android系统引入了ActivityTaskManager（ATM），并在很大程度上取代了之前的ActivityManagerService（AMS）的许多职责。具体来说，AMS负责管理整个系统的活动生命周期和任务堆栈，而在Android 10中，这些职责被重新分配并分离到新的ActivityTaskManager和ActivityManager中。 ActivityTaskManager专注于任务和活动的管理，处理任务堆栈的操作和活动的启动、切换等。而ActivityManager则更多地处理与应用进程管理相关的功能，如进程的生命周期、内存管理等。 这一改变是为了简化代码结构、提升系统的模块化和可维护性，同时也是为了更好地支持多窗口和多任务操作等新的特性。 总结起来，ActivityTaskManager的引入和实现从Android 10开始正式应用，取代了原有的部分ActivityManagerService的功能。 ActivityManager : Display / startActivity Android6/7 简单结论：display 只统计A onPause之后（不包含A onPause） AMS 启动新ActivityB 并 执行 B的onCreate、onstart、onresume 与 B向WMS注册窗口到编舞者发起的第一次测绘 完成 Activity的启动可以分为三个步骤，以ActivityA启动ActivityB为例，三步骤分别为： 以ActivityA调用startActivity，到ActivityA成功pause为止 displayTimeStart ActivityB成功初始化，到执行完resume为止 ActivityB向WSM注册窗口，到第一帧绘制完成为止displayTimeEnd","link":"/2024/06/04/FirstScreenCost/"},{"title":"empty","text":"PackageManagerService WindowManagerService(done?) ActivityManagerService(done?) ServiceManager(done?) Binder ANR 1、reviewkernel bright spots Apm监控 fresco深入优化 性能优化工作/工具 skills pool recyclerview缓存和优化 app、android启动流程 编译流程 编舞者以及屏幕刷新原理（与耗时方法监听之） 插件化（代理和hook两种方式） handler https&amp;http（http version） hashmap Matrix为主，Dokit、blockcanary等APM框架 Jmm与GC算法（深入理解java虚拟机-标记清除之类） tcp滑动窗口之类（就找一篇文章like腾讯之前的那篇tcp ip问题彻底弄懂TCP协议：从三次握手说起 (qq.com)） leakCanary、retrofit、okhttp、glide、 threadLocal、Rv四级缓存 2、TODO kotlin协程 锁 算法（1~2） View测绘，事件分发（事件系列只能被整一个处理） SurfaceView, TextureView及View的区别。SurfaceView怎么控制它处于的层级 SMTP了解下 3、Optimize Experience 图片内存优化工作：fresco关于gif缓存问题修复，dokit图片闪烁缓存失效问题的修复、基于dokit框架（ASM）下尺寸过大图片识别实现。（基于业务做的一些图片加载的优化，如cdn链接统一域名，regex（String.replace）耗时200us） 耗时方法，两种常见的监听方式：looper.printer 以及 编舞者回调监听 recyclerview优化 4、Other h5图片缓存共用的优化思路 阿里patron和Metrix做的native hook 减少32bit模式下app内存占用 Project Experience从购物车重构到购物车预加载ps:我并不想抽象的去将购物车的架构之类的东西，而是更具体的讲遇到的问题及解决方案。不过还是得简单讲一下设计 购物车代码十分屎山，难以维护。在23年时做了一次历经一个月的重构，边开车边换轮子。使用多数业务在用的协议架构奥创重构：先说收益：奥创加购以组件为单位，职责清晰，易于复用维护，端侧组件使用MVVM架构进一步解耦逻辑： 举个例子，请求在model层（共用的Repository，维护于Engine层），每个组件通过注册组件的ViewHolder获得独立的View，注册组件的Parser获得独立的ViewModel解析数据及进行业务逻辑处理。view与vm之间使用liveData进行数据更新后的通知view状态渲染。 遇到的问题： 奥创冗余数据及后端接口慢 -&gt; 购物车本地数据缓存 + （detail/购物车进下单页）的数据预加载 + 购物车预加载的根据abtest下做的精细运营。 LiveData的使用：购物车提供给MainActiivty的其他Tab由于时机问题导致的刷新问题 多国家配置不同组件 -&gt; 问题：一些组件不同国家需要配置不同的样式和逻辑，但是下发的组件名是一致的。那么当时有两种做法：一种是直接在解析是篡改掉网络数据中的组件名，本地正常映射。但是这个评估完认为直接修改了数据，风险更不好控。于是我在注册组件名时根据依靠 同名Parser后注册的Parser优先匹配的机制 实现 的特性，在注册Parser时提供将多国家的parser后置接口，于是当解析完多国家组件parser后即不会再映射通用组件了，即不影响原数据，也实现了多国家不新增后端组件。 RTL adapte What: Ltr下不同币种导致的显示顺序错乱； How: 服务端配置下发特殊符号 More: 做过印象比较深的事情 ，有挑战的事情 弱网环境优化：业务和技术的手段，有什么很技术的手段来做吗 当前团队的优劣点 遇到不合理需求你会怎么拒绝 有用过新的东西吗 线上问题怎么解决，因为不能用动态字节码技术 遇到啥有意思的问题吗，crash。window 123456789101112131415161718192021222324252627282930313233343536373839java.lang.IllegalArgumentException: View=android.widget.PopupWindow$PopupDecorView{2a10009 V.E...... R.....I. 0,0-0,0} not attached to window manager at android.view.WindowManagerGlobal.findViewLocked(WindowManagerGlobal.java:544) at android.view.WindowManagerGlobal.updateViewLayout(WindowManagerGlobal.java:433) at android.view.WindowManagerImpl.updateViewLayout(WindowManagerImpl.java:162) at android.widget.PopupWindow.update(PopupWindow.java:2226) at android.widget.PopupWindow.update(PopupWindow.java:2347) at android.widget.PopupWindow.alignToAnchor(PopupWindow.java:2517) at android.widget.PopupWindow.-$$Nest$malignToAnchor(Unknown Source:0) at android.widget.PopupWindow$1.onViewAttachedToWindow(PopupWindow.java:243) at android.view.View.dispatchAttachedToWindow(View.java:21423) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3502) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3509) at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:3011) at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:2518) at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:9389) at android.view.Choreographer$CallbackRecord.run(Choreographer.java:1451) at android.view.Choreographer$CallbackRecord.run(Choreographer.java:1459) at android.view.Choreographer.doCallbacks(Choreographer.java:1089) at android.view.Choreographer.doFrame(Choreographer.java:1003) at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:1431) at android.os.Handler.handleCallback(Handler.java:942) at android.os.Handler.dispatchMessage(Handler.java:99) at android.os.Looper.loopOnce(Looper.java:210) at android.os.Looper.loop(Looper.java:299) at android.app.ActivityThread.main(ActivityThread.java:8261) at java.lang.reflect.Method.invoke(Native Method) at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:559) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:954) OOM的治理：crash率在一次架构组的升级后由万4涨到万6，其中新增了很多的OOM。1：修复了EventCenter的内存泄露；2：搜推服务造成的泄露； 内存兜底措施：2g设备直接改为RGB565，其他才开ARGB8888；同时降低起设备图片内存池大小;","link":"/2021/07/30/Emty/"},{"title":"fresco","text":"Fresco（2.5.0）以MVC的 Fresco架构入手，层层递进分析fresco的整体思路。 个人理解会将 图中的UI层进一步分为 DraweeView为View层（负责渲染），DraweeHierarchy为Model层（记录配置与数据Drawable[6]），DraweeController为Controller层（分离PorducerSequence加载缓存责任链条） ps：MVC现在很多变种中都会有View层与Model层 交互，View层与Controller层 交互。但一般都不会有Model持有Controller。所以我会将fresco理解为MVC。 View—DraweeView也就是我们直接接触到的具体实现类 SimpleDraweeView 。早期是继承imageView类的，后来是改成view并由draweeView自己渲染图层 继承于 View, 负责图片的显示。持有DraweeHolder （DraweeHolder中含有的model层 和 DraweeController 的controller层）。//见上图 SimpleDraweeView中，setImageUrl方法中直接调用 1AbstractDraweeControllerBuilder.build() 以构造Controller。 至于AbstractDraweeControllerBuilder唯一继承类，是PipelineDraweeControllerBuilder。 PipelineDraweeControllerBuilder中obtainController是借助PipelineDraweeControllerFactory完成的 具体看下面的Controler—DraweeController解析 Model—DraweeHierarchy直接用到的是GenericDraweeHierarchy，这一层保存和管理图片的六个图层（layers），如果有overlay的话再加一层 Fresco 图片渲染 —— 六层drawable1234567public class DraweeView&lt;DH extends DraweeHierarchy&gt; extends ImageView { public void setController(@Nullable DraweeController draweeController) { mDraweeHolder.setController(draweeController); super.setImageDrawable(mDraweeHolder.getTopLevelDrawable()); }} 在调用SimpleDraweeView.setImageUri()时会调用到DraweeView.setController(),即此时是直接显示的mDraweeHolder.getTopLevelDrawable(): DraweeHolder.java 123public @Nullable Drawable getTopLevelDrawable() { return mHierarchy == null ? null : mHierarchy.getTopLevelDrawable();} 所以最终的显示的Drawable是mHierarchy.getTopLevelDrawable()。mHierarchy的实现是GenericDraweeHierarchy。mHierarchy.getTopLevelDrawable()获取的Drawable实际上可以理解为FadeDrawable: GenericDraweeHierarchy.java 12345GenericDraweeHierarchy(GenericDraweeHierarchyBuilder builder) { mFadeDrawable = new FadeDrawable(layers); Drawable maybeRoundedDrawable = WrappingUtils.maybeWrapWithRoundedOverlayColor(mFadeDrawable, mRoundingParams); mTopLevelDrawable = new RootDrawable(maybeRoundedDrawable); //RootDrawable 只是一个装饰类} FadeDrawable内部维护着一个Drawable数组，它可以由一个Drawable切换到另一个Drawable，Drawable的切换过程中伴有着透明度改变的动画: 12345678910111213public class FadeDrawable extends ArrayDrawable { private final Drawable[] mLayers; @Override public void draw(Canvas canvas) { ...更新Drawable的透明度 //从前往后一层一层的画出来 for (int i = 0; i &lt; mLayers.length; i++) { drawDrawableWithAlpha(canvas, mLayers[i], mAlphas[i] * mAlpha / 255); } }} 主要有顶级图层，占位符图层，目标显示图层，重新加载图层，显示失败图层， 进度条图层，控制覆盖图层 DraweeHierarchy由DraweeController直接持有的，DraweeController通过DataSource能轻易得到各个图片加载时机，因此对于不同图片显示的切换操作具体是由DraweeController来直接操作的。 Controler—DraweeController关键词：依赖注入（控制反转的思想）、责任链、生产者消费者、构建者 fresco中具体实现为PipelineDraweeController，集成关系： 1public class PipelineDraweeController extends AbstractDraweeController 12345678910public abstract class AbstractDraweeController&lt;T, INFO&gt; implements DraweeController { public void onAttach() { } public void onDetach() { } protected void submitRequest() { }} 1public interface DraweeController DraweeController与DataSource直接交互，通过DataSource控制ProducterSequence以 责任链模式的思想 加载图片。 从 bitmap对象 到 未解码图片的内存缓存 到 图片的磁盘缓存 到 网络拉取 DraweeController的构造在Fresco中DraweeController是通过DraweeControllerBuilder来构造的。而DraweeControllerBuilder在Fresco中是以单例的形式存在的。Fresco在初始化时会调用下面的代码: Fresco.java 1234private static void initializeDrawee(Context context, @Nullable DraweeConfig draweeConfig) { sDraweeControllerBuilderSupplier = new PipelineDraweeControllerBuilderSupplier(context, draweeConfig); SimpleDraweeView.initialize(sDraweeControllerBuilderSupplier);} 所以所有的DraweeController都是通过同一个DraweeControllerBuilder来构造的。Fresco每次图片加载都会对应到一个DraweeController，一个DraweeView的多次图片加载可以复用同一个DraweeController: SimpleDraweeView.java 123456789public void setImageURI(Uri uri, @Nullable Object callerContext) { DraweeController controller = mControllerBuilder .setCallerContext(callerContext) .setUri(uri) //设置新的图片加载路径 .setOldController(getController()) //复用 controller .build(); setController(controller);} 所以一般情况下 : **一个DraweeView对应一个DraweeController**。由于DraweeController很重，所以使用obtainController() 回收利用并ControllerBuilder提供setOldController()传入draweeView复用DraweeController 通过DataSource发起图片加载在前面已经说了DraweeController是直接持有DraweeHierachy，所以它观察到ProducerSequence的数据变化是可以很容易更新到DraweeHierachy（具体代码先不展示了）。那它是如何控制ProducerSequence来加载图片的呢？其实DraweeController并不会直接和ProducerSequence发生关联。对于图片的加载，它直接接触的是DataSource，由DataSource进而来控制ProducerSequence发起图片加载和处理流程。下面就跟随源码来看一下DraweeController是如果通过DataSource来控制ProducerSequence发起图片加载和处理流程的。 DraweeController发起图片加载请求的方法是(AbstractDraweeController.java): 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970protected void submitRequest() { final T closeableImage = getCachedImage(); //从mImagePipeline.getBitmapMemoryCache()中寻找内存（解码后）是否存在 if(closeableImage != null) { //处理获取图像结果 onNewResultInternal(mId, mDataSource, closeableImage, 1.0f, true, true, true); } mDataSource = getDataSource(); final DataSubscriber&lt;T&gt; dataSubscriber = new BaseDataSubscriber&lt;T&gt;() { //可以简单的把它理解为一个监听者 @Override public void onNewResultImpl(DataSource&lt;T&gt; dataSource) { //图片加载回调 boolean isFinished = dataSource.isFinished(); boolean hasMultipleResults = dataSource.hasMultipleResults(); float progress = dataSource.getProgress(); T image = dataSource.getResult(); if (image != null) { //加载成功，处理图像结果 onNewResultInternal( id, dataSource, image, progress, isFinished, wasImmediate, hasMultipleResults); } else if (isFinished){ //处理失败 onFailureInternal(id, dataSource, new NullPointerException(), /* isFinished */ true); } } ... }; ... mDataSource.subscribe(dataSubscriber, mUiThreadImmediateExecutor); //mUiThreadImmediateExecutor是指 dataSubscriber 回调方法运行的线程，这里是主线程}private void onNewResultInternal( String id, DataSource&lt;T&gt; dataSource, @Nullable T image, float progress, boolean isFinished, boolean wasImmediate, boolean deliverTempResult) { // create drawable Drawable drawable; try { drawable = createDrawable(image); } catch (Exception exception) { ... return; } T previousImage = mFetchedImage; Drawable previousDrawable = mDrawable; mFetchedImage = image; mDrawable = drawable; try { // set the new image if (isFinished) { //完成加载，设置Hierarchy（View层）图层，并由controller监听器回调切换图层 mSettableDraweeHierarchy.setImage(drawable, 1f, wasImmediate); getControllerListener().onFinalImageSet(id, getImageInfo(image), getAnimatable()); } else if (deliverTempResult) { ... } else { ... } } finally { //释放图像资源 ... releaseDrawable(previousDrawable); ... releaseImage(previousImage); } } 那DataSource是什么呢？ getDataSource()最终会调用到: ImagePipeline.java 12345678910111213141516public DataSource&lt;CloseableReference&lt;CloseableImage&gt;&gt; fetchDecodedImage(ImageRequest imageRequest,...) { //获取加载图片的ProducerSequence Producer&lt;CloseableReference&lt;CloseableImage&gt;&gt; producerSequence = mProducerSequenceFactory.getDecodedImageProducerSequence(imageRequest); return submitFetchRequest( producerSequence, imageRequest, lowestPermittedRequestLevelOnSubmit, callerContext, requestListener);}private &lt;T&gt; DataSource&lt;CloseableReference&lt;T&gt;&gt; submitFetchRequest(...) { ... return CloseableProducerToDataSourceAdapter.create(producerSequence, settableProducerContext, finalRequestListener);} 所以DraweeController最终拿到的DataSource是CloseableProducerToDataSourceAdapter。这个类在构造的时候就会启动图片加载流程(它的构造方法会调用producer.produceResults(...),这个方法就是图片加载的起点，我们后面再看)。 DataSource小结 Fresco中DataSource的概念以及作用:在Fresco中DraweeController每发起一次图片加载就会创建一个DataSource,这个DataSource用来提供这次请求的数据(图片)。DataSource只是一个接口，至于具体的加载流程Fresco是通过ProducerSequence来实现的。 C层更具体的ProducerSequence怎么实现下载、解码、缓存的下面将进一步说明： ProducerSequenceImagePipeline获取图片时，会根据不同的请求（获取解码图片：fetchDecodedImage，或者获取未解码图片：fetchEncodedImage）生成不同的Producer Sequence，其实就是一个Producer链条，每个Producer只负责整个链条中的一环，例如：NetworkFetchProducer负责下载图片，DecodeProducer负责解码图片等。 Producer的作用:一个Producer用来处理整个Fresco图片处理流程中的一步，比如从网络获取图片、内存获取图片、解码图片等等，而Consumer可以把它理解为监听者。 Producer的处理结果可以通过Consumer来告诉外界，比如是失败还是成功。 一个ProducerA可以接收另一个ProducerB作为参数，如果ProducerA处理完毕后可以调用ProducerB来继续处理。并传入Consumer来观察ProducerB的处理结果。比如Fresco在加载图片时会先去内存缓存获取，如果内存缓存中没有那么就网络加载。这里涉及到两个Producer分别是BitmapMemoryCacheProducer和NetworkFetchProducer，假设BitmapMemoryCacheProducer为ProducerA，NetworkFetchProducer为ProducerB。 见附录：完整ProducerSequence； 这张图描述了Fresco在第一次网络图片时所经历的过程，从图中可以看出涉及到缓存的Producer共有4个:BitmapMemroyCacheGetProducer、BitmapMemoryCacheProducer、EncodedMemoryCacheProducer和DiskCacheWriteProducer。Fresco在加载图片时会按照图中绿色箭头所示依次经过这四个缓存Producer，一旦在某个Producer得到图片请求结果，就会按照蓝色箭头所示把结果依次回调回来。简单介绍一下这4个Producer的功能: BitmapMemroyCacheGetProducer: 这个Producer会去内存缓存中检查这次请求有没命中缓存，如果命中则将缓存的图片作为这次请求结果。 BitmapMemoryCacheProducer: 这个Producer会监听其后面的Producer的Result，并把Result(CloseableImage)存入缓存。 EncodedMemoryCacheProducer: 它也是一个内存缓存，不过它缓存的是未解码的图片，即图片原始字节。 DiskCacheWriteProducer: 顾名思义，它负责把图片缓存到磁盘，它缓存的也是未解码的图片。获取图片时如果命中了磁盘缓存那么就返回缓存的结果。 这里仅以Bitmap内存缓存为例子，展开说明PorducerSequence中其中 磁盘缓存或内存缓存 CacheProducer节点的工作流程： BitmapMemroyCacheGetProducer派生自BitmapMemoryCacheProducer,与BitmapMemoryCacheProducer的不同就是只读不写而已。 大致看一下BitmapMemoryCacheProducer的缓存运作逻辑: BitmapMemoryCacheProducer.java 1234567891011121314151617181920212223242526272829303132333435363738public class BitmapMemoryCacheProducer implements Producer&lt;CloseableReference&lt;CloseableImage&gt;&gt; { private final MemoryCache&lt;CacheKey, CloseableImage&gt; mMemoryCache; //图片缓存的实现 @Override public void produceResults(Consumer&lt;CloseableReference&lt;CloseableImage&gt;&gt; consumer...){ //1.先去缓存中获取 CloseableReference&lt;CloseableImage&gt; cachedReference = mMemoryCache.get(cacheKey); //2.命中缓存直接返回请求结果 if (cachedReference != null) { consumer.onNewResult(cachedReference, BaseConsumer.simpleStatusForIsLast(isFinal)); return; } ... //3.wrapConsumer来观察后续Producer的结果 Consumer&lt;CloseableReference&lt;CloseableImage&gt;&gt; wrappedConsumer = wrapConsumer(consumer..); //4.让下一个Producer继续工作 mInputProducer.produceResults(wrappedConsumer, producerContext); } protected Consumer&lt;CloseableReference&lt;CloseableImage&gt;&gt; wrapConsumer(){ return new DelegatingConsumer&lt;...&gt;(consumer) { @Override public void onNewResultImpl(CloseableReference&lt;CloseableImage&gt; newResult...){ //5.缓存结果 newCachedResult = mMemoryCache.cache(cacheKey, newResult); //6.通知前面的Producer图片请求结果 getConsumer().onNewResult((newCachedResult != null) ? newCachedResult : newResult, status); } } }} 它的主要流程图如下(后面两个缓存的流程与它基本相同，因此对于缓存整体流程只画这一次): ​ BitmapMemoryCacheProducer工作流.png 图中红色箭头和字体是正常网络加载图片(第一次)的步骤 内存缓存 : MemoryCacheMemoryCache是一个接口，在这里它的对应实现是CountingMemoryCache, 先来看一下这个类的构造函数: CountingMemoryCache.java 123456789101112131415public class CountingMemoryCache&lt;K, V&gt; implements MemoryCache&lt;K, V&gt;, MemoryTrimmable { //缓存的集合其实就是一个map，不过这个map使用 Lru 算法 final CountingLruMap&lt;K, Entry&lt;K, V&gt;&gt; mExclusiveEntries; final CountingLruMap&lt;K, Entry&lt;K, V&gt;&gt; mCachedEntries; public CountingMemoryCache(ValueDescriptor&lt;V&gt; valueDescriptor,CacheTrimStrategy cacheTrimStrategy,Supplier&lt;MemoryCacheParams&gt; memoryCacheParamsSupplier) { mValueDescriptor = valueDescriptor;// 用来估算当前缓存实体的大小 mExclusiveEntries = new CountingLruMap&lt;&gt;(wrapValueDescriptor(valueDescriptor)); // 主要存放没有被引用的对象，它的所有元素一定在 mCachedEntries 集合中存在 mCachedEntries = new CountingLruMap&lt;&gt;(wrapValueDescriptor(valueDescriptor)); // 主要缓存集合 mCacheTrimStrategy = cacheTrimStrategy; // trim缓存的策略 (其实就是指定了trim ratio) mMemoryCacheParams = mMemoryCacheParamsSupplier.get(); // 通过 ImagePipelineConfig 来配置的缓存参数 } ...} 通过构造函数可以知道CountingMemoryCache一共含有两个缓存集合 : mCachedEntries : 它是用来存放所有缓存对象的集合 mExclusiveEntries: 它是用来存放当前没有被引用的对象，在trim缓存是，主要是trim掉这个缓存集合的中的对象。 CountingMemoryCache的缓存逻辑主要是围绕这两个集合展开的。接下来看一下它的cache和get的方法(这两个方法是缓存的核心方法)。 将图片保存到内存缓存 : CountingMemoryCache.cache()1234567891011121314151617181920212223242526public CloseableReference&lt;V&gt; cache(K key, CloseableReference&lt;V&gt; valueRef, EntryStateObserver&lt;K&gt; observer) { Entry&lt;K, V&gt; oldExclusive; CloseableReference&lt;V&gt; oldRefToClose = null; CloseableReference&lt;V&gt; clientRef = null; synchronized (this) { oldExclusive = mExclusiveEntries.remove(key); //如果存在的话，从没有引用的缓存集合中清除 Entry&lt;K, V&gt; oldEntry = mCachedEntries.remove(key); //从主缓存集合中移除 if (oldEntry != null) { makeOrphan(oldEntry); oldRefToClose = referenceToClose(oldEntry); } if (canCacheNewValue(valueRef.get())) { //会判断是否到达了当前缓存的最大值 Entry&lt;K, V&gt; newEntry = Entry.of(key, valueRef, observer); // 构造一个缓存实体(Entry) mCachedEntries.put(key, newEntry); //缓存 clientRef = newClientReference(newEntry); } } CloseableReference.closeSafely(oldRefToClose); //可能会调用到 release 方法， ... return clientRef;} 上面代码我做了比较详细的注释。简单的讲就是把这个对象放入到mCachedEntries集合中，如果原来就已经缓存了这个对象，那么就要把它先从mCachedEntries和mExclusiveEntries集合中移除。 Fresco的默认内存缓存大小上面canCacheNewValue()是用来判断当前缓存是否已经达到了最大值。那Fresco内存缓存的最大值是多少呢？这个值可以通过ImagePipelineConfig来配置，如果没有配置的话默认配置是:DefaultBitmapMemoryCacheParamsSupplier: DefaultBitmapMemoryCacheParamsSupplier.java 123456789101112131415161718public class DefaultBitmapMemoryCacheParamsSupplier implements Supplier&lt;MemoryCacheParams&gt; { ... private int getMaxCacheSize() { final int maxMemory = Math.min(mActivityManager.getMemoryClass() * ByteConstants.MB, Integer.MAX_VALUE); if (maxMemory &lt; 32 * ByteConstants.MB) { return 4 * ByteConstants.MB; } else if (maxMemory &lt; 64 * ByteConstants.MB) { return 6 * ByteConstants.MB; } else { if (Build.VERSION.SDK_INT &lt; Build.VERSION_CODES.HONEYCOMB) { return 8 * ByteConstants.MB; } else { return maxMemory / 4; } } }} 即Fresco的默认缓存大小是根据当前应用的运行内存来决定的，对于应用运行内存达到64MB以上的手机(现在的手机普遍已经大于这个值了)，Fresco的默认缓存大小是maxMemory / 4 从内存缓存中获取图片 : CountingMemoryCache.get()缓存获取的逻辑也很简单: CountingMemoryCache.java 123456789101112131415public CloseableReference&lt;V&gt; get(final K key) {Entry&lt;K, V&gt; oldExclusive; CloseableReference&lt;V&gt; clientRef = null; synchronized (this) { oldExclusive = mExclusiveEntries.remove(key); Entry&lt;K, V&gt; entry = mCachedEntries.get(key); if (entry != null) { clientRef = newClientReference(entry); } } maybeNotifyExclusiveEntryRemoval(oldExclusive); maybeUpdateCacheParams(); maybeEvictEntries(); return clientRef;} 即从mCachedEntries集合中获取，如果mExclusiveEntries集合中存在的话就移除。 trim策略 : CountingMemoryCache.getrimt()当内存缓存达到峰值或系统内存不足时就需要对当前的内存缓存做trim操作, trim时是基于Lru算法的，我们看一下它的具体逻辑: 1234567891011public void trim(MemoryTrimType trimType) { ArrayList&lt;Entry&lt;K, V&gt;&gt; oldEntries; //根据当前的应用状态来确定trim ratio。 应用状态是指: 应用处于前台、后台等等 final double trimRatio = mCacheTrimStrategy.getTrimRatio(trimType); ... int targetCacheSize = (int) (mCachedEntries.getSizeInBytes() * (1 - trimRatio)); // trim到当前缓存的多少 int targetEvictionQueueSize = Math.max(0, targetCacheSize - getInUseSizeInBytes()); // 到底能trim多大 oldEntries = trimExclusivelyOwnedEntries(Integer.MAX_VALUE, targetEvictionQueueSize); //trim mExclusiveEntries集合 集合中的对象 makeOrphans(oldEntries); ...} trim操作的主要步骤是: 根据当前应用的状态决定trim ratio (应用状态是指应用处于前台、后台等等)。 根据trim ratio来算出经过trim后缓存的大小targetCacheSize 根据mExclusiveEntries集合的大小来决定到底能trim多少 (能trim的最大就是mExclusiveEntries.size) 对mExclusiveEntries集合做trim操作，即移除其中的元素。 即trim时最大能trim掉的大小是mExclusiveEntries集合的大小。所以如果当前应用存在内存泄漏，导致mExclusiveEntries中的元素很少，那么trim操作几乎是没有效果的。 编码内存缓存 : EncodedMemoryCacheProducer这个缓存Producer的工作逻辑和BitmapMemoryCacheProducer相同,不同的是它缓存的对象: 12345public class EncodedMemoryCacheProducer implements Producer&lt;EncodedImage&gt; { private final MemoryCache&lt;CacheKey, PooledByteBuffer&gt; mMemoryCache; ...} 即它缓存的是PooledByteBuffer, 它是什么东西呢? 它牵扯到Fresco编码图片的内存管理，这些内容我会单开一篇文章来讲一下。这里就先不说了。PooledByteBuffer你可以简单的把它当成一个字节数组。 磁盘缓存 : DiskCacheWriteProducer它是Fresco图片磁盘缓存的逻辑管理者，整个缓存逻辑和BitmapMemoryCacheProducer差不多: 123456789101112public class DiskCacheWriteProducer implements Producer&lt;EncodedImage&gt; { private final BufferedDiskCache mDefaultBufferedDiskCache; / ... private static class DiskCacheWriteConsumer extends DelegatingConsumer&lt;EncodedImage, EncodedImage&gt; { @Override public void onNewResultImpl(EncodedImage newResult, @Status int status) { ... mDefaultBufferedDiskCache.put(cacheKey, newResult); } }} 接下来我们主要看一下它的磁盘存储逻辑(怎么存), 对于存储逻辑是由BufferedDiskCache来负责的: BufferedDiskCache先来看一下类的组成结构: 12345public class BufferedDiskCache { private final FileCache mFileCache; // 文件存储的实现 private final Executor mWriteExecutor; //存储文件时的线程 private final StagingArea mStagingArea; } FileCache : 将EncodeImage保存到磁盘存储实现。 Executor : 指定文件保存操作所运行的线程。 StagingArea: 类似于git中的stage概念,它是一个map,用于保存当前正在进行磁盘缓存操作。 将图片保存至磁盘 : BufferedDiskCache.put()这个方法主要负责往磁盘缓存一张图片: 1234567891011121314151617181920public void put(final CacheKey key, EncodedImage encodedImage) { .. mStagingArea.put(key, encodedImage); //把这次缓存操作放到暂存区 ... final EncodedImage finalEncodedImage = EncodedImage.cloneOrNull(encodedImage); mWriteExecutor.execute( //开启写入线程 new Runnable() { @Override public void run() { try { writeToDiskCache(key, finalEncodedImage); //写入到磁盘 } finally { mStagingArea.remove(key, finalEncodedImage); //从操作暂存区中移除这次操作 EncodedImage.closeSafely(finalEncodedImage); } } }); } ...} writeToDiskCache()主要调用mFileCache.insert()来把图片保存到磁盘: 1234567mFileCache.insert(key, new WriterCallback() { @Override public void write(OutputStream os) throws IOException { mPooledByteStreams.copy(encodedImage.getInputStream(), os); //实际上就是把encodeImage 写入到 os(OutputStream) 中 } }); 至于mFileCache.insert()的具体实现涉及的源码较多，考虑文章篇幅的原因这里我不去具体跟了。简单的总结一下其实现步骤和一些关键点: Step1 : 生成ResourceId这个ResourceId可以简单的理解为缓存文件的文件名，它的生成算法如下: 1SecureHashUtil.makeSHA1HashBase64(key.getUriString().getBytes(&quot;UTF-8&quot;)); // key就是CacheKey 即SHA-1 + Base64。 Step2 : 创建临时文件，并把图片写入到临时文件中 创建临时文件 123public File createTempFile(File parent) throws IOException { return File.createTempFile(resourceId + &quot;.&quot;, TEMP_FILE_EXTENSION, parent);} 把图片写入到这个临时文件中 : DefaultDiskStorage.java 123456public void writeData(WriterCallback callback, Object debugInfo) throws IOException { FileOutputStream fileStream = new FileOutputStream(mTemporaryFile); ... CountingOutputStream countingStream = new CountingOutputStream(fileStream); callback.write(countingStream); countingStream.flush(); 这里的callback(WriterCallback)就是mFileCache.insert()方法传入的那个callback -&gt; { mPooledByteStreams.copy(encodedImage.getInputStream(), os); } Step3 : 把临时文件重命名为resourceIdStep4 : 设置好文件的最后修改时间从磁盘中获取文件 : BufferedDiskCache.get()读就是写的逆操作，这里不做具体分析了。 AttentionFresco KeyMemoryCacheKey解码内存缓存时由CountingMemoryCache类真正实现，内部维护CountingLruMap (内为LinkedHashMap)，value为CountingMemoryCache$Entry (持有CloseableReference-&gt;Bitmap)。 key为（内存缓存CacheKey子类 BitmapMemoryCacheKey ）：对于内存的缓存，fresco根据 Uri字符串、缩放尺寸、解码参数、PostProcessor等关键参数进行hashCode 生成缓存key来缓存bitmap EncodeImageKey未解码内存缓存也由CountingMemoryCache类真正实现，内部维护CountingLruMap (内为LinkedHashMap)，value为 CountingMemoryCache$Entry (真正持有是MemoryPooledByteBuffer-&gt;NativeMemoryChunk) Key为默认实现是SimpleCacheKey：参数只有图片Uri DiskCacheKey：生成固定的缓存图片目录，直接把图片Uri哈希1后base64加密作为文件名，get时就直接”判断路径+hash1base64 “是否存在 缓存大小 内存缓存一般是 四分之一 ActivityManager.getMemoryClass 未解码的图片缓存一般是 4MB 磁盘缓存一般是 40MB 生命周期获取通过DraweeView的onAttachedToWindow()和onDetachedFromWindow()时attachController()和detachController()，controller持有hierarchy，所以也会释放掉hierarchy。 DecodeProducer - Gif Decode*解码会根据为解码的图片格式，选择不同的解码器(PNG/JPEG/GIF/WEBP)*，此处仅以Gif图decode为分析对象（网络拉取gif、解码、缓存） 12345678910111213141516171819202122232425262728293031323334353637383940//ImagePipeline.javapublic DataSource&lt;CloseableReference&lt;CloseableImage&gt;&gt; fetchDecodedImage( ImageRequest imageRequest, Object callerContext, ImageRequest.RequestLevel lowestPermittedRequestLevelOnSubmit, @Nullable RequestListener requestListener, @Nullable String uiComponentId) { try { //生产者序列工厂 获取 下载、缓存、解码图片的生产者序列 Producer&lt;CloseableReference&lt;CloseableImage&gt;&gt; producerSequence = mProducerSequenceFactory.getDecodedImageProducerSequence(imageRequest); //封装到DataSorce中处理 return submitFetchRequest( producerSequence, imageRequest, lowestPermittedRequestLevelOnSubmit, callerContext, requestListener, uiComponentId); } catch (Exception exception) { return DataSources.immediateFailedDataSource(exception); }}//mProducerSequenceFactory.getDecodedImageProducerSequence 调用的是getBasicDecodedImageSequence//ProducerSequenceFactory.class//ProducerSequenceFactory.getBasicDecodedImageSequence 方法中会根据imageRequest的uri的SCHEME（http/https、file等）选择合适的生产者序列工厂。此处以经典的https为例，返回的是：网络拉取序列单例mNetworkFetchSequence = newBitmapCacheGetToDecodeSequence(getCommonNetworkFetchToEncodedMemorySequence());//getCommonNetworkFetchToEncodedMemorySequence负责： multiplex -&gt; encoded cache -&gt; disk cache -&gt; (webp transcode) -&gt; network fetch. //newBitmapCacheGetToDecodeSequence追加producer后： bitmap cache get -&gt; background thread hand-off -&gt; multiplex -&gt; bitmap cache -&gt; decode -&gt; multiplex -&gt; encoded cache -&gt; disk cache -&gt; (webp transcode) -&gt; network fetch. 每一层生产者负责各自的责任，这里具体分析负责decode的DecodeProducer。 1234567891011121314151617//ProducerSequenceFactory.BitmapCacheGetToDecodeSequence()DecodeProducer decodeProducer = mProducerFactory.newDecodeProducer(inputProducer);//ProducerFactory.classpublic DecodeProducer newDecodeProducer(Producer&lt;EncodedImage&gt; inputProducer) { return new DecodeProducer( mByteArrayPool, mExecutorSupplier.forDecode(), mImageDecoder, //！！就是这里传入的解码器 mProgressiveJpegConfig, mDownsampleEnabled, mResizeAndRotateEnabledForNetwork, mDecodeCancellationEnabled, inputProducer, mMaxBitmapSize, mCloseableReferenceFactory); } 下面分析mImageDecoder创建来源: imageDecoder的创建简述：就是构造一个单例的匿名内部ImageDecoder类，其中方法decodeGif()具体通过AnimatedImageFactoryImpl的同名方法实现。 首先是ProducerFactory的构建时就调用getImageDecoder创建ImageDecode单例并入参。 1234567891011121314151617181920212223242526272829303132333435363738ImagePipelineFactory.class private ProducerFactory getProducerFactory() { if (mProducerFactory == null) { mProducerFactory = mConfig .getExperiments() .getProducerFactoryMethod() .createProducerFactory( mConfig.getContext(), mConfig.getPoolFactory().getSmallByteArrayPool(), getImageDecoder(), //... } return mProducerFactory; } private ImageDecoder getImageDecoder() { if (mImageDecoder == null) { if (mConfig.getImageDecoder() != null) { mImageDecoder = mConfig.getImageDecoder(); } else { /*getAnimatedFactory()利用AnimatedFactoryProvider以反射方式实例化AnimatedFactoryV2Impl并返回*/ final AnimatedFactory animatedFactory = getAnimatedFactory(); ImageDecoder gifDecoder = null; ImageDecoder webPDecoder = null; if (animatedFactory != null) { gifDecoder = animatedFactory.getGifDecoder(mConfig.getBitmapConfig()); webPDecoder = animatedFactory.getWebPDecoder(mConfig.getBitmapConfig()); } //... return mImageDecoder;} 123456789101112131415161718192021222324252627282930313233343536373839404142AnimatedFactoryV2Impl implements AnimatedFactory//AnimatedFactoryV2Impl.class//AnimatedFactoryV2Impl.getGifDeocder()中直接返回：//由AnimatedFactoryV2Impl.getAnimatedImageFactory().decodeGif()实现解码的匿名内部类ImageDecoder实例;其中getAnimatedIamgeFractory()返回AnimatedImageFactoryImpl单例。 public ImageDecoder getGifDecoder(final Bitmap.Config bitmapConfig) { return new ImageDecoder() { @Override public CloseableImage decode( EncodedImage encodedImage, int length, QualityInfo qualityInfo, ImageDecodeOptions options) { return getAnimatedImageFactory().decodeGif(encodedImage, options, bitmapConfig); } }; } private AnimatedImageFactory getAnimatedImageFactory() { if (mAnimatedImageFactory == null) { mAnimatedImageFactory = buildAnimatedImageFactory(); } return mAnimatedImageFactory; } private AnimatedImageFactory buildAnimatedImageFactory() { AnimatedDrawableBackendProvider animatedDrawableBackendProvider = new AnimatedDrawableBackendProvider() { @Override public AnimatedDrawableBackend get(AnimatedImageResult imageResult, Rect bounds) { return new AnimatedDrawableBackendImpl( getAnimatedDrawableUtil(), imageResult, bounds, mDownscaleFrameToDrawableDimensions); } }; return new AnimatedImageFactoryImpl(animatedDrawableBackendProvider, mPlatformBitmapFactory); } encodeImage的decode过程简述：先将未解码图像中解析出gif的元数据，封装 gif元数据（帧数、间隔、循环次数等） 与 未解码图像字节数组为 AnimatedImage（GifImage）。 通过getCloseableImage（）根据option配置将上述AnimatedImage（GifImage）传入进一步解析， 即将 AnimatedImage（GifImage）中的未解码字节数组 进一步解析， 将AnimatedImage（GifImage）、预览图(maybe null)、预览帧(maybe null)、所有帧列表（如果打开了options.decodeAllFrames,maybe null），封装成AnimatedImageResult。 最后 GifImage在AnimatedDrawable2.draw 渲染时再进一步decode出需要的帧（GifFrame） 至于提到的 未解码字节数组 解析成帧的过程，是通过GifImage类实例sGifAnimatedImageDecoder，通过Native解码，主要是借助giflib库在Native层进行解码。 12345678910111213141516171819202122232425262728293031323334353637383940414243//大致就是个中间层调用AnimatedImageFactoryImpl解析encodeImage成CloseableImageAnimatedImageFactoryImpl implements AnimatedImageFactory{ static { sGifAnimatedImageDecoder = loadIfPresent(&quot;com.facebook.animated.gif.GifImage&quot;); sWebpAnimatedImageDecoder = loadIfPresent(&quot;com.facebook.animated.webp.WebPImage&quot;); }//将encodeImage（未解码的图像，包括未解码字节与元数据的native字节数组）解析成CloseableImage（解析元数据后的图像信息）//GifImage就代表一个GIF，这里只会解析出GIF的元数据，不会真正解码GIF帧 public CloseableImage decodeGif( final EncodedImage encodedImage, final ImageDecodeOptions options, final Bitmap.Config bitmapConfig) { if (sGifAnimatedImageDecoder == null) { throw new UnsupportedOperationException( &quot;To encode animated gif please add the dependency &quot; + &quot;to the animated-gif module&quot;); } final CloseableReference&lt;PooledByteBuffer&gt; bytesRef = encodedImage.getByteBufferRef(); Preconditions.checkNotNull(bytesRef); try { final PooledByteBuffer input = bytesRef.get(); /*AnimateImage：Gif的表示，具体实现为GifImage， 该类的实例将在内存中保存未解码数据的副本和已解码的元数据（即解析出了图像的帧数、间隔、循环次数等元数据）。 ps：帧通过GifFrame按需解码。*/ AnimatedImage gifImage; if (input.getByteBuffer() != null) { /*sGifAnimatedImageDecoder其实也就是是GifImage*/ gifImage = sGifAnimatedImageDecoder.decode(input.getByteBuffer()); } else { gifImage = sGifAnimatedImageDecoder.decode(input.getNativePtr(), input.size()); } /*上面解析出来的AnimateImage信息，根据option配置，决定是否解析成静态图片，是否解析全部帧位图列表，是否设置预览帧等进一步封装成CloseableImage*/ return getCloseableImage(options, gifImage, bitmapConfig); } finally { CloseableReference.closeSafely(bytesRef); } }} Gif解码后帧的缓存（问题出在哪）还记得上面submitRequest后需要走加载流程后的图像加载成功结果onNewResultInternal吗， 1234567891011AnimatedImageFactoryImpl.classprivate CloseableImage getCloseableImage( ImageDecodeOptions options, AnimatedImage image, Bitmap.Config bitmapConfig) { AnimatedImageResult animatedImageResult = AnimatedImageResult.newBuilder(image) .setPreviewBitmap(previewBitmap) .setFrameForPreview(frameForPreview) .setDecodedFrames(decodedFrames) .build(); return new CloseableAnimatedImage(animatedImageResult);} 这个方法会将AnimatedImage（GifImage）进一步封装成AnimatedResult（构建者模式构建），然后返回一个new CloseableAnimatedImage(animatedImageResult) 此时CloseableAnimatedImage中就有了新建的animatedImageResult（未解码的图像与gif元数据），最后这个closeableAnimatedImage会被传递到AbstractDraweeController.class中的 onNewResultInternal(String id, DataSource&lt;T&gt; dataSource, @Nullable T image, float progress, boolean isFinished, boolean wasImmediate, boolean deliverTempResult) ， 执行 drawable = createDrawable(image); 此方法具体实现在PipelineDraweeController（extends AbstractDraweeController）中 12345678910//PipelineDraweeControllerprotected Drawable createDrawable(CloseableReference&lt;CloseableImage&gt; image) { ... drawable = mDefaultDrawableFactory.createDrawable(closeableImage); if (drawable != null) { return drawable; } ... }} mDefaultDrawableFactory是ExperimentalBitmapAnimationDrawableFactory（ implements DrawableFactory）的实例， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125//ExperimentalBitmapAnimationDrawableFactory.classpublic AnimatedDrawable2 createDrawable(CloseableImage image) { return new AnimatedDrawable2( //((CloseableAnimatedImage) image).getImageResult())也就是上面AnimatedImageFactoryImpl.getCloseableImage返回的AnimatedResult对象。 createAnimationBackend(((CloseableAnimatedImage) image).getImageResult()));}private AnimationBackend createAnimationBackend(AnimatedImageResult animatedImageResult) { ... BitmapFrameCache bitmapFrameCache = createBitmapFrameCache(animatedImageResult); ...}private AnimatedFrameCache createAnimatedFrameCache( final AnimatedImageResult animatedImageResult) { return new AnimatedFrameCache( new AnimationFrameCacheKey(animatedImageResult.hashCode()), mBackingCache);}public class AnimationFrameCacheKey implements CacheKey { private static final String URI_PREFIX = &quot;anim://&quot;; private final String mAnimationUriString; private final boolean mDeepEquals; //源码中为false //imageId = animatedImageResult.hashCode() public AnimationFrameCacheKey(int imageId) { mAnimationUriString = URI_PREFIX + imageId; //e.g： “anim://306123060&quot; } //重写equals与hashCode方法以求 得到正确的比对结果 @Override public boolean equals(@Nullable Object o) { if (!mDeepEquals) { return super.equals(o); } if (this == o) { return true; } if (o == null || getClass() != o.getClass()) { return false; } AnimationFrameCacheKey that = (AnimationFrameCacheKey) o; return mAnimationUriString.equals(that.mAnimationUriString); } @Override public int hashCode() { if (!mDeepEquals) { return super.hashCode(); } return mAnimationUriString.hashCode(); }}public class AnimatedFrameCache { @Nullable public CloseableReference&lt;CloseableImage&gt; cache( int frameIndex, CloseableReference&lt;CloseableImage&gt; imageRef) { return mBackingCache.cache(keyFor(frameIndex), imageRef, mEntryStateObserver); } private FrameKey keyFor(int frameIndex) { return new FrameKey(mImageCacheKey, frameIndex); } //每一帧的缓存Key。equals时比较类型、 static class FrameKey implements CacheKey { //这里CacheKey 是 AnimationFrameCacheKey private final CacheKey mImageCacheKey; private final int mFrameIndex; public FrameKey(CacheKey imageCacheKey, int frameIndex) { mImageCacheKey = imageCacheKey; mFrameIndex = frameIndex; } public boolean equals(Object o) { if (o == this) { return true; } if (o instanceof FrameKey) { FrameKey that = (FrameKey) o; return this.mFrameIndex == that.mFrameIndex &amp;&amp; this.mImageCacheKey.equals(that.mImageCacheKey); } return false; } } } public synchronized void onFrameRendered( int frameNumber, CloseableReference&lt;Bitmap&gt; bitmapReference, @BitmapAnimationBackend.FrameType int frameType) { Preconditions.checkNotNull(bitmapReference); // Close up prepared references. removePreparedReference(frameNumber); // Create the new image reference and cache it. CloseableReference&lt;CloseableImage&gt; closableReference = null; try { closableReference = createImageReference(bitmapReference); if (closableReference != null) { CloseableReference.closeSafely(mLastRenderedItem); mLastRenderedItem = mAnimatedFrameCache.cache(frameNumber, closableReference); } } finally { CloseableReference.closeSafely(closableReference); } } mBackingCache内存缓存池 缓存gif每一帧时，key为FrameKey，FrameKey由 整个Gif图形的缓存key mImageCacheKey + 帧索引mFrameIndex） 组成。 而 mImageCacheKey 是AnimationFrameCacheKey的实例，其中 核心变量为mAnimationUriString，是由 “anim://“ + animatedImageResult.hashCode组成的字符串，并保存布尔值mDeepEquals是否进行内容判断。 （animatedImageResult中保存了AnimatedImage（GifImage）、预览图(maybe null)、预览帧(maybe null)、所有帧列表（如果打开了options.decodeAllFrames,maybe null），是由 未解码gif图形缓存encodeImage 初步解析元数据后 的封装） 如果mDeepEquals是true的话，判断缓存是否存在 ​ 是依据FrameKey.mImageCacheKey.mAnimationUriString 内容是否相同 与 FrameKey.mFrameIndex是否相等。 如果mDeepEquals是false的话，判断缓存是否存在 ​ 是依据FrameKey.mImageCacheKey.mAnimationUriString 对象是否相同 与 FrameKey.mFrameIndex是否相等 由于原代码中由于mDeepEquals=false，且mAnimationUriString每次都是new出来的，所以必然不会相等，也就是帧内存缓存永远无法命中。 那么第一步就是mDeepEquals置为true， 但是由于mAnimationUriString = “anim://“ + animatedImageResult.hashCode 又：animatedImageResult是每次解析encodeImage都会重新构建的对象，也就是： 从 未解码图像缓存 中，同张图片 每次解析 都会得到不同的animatedImageResult，mAnimationUriString又是每一次解析都是不同的。 所以帧内存缓存又无法命中。 所以第二步需要 一个encodeImage对应的唯一 值替代 animatedImageResult.hashCode 。 考虑可以选择两个： 一个是 encodeImage的hash值， 未解码图片内存缓存是正确的，每次应用完整周期 都会有一个唯一的encodeImage 对应图像，decodeGif时encodeImage中存储未解码图像字节数组CloseableReference&lt;PooledByteBuffer&gt; mPooledByteBufferRef;的getValueHash方法。 123456CloseableReference.classMethod used for tracking Closeables pointed by CloseableReference. Use only for debugging and logging.public int getValueHash() { return isValid() ? System.identityHashCode(mSharedReference.get()) : 0;}//identityHashCode ≈ hashCode() 一个是 根据url生成的cacheKey，设想是直接用图像url生成的磁盘缓存key，但是传递链太长了 我暂时选择的是getValueHash 像dokit跟fresco都在key的生成和使用中出过一些bug，以下是我的pullRequest dokit对fresco框架下的大图检测功能导致图片闪烁（源于自定义的postProcessor每次都重新都新建了 内存缓存管理类CacheKey） https://github.com/didi/DoraemonKit/pull/714/commits/4dbc58b84cfe1286c666d0cab5031092df52d81e fresco官方中gif图缓存失效，导致重复加载同一张gif图时内存持续增长 （源于一个EndcodeImage在进一步解析成文件字节数组包裹的对象AnimatedResult时，每次都是新建的AnimatedResult对象，又用这个对象的hashcode+frameIndex作为解析成帧内存缓存时的key信息，所以就导致了帧内存缓存失效） Gif cache doesn’t seem to be working. · Issue #2605 · facebook/fresco (github.com) change imageId in AnimatedImageResult from the class hash to decodeHa… by WhileCrow · Pull Request #2612 · facebook/fresco (github.com) 附录：完整ProducerSequence整个Producer Sequence，如下所示： NetworkFetchProducer : 负责从网络下载图片数据，内部持有NetworkFetcher，负责使用不同的Http框架去实现下载逻辑，例如：HttpUrlConnectionNetworkFetcher、OkHttpNetworkFetcher、VolleyNetworkFetcher等。 WebpTranscodeProducer : 因为不是所有Android平台都支持WebP，具体可以参考WebpTranscodeProducer.shouldTranscode方法，所以对于不支持WebP的平台，需要转换成jpg/png。其中无损或者带透明度的WebP（DefaultImageFormats.WEBP_LOSSLESS和DefaultImageFormats.WEBP_EXTENDED_WITH_ALPHA），需要转换成PNG，具体方法是先把WebP解码成RGBA，然后再把RGBA编码成PNG；简单或者扩展的WebP（DefaultImageFormats.WEBP_SIMPLE和DefaultImageFormats.WEBP_EXTENDED），需要转换成JPEG。具体方法是先把WebP解码成RGB，然后再把RGB编码成JPEG。 PartialDiskCacheProducer : 解下来的三个是磁盘缓存EncodedImage相关 DiskCacheWriteProducer DiskCacheReadProducer EncodedMemoryCacheProducer : 未解码数据的内存缓存 EncodedCacheKeyMultiplexProducer AddImageTransformMetaDataProducer ResizeAndRotateProducer : 负责采样和图片旋转 DecodeProducer : 上述的Producer都是基于EncodedImage，DecodeProducer会把EncodedImage解码成CloseableReference BitmapMemoryCacheProducer : 接下来的两个是内存Bitmap缓存相关 BitmapMemoryCacheKeyMultiplexProducer ThreadHandoffProducer : 负责切换线程 BitmapMemoryCacheGetProducer PostprocessorProducer PostprocessedBitmapMemoryCacheProducer BitmapPrepareProducer 从下往上，依次持有引用；从上往下，依次返回数据 OtherFresco网络大图检测123456789101112131415161718192021222324252627282930313233//插桩/* 思路：draweeView在xml或手动setUri最终都需要为draweeView构建DraweeController，由此得到了统一的draweeView传入链接的入口时机：构建完将该DraweeController设置为controller时目的：获得draweeView的宽高（注册其布局回调完成）、draweeView所在页面及id、图片链接 */private fun createDraweeViewInsnList(): InsnList { return with(InsnList()) { add(VarInsnNode(ALOAD, 0)) //由于DraweeView.setController方法内引用了全局变量，故方法字节码中会将DraweeView对象最为参数传入方法 add(VarInsnNode(ALOAD, 1)) add(MethodInsnNode(INVOKESTATIC, &quot;com/didichuxing/doraemonkit/aop/bigimg/fresco/MyFrescoHook&quot;, &quot;frescoRealHook&quot;, &quot;(Landroid/view/View;Lcom/facebook/drawee/interfaces/DraweeController;)V&quot;, false)) this } }//插桩/* 思路：设置自定义postProcessor，postProcessor会回调图片加载完成时机时机：在图片下载解析完成时目的：获得内存图片大小与图片链接 */private fun createFrescoInsnList(): InsnList { return with(InsnList()) { add(VarInsnNode(ALOAD, 1)) add(VarInsnNode(ALOAD, 1)) add(MethodInsnNode(INVOKEVIRTUAL, &quot;com/facebook/imagepipeline/request/ImageRequestBuilder&quot;, &quot;getSourceUri&quot;, &quot;()Landroid/net/Uri;&quot;, false)) add(VarInsnNode(ALOAD, 1)) add(MethodInsnNode(INVOKEVIRTUAL, &quot;com/facebook/imagepipeline/request/ImageRequestBuilder&quot;, &quot;getPostprocessor&quot;, &quot;()Lcom/facebook/imagepipeline/request/Postprocessor;&quot;, false)) add(MethodInsnNode(INVOKESTATIC, &quot;com/didichuxing/doraemonkit/aop/bigimg/fresco/FrescoHook&quot;, &quot;proxy&quot;, &quot;(Landroid/net/Uri;Lcom/facebook/imagepipeline/request/Postprocessor;)Lcom/facebook/imagepipeline/request/Postprocessor;&quot;, false)) add(MethodInsnNode(INVOKEVIRTUAL, &quot;com/facebook/imagepipeline/request/ImageRequestBuilder&quot;, &quot;setPostprocessor&quot;, &quot;(Lcom/facebook/imagepipeline/request/Postprocessor;)Lcom/facebook/imagepipeline/request/ImageRequestBuilder;&quot;, false)) this } } //之后就是以图片链接为桥梁，将两个不同时机获取的信息整合，比对内存尺寸与view尺寸 参考 Fresco架构设计赏析 | susion Fresco缓存架构分析 | susion Fresco缓存架构分析 | susion Fresco图片显示原理浅析 | susion Fresco使用的扩展 | susion GIF面面观 - 掘金 (juejin.cn)","link":"/2021/04/09/Fresco/"},{"title":"Git","text":"节点Q：每次commit，Git储存的是全新的文件快照还是储存文件的变更部分？ A: 全新的文件快照 Git储存的是全新的文件快照，而不是文件的变更记录。也就是说，就算你只是在文件中添加一行，Git也会新建一个全新的blob object。那这样子是不是很浪费空间呢? 这其实是Git在空间和时间上的一个取舍，思考一下你要checkout一个commit，或对比两个commit之间的差异。如果Git储存的是问卷的变更部分，那么为了拿到一个commit的内容，Git都只能从第一个commit开始，然后一直计算变更，直到目标commit，这会花费很长时间。而相反，Git采用的储存全新文件快照的方法能使这个操作变得很快，直接从快照里面拿取内容就行了。 当然，在涉及网络传输或者Git仓库真的体积很大的时候，Git会有垃圾回收机制gc，不仅会清除无用的object，还会把已有的相似object打包压缩。 Merge 和 Rebase的区别$ git pull --rebase和$ git pull区别git pull是git fetch + git merge FETCH_HEAD的缩写，所以默认情况下，git pull就是先fetch,然后执行merge操作，如果加-rebase参数，就是使用git rebase代替git merge 。 现在有这样一个现实的请况，就是B同学准备进行第4次提交的时候，同学A在master主分支上进行了一次提交，master的提交已经向前走了 此时的git分支类图是这样的 此时我们知道B同学开发的dev分支是基于C2提交点切出来的，而这个时候master分支已经被更新了 如果B同学开发完毕，需要将其所作的功能合并到master分支 ，他可以有两种选择： Merge直接git merge，那么这个时候会这么做 （1）找到master和dev的共同祖先，即C2 （2）将dev的最新提交C5和master的最新提交即C6合并成一个新的提交C7，有冲突的话，解决冲突 （3）将C2之后的dev和master所有提交点，按照提交时间合并到master Rebase直接git rebase 切换分支到需要rebase的分支，这里是dev分支 执行git rebase master，有冲突就解决冲突，解决后直接git add . 再git rebase –continue即可 发现采用rebase的方式进行分支合并，整个master分支并没有多出一个新的commit，原来dev分支上的那几次（C3，C4，C5）commit记录在rebase之后其hash值发生了变化，不在是当初在dev分支上提交的时候的hash值了，但是提交的内容被全部复制保留了，并且整个master分支的commit记录呈线性记录 此时git的分支类图 小结简单来讲：rebase会改变提交历史，但可以使分支干净，需要慎重。merge会新建节点，不改变提交，但是容易使分支变乱。 git merge 会让2个分支的提交按照提交时间进行排序，并且会把最新的2个commit合并成一个commit。最后的分支树呈现非线性的结构。（创建新的commit，节点hash不变） git reabse 将dev的当前提交复制到master的最新提交之后，会形成一个线性的分支树。（无新建commit，发起rebase的分支非祖先节点往后的节点复制，hash值改变） Pull 和 Fetch 的区别git fetch在拉取代码过程中，git fetch会首先检查本地仓库和远程仓库的差异，检查哪些不存在于本地仓库，然后将这些变动的提交拉取到本地。 但是，这里请注意，它是把远程提交拉取到本地仓库，而不是本地工作目录，它不会自行将这些新数据合并到当前工作目录中，我们需要继续执行git merge才会把这些变动合并到当前工作目录。 git pullgit pull和git fetch刚好相反，它直接获取远程的最新提交，直接拉取并合并到本地工作目录，而且在合并过程中不会经过我们的审查，如果不仔细检查，这样很容易遇到冲突。 原理","link":"/2022/07/26/Git/"},{"title":"Fragment","text":"https://developer.android.com/guide/fragments/lifecycle?hl=zh-cn 生命周期//简述：还有一个生命周期是 onViewCreated()，该生命周期会在onCreateView后立即调用（此时布局inflate已完成），故而一般fragment的onCreateView中执行inflate layout操作后返回rootView，之后在onViewCreated中执行具体的View操作。 UseFragmentTransaction的4种提交方式commit()：commit是非同步提交（我认为不应称为异步）且检查是否存储状态的 The commit does not happen immediately; it will be scheduled as work on the main thread to be done the next time that thread is ready. 非同步提交：即操作会被post到主线程handler的消息队列中，等候轮到时执行； 检查存储状态：如果宿主(FragmentActivity)已经执行了onSaveInstanceState再执行该操作，会抛出异常 123456//FragmentManager.classprivate void checkStateLoss() { if (this.isStateSaved()) { throw new IllegalStateException(&quot;Can not perform this action after onSaveInstanceState&quot;); }} commitAllowingStateLoss():非同步提交且不检查状态 如果在宿主执行了onSaveInstanceSate之后再执行该操作，不会去检查宿主状态,不会抛出异常。但该操作不会被Activity记录，恢复时也就没办法恢复这些提交操作，所以该操作适用不重要的事务。同属于异步事务。 commitNow():同步提交且检查状态。 会立刻执行当前提交的transaction事务。 commitNowAllowingStateLoss():同步提交且不检查状态 既是同步执行，也不会检查宿主的状态,有可能该操作不会被正确恢复 同时：使用 commitNow() 或 commitNowAllowingStateLoss() 提交的事务不允许加入回退栈 1234567891011@Overridepublic void commitNow() { disallowAddToBackStack(); mManager.execSingleAction(this, false);}@Overridepublic void commitNowAllowingStateLoss() { disallowAddToBackStack(); mManager.execSingleAction(this, true);} Principle源码中fragment的生命周期方法回调在于 内置定义的五种状态的转移： 当宿主生命周期发生变化时，Fragment 的状态会同步到宿主的状态。从源码看，体现在宿主生命周期回调中会调用 FragmentManager 中一系列 dispatchXXX() 方法来触发 Fragment 状态转移。 12345678//FragmentActivity@Overrideprotected void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); mFragmentLifecycleRegistry.handleLifecycleEvent(Lifecycle.Event.ON_CREATE); mFragments.dispatchCreate();} 123456789101112//android.fragment:fragment:1.3.6 Fragment static final int INITIALIZING = -1; // Not yet attached.static final int ATTACHED = 0; // Attached to the host.static final int CREATED = 1; // Created.static final int VIEW_CREATED = 2; // View Created.static final int AWAITING_EXIT_EFFECTS = 3; // Downward state, awaiting exit effectsstatic final int ACTIVITY_CREATED = 4; // Fully created, not started.static final int STARTED = 5; // Created and started, not resumed.static final int AWAITING_ENTER_EFFECTS = 6; // Upward state, awaiting enter effectsstatic final int RESUMED = 7; // Created started and resumed.int mState = INITIALIZING; INITIALIZING，ATTACHED，CREATED，VIEW_CREATED，ACTIVITY_CREATED，STARTED，RESUMED七种状态轮换，每个状态轮换之间，生命周期也就自然被调用到 如一次创建流程， 枚举状态INITALIZING-&gt;RESUME，就会依次调用到：onAttach(), onCreate(), onCreateView(), onActivityCreate(), onStart(), onResume(); 反之，RESUME-&gt;INITIALIZING，就会依次调用:onPause(), onStop(), onSaveInstanceState(), onDestroyView(), onDestroy(), onDetach() 当然，是否需要被调用，case也会自己判断； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169 @SuppressWarnings(&quot;deprecation&quot;)void moveToState(@NonNull Fragment f, int newState) { FragmentStateManager fragmentStateManager = mFragmentStore.getFragmentStateManager(f.mWho); if (fragmentStateManager == null) { // Ideally, we only call moveToState() on active Fragments. However, // in restoreSaveState() we can call moveToState() on retained Fragments // just to clean them up without them ever being added to mActive. // For these cases, a brand new FragmentStateManager is enough. fragmentStateManager = new FragmentStateManager(mLifecycleCallbacksDispatcher, mFragmentStore, f); // Only allow this FragmentStateManager to go up to CREATED at the most fragmentStateManager.setFragmentManagerState(Fragment.CREATED); } // When inflating an Activity view with a resource instead of using setContentView(), and // that resource adds a fragment using the &lt;fragment&gt; tag (i.e. from layout and in layout), // the fragment will move to the VIEW_CREATED state before the fragment manager // moves to CREATED. So when moving the fragment manager moves to CREATED and the // inflated fragment is already in VIEW_CREATED we need to move new state up from CREATED // to VIEW_CREATED. This avoids accidentally moving the fragment back down to CREATED // which would immediately destroy the Fragment's view. We rely on computeExpectedState() // to pull the state back down if needed. if (f.mFromLayout &amp;&amp; f.mInLayout &amp;&amp; f.mState == Fragment.VIEW_CREATED) { newState = Math.max(newState, Fragment.VIEW_CREATED); } newState = Math.min(newState, fragmentStateManager.computeExpectedState()); if (f.mState &lt;= newState) { // If we are moving to the same state, we do not need to give up on the animation. if (f.mState &lt; newState &amp;&amp; !mExitAnimationCancellationSignals.isEmpty()) { // The fragment is currently being animated... but! Now we // want to move our state back up. Give up on waiting for the // animation and proceed from where we are. cancelExitAnimation(f); } switch (f.mState) { case Fragment.INITIALIZING: if (newState &gt; Fragment.INITIALIZING) { fragmentStateManager.attach(); } // fall through case Fragment.ATTACHED: if (newState &gt; Fragment.ATTACHED) { fragmentStateManager.create(); } // fall through case Fragment.CREATED: // We want to unconditionally run this anytime we do a moveToState that // moves the Fragment above INITIALIZING, including cases such as when // we move from CREATED =&gt; CREATED as part of the case fall through above. if (newState &gt; Fragment.INITIALIZING) { fragmentStateManager.ensureInflatedView(); } if (newState &gt; Fragment.CREATED) { fragmentStateManager.createView(); } // fall through case Fragment.VIEW_CREATED: if (newState &gt; Fragment.VIEW_CREATED) { fragmentStateManager.activityCreated(); } // fall through case Fragment.ACTIVITY_CREATED: if (newState &gt; Fragment.ACTIVITY_CREATED) { fragmentStateManager.start(); } // fall through case Fragment.STARTED: if (newState &gt; Fragment.STARTED) { fragmentStateManager.resume(); } } } else if (f.mState &gt; newState) { switch (f.mState) { case Fragment.RESUMED: if (newState &lt; Fragment.RESUMED) { fragmentStateManager.pause(); } // fall through case Fragment.STARTED: if (newState &lt; Fragment.STARTED) { fragmentStateManager.stop(); } // fall through case Fragment.ACTIVITY_CREATED: if (newState &lt; Fragment.ACTIVITY_CREATED) { if (isLoggingEnabled(Log.DEBUG)) { Log.d(TAG, &quot;movefrom ACTIVITY_CREATED: &quot; + f); } if (f.mView != null) { // Need to save the current view state if not // done already. if (mHost.onShouldSaveFragmentState(f) &amp;&amp; f.mSavedViewState == null) { fragmentStateManager.saveViewState(); } } } // fall through case Fragment.VIEW_CREATED: if (newState &lt; Fragment.VIEW_CREATED) { FragmentAnim.AnimationOrAnimator anim = null; if (f.mView != null &amp;&amp; f.mContainer != null) { // Stop any current animations: f.mContainer.endViewTransition(f.mView); f.mView.clearAnimation(); // If parent is being removed, no need to handle child animations. if (!f.isRemovingParent()) { if (mCurState &gt; Fragment.INITIALIZING &amp;&amp; !mDestroyed &amp;&amp; f.mView.getVisibility() == View.VISIBLE &amp;&amp; f.mPostponedAlpha &gt;= 0) { anim = FragmentAnim.loadAnimation(mHost.getContext(), f, false, f.getPopDirection()); } f.mPostponedAlpha = 0; // Robolectric tests do not post the animation like a real device // so we should keep up with the container and view in case the // fragment view is destroyed before we can remove it. ViewGroup container = f.mContainer; View view = f.mView; if (anim != null) { FragmentAnim.animateRemoveFragment(f, anim, mFragmentTransitionCallback); } container.removeView(view); if (FragmentManager.isLoggingEnabled(Log.VERBOSE)) { Log.v(FragmentManager.TAG, &quot;Removing view &quot; + view + &quot; for &quot; + &quot;fragment &quot; + f + &quot; from container &quot; + container); } // If the local container is different from the fragment // container, that means onAnimationEnd was called, onDestroyView // was dispatched and the fragment was already moved to state, so // we should early return here instead of attempting to move to // state again. if (container != f.mContainer) { return; } } } // If a fragment has an exit animation (or transition), do not destroy // its view immediately and set the state after animating if (mExitAnimationCancellationSignals.get(f) == null) { fragmentStateManager.destroyFragmentView(); } } // fall through case Fragment.CREATED: if (newState &lt; Fragment.CREATED) { if (mExitAnimationCancellationSignals.get(f) != null) { // We are waiting for the fragment's view to finish animating away. newState = Fragment.CREATED; } else { fragmentStateManager.destroy(); } } // fall through case Fragment.ATTACHED: if (newState &lt; Fragment.ATTACHED) { fragmentStateManager.detach(); } } } if (f.mState != newState) { if (isLoggingEnabled(Log.DEBUG)) { Log.d(TAG, &quot;moveToState: Fragment state for &quot; + f + &quot; not updated inline; &quot; + &quot;expected state &quot; + newState + &quot; found &quot; + f.mState); } f.mState = newState; }}","link":"/2023/12/22/Fragment/"},{"title":"Gc","text":"现代VM：”引用计数法，不行。可达性分析法，行！”JVM：”可达分析法，很行”","link":"/2021/04/30/Gc/"},{"title":"Glide","text":"Glide缓存磁盘(DiskLruCache) -&gt; LRUCache(不活跃资源) -&gt; WeakReference(使用中资源) 内存缓存分为弱引用的和 LruCache ，其中正在使用的图片使用弱引用缓存，暂时不使用的图片用 LruCache缓存，这一点是通过 图片引用计数器（acquired变量）来实现的 Glide生成key（内存缓存Key类型为EngineKey）的方式远比我们想象的要复杂，决定缓存Key的参数有8种，其中包括图片URL、宽、高。 12EngineKey key = keyFactory.buildKey(model, signature, width, height, transformations, resourceClass, transcodeClass, options); 这里可以得出一个结论，几乎任意配置的改变都会导致同一张图片生成多个缓存key。举个例子：同一张图片加载到2个不同大小的ImageView会生成2个缓存图片 Glide QAglide是怎么拿到的width,height（view未测绘前拿不到宽高）width,height能拿到的原因是ViewTarget会为所持有的View注册view树绘制回调 addOnPreDrawListener(OnPreDrawListener listener) Glide的缓存大小默认是多少内存缓存最大空间(maxSize) = 每个进程可用的最大内存（activityManager.getMemoryClass() * 0.4 (低配手机的话是: 每个进程可用的最大内存 * 0.33) activityManager.getMemoryClass值： 低端设备可能在 16-32 MB 范围内。 中档设备通常在 64-128 MB 范围内。 高端设备和新款设备可能在 256 MB 或更高。//当设置largeHeap时，最多可申请512M 磁盘缓存大小: 默认250MB 磁盘缓存目录: 项目/cache/image_manager_disk_cache //todo Glide特点 会根据控件大小进行下采样，以解码出符合需求的大小，对内存更友好 内存缓存+磁盘缓存 感知生命周期，取消任务，防止内存泄漏 感知内存吃紧，进行回收 BitmapPool，防止内存抖动的进行bitmap��换 定义请求优先级 手写一个图片库注意事项 获取资源：异步并发下载图片，最大化利用cpu资源 资源解码：按实际需求异步解码，多线程并发是否能加快解码速度 资源变换：使用资源池，复用变换的资源，避免内存抖动 缓存：磁盘缓存原始图片，或变换的资源。内存缓存刚使用过的资源，使用lru策略控制大小 感知生命周期：避免内存泄漏 感知内存吃紧：清理缓存 Glide 数据加载流程 RequestBuilder 构建 Request和 Target，将请求委托给RequestManager，RequestManager触发Request.begin(),然后调用Engine.load()加载资源，若有内存缓存则返回，否则启动异步任务加载磁盘缓存，若无则从网络加载 DecodeJob 负责加载数据（可能从磁盘，或网络，onDataFetcherReady），再进行数据解码（onDataFetcherReady），再进行数据变换（Transformation），写ActiveResource，（将变换后的数据回调给Target），将变换后的资源写文件（ResourceEncoder） 预加载preload，加载到一个PreloadTarget，等资源加载好了，就调用clear，将资源从ActiveResource移除存到Lrucache中 感知内存吃紧注册ComponentCallbacks2，实现细粒度内存管理： onLowMemory(){清除内存} onTrimMemory(){修剪内存} 123memoryCache.trimMemory(level); // 内存缓存bitmapPool.trimMemory(level); // bitmap池arrayPool.trimMemory(level); // 字节数组池 可以设置在onTrimMemory时，取消所有正在进行的请求。 BitmapPool BitmatPool 是 Glide 维护了一个图片复用池，LruBitmapPool 使用 Lru 算法保留最近使用的尺寸的 Bitmap。 api19 后使用bitmap的字节数和config作为key，而之前使用宽高和congif，所以19以后复用度更高 用类似LinkedHashMap存储，键值对中的值是一组Bitmap，相同字节数的Bitmap 存在一个List中（这样设计的目的是，将Lru策略运用在Bitmap大小上，而不是单个Bitmap上），控制BitmapPool大小通过删除数据组中最后一个Bitmap。 BitmapPool 大部分用于Bitmap变换和gif加载时 ArrayPool 是一个采用Lru策略的数组池，用于解码时候的字节数组的复用。 清理内存意味着清理MemoryCache，BitmapPool,ArrayPool 缓存默认情况下，Glide 会在开始一个新的图片请求之前检查以下多级的缓存： 活动资源 (Active Resources) - 现在是否有另一个 View 正在展示这张图片？ 内存缓存 (Memory cache) - 该图片是否最近被加载过并仍存在于内存中？ 资源类型（Resource） - 该图片是否之前曾被解码、转换并写入过磁盘缓存？ 数据来源 (Data) - 构建这个图片的资源是否之前曾被写入过文件缓存？ 在 Glide v4 里，所有缓存键都包含至少两个元素 活动资源，内存缓存，资源磁盘缓存的缓存键还包含一些其他数据，包括： 必选：Model 可选：签名 宽度和高度 可选的变换（Transformation） 额外添加的任何 选项(Options) 请求的数据类型 (Bitmap, GIF, 或其他) 磁盘缓存策略 如果缓存策略是AUTOMATIC（默认），对于网络图片只缓存原始数据，加载本地资源是存储变换过的数据，如果加载不同尺寸的图片，则会获取原始缓存并在此基础上做变换。 如果缓存策略是ALL，会缓存原始图片以及每个尺寸的副本， 如果缓存策略是SOURCE,只会缓存变换过的资源，如果另一个界面换一个尺寸显示图片，则会重新拉取网络 可通过自定义Key实现操控缓存命中策略（混入自己的值，比如修改时间） 内存缓存 内存缓存分为两级 活跃图片 ActiveResource 使用HashMap存储正在使用资源的弱引用 资源被包装成带引用计数的EngineResource，标记引用资源的次数（当引用数不为0时阻止被回收或降级，降级即是存储到LruCache中） 这一级缓存没有大小限制，所以使用了资源的弱引用 存：每当下载资源后会在onEngineJobComplete()中存入ActiveResource，或者LruCache命中后，将资源从中LruCache移除并存入ActiveResource。 取：每当资源释放时，会降级到LruCache中（请求对应的context onDestroy了或者被gc了） 开一个后台线程，监听ReferenceQueue，不停地从中获取被gc的资源，将其从ActiveResource中移除，并重新构建一个新资源将其降级为LruCache ActiveResource是为了缓解LruCache中缓存造成压力，因为LruCache中没有命中的缓存只有等到容量超限时才会被清除，强引用即使内存吃紧也不会被gc，现在当LruCache命中后移到ActiveResource，弱引用持有，当内存吃紧时能被回收。 LruCache 使用 LinkedHashMap 存储从活跃图片降级的资源，使用Lru算法淘汰最近最少使用的 存：从活跃图片降级的资源（退出当前界面，或者ActiveResource资源被回收） 取：网络请求资源之前，从缓存中取，若命中则直接从LruCache中移除了。 内存缓存只会缓存经过转换后的图片 内存缓存键根据10多个参数生成，url，宽高 磁盘缓存 会将源数据或经过变换的数据存储在磁盘，在内存中用LinkedHashMap记录一组Entry，Entry内部包含一组文件，文件名即是key，并且有开启后台线程执行删除文件操作以控制磁盘缓存大小。 写磁盘缓存即是触发Writer将数据写入磁盘，并在内存构建对应的File缓存在LinkedHashMap中 根据缓存策略的不同，可能存储源数据和经过变换的数据。 感知生命周期 构造RequestManager时传入context，可以是app的，activity的，或者是view的 向界面添加无界面Fragment（SupportRequestManagerFragment），Fragment把生命周期传递给Lifecycle，Fragment持有RequestManager，RequestManager监听Lifecycle，RequestManager向RequestTracker传递生命周期以暂停加载，RequestTracker遍历所有正在进行的请求，并暂停他们（移除回调resourceReady回调） 当绑定context destroy时，RequestManager会将该事件传递给RequestTracker，然后触发该请求Resource的clear，再调用Engine.release，将resource降级到LruCache 通过HashMap结构保存无界面Fragment以避免重复创建 取消请求通过移除回调，设置取消标志位实现：无法取消已经发出的请求，会在DecodeJob的异步任务的run()方法中判断，如果cancel，则返回。移除各种回调，会传递到DataFetcher，httpUrlConnection 读取数据后会判断是否cancel，如果是则返回null。并没有断开链接 感知网络变化 通过 ConnectivityManager 监听网络变化，当网络恢复时，遍历请求列表，将没有完成的任务继续开始 Transformation 所有的BitmapTransformation 都是从BitmapPool 拿到一个bitmap，然后将在原有bitmap基础上应用一个matrix再画到新bitmap上。 变换也是一个key，用以在缓存的时候做区别 RecycleView图片错乱 异步任务+视图复用导致 解决方案：设置占位图+回收表项时取消图片加载（或者新得加载开始时取消旧的加载）+imageview加tag判断是否是自己的图片如果不是则先调用clear Glide 缓存失效 是因为 Key 发生变化，Url是生成key的依据，Url可能发生变化比如把token追加在后面 自定义生成key的方式，继承GlideUrl重写getCacheKey() 自定义加载 定义一个Model类用于包装需要加载的数据 定义一个Key的实现类，用于实现第一步的Model中的数据的签名用于区分缓存 定义一个DataFetcher的实现类，用于告诉Glide音频封面如何加载，并把加载结果回调出去 定义一个ModelLoader的实现类用于包装DataFetcher 定义一个ModelLoaderFactory的实现类用于生成ModelLoader实例 将自定义加载配置到AppGlideModule中 Glide线程池 磁盘缓存线程池，一个核心线程：用于io图片编码 加载资源线程池，最多不超过4个核心线程数，用于处理网络请求，图片解码转码 动画线程池，最多不超过2个线程 磁盘缓存清理线程池 ActiveResource 开启一个后台线程监听ReferenceQueue 所有线程池都默认采用优先级队列 加载Gif流程读取流的前三个字节，若判断是gif，则会命中gif解码器-将资源解码成GifDrawable，它持有GifFrameLoader会将资源解码成一张张Bitmap并且传递给DelayTarget的对象，该对象每次资源加载完毕都会通过handler发送延迟消息回调 onFrameReady() 以触发GifDrawable.invalidataSelf()重绘。加载下一帧时会重新构建DelayTarget 请求优先级通过给加载线程池配置优先级队列，加载任务DecodeJob 实现了 compareTo 方法，将priority相减 图片加载优化 服务器存多种尺寸的图片 自定义 AppGlideModule，按设备性能好坏设定MemoryCategory.HIGH,LOW,NORMAL，内存缓存和bitmapPool的大小系数，以及图片解码格式，ARGB_8888，RGB_565 RecyclerView 在onViewRecycled 中调用clear ，因为recyclerView会默认会缓存5个同类表项，如果类型很多，内存中会持有表项，如果这些表项都包含图片，Glide 的ActiveResource会膨胀。导致gc 如果 RecyclerView 包含一个很长的itemView，超过一屏，其中包含很多照片，最好把长itemView拆成多个itemView 使用thumbnail，加载一个缩略图，最好是一个独立的链接，如果是本地的也不差 使用preload，将资源提前加载到内存中。 大部分情况下 RESOURCE ，即缓存经过变换的图片上是最好选择，节约内存和磁盘。对于gif资源只缓存原始资源DATA，因为gif是多张图每次编码解码反而耗时 使用Glide实现变换，因为有BitmapPool供复用","link":"/2021/09/30/Glide/"},{"title":"Generics","text":"Java泛型简述： 理解的泛型，其实是这样的：假如没有泛型，出现在泛型类型位置的就会是Object类，而程序员在使用该类型的时候再手动将类型强转一下，不仅代码啰嗦、而且有类型不匹配的crash可能。 而java1.5提供泛型同时为了兼容旧版，本质上也是用了Object，只不过编译器将.java编译成.class时进行“泛型擦除”时会把泛型类型替代成Object或上限类型（字节码中就不存在泛型了），再自动地使用处前加上原始类型的强转，之后再加载到JVM中。而在编译期存在的泛型可以借由IDE有效的进行类型检测和可读的扩展，防止类型不匹配。 //java伪泛型的设计原因主要为了兼容老版本的java。真泛型并非做不到，而是因为如果用真泛型（即类型保留），老程序都需要修改。 //另外泛型类中基础数据类型需要使用Integer、Long等封装类的原因也是因为“擦除后会把泛型类型替代成Object或上限类型” 而kotlin的泛型是跟java一样的，在编译时会被擦除。但是kotlin提供了新的特性可以保留类型，就是**内联函数+reified(ˈriːɪfʌɪ/)**，泛型实化，可以说是真泛型：内联函数(inline)会把方法体copy到调用处（即不会创建新的虚拟机栈帧）， 123inline fun &lt;reified C : Activity&gt; Context.startActivityKtx() { startActivity(Intent(this, C::class.java))} 协变：①协变：父子关系一致→子类也可以作为参数传进来→java&lt;? extends Entity&gt;→上界通配符→kotlin&lt;out Entity&gt; 逆变：②逆变：父子关系颠倒→父类也可以作为参数传进来→java&lt;? super Article&gt;→下界通配符→kotlin&lt;in Entiry&gt; 不变：③不变：只能 无限通配符&lt;?&gt; == java &lt;? extend Object&gt; == kotlin&lt;*&gt; == kotlin&lt;out Any&gt; 不变比如： 12345/** * 支持添加和删除元素的通用有序元素集合。 * 参数： * E - 列表中包含的元素的类型。可变列表的元素类型是不变的。 */public interface MutableList&lt;E&gt; : List&lt;E&gt;, MutableCollection&lt;E&gt; 协变比如： 123456/** * 通用的有序元素集合。该接口中的方法仅支持对列表的只读访问；通过MutableList接口支持读/写访问。 * 参数： * E - 列表中包含的元素的类型。该列表的元素类型是协变的。 */public interface Collection&lt;out E&gt; : Iterable&lt;E&gt; 与普通的 Object 代替一切类型这样简单粗暴而言， 简述：泛型提供了可以使类型像参数一样由外部传递进来的扩展能力，同时还提供了编译时的类型检测机制，即当传入数据类型为泛型 时才能编译通过，提高了可读性。 但出于规范的目的，Java 还是建议我们用单个大写字母来代表类型参数。常见的如： T 代表一般的任何类。E 代表 Element 的意思，或者 Exception 异常的意思。K 代表 Key 的意思。V 代表 Value 的意思，通常与 K 一起配合使用。S 代表 Subtype 的意思，文章后面部分会讲解示意。 泛型可以为类和方法分别定义泛型参数， 泛型类： 1234//尖括号 &lt;&gt;中的 T 被称作是类型参数，用于指代任何类型。事实上，T 只是一种习惯性写法，如果你愿意。你可以这样写。public class Test&lt;T&gt; { T field1;} 泛型方法始终以自己定义的类型参数为准。 通配符的出现是为了指定泛型中的类型范围。 通配符有 3 种形式。 &lt;?&gt;被称作无限定的通配符。 &lt;? extends T&gt;被称作有上限的通配符。 &lt;? super T&gt;被称作有下限的通配符。 泛型信息只存在于代码编译阶段，在进入 JVM 之前，与泛型相关的信息会被擦除掉，专业术语叫做类型擦除 在泛型类被类型擦除的时候，之前泛型类中的类型参数部分如果没有指定上限，如 &lt;T&gt;则会被转译成普通的 Object 类型，如果指定了上限如 &lt;T extends String&gt;则类型参数就被替换成类型上限。 Java获取泛型的class方法：一：在构造类时传递泛型类型参数1234567891011121314class MyClass&lt;T&gt; { private Class&lt;T&gt; type; public MyClass(Class&lt;T&gt; type) { this.type = type; }}public class Main { public static void main(String[] args) { MyClass&lt;String&gt; myObj = new MyClass&lt;&gt;(String.class); myObj.printType(); // Output: Type: java.lang.String }} 二：反射获取123456789class MyClass&lt;T&gt; { public void printType() { Type superclass = getClass().getGenericSuperclass(); if (superclass instanceof ParameterizedType) { Type[] typeArguments = ((ParameterizedType) superclass).getActualTypeArguments(); typeArguments[0]//泛型类型可能多个 } }} 匿名内部类在初始化的时候就会绑定父类或者父接口的信息，这样就能通过获取父类或父接口的泛型类型信息，来实现我们的需求 如Gson中的TypeToken或FastJson中的TypeReference，使用创建继承于特定抽象类的匿名内部类对象获得 kotlin 泛型Kotlin 泛型系统继承于 Java泛型，依然是一种语法糖的伪泛型，会在编译时发生类型擦除。但可以通过inline+reified实现泛型实化的真泛型 Inline+reified 泛型实化的原理：我们都知道内联函数的原理，编译器把实现内联函数的字节码动态插入到每次的调用点。那么实化的原理正是基于这个机制，每次调用带实化类型参数的函数时，编译器都知道此次调用中作为泛型类型实参的具体类型。所以编译器只要在每次调用时生成对应不同类型实参调用的字节码插入到调用点即可。 总之一句话很简单，就是带实化参数的函数每次调用都生成不同类型实参的字节码，动态插入到调用点。由于生成的字节码的类型实参引用了具体的类型，而不是类型参数所以不会存在擦除问题。 简述：由于inline的存在，泛型类型实参的调用处在同一个方法体内，相当于直接知道了类型，所以只要编译时直接生成对应的不同类型实参即可 实化类型参数函数的使用限制这里说的使用限制主要有两点: 1、Java调用Kotlin中的实化类型参数函数限制明确回答Kotlin中的实化类型参数函数不能在Java中的调用，我们可以简单的分析下，首先Kotlin的实化类型参数函数主要得益于inline函数的内联功能，但是Java可以调用普通的内联函数但是失去了内联功能，失去内联功能也就意味实化操作也就化为泡影。故重申一次Kotlin中的实化类型参数函数不能在Java中的调用 2、Kotlin实化类型参数函数的使用限制 不能使用非实化类型形参作为类型实参调用带实化类型参数的函数 不能使用实化类型参数创建该类型参数的实例对象 不能调用实化类型参数的伴生对象方法 reified关键字只能标记实化类型参数的内联函数，不能作用与类和属性。 泛型类型获取方式在Kotlin中可以通过下述方法获取泛型的类型 通过匿名内部类获得泛型参数类型具体示例： 1234567// Java ArrayList arrayList = new ArrayList&lt;String&gt;(){};System.out.println(arrayList.getClass().getGenericSuperclass());// Kotlinval clazz = object :ArrayList&lt;String&gt;(){}// Kotlin 的匿名内部类println(clazz.javaClass.genericSuperclass) 为什么可以通过匿名内部类可以在运行期获得泛型参数的类型呢？这是因为 泛型的类型擦除并不是完全的将所有信息擦除，而会 将类型信息放在所属 class 的常量池中，这样我们就可以通过相应的方式获得类型信息，而匿名内部类就可以实现这个功能。 Java 将泛型信息存储在何处：类信息的签名中。 匿名内部类在初始化的时候就会绑定父类或者父接口的信息，这样就能通过获取父类或父接口的泛型类型信息，来实现我们的需求，可以通过利用此来设计一个获得所有类型信息的泛型类： 12345678910111213open class GenericsToken&lt;T&gt;{ var type : Type = Any::class.java init { val superClass = this.javaClass.genericSuperclass type = (superClass as ParameterizedType).actualTypeArguments[0] }}fun main(args: Array&lt;String&gt;) { // 创建一个匿名内部类 val oneKt = object:GenericsToken&lt;Map&lt;String,String&gt;&gt;(){} println(oneKt.type)} 打印日志： 1java.util.Map&lt;java.lang.String, ? extends java.lang.String&gt; 至于如果获得参数化类型，可参见此博客：ParameterizedType应用，java反射，获取参数化类型的class实例 其实正是因为类型擦除的原因，在使用 Gson 反序列化对象的时候除了制定泛型参数，还需要传入一个 class ： 123public &lt;T&gt; T fromJson(String json, Class&lt;T&gt; classOfT) throws JsonSyntaxException { ... } 因为 Gson 没有办法根据 T 直接去反序列化，所以 Gson 也是使用了相同的设计，通过匿名内部类获得相应的类型参数，然后传到 fromJson 中进行反序列化。 看一下在 Kotlin 中我们使用 Gson 来进行泛型类的反序列化： 123val json = &quot;....&quot;val rType = object: TypeToken&lt;List&lt;String&gt;&gt;(){}.type// 获得反序列化的数据类型val stringList = Gson().fromJson&lt;List&lt;String&gt;&gt;(json,rType) 当然可以直接传输数据类型： 12// 存在局限，比如不能传入 List&lt;String&gt; 的数据类型val stringList = Gson().fromJson&lt;String::class.java&gt;(json,rType) 在 Kotlin 中除了使用匿名内部类获得泛型参数外，还可以使用内联函数来获取。 使用内联函数获取泛型的参数类型内联函数的特征： 内联函数(inline)在编译时会将具体的函数字节码插入调用的地方，类型插入相应的字节码中，这就意味着泛型参数类型也会被插入到字节码中，那么就可以实现在运行时就可以获得对应的参数类型了。 使用内联函数获取泛型的参数类型十分的简单，只要加上 reified 关键字，意思是：在编译时会将 具体的类型 插入到相应的字节码中，那么就可以获得对应参数的类型，与 Java 中的泛型在编译器进行类型擦除不同，Kotlin 中使用 reified 修饰泛型，该泛型类型信息不会被抹去，所以 Kotiln 中的该泛型为 真泛型。 reified 为 Kotlin 中的一个关键字，还有一个叫做 inline，后者可以将函数定义为内联函数，前者可以将内联函数的泛型参数当做真实类型使用. 可以借此来为 Gson 定义一个扩展函数： 1234inline fun &lt;reified T: Any&gt; Gson.fromJson(json: String): T{ return fromJson(json, T::class.java) } 有了此扩展方法，就无须在 Kotlin 当中显式的传入一个 class 对象就可以直接反序列化 json 了： 12345class Person(var id: Int, var name: String) fun test(){ val person: Person = Gson().fromJson&lt;User&gt;(&quot;&quot;&quot;{&quot;id&quot;: 0, &quot;name&quot;: &quot;Jack&quot; }&quot;&quot;&quot;) } 由于 Gson.fromJson 是内联函数，方法调用时插入调用位置，T 的类型在编译时就可以确定了，反编译之后的代码： 12345public static final void test() { Gson $receiver$iv = new Gson(); String json$iv = &quot;{\\&quot;id\\&quot;: 0, \\&quot;name\\&quot;: \\&quot;Jack\\&quot; }&quot;; Person person = (Person)$receiver$iv.fromJson(json$iv, Person.class); } 这就是 Kotin 的泛型被称为 真泛型 的原因。 但是 refied 存在一个问题：reified 只能修饰方法，而当定义一个泛型类时，reified 是无法通过类似以上的方式获得泛型参数的，但是仍然可以通过其他方式获得泛型类中的泛型参数类型，具体如下： 123456789101112131415class View&lt;T&gt;(val clazz:Class&lt;T&gt;){ val presenter by lazy { clazz.newInstance() } companion object{ // 在构造函数执行之前，执行了此处，真泛型的重载函数。 inline operator fun &lt;reified T&gt; invoke() = View(T::class.java) }}class Presenterfun main(args: Array&lt;String&gt;) { // 两者等效，具体实现如下 val p = View&lt;Presenter&gt;().presenter val a = View.Companion.invoke&lt;Presenter&gt;().presenter} 这种写法特别适合在 android 中的 MVP，不用再在 Activity 中显式的显示 Presenter 的类名。 12345678910111213141516171819202122232425262728293031323334353637//接受多个类型参数。public class MultiType &lt;E,T&gt;{ E value1; T value2; public E getValue1(){ return value1; } public T getValue2(){ return value2; }}//泛型类与泛型方法的共存public class Test1&lt;T&gt;{ public void testMethod(T t){ System.out.println(t.getClass().getName()); } public &lt;T&gt; T testMethod1(T t){ return t; }}//上述泛型类与泛型方法共存的testMethod1实际上其类型参数是自己在函数申明的pulic &lt;T&gt; 中，与 整个类的T没关系，//为了避免混淆，如果在一个泛型类中存在泛型方法，那么两者的类型参数最好不要同名。应该像下面这样写。public class Test1&lt;T&gt;{ public void testMethod(T t){ System.out.println(t.getClass().getName()); } public &lt;E&gt; E testMethod1(E e){ return e; }}","link":"/2021/12/31/Generics/"},{"title":"HandlerEpoll","text":"Looper的阻塞唤醒简述：通过pipe/epoll机制，实现MessageQueue.next的无消息时阻塞，有消息时唤醒，pipe 原理具体来说，当Looper在处理消息时，如果消息队列为空，那么它会调用MessageQueue的next方法来等待新的消息到来，通过Linux内核的epoll机制阻塞线程，等待新的消息到来。在阻塞期间，线程处于睡眠状态，不会占用CPU资源;当新的消息到来时，MessageQueue对象会将消息加入队列，并通知Looper对象，从而唤醒线程并继续执行消息的分发和处理。 epoll机制是Linux内核提供的一种高效的I/O多路复用机制，可以在多个文件描述符上等待，并在其中任何一个文件描述符有事件到达时立即返回，从而实现高效的I/O事件处理。 epoll机制主要分为以下三个步骤： 创建epoll句柄：在使用epoll机制之前，首先需要创建一个epoll句柄。这可以通过调用epoll_create函数来完成，它会返回一个整型的文件描述符，可以用于后续的epoll操作。 添加文件描述符到epoll：将需要监听的文件描述符添加到epoll中，可以通过调用epoll_ctl函数来完成。在添加文件描述符时，需要指定文件描述符的类型（例如管道、socket等）、事件类型（例如读事件、写事件等）以及回调函数等信息。 等待事件到达：等待事件到达是epoll机制的核心。可以通过调用epoll_wait函数来等待文件描述符上的事件。该函数会阻塞，直到有文件描述符上有事件到达或者超时时间到达。当有事件到达时，函数会立即返回，返回值为就绪文件描述符的个数，同时将就绪文件描述符的信息填充到一个事件数组中。 在处理就绪事件时，可以遍历事件数组，并根据每个事件的类型来进行相应的处理。例如，如果是读事件，可以使用read函数来读取文件描述符上的数据。 总之，通过使用epoll机制，可以高效地处理多个文件描述符上的I/O事件，并及时响应事件的到达。这种机制在Linux系统中得到了广泛的应用，包括网络编程、图形界面等领域。 为什么不用wait和notify实现Looper的阻塞唤醒机制Android的Handler Framework中的Looper的阻塞唤醒机制是依靠Linux内核的轮询机制来实现的，而不是使用Java中的wait和notify方法。 在Android系统中，每个线程都有一个EventLoop，它由Looper来管理。Looper使用Linux内核的poll系统调用来阻塞线程，同时在有消息到来时唤醒线程。poll是Linux内核中的一个系统调用，它可以用来等待文件描述符的状态变化，比如数据是否可读或可写等。Looper将MessageQueue封装成一个管道（pipe），然后将管道的读端口添加到poll的监听列表中。当消息到达时，MessageQueue就会将消息写入管道的写端口，从而使得poll返回。然后Looper就可以从管道中读取消息，进行相应的处理。 使用Linux内核的poll系统调用可以避免使用Java中的wait和notify方法的缺陷，例如不会发生死锁、不会占用CPU资源等。此外，这种机制还可以支持更多的线程，因为每个线程都有自己的EventLoop和MessageQueue，它们之间相互独立，不会发生竞争问题。 Native Framework 早期的Android MessageQueue底层是select实现Looper唤醒的，后面由于select效率在频繁调用的情况下不如Linux 2.6内核正式引入的epoll IO 多路复用的需求和原理。 IO 多路复用就是 1 个线程处理 多个 fd 的模式。我们的要求是：这个 “1” 就要尽可能的快，避免一切无效工作，要把所有的时间都用在处理句柄的 IO 上，不能有任何空转，sleep 的时间浪费。 这 3 种都能够管理 fd 的可读可写事件，在所有 fd 不可读不可写无所事事的时候，可以阻塞线程，切走 cpu 。fd 有情况的时候，都要线程能够要能被唤醒。 表 1. select、poll和epoll三种I/O复用模式的比较（ 摘录自《linux高性能服务器编程》） 系统调用 select poll epoll 事件集合 通过3个参数分别传入感兴趣的可读，可写及异常等事件内核通过对这些参数的在线修改来反馈其中的就绪事件这使得用户每次调用select都要重置这3个参数 统一处理所有事件类型，因此只需要一个事件集参数。用户通过pollfd.events传入感兴趣的事件，内核通过修改pollfd.revents反馈其中就绪的事件 内核通过一个事件表直接管理用户感兴趣的所有事件。因此每次调用epoll_wait时，无需反复传入用户感兴趣的事件。epoll_wait系统调用的参数events仅用来反馈就绪的事件 应用程序索引就绪文件描述符的时间复杂度 O(n) O(n) O(1) 最大支持文件描述符数 一般有最大值限制 65535 65535 工作模式 LT LT 支持ET高效模式 内核实现和工作效率 采用轮询方式检测就绪事件，时间复杂度：O(n) 采用轮询方式检测就绪事件，时间复杂度：O(n) 采用回调方式检测就绪事件，时间复杂度：O(1) select在loop的一次循环中sleep 一段时间（cpu释放出去），在定时到达后进入下一次循环执行任务，此次任务中会遍历所有fd，查询哪个已经ready，效率很差 poll相比于select机制，poll只是取消了最大监控文件描述符数限制，并没有从根本上解决select存在的问题。 poll和select库，它们的最大的问题就在于效率。它们的处理方式都是创建一个事件列表，然后把这个列表发给内核，返回的时候，再去轮询检查这个列表，这样在描述符比较多的应用中，效率就显得比较低下了。 epoll执行完所有任务之后进入休眠， 挂了个钩子，设置了唤醒的回调路径。epoll 跟底层对接的回调函数是：ep_poll_callback，这个函数其实很简单，做两件事情： 把事件就绪的 fd 对应的结构体放到一个特定的队列（就绪队列，ready list）； 唤醒 epoll ，活来啦！ 当 fd 满足可读可写的时候就会经过层层回调，最终调用到这个回调函数，把对应 fd 的结构体放入就绪队列中，从而把 epoll 从 epoll_wait 出唤醒。 由epoll_wait() 唤醒的时候已经精准地拿到了ready的fd数组了，于是就能直接执行 poll是翻译轮询的意思，我们可以看到poll和epoll都有轮询的过程。不同点在于：poll轮询的是所有的socket。而epoll只轮询就绪的socket epoll是一种比较好的做法，它把描述符列表交给内核，一旦有事件发生，内核把发生事件的描述符列表通知给进程，这样就避免了轮询整个描述符列表。 epoll 之所以做到了高效，最关键的两点： 内部管理 fd 使用了高效的红黑树结构管理，做到了增删改之后性能的优化和平衡； epoll 池添加 fd 的时候，调用 file_operations-&gt;poll ，把这个 fd 就绪之后的回调路径安排好。通过事件通知的形式，做到最高效的运行； epoll 池核心的两个数据结构：红黑树和就绪列表。红黑树是为了应对用户的增删改需求，就绪列表是 fd 事件就绪之后放置的特殊地点，epoll 池只需要遍历这个就绪链表，就能给用户返回所有已经就绪的 fd 数组； Java Framework 附录NativeMessageQueue.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236/* * Copyright (C) 2010 The Android Open Source Project * * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */#define LOG_TAG &quot;MessageQueue-JNI&quot;#include &lt;nativehelper/JNIHelp.h&gt;#include &lt;android_runtime/AndroidRuntime.h&gt;#include &lt;utils/Looper.h&gt;#include &lt;utils/Log.h&gt;#include &quot;android_os_MessageQueue.h&quot;#include &quot;core_jni_helpers.h&quot;namespace android {static struct { jfieldID mPtr; // native object attached to the DVM MessageQueue jmethodID dispatchEvents;} gMessageQueueClassInfo;// Must be kept in sync with the constants in Looper.FileDescriptorCallbackstatic const int CALLBACK_EVENT_INPUT = 1 &lt;&lt; 0;static const int CALLBACK_EVENT_OUTPUT = 1 &lt;&lt; 1;static const int CALLBACK_EVENT_ERROR = 1 &lt;&lt; 2;class NativeMessageQueue : public MessageQueue, public LooperCallback {public: NativeMessageQueue(); virtual ~NativeMessageQueue(); virtual void raiseException(JNIEnv* env, const char* msg, jthrowable exceptionObj); void pollOnce(JNIEnv* env, jobject obj, int timeoutMillis); void wake(); void setFileDescriptorEvents(int fd, int events); virtual int handleEvent(int fd, int events, void* data);private: JNIEnv* mPollEnv; jobject mPollObj; jthrowable mExceptionObj;};MessageQueue::MessageQueue() {}MessageQueue::~MessageQueue() {}bool MessageQueue::raiseAndClearException(JNIEnv* env, const char* msg) { if (env-&gt;ExceptionCheck()) { jthrowable exceptionObj = env-&gt;ExceptionOccurred(); env-&gt;ExceptionClear(); raiseException(env, msg, exceptionObj); env-&gt;DeleteLocalRef(exceptionObj); return true; } return false;}NativeMessageQueue::NativeMessageQueue() : mPollEnv(NULL), mPollObj(NULL), mExceptionObj(NULL) { mLooper = Looper::getForThread(); if (mLooper == NULL) { mLooper = new Looper(false); Looper::setForThread(mLooper); }}NativeMessageQueue::~NativeMessageQueue() {}void NativeMessageQueue::raiseException(JNIEnv* env, const char* msg, jthrowable exceptionObj) { if (exceptionObj) { if (mPollEnv == env) { if (mExceptionObj) { env-&gt;DeleteLocalRef(mExceptionObj); } mExceptionObj = jthrowable(env-&gt;NewLocalRef(exceptionObj)); ALOGE(&quot;Exception in MessageQueue callback: %s&quot;, msg); jniLogException(env, ANDROID_LOG_ERROR, LOG_TAG, exceptionObj); } else { ALOGE(&quot;Exception: %s&quot;, msg); jniLogException(env, ANDROID_LOG_ERROR, LOG_TAG, exceptionObj); LOG_ALWAYS_FATAL(&quot;raiseException() was called when not in a callback, exiting.&quot;); } }}void NativeMessageQueue::pollOnce(JNIEnv* env, jobject pollObj, int timeoutMillis) { mPollEnv = env; mPollObj = pollObj; mLooper-&gt;pollOnce(timeoutMillis); mPollObj = NULL; mPollEnv = NULL; if (mExceptionObj) { env-&gt;Throw(mExceptionObj); env-&gt;DeleteLocalRef(mExceptionObj); mExceptionObj = NULL; }}void NativeMessageQueue::wake() { mLooper-&gt;wake();}void NativeMessageQueue::setFileDescriptorEvents(int fd, int events) { if (events) { int looperEvents = 0; if (events &amp; CALLBACK_EVENT_INPUT) { looperEvents |= Looper::EVENT_INPUT; } if (events &amp; CALLBACK_EVENT_OUTPUT) { looperEvents |= Looper::EVENT_OUTPUT; } mLooper-&gt;addFd(fd, Looper::POLL_CALLBACK, looperEvents, this, reinterpret_cast&lt;void*&gt;(events)); } else { mLooper-&gt;removeFd(fd); }}int NativeMessageQueue::handleEvent(int fd, int looperEvents, void* data) { int events = 0; if (looperEvents &amp; Looper::EVENT_INPUT) { events |= CALLBACK_EVENT_INPUT; } if (looperEvents &amp; Looper::EVENT_OUTPUT) { events |= CALLBACK_EVENT_OUTPUT; } if (looperEvents &amp; (Looper::EVENT_ERROR | Looper::EVENT_HANGUP | Looper::EVENT_INVALID)) { events |= CALLBACK_EVENT_ERROR; } int oldWatchedEvents = reinterpret_cast&lt;intptr_t&gt;(data); int newWatchedEvents = mPollEnv-&gt;CallIntMethod(mPollObj, gMessageQueueClassInfo.dispatchEvents, fd, events); if (!newWatchedEvents) { return 0; // unregister the fd } if (newWatchedEvents != oldWatchedEvents) { setFileDescriptorEvents(fd, newWatchedEvents); } return 1;}// ----------------------------------------------------------------------------sp&lt;MessageQueue&gt; android_os_MessageQueue_getMessageQueue(JNIEnv* env, jobject messageQueueObj) { jlong ptr = env-&gt;GetLongField(messageQueueObj, gMessageQueueClassInfo.mPtr); return reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr);}static jlong android_os_MessageQueue_nativeInit(JNIEnv* env, jclass clazz) { NativeMessageQueue* nativeMessageQueue = new NativeMessageQueue(); if (!nativeMessageQueue) { jniThrowRuntimeException(env, &quot;Unable to allocate native queue&quot;); return 0; } nativeMessageQueue-&gt;incStrong(env); return reinterpret_cast&lt;jlong&gt;(nativeMessageQueue);}static void android_os_MessageQueue_nativeDestroy(JNIEnv* env, jclass clazz, jlong ptr) { NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr); nativeMessageQueue-&gt;decStrong(env);}static void android_os_MessageQueue_nativePollOnce(JNIEnv* env, jobject obj, jlong ptr, jint timeoutMillis) { NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr); nativeMessageQueue-&gt;pollOnce(env, obj, timeoutMillis);}static void android_os_MessageQueue_nativeWake(JNIEnv* env, jclass clazz, jlong ptr) { NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr); nativeMessageQueue-&gt;wake();}static jboolean android_os_MessageQueue_nativeIsPolling(JNIEnv* env, jclass clazz, jlong ptr) { NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr); return nativeMessageQueue-&gt;getLooper()-&gt;isPolling();}static void android_os_MessageQueue_nativeSetFileDescriptorEvents(JNIEnv* env, jclass clazz, jlong ptr, jint fd, jint events) { NativeMessageQueue* nativeMessageQueue = reinterpret_cast&lt;NativeMessageQueue*&gt;(ptr); nativeMessageQueue-&gt;setFileDescriptorEvents(fd, events);}// ----------------------------------------------------------------------------static const JNINativeMethod gMessageQueueMethods[] = { /* name, signature, funcPtr */ { &quot;nativeInit&quot;, &quot;()J&quot;, (void*)android_os_MessageQueue_nativeInit }, { &quot;nativeDestroy&quot;, &quot;(J)V&quot;, (void*)android_os_MessageQueue_nativeDestroy }, { &quot;nativePollOnce&quot;, &quot;(JI)V&quot;, (void*)android_os_MessageQueue_nativePollOnce }, { &quot;nativeWake&quot;, &quot;(J)V&quot;, (void*)android_os_MessageQueue_nativeWake }, { &quot;nativeIsPolling&quot;, &quot;(J)Z&quot;, (void*)android_os_MessageQueue_nativeIsPolling }, { &quot;nativeSetFileDescriptorEvents&quot;, &quot;(JII)V&quot;, (void*)android_os_MessageQueue_nativeSetFileDescriptorEvents },};int register_android_os_MessageQueue(JNIEnv* env) { int res = RegisterMethodsOrDie(env, &quot;android/os/MessageQueue&quot;, gMessageQueueMethods, NELEM(gMessageQueueMethods)); jclass clazz = FindClassOrDie(env, &quot;android/os/MessageQueue&quot;); gMessageQueueClassInfo.mPtr = GetFieldIDOrDie(env, clazz, &quot;mPtr&quot;, &quot;J&quot;); gMessageQueueClassInfo.dispatchEvents = GetMethodIDOrDie(env, clazz, &quot;dispatchEvents&quot;, &quot;(II)I&quot;); return res;}} // namespace android Looper.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561//// Copyright 2010 The Android Open Source Project//// A looper implementation based on epoll().//#define LOG_TAG &quot;Looper&quot;//#define LOG_NDEBUG 0// Debugs poll and wake interactions.#define DEBUG_POLL_AND_WAKE 0// Debugs callback registration and invocation.#define DEBUG_CALLBACKS 0#include &lt;cutils/log.h&gt;#include &lt;utils/Looper.h&gt;#include &lt;utils/Timers.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;limits.h&gt;namespace android {// --- WeakMessageHandler ---WeakMessageHandler::WeakMessageHandler(const wp&lt;MessageHandler&gt;&amp; handler) : mHandler(handler) {}WeakMessageHandler::~WeakMessageHandler() {}void WeakMessageHandler::handleMessage(const Message&amp; message) { sp&lt;MessageHandler&gt; handler = mHandler.promote(); if (handler != NULL) { handler-&gt;handleMessage(message); }}// --- SimpleLooperCallback ---SimpleLooperCallback::SimpleLooperCallback(ALooper_callbackFunc callback) : mCallback(callback) {}SimpleLooperCallback::~SimpleLooperCallback() {}int SimpleLooperCallback::handleEvent(int fd, int events, void* data) { return mCallback(fd, events, data);}// --- Looper ---// Hint for number of file descriptors to be associated with the epoll instance.static const int EPOLL_SIZE_HINT = 8;// Maximum number of file descriptors for which to retrieve poll events each iteration.static const int EPOLL_MAX_EVENTS = 16;static pthread_once_t gTLSOnce = PTHREAD_ONCE_INIT;static pthread_key_t gTLSKey = 0;Looper::Looper(bool allowNonCallbacks) : mAllowNonCallbacks(allowNonCallbacks), mSendingMessage(false), mResponseIndex(0), mNextMessageUptime(LLONG_MAX) { int wakeFds[2]; int result = pipe(wakeFds); LOG_ALWAYS_FATAL_IF(result != 0, &quot;Could not create wake pipe. errno=%d&quot;, errno); mWakeReadPipeFd = wakeFds[0]; mWakeWritePipeFd = wakeFds[1]; result = fcntl(mWakeReadPipeFd, F_SETFL, O_NONBLOCK); LOG_ALWAYS_FATAL_IF(result != 0, &quot;Could not make wake read pipe non-blocking. errno=%d&quot;, errno); result = fcntl(mWakeWritePipeFd, F_SETFL, O_NONBLOCK); LOG_ALWAYS_FATAL_IF(result != 0, &quot;Could not make wake write pipe non-blocking. errno=%d&quot;, errno); // Allocate the epoll instance and register the wake pipe. mEpollFd = epoll_create(EPOLL_SIZE_HINT); LOG_ALWAYS_FATAL_IF(mEpollFd &lt; 0, &quot;Could not create epoll instance. errno=%d&quot;, errno); struct epoll_event eventItem; memset(&amp; eventItem, 0, sizeof(epoll_event)); // zero out unused members of data field union eventItem.events = EPOLLIN; eventItem.data.fd = mWakeReadPipeFd; result = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, mWakeReadPipeFd, &amp; eventItem); LOG_ALWAYS_FATAL_IF(result != 0, &quot;Could not add wake read pipe to epoll instance. errno=%d&quot;, errno);}Looper::~Looper() { close(mWakeReadPipeFd); close(mWakeWritePipeFd); close(mEpollFd);}void Looper::initTLSKey() { int result = pthread_key_create(&amp; gTLSKey, threadDestructor); LOG_ALWAYS_FATAL_IF(result != 0, &quot;Could not allocate TLS key.&quot;);}void Looper::threadDestructor(void *st) { Looper* const self = static_cast&lt;Looper*&gt;(st); if (self != NULL) { self-&gt;decStrong((void*)threadDestructor); }}void Looper::setForThread(const sp&lt;Looper&gt;&amp; looper) { sp&lt;Looper&gt; old = getForThread(); // also has side-effect of initializing TLS if (looper != NULL) { looper-&gt;incStrong((void*)threadDestructor); } pthread_setspecific(gTLSKey, looper.get()); if (old != NULL) { old-&gt;decStrong((void*)threadDestructor); }}sp&lt;Looper&gt; Looper::getForThread() { int result = pthread_once(&amp; gTLSOnce, initTLSKey); LOG_ALWAYS_FATAL_IF(result != 0, &quot;pthread_once failed&quot;); return (Looper*)pthread_getspecific(gTLSKey);}sp&lt;Looper&gt; Looper::prepare(int opts) { bool allowNonCallbacks = opts &amp; ALOOPER_PREPARE_ALLOW_NON_CALLBACKS; sp&lt;Looper&gt; looper = Looper::getForThread(); if (looper == NULL) { looper = new Looper(allowNonCallbacks); Looper::setForThread(looper); } if (looper-&gt;getAllowNonCallbacks() != allowNonCallbacks) { ALOGW(&quot;Looper already prepared for this thread with a different value for the &quot; &quot;ALOOPER_PREPARE_ALLOW_NON_CALLBACKS option.&quot;); } return looper;}bool Looper::getAllowNonCallbacks() const { return mAllowNonCallbacks;}int Looper::pollOnce(int timeoutMillis, int* outFd, int* outEvents, void** outData) { int result = 0; for (;;) { while (mResponseIndex &lt; mResponses.size()) { const Response&amp; response = mResponses.itemAt(mResponseIndex++); int ident = response.request.ident; if (ident &gt;= 0) { int fd = response.request.fd; int events = response.events; void* data = response.request.data;#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ pollOnce - returning signalled identifier %d: &quot; &quot;fd=%d, events=0x%x, data=%p&quot;, this, ident, fd, events, data);#endif if (outFd != NULL) *outFd = fd; if (outEvents != NULL) *outEvents = events; if (outData != NULL) *outData = data; return ident; } } if (result != 0) {#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ pollOnce - returning result %d&quot;, this, result);#endif if (outFd != NULL) *outFd = 0; if (outEvents != NULL) *outEvents = 0; if (outData != NULL) *outData = NULL; return result; } result = pollInner(timeoutMillis); }}int Looper::pollInner(int timeoutMillis) {#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ pollOnce - waiting: timeoutMillis=%d&quot;, this, timeoutMillis);#endif // Adjust the timeout based on when the next message is due. if (timeoutMillis != 0 &amp;&amp; mNextMessageUptime != LLONG_MAX) { nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); int messageTimeoutMillis = toMillisecondTimeoutDelay(now, mNextMessageUptime); if (messageTimeoutMillis &gt;= 0 &amp;&amp; (timeoutMillis &lt; 0 || messageTimeoutMillis &lt; timeoutMillis)) { timeoutMillis = messageTimeoutMillis; }#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ pollOnce - next message in %lldns, adjusted timeout: timeoutMillis=%d&quot;, this, mNextMessageUptime - now, timeoutMillis);#endif } // Poll. int result = ALOOPER_POLL_WAKE; mResponses.clear(); mResponseIndex = 0; struct epoll_event eventItems[EPOLL_MAX_EVENTS]; int eventCount = epoll_wait(mEpollFd, eventItems, EPOLL_MAX_EVENTS, timeoutMillis); // Acquire lock. mLock.lock(); // Check for poll error. if (eventCount &lt; 0) { if (errno == EINTR) { goto Done; } ALOGW(&quot;Poll failed with an unexpected error, errno=%d&quot;, errno); result = ALOOPER_POLL_ERROR; goto Done; } // Check for poll timeout. if (eventCount == 0) {#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ pollOnce - timeout&quot;, this);#endif result = ALOOPER_POLL_TIMEOUT; goto Done; } // Handle all events.#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ pollOnce - handling events from %d fds&quot;, this, eventCount);#endif for (int i = 0; i &lt; eventCount; i++) { int fd = eventItems[i].data.fd; uint32_t epollEvents = eventItems[i].events; if (fd == mWakeReadPipeFd) { if (epollEvents &amp; EPOLLIN) { awoken(); } else { ALOGW(&quot;Ignoring unexpected epoll events 0x%x on wake read pipe.&quot;, epollEvents); } } else { ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex &gt;= 0) { int events = 0; if (epollEvents &amp; EPOLLIN) events |= ALOOPER_EVENT_INPUT; if (epollEvents &amp; EPOLLOUT) events |= ALOOPER_EVENT_OUTPUT; if (epollEvents &amp; EPOLLERR) events |= ALOOPER_EVENT_ERROR; if (epollEvents &amp; EPOLLHUP) events |= ALOOPER_EVENT_HANGUP; pushResponse(events, mRequests.valueAt(requestIndex)); } else { ALOGW(&quot;Ignoring unexpected epoll events 0x%x on fd %d that is &quot; &quot;no longer registered.&quot;, epollEvents, fd); } } }Done: ; // Invoke pending message callbacks. mNextMessageUptime = LLONG_MAX; while (mMessageEnvelopes.size() != 0) { nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); const MessageEnvelope&amp; messageEnvelope = mMessageEnvelopes.itemAt(0); if (messageEnvelope.uptime &lt;= now) { // Remove the envelope from the list. // We keep a strong reference to the handler until the call to handleMessage // finishes. Then we drop it so that the handler can be deleted *before* // we reacquire our lock. { // obtain handler sp&lt;MessageHandler&gt; handler = messageEnvelope.handler; Message message = messageEnvelope.message; mMessageEnvelopes.removeAt(0); mSendingMessage = true; mLock.unlock();#if DEBUG_POLL_AND_WAKE || DEBUG_CALLBACKS ALOGD(&quot;%p ~ pollOnce - sending message: handler=%p, what=%d&quot;, this, handler.get(), message.what);#endif handler-&gt;handleMessage(message); } // release handler mLock.lock(); mSendingMessage = false; result = ALOOPER_POLL_CALLBACK; } else { // The last message left at the head of the queue determines the next wakeup time. mNextMessageUptime = messageEnvelope.uptime; break; } } // Release lock. mLock.unlock(); // Invoke all response callbacks. for (size_t i = 0; i &lt; mResponses.size(); i++) { Response&amp; response = mResponses.editItemAt(i); if (response.request.ident == ALOOPER_POLL_CALLBACK) { int fd = response.request.fd; int events = response.events; void* data = response.request.data;#if DEBUG_POLL_AND_WAKE || DEBUG_CALLBACKS ALOGD(&quot;%p ~ pollOnce - invoking fd event callback %p: fd=%d, events=0x%x, data=%p&quot;, this, response.request.callback.get(), fd, events, data);#endifALOOPER_POLL_CALLBACK int callbackResult = response.request.callback-&gt;handleEvent(fd, events, data); if (callbackResult == 0) { removeFd(fd); } // Clear the callback reference in the response structure promptly because we // will not clear the response vector itself until the next poll. response.request.callback.clear(); result = ALOOPER_POLL_CALLBACK; } } return result;}int Looper::pollAll(int timeoutMillis, int* outFd, int* outEvents, void** outData) { if (timeoutMillis &lt;= 0) { int result; do { result = pollOnce(timeoutMillis, outFd, outEvents, outData); } while (result == ALOOPER_POLL_CALLBACK); return result; } else { nsecs_t endTime = systemTime(SYSTEM_TIME_MONOTONIC) + milliseconds_to_nanoseconds(timeoutMillis); for (;;) { int result = pollOnce(timeoutMillis, outFd, outEvents, outData); if (result != ALOOPER_POLL_CALLBACK) { return result; } nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); timeoutMillis = toMillisecondTimeoutDelay(now, endTime); if (timeoutMillis == 0) { return ALOOPER_POLL_TIMEOUT; } } }}void Looper::wake() {#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ wake&quot;, this);#endif ssize_t nWrite; do { nWrite = write(mWakeWritePipeFd, &quot;W&quot;, 1); } while (nWrite == -1 &amp;&amp; errno == EINTR); if (nWrite != 1) { if (errno != EAGAIN) { ALOGW(&quot;Could not write wake signal, errno=%d&quot;, errno); } }}void Looper::awoken() {#if DEBUG_POLL_AND_WAKE ALOGD(&quot;%p ~ awoken&quot;, this);#endif char buffer[16]; ssize_t nRead; do { nRead = read(mWakeReadPipeFd, buffer, sizeof(buffer)); } while ((nRead == -1 &amp;&amp; errno == EINTR) || nRead == sizeof(buffer));}void Looper::pushResponse(int events, const Request&amp; request) { Response response; response.events = events; response.request = request; mResponses.push(response);}int Looper::addFd(int fd, int ident, int events, ALooper_callbackFunc callback, void* data) { return addFd(fd, ident, events, callback ? new SimpleLooperCallback(callback) : NULL, data);}int Looper::addFd(int fd, int ident, int events, const sp&lt;LooperCallback&gt;&amp; callback, void* data) {#if DEBUG_CALLBACKS ALOGD(&quot;%p ~ addFd - fd=%d, ident=%d, events=0x%x, callback=%p, data=%p&quot;, this, fd, ident, events, callback.get(), data);#endif if (!callback.get()) { if (! mAllowNonCallbacks) { ALOGE(&quot;Invalid attempt to set NULL callback but not allowed for this looper.&quot;); return -1; } if (ident &lt; 0) { ALOGE(&quot;Invalid attempt to set NULL callback with ident &lt; 0.&quot;); return -1; } } else { ident = ALOOPER_POLL_CALLBACK; } int epollEvents = 0; if (events &amp; ALOOPER_EVENT_INPUT) epollEvents |= EPOLLIN; if (events &amp; ALOOPER_EVENT_OUTPUT) epollEvents |= EPOLLOUT; { // acquire lock AutoMutex _l(mLock); Request request; request.fd = fd; request.ident = ident; request.callback = callback; request.data = data; struct epoll_event eventItem; memset(&amp; eventItem, 0, sizeof(epoll_event)); // zero out unused members of data field union eventItem.events = epollEvents; eventItem.data.fd = fd; ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex &lt; 0) { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_ADD, fd, &amp; eventItem); if (epollResult &lt; 0) { ALOGE(&quot;Error adding epoll events for fd %d, errno=%d&quot;, fd, errno); return -1; } mRequests.add(fd, request); } else { int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_MOD, fd, &amp; eventItem); if (epollResult &lt; 0) { ALOGE(&quot;Error modifying epoll events for fd %d, errno=%d&quot;, fd, errno); return -1; } mRequests.replaceValueAt(requestIndex, request); } } // release lock return 1;}int Looper::removeFd(int fd) {#if DEBUG_CALLBACKS ALOGD(&quot;%p ~ removeFd - fd=%d&quot;, this, fd);#endif { // acquire lock AutoMutex _l(mLock); ssize_t requestIndex = mRequests.indexOfKey(fd); if (requestIndex &lt; 0) { return 0; } int epollResult = epoll_ctl(mEpollFd, EPOLL_CTL_DEL, fd, NULL); if (epollResult &lt; 0) { ALOGE(&quot;Error removing epoll events for fd %d, errno=%d&quot;, fd, errno); return -1; } mRequests.removeItemsAt(requestIndex); } // release lock return 1;}void Looper::sendMessage(const sp&lt;MessageHandler&gt;&amp; handler, const Message&amp; message) { nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); sendMessageAtTime(now, handler, message);}void Looper::sendMessageDelayed(nsecs_t uptimeDelay, const sp&lt;MessageHandler&gt;&amp; handler, const Message&amp; message) { nsecs_t now = systemTime(SYSTEM_TIME_MONOTONIC); sendMessageAtTime(now + uptimeDelay, handler, message);}void Looper::sendMessageAtTime(nsecs_t uptime, const sp&lt;MessageHandler&gt;&amp; handler, const Message&amp; message) {#if DEBUG_CALLBACKS ALOGD(&quot;%p ~ sendMessageAtTime - uptime=%lld, handler=%p, what=%d&quot;, this, uptime, handler.get(), message.what);#endif size_t i = 0; { // acquire lock AutoMutex _l(mLock); size_t messageCount = mMessageEnvelopes.size(); while (i &lt; messageCount &amp;&amp; uptime &gt;= mMessageEnvelopes.itemAt(i).uptime) { i += 1; } MessageEnvelope messageEnvelope(uptime, handler, message); mMessageEnvelopes.insertAt(messageEnvelope, i, 1); // Optimization: If the Looper is currently sending a message, then we can skip // the call to wake() because the next thing the Looper will do after processing // messages is to decide when the next wakeup time should be. In fact, it does // not even matter whether this code is running on the Looper thread. if (mSendingMessage) { return; } } // release lock // Wake the poll loop only when we enqueue a new message at the head. if (i == 0) { wake(); }}void Looper::removeMessages(const sp&lt;MessageHandler&gt;&amp; handler) {#if DEBUG_CALLBACKS ALOGD(&quot;%p ~ removeMessages - handler=%p&quot;, this, handler.get());#endif { // acquire lock AutoMutex _l(mLock); for (size_t i = mMessageEnvelopes.size(); i != 0; ) { const MessageEnvelope&amp; messageEnvelope = mMessageEnvelopes.itemAt(--i); if (messageEnvelope.handler == handler) { mMessageEnvelopes.removeAt(i); } } } // release lock}void Looper::removeMessages(const sp&lt;MessageHandler&gt;&amp; handler, int what) {#if DEBUG_CALLBACKS ALOGD(&quot;%p ~ removeMessages - handler=%p, what=%d&quot;, this, handler.get(), what);#endif { // acquire lock AutoMutex _l(mLock); for (size_t i = mMessageEnvelopes.size(); i != 0; ) { const MessageEnvelope&amp; messageEnvelope = mMessageEnvelopes.itemAt(--i); if (messageEnvelope.handler == handler &amp;&amp; messageEnvelope.message.what == what) { mMessageEnvelopes.removeAt(i); } } } // release lock}} // namespace android","link":"/2022/01/24/HandlerEpoll/"},{"title":"Graphics","text":"移动端渲染 移动App的整体UI框架大致分成下面4个层次： 1）UI库 跟Android、iOS原生开发类似，Flutter用dart语言实现一整套UI控件。Flutter先将控件树转成渲染树，然后交由skia库绘制界面。 2）图形库 Skia图形库跟iOS平台的CoreAnimation等库功能类似，不仅提供了图形渲染功能，还提供文字绘制和图片显示功能。高级图形图像库将需要绘制的图形转成点、线、三角形等图元，再调用底层图形接口实现绘制。 3）低级图形接口 OpenGL是使用最广的低级图形接口，兼容性最好，基本上支持市面上的所有GPU。Vulkan是最近几年新推出的图形API，除了iPhone的GPU，其他厂家的GPU基本都支持。Metal是苹果新推出的图形API，只支持自家GPU。 4）硬件设备层 目前的移动设备出于性能考虑，大部分图形都是通过GPU渲染，少数情况也会使用CPU渲染，后文会介绍skia使用CPU和GPU渲染的具体场景。 iPhone 在A11芯片以前使用power vr系列GPU，之后采用自研GPU。安卓手机大部分采用高通Adreno GPU或ARM mail GPU。GPU渲染完一帧图像后送FrameBuffer，最后在合适的时机展示在屏幕上。 Skia应用广泛并且跨平台，不仅用于Flutter和Android操作系统，还用于Google Chrome浏览器，同时支持windows、Mac、iOS操作系统。Skia由C++编写，代码开源，通过研究skia有助于理解图形图像的绘制原理，为UI性能优化提供思路。 图形Android 框架提供了各种用于 2D 和 3D 图形渲染的 API，可与制造商的图形驱动程序实现代码交互，因此，务必更好地了解这些 API 的工作原理。本页介绍了在其上构建这些驱动程序的 图形硬件抽象层 (HAL)。 应用开发者可通过三种方式将图像绘制到屏幕上：使用canvas、OpenGL ES 或 Vulkan(UE4支持)。 Android 图形组件无论开发者使用什么渲染 API，一切内容都会渲染到 Surface 上。Surface 表示缓冲区队列中的生产方，而缓冲区队列通常会被 SurfaceFlinger 消耗。在 Android 平台上创建的每个窗口都由 Surface 提供支持。所有被渲染的可见 Surface 都被 SurfaceFlinger 合成到屏幕。 下图显示了关键组件如何协同工作： 图 1. Surface 如何被渲染 主要组件如下所述： 图像流生产方 IMAGE STREAM PRODUCERS图像流生产方可以是生成图形缓冲区以供消耗的任何内容。例如 OpenGL ES、Canvas 2D 和 mediaserver 视频解码器。 图像流消耗方 IMAGE STREAM CONSUMERS图像流的最常见消耗方是 SurfaceFlinger，该系统服务会消耗当前可见的 Surface，并使用窗口管理器中提供的信息将它们合成到屏幕。SurfaceFlinger 是可以修改所显示部分内容的唯一服务。SurfaceFlinger 使用 OpenGL 和 Hardware Composer 来合成一组 Surface。 其他 OpenGL ES 应用也可以消耗图像流，例如相机应用会消耗相机预览图像流。非 GL 应用也可以是使用方，例如 ImageReader 类。 硬件作曲家 Hardware Composer (简称HWC)显示子系统的硬件抽象实现。SurfaceFlinger 可以将某些合成工作委托给Hardware Composer，以分担 OpenGL 和 GPU 上的工作量。SurfaceFlinger 只是充当另一个 OpenGL ES 客户端。因此，在 SurfaceFlinger 将一个或两个缓冲区合成到第三个缓冲区中的过程中，它会使用 OpenGL ES。这会让合成的功耗比通过 GPU 执行所有计算时更低。 硬件作曲家 Hardware Composer HAL 则进行另一半的工作，是所有 Android 图形渲染的中心点。Hardware Composer 必须支持事件，其中之一是 VSYNC（另一个是支持即插即用 HDMI 的热插拔）。 Gralloc需要使用图形内存分配器 (Gralloc) 来分配图像生产方请求的内存。有关详情，请参阅 Gralloc HAL。 数据流有关 Android 图形管道的描述，请参见下图： 图 2. 流经 Android 的图形数据流 左侧的对象是生成图形缓冲区的渲染器，如主屏幕、状态栏和系统界面。SurfaceFlinger 是合成器，而硬件混合渲染器是制作器。 BufferQueueBufferQueues 是 Android 图形组件之间的粘合剂。它们是一对队列，可以调解缓冲区从生产方到消耗方的固定周期。一旦生产方移交其缓冲区，SurfaceFlinger 便会负责将所有内容合成到显示部分。 有关 BufferQueue 通信过程，请参见下图。 图 3. BufferQueue 通信过程 BufferQueue 包含将图像流生产方与图像流消耗方结合在一起的逻辑。图像生产方的一些示例包括由相机 HAL 或 OpenGL ES 游戏生成的相机预览。图像消耗方的一些示例包括 SurfaceFlinger 或显示 OpenGL ES 流的另一个应用，如显示相机取景器的相机应用。 BufferQueue 是将缓冲区池与队列相结合的数据结构，它使用 Binder IPC 在进程之间传递缓冲区。生产方接口，或者您传递给想要生成图形缓冲区的某个人的内容，即是 IGraphicBufferProducer（SurfaceTexture 的一部分）。BufferQueue 通常用于渲染到 Surface，并且与 GL 消耗方及其他任务一起消耗内容。 BufferQueue 可以在三种不同的模式下运行： 类同步模式 - 默认情况下，BufferQueue 在类同步模式下运行，在该模式下，从生产方进入的每个缓冲区都在消耗方那退出。在此模式下不会舍弃任何缓冲区。如果生产方速度太快，创建缓冲区的速度比消耗缓冲区的速度更快，它将阻塞并等待可用的缓冲区。 非阻塞模式 - BufferQueue 还可以在非阻塞模式下运行，在此类情况下，它会生成错误，而不是等待缓冲区。在此模式下也不会舍弃缓冲区。这有助于避免可能不了解图形框架的复杂依赖项的应用软件出现潜在死锁现象。 舍弃模式 - 最后，BufferQueue 可以配置为丢弃旧缓冲区，而不是生成错误或进行等待。例如，如果对纹理视图执行 GL 渲染并尽快绘制，则必须丢弃缓冲区。 为了执行这项工作的大部分环节，SurfaceFlinger 就像另一个 OpenGL ES 客户端一样工作。例如，当 SurfaceFlinger 正在积极地将一个缓冲区或两个缓冲区合成到第三个缓冲区中时，它使用的是 OpenGL ES。 Hardware Composer HAL 执行另一半工作。该 HAL 充当所有 Android 图形渲染的中心点。","link":"/2024/03/25/GraphicsOverriew/"},{"title":"HashMap","text":"常见Map类简述：HashMap是非线程安全的，如需要线程安全的哈希隐射类，应使用实现了分段锁（1.8）的ConcurrentHashMap，而不建议使用遗留类HashTable（HashTable实现线程安全是依靠用synchronized关键字修饰put/get方法，效率较低）。 如果需要保存记录插入的顺序，可使用LinkHashMap()，其内部实现了一个双向链表，即每个节点本身记录了前后节点的引用。(btw:MessageQueue是单链表) (1) HashMap：它根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以使用ConcurrentHashMap（synchronizedMap与HashTable都因为其实现的线程安全依靠全表锁导致性能较差，故不建议）。 (2) 不推荐的线程安全Map：(2.1)HashTable​ Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，并且是线程安全的，HashTable的get/put方法都被synchronized关键字修饰，说明它们是方法级别阻塞的，它们占用共享资源锁，所以导致同时只能一个线程操作get或者put，而且get/put操作不能同时执行，所以这种同步的集合效率非常低，一般不建议使用这个集合。 (2.2)SynchronizedMap​ Collections.synchronizedMap类似，如果传入的是 HashMap 对象，其实也是对 HashMap 做的方法做了一层包装，里面使用对象锁来保证多线程场景下操作安全，本质也是对 HashMap 进行全表锁！，性能低下 (3) ConcurrentHashMap:这个也是最推荐使用的线程安全的Map，也是实现方式最复杂的一个集合，每个版本的实现方式也不一样，在jdk8之前是使用分段加锁的一个方式，分成16个segment，每次只加锁其中一个segment，而在jdk8加入了红黑树和CAS算法后，又改用synchronized锁住哈希数组的头结点作为线程安全来实现。 (4) LinkedHashMap：LinkedHashMap是HashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 (5) TreeMap：TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。如果使用排序的映射，建议使用TreeMap。在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 对于上述四种Map类型的类，要求映射中的key是不可变对象。不可变对象是该对象在创建后它的哈希值不会被改变。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。 HashMap原理通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。 (1) 存储结构：从源码可知，HashMap类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) { ... } public final K getKey(){ ... } public final V getValue() { ... } public final String toString() { ... } public final int hashCode() { ... } public final V setValue(V newValue) { ... } public final boolean equals(Object o) { ... }} Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。 (2) 哈希冲突：HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题 Java中HashMap采用了**链地址法(拉链法)**。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。（1.8之后又加入了红黑树） (3)位置确定：hashCode高低16位相异或后跟n-1相与 简述：取Key的32位hashCode值进行低16位与高16位异或运算，并将运算结果取模(n-1)。 这里插一句：由于index是取模(n-1)的，所以JDK1.8后 n -&gt; 2n 扩容时无需重新hash，只需要把多出来的一个bit作为是否移动到新开辟空间的标记即可 分两步： 第一步：hashCode高低16位异或hash = (hashCode &gt;&gt;&gt; 16) ^ hashcode)。 这一步得出低16位与高16位的异或结果，也就是为了高低16位都能参与到后一步的取模运算。 第二步：与n-1相与hash &amp; (n - 1) (4) 扩容 扩容时机： put插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。每次扩容的容量都是之前容量的2倍。最大(2^30)。 初始值： capacity 即容量，默认16。 loadFactor 加载因子，默认是0.75 threshold 阈值。 threshhold阈值=容量*加载因子。默认12。当元素数量超过阈值时便会触发扩容。 如果某个桶内的元素超过8个，则会将链表转化成红黑树，加快数据查询效率。 如果remove的过程中，桶内的元素低于6个，红黑树又会转化成链表 扩容机制： 简述： JDK1.7：创建一个新的两倍大小的数组，将原数组用头插法的方式将所有节点rehash后插入新数组，故链表顺序会相反。 JDK1.8：创建一个新的两倍大小的数组，每一个元素通过hash转换坐标的方法计算后，最高位是0则坐标不变，最高位是1则坐标变为“原长度+原坐标”。迁移元素时是正序的，不会出现链表转置的发生。， 详解：扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。 12345678910111213void resize(int newCapacity) { //传入新的容量 Entry[] oldTable = table; //引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; } Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int)(newCapacity * loadFactor);//修改阈值} 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 1234567891011121314151617void transfer(Entry[] newTable) { Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) { //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) { src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do { Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 } while (e != null); } }} newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的\b哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 JDK1.8扩容做了优化，不再需要重新全部rehash，而是根据hash值新增的那个bit是1还是0就好了，省下了hash时间， 同时还可以借由新增的1bit是随机的，而均匀地把之前冲突的节点重新打散了因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了 我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： （注意看，蓝色的为新增1bit为0的情况，保持原index不动，绿色的为新增1bit为1，会移动到16(oldCap) + 15(srcIndex)的位置上） JDK1.8省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了 JDK8的元素迁移 JDK8则因为巧妙的设计，性能有了大大的提升：由于数组的容量是以2的幂次方扩容的，那么一个Entity在扩容时，新的位置要么在原位置，要么在原长度+原位置的位置。原因如下图： 数组长度变为原来的2倍，表现在二进制上就是多了一个高位参与数组下标确定。此时，一个元素通过hash转换坐标的方法计算后，恰好出现一个现象：最高位是0则坐标不变，最高位是1则坐标变为“10000+原坐标”，即“原长度+原坐标”。如下图（扩容16 -&gt; 32）： 因此，在扩容时，不需要重新计算元素的hash了，只需要判断最高位是1还是0就好了。 (5)Get通过hashCode高低16位相异或后跟n-1相与，得出的数组位置index，如该位置是目标则直接返回，如该位置是链表节点则链表方式索引，如果是红黑树则以红黑树的方式索引。 (6)Put也是先通过hashCode与当前数组长度n-1计算出index，然后判断该位置是否为空，为空则直接插入元素；如果该位置只有一个元素则转化为链表并插入；如果该位置为链表节点则以尾插法的方式插入新增节点；如果该位置为红黑树，则以红黑树的方式插入新增节点。 插入后，超过阈值则扩容。 ConcurrentHashMap原理简述：concurrentHashMap在JDK1.7之前是分段锁，也就是在存储方面是一个 Segment 数组，一个 Segment 就是一个子哈希表，Segment 里维护了一个 HashEntry 数组，相当于是把整个哈希表分割成了ssize个segment数组，增删时通过对对应的segment加锁，达到只锁一段不影响其他segment的效果；同时也为每个节点Node的val和next都使用了volatile关键字保证可见性。 JDK1.8之后保留了Node节点的val和next字段的volatile关键字，不再使用Segment分段锁，而是以table数组对应index的结点作为synchronized的锁。 ConcurrentHashMap保证线程安全主要有三个地方。 一、使用volatile保证当Node中的值变化时对于其他线程是可见的 二、当对应index结点为null时（未有哈希冲突），使用CAS操作来保证数据能正确的写入 三、其他情况（即链表/红黑树）使用table数组的头结点（链表或树的头结点）作为synchronized的锁来保证写操作的安全 put大体思路： 如果table数组还没有初始化，则使用CAS进行初始化 如果table数组中i位置处元素为空，则使用CAS将table[i]的值设置为value 如果其他线程正在对table数组进行扩容，则当前线程去协助其进行扩容 其他情况，则使用synchronized锁住**table[i]这个元素（链表表头或红黑树根节点**），并将元素追加插入到链表或红黑树中；插入后，检查是否需要将该桶的数据结构由链表转化为红黑树。 成功设置&lt;key, value&gt;后，检查是否需要进行扩容 要想对链表或红黑树进行put操作，必须拿到表头或根节点，所以，锁住了表头或根节点，就相当于锁住了整个链表或者整棵树。这个设计与分段锁的思想一致，只是其他读取操作需要用cas来保证。 Getget简单很多，由于get在Node.val值被volatile修饰的情况下不需要考虑加锁，所以只需要正常检索即可。也就是通过hashCode高低16位相异或后跟n-1相与，得出的数组位置index，如该位置是目标则直接返回，如该位置是链表节点则链表方式索引，如果是红黑树则以红黑树的方式索引。 扩容中，且当前index位置未完成扩容的，由于扩容过程是形成hn和ln复制链而非剪切的，故原位置仍可正常访问。 扩容中，且当前index已完成扩容的，由于迁移过程中每移动完一个hash桶原地会留下新地址的头结点，以该头节点进行索引即可。 Size至于size()方法在JDK1.8版本中，对于size的计算，在扩容和addCount()方法就已经有处理了，JDK1.7是在调用size()方法才去计算 Transfer扩容(ConcurrentHashMap1.8 - 扩容详解_ZOKEKAI的博客-CSDN博客_concurrenthashmap 扩容 多线程协同扩容；index的计算依然与JDK1.8一样，是依靠新增的1bit为0则留在原index，为1则迁移到index + 原数组长度。","link":"/2021/11/01/HashMap/"},{"title":"HttpProtocol","text":"Http 缓存在请求一个静态文件的时候（图片，css，js）等，这些文件的特点是文件不经常变化，将这些不经常变化的文件存储起来，对客户端来说是一个优化用户浏览体验的方法。那么这个就是客户端缓存的意义了。 简述： 强制缓存是根据上次响应header中的Cache-Control:Max-age或是Expries，客户端直接判断缓存是否能用该资源缓存； 协商缓存需要客户端用记录下来的上次响应header中的ETag或是Last-Modified，通过与向服务器的请求request的header中赋值If-None-Match或If-Modified-Since，由服务器判断资源是否更新，结果由code和是否存在body明确是否命中缓存； 同时出现的优先级排序： 强制缓存 &gt; 协商缓存；ETag &amp; If-None-Match &gt; Last-Modified &amp; If-Modified-Since ;Cache-Control &gt; Expries； 官方文档https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Caching 一. 强制缓存强制缓存命中后请求没有到达后端，浏览器从缓存中提取资源，以statue code=200 OK(from memory cache)返回 Cache-Control max-age：指定缓存的最大有效时间，以秒为单位。 no-cache：表示缓存需要重新验证，但仍然可以缓存。 no-store：表示不应该缓存这个资源。 public：表示响应可以被任何中间缓存存储。 private：表示响应只能够被个人用户缓存，不允许中间缓存存储。 must-revalidate：表示如果缓存过期，客户端必须重新验证资源的有效性。 s-maxage：类似于max-age，但只作用于共享缓存，比如代理服务器。 e.g: Cache-Control: max-age=3600, immutable 这表示资源将在缓存中保持1小时（3600秒），并且该资源的内容在这个时间内都不会改变。如果客户端或中间缓存服务器收到了一个带有 “immutable” 指令的资源，并且已经将该资源存储在缓存中，它们可以安全地假设资源的内容在其声明的时间内保持不变，而无需重新验证。 Expires（Http1.0废弃）简述：过期日期，值为具体时间，资源在这个时间之前都能使用缓存 如：Expires:Thu, 31 Dec 2016 23:55:55 GMT 二. 协商缓存ETag &amp; If-None-Match简述：资源关键信息的hash，服务器下发response时携带在header中的ETag字段，客户端将上次缓存下来的该ETag值附在request请求header的If-None-Match中。服务器将客户端request发来的If-None-Match对比服务器当前资源ETag，若相同则缓存，即返回response304和header（无body）；不同则下发新资源，即返回200和header+body新资源 Last-Modified &amp; If-Modified-Since简述：资源更新时间，类似ETag，服务器下发response时header中Last-Modifiled，客户端存储该GMT时间，下次请求该资源时request的header中If-Modified-Since附上。服务器从request中取出If-Modified-Since后将该时间与本地的资源更新时间对比，若相同则缓存，即返回response304和header（无body）；不同则下发新资源，即返回200和header+body新资源 整体流程： 在前一次服务器响应时下发所有的缓存字段，包括：强制缓存的Cache-control:max-age、expires，协商缓存的Etag和Last-Modified。 接下来客户端发起请求时，从四个Header中选择一个的特定header（没必要多个，会按优先级只取一个），即客户端选择是强制缓存还是协商缓存。 如果是强制缓存并且命中（即据上次请求时间小于max-age或者Expires还没到）则会直接客户端自取本地缓存并返回200(from memory cache)，请求根本不会到达服务器； 如果是协商缓存，则会在请求中带上步骤1中的If-None-Match: cache_Etag或If-Modified-Since: cache_Last-Modified，向服务器发出请求 此步骤仅为协商缓存所有：服务器将 客户端请求中的If-None-Match值或Last-If-Modified-Since时间 与服务器中资源值的最新哈希值或修改时间 比较，如果资源有了更新则返回200和新的资源；如果资源没有更新则返回304(No Modified)和空body Http特性什么是Http协议 Http协议是对客户端和服务器端之间数据之间实现可靠性的传输文字、图片、音频、视频等超文本数据的规范，格式简称为“超文本传输协议” Http协议属于应用层，及用户访问的第一层就是http TcpIp协议分层：http,tls所在的应用层；tcp,udp所在的传输层；ip所在的网络层；arp（ip解析成mac）,rarp所在的链路层 1 常用HTTP状态码和分类 HTTP状态码表示客户端HTTP请求的返回结果、标识服务器处理是否正常、表明请求出现的错误等。 状态码的类别： 类别 描述 1xx： 指示信息–表示请求已接收，正在处理 2xx： 成功–表示请求已被成功接收、理解、接受 3xx： 重定向–要完成请求必须进行更进一步的操作 4xx： 客户端错误–请求有语法错误或请求无法实现 5xx： 服务器端错误–服务器未能实现合法的请求 常见的状态码： 状态码 描述 200： 请求被正常处理 204： 请求被受理但没有资源可以返回 206： 客户端只是请求资源的一部分，服务器只对请求的部分资源执行GET方法，相应报文中通过Content-Range指定范围的资源。 301： 永久性重定向 302： 临时重定向 303： 与302状态码有相似功能，只是它希望客户端在请求一个URI的时候，能通过GET方法重定向到另一个URI上 304： 协商缓存命中，返回空body。发送附带条件的请求时，条件不满足时返回，与重定向无关 307： 临时重定向，与302类似，只是强制要求使用POST方法 400： 请求报文语法有误，服务器无法识别 401： 请求需要认证 403： 请求的对应资源禁止被访问 404： 服务器无法找到对应资源 500： 服务器内部错误 503： 服务器正忙 2 请求和响应格式请求格式：12345678910111213Mothed Path HttpVersion （MPV）HeaderBody(if have)//示例：GET /d?ttl=1&amp;dn=82f3b6f4e75e6679742bdc4e8990e7e2e0e927e6bb3e8030&amp;id=316 HTTP/1.1Host: 119.29.29.29Connection: Keep-AliveAccept-Encoding: gzipUser-Agent: android/okhttp17d10738b8085b2c9030ce1e4c7aace2998b95e308abbdcbbf425336f3d2e006(if Post) 响应格式：12345678910111213HttpVersion StatusCode StatusMessage (VSS)HeaderBody//示例：HTTP/1.1 200 OKConnection: closeServer: Http ServerContent-Type: text/htmlContent-Length: 6417d10738b8085b2c9030ce1e4c7aace2998b95e308abbdcbbf425336f3d2e006 3 Http请求方式HTTP协议定义了多种请求方式，具体如下：GET：获取资源，用来请求访问已被URI（统一资源标志符，和URL是包含和被包含的关系）识别的资源。POST：用来传输实体的主体，虽然GET也可以实现，但是一般不用。PUT：传输文件。但是鉴于PUT方法自身不带验证机制，任何人都可以上传文件，存在安全性问题，因此一般网站都不采用该方法。HEAD:获得报文首部。和GET请求一样，只是不返回报文主体部分。DELETE：删除文件。同样不带验证机制，存在安全性问题。OPTIONS:询问指定的请求URI支持哪些方法。CONNECT：要求在与代理服务器通信时建立隧道，实现隧道协议进行TCP通信。 HTTP 幂等方法是指无论调用多少次都不会有不同结果的 HTTP 方法。它无论是调用一次，还是十次都无关紧要。结果仍应相同。 ps：只有POST是非幂等的，其他都是幂等的。 这里还想补充说明一点，就是通过浏览器地址栏输入URL访问资源的方式都是GET请求。 3 POST和GET请求区别厘清3.1 请求参数长度限制：GET请求长度最多1024kb，POST对请求数据没有限制？关于此点，在HTTP协议中没有对URL长度进行限制，这个限制是不同的浏览器及服务器由于有不同的规范而带来的限制。 3.2 GET请求一定不能用request body传输数据？GET可以带request body，但不能保证一定能被接收到。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你读出数据，有些服务器直接忽略。 3.3 POST比GET安全性要高！这里的安全是相对性，通过GET提交的数据都将显示到URL上，页面会被浏览器缓存，其他人查看历史记录会看到提交的数据，而POST不会。另外GET提交数据还可能会造成CSRF攻击。 （有误）3.4 GET产生一个TCP数据包，POST产生两个TCP数据包！对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200 OK(返回数据);而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 OK(返回数据)。注意，尽管POST请求会分两次，但body 是紧随在 header 后面发送的，根本不存在『等待服务器响应』一说。 4 POST和GET请求的区别小结请求参数：GET请求参数是通过URL传递的，多个参数以&amp;连接，POST请求放在request body中。请求缓存：GET请求会被缓存，而POST请求不会，除非手动设置。收藏为书签：GET请求支持，POST请求不支持。安全性：POST比GET安全，GET请求在浏览器回退时是无害的，而POST会再次请求。历史记录：GET请求参数会被完整保留在浏览历史记录里，而POST中的参数不会被保留。编码方式：GET请求只能进行url编码，而POST支持多种编码方式。对参数的数据类型：GET只接受ASCII字符，而POST没有限制。 Http Version简述：最为人诟病的就是当客户端同时发出多个请求时需要排队进行会产生队头阻塞，这也是为何一些在1.x站点会有多个[静态资源]CDN 域名的原因之一，目的就是变相的解决浏览器针对同一[域名]的请求限制阻塞问题 HTTP1.0（几乎没有使用）无链接，即每次请求都要建立新的tcp链接；缓存只有Expires http1.0被抱怨最多的就是 连接无法复用 和 head of line blocking 这两个问题。 理解这两个问题的前提： 1、每个连接（也就是Tcp连接）建立要经过三次握手，断开需要四次挥手，十分耗时 2、客户端是依据域名来向服务器建立连接，一般PC端浏览器会针对单个域名的server同时建立6～8个连接，手机端的连接数则一般控制在4～6个。显然连接数并不是越多越好，资源开销和整体延迟都会随之增大。 无连接，浏览器的每次请求都需要与服务器经过三次握手建立一个TCP连接，服务器处理完成后立即四次挥手断开TCP连接（无连接）。 缓存只有Expires HTTP1.1默认keep-alive长连接，即请求可以复用同一个tcp链接；协商缓存；响应分块；另外还有几乎没咋用的管线化 长连接复用，即 Connection: Keep-Alive 字段默认开启，这个字段允许服务端和客户端保持一个长时间存活的TCP连接，当后续客户端发送另一个请求时，它会复用同一个TCP连接。这里需要说明的是，如果同时发起了多个请求，还是需要建立多个Tcp连接的。 管线化(实际上不启动)，客户端可以同时发出多个HTTP请求，而不用一个个等待响应. 支持响应分块， Transfer-Encoding(chunked) 与 Content-Encoding(gzip) 协商缓存：废弃Expires，启用Cache-Control。新增协商缓存。 解决了Http1.0中连接无法复用的问题，默认长连接； 但依然解决不了 head of line blocking 队头阻塞问题，http1.1试图用管线化机制同时发送多个请求 来解决head of line blocking，但即使pipelining 可以同时在一个 TCP 中发送多个 HTTP 请求，客户端接收服务端响应信息时，还是按照发送时的顺序来接收响应信息，依然会有队头阻塞的问题 长连接复用​ 在 HTTP 1.1 中， Connection: Keep-Alive 字段默认开启，这个字段允许服务端和客户端保持一个长连接，当客户端发送另一个请求时，它会复用同一个连接。这个连接会一直持续到客户端或服务器端认为会话已经结束，其中一方中断连接。中断连接的取决与否取决于 Keep-Alive 字段中的： timeout: 决定当前 tcp的最长保持连接时间，单位为 s ，超过设置的时间后断开连接 max：决定了当前连接最多的可复用次数 ​ 容易混淆的概念——TCP的keep alive和HTTP的Keep-alive： TCP的keep alive是检查当前TCP连接是否活着; HTTP的Keep-alive是要让一个TCP连接活久点。它们是不同层次的概念。 TCP keep alive的表现： 当一个连接“一段时间”没有数据通讯时，一方会发出一个心跳包(Keep Alive包)，如果对方有回包则表明当前连接有效，继续监控。 响应分块Transfer-Encoding(chunked) 与 Content-Encoding(gzip) 注： HTTP2 不再支持使用 chunked 分块机制传输数据，有了更好的流传输机制 支持 Chunked Responses ，也就是说，在Response的时候，不必说明 Content-Length 这样，客户端就不能断连接，直到收到服务端的EOF标识。这种技术又叫 “服务端Push模型”，或是 “服务端Push式的HTTP 持久链接” 管线化（http pipelining） 注： 默认不启用，HTTP2 中流水线已经被更好的算法给代替，如 multiplexing ​ HTTP管线化（英语：HTTP pipelining）是将多个 HTTP 请求（request）整批提交的技术，而在发送过程中不需先等待服务器的回应。 ​ 流水线操作建立在长连接之上，可以将所有的 HTTP 请求一次性发出，而无需关心上一次发送请求的状态，虽然说客户端一次性能够发出所有的请求，但是在服务端接收到的请求还是一一进行处理的，如果当服务端返回的其中一个响应阻塞后，接下来的响应也会被阻塞。 HTTP 1.1 利用 pipelining 可以同时在一个 TCP 中发送多个 HTTP 请求，但是客户端接收服务端响应信息时，还是按照发送时的顺序来接收响应信息。 HTTP2.0简述：Http2核心优化是通过多路复用机制，解决了Http请求队头阻塞问题，将两端所有的请求都放到了同一个Tcp连接中（但Tcp传输的局限性导致了Tcp队头阻塞且无法解决）；舍弃了低效的plain text格式使用二进制格式进行解析传输；使用HPACK算法对多个请求的首部进行差量更新；通过服务器提前将客户端可能要的资源响应回去（服务器：虽然你只请求了Html页面，但是我觉得你还需要这里面所有的资源如js、css等） 二进制分帧（采用二进制格式的编码将其封装） 首部压缩（设置了专门的首部压缩设计的HPACK算法。） 多路复用（可以在共享TCP链接的基础上同时发送请求和响应） 服务器推送（server push;几乎没咋用。就是服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资 源无需客户端明确的请求。） 二进制分帧新的二进制格式（Binary Format），二进制协议，增加了数据传输的效率。 HTTP1.x的解析是基于文本（plain text），低效且健壮性差。http2.0的格式定义更接近tcp层的方式，十分高效且精简。而且实际上http2.0并没有改变http1.x的语义，只是把原来http1.x的header和body部分用frame重新封装了一层而已。调试的时候浏览器甚至会把http2.0的frame自动还原成http1.x的格式。 多路复用多路复用，可以在一个TCP链接中并发请求多个HTTP请求。 一个客户端和一个服务器的多个（即使是同时发出）的请求都是在同一个Tcp连接中进行的。 减少了需要进行多个连接的耗时，再多的请求也只需要一个Tcp连接的三次握手耗时 解决了一个Host只支持6个左右连接的限制，只用一个连接进行所有请求 解决了head of line blocking（丢包失序时还是会阻塞），多个请求可以同时发出（但由于基于Tcp，Tcp为了保证数据的有序传输，如果Tcp传输中某个数据包丢失或者失序了，那么接收端会等待该数据包导致后面数据包的整个阻塞） 首部压缩（HPACK-Huffman算法无损压缩）header压缩，压缩头，如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。这就是所谓的HPACK算法 HTTP1.x的header带有大量信息（包含cookie可达到kb等级占用），而且每次都要重复发送，HTTP2.0使用HPACK算法encoder来减少需要传输的header大小，通讯双方各自cache一份header 字典进行差量更新，既避免了重复header的传输，又减小了需要传输的大小。 服务端推送服务端推送是一种在客户端请求之前发送数据的机制。在 HTTP/2 中，服务器可以对客户端的一个请求发送多个响应。Server Push 让HTTP1.x 时代使用内嵌资源的优化手段变得没有意义；如果一个请求是由你的主页发起的，服务器很可能会响应主页内容、logo 以及样式表，因为它知道客户端会用到这些东西。这相当于在一个 HTML 文档内集合了所有的资源，不过与之相比，服务器推送还有一个很大的优势：可以缓存！也让在遵循同源的情况下，不同页面之间可以共享缓存资源成为可能。 Ps：如果不需要的话，客户端能自主选择是否需要中断该推送的流，通过发送一个RST_STREAM帧来中止。 问题队头阻塞队头阻塞翻译自英文head-of-line blocking，这个词并不新鲜，因为早在HTTP/1.1时代，就一直存在着队头阻塞的问题。 但是很多人在一些资料中会看到有论点说HTTP/2解决了队头阻塞的问题。但是这句话只对了一半。 **只能说HTTP/2解决了HTTP的队头阻塞问题，但是并没有解决TCP队头阻塞问题!**也就是请求的队头阻塞问题解决了，tcp传输丢包的队头阻塞问题没有解决。（ps：解决办法就是不用Tcp，也就是H3/QUIC中的UDP） HTTP队头阻塞的问题在HTTP/2中得到了有效的解决。HTTP/2创新性的引入了帧、消息和数据流等概念。客户端和服务器可以把 HTTP 消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来。 因为没有顺序了，所以就不需要阻塞了，就有效的解决了HTTP队头阻塞的问题。 但是，HTTP/2仍然会存在TCP队头阻塞的问题，那是因为HTTP/2其实还是依赖TCP协议实现的。 TCP传输过程中会把数据拆分为一个个按照顺序排列的数据包，这些数据包通过网络传输到了接收端，接收端再按照顺序将这些数据包组合成原始数据，这样就完成了数据传输。 但是如果其中的某一个数据包没有按照顺序到达，接收端会一直保持连接等待数据包返回，这时候就会阻塞后续请求。这就发生了TCP队头阻塞。 由于HTTP/2中同一个域名只是用一个TCP连接，所有的数据包都是通过这个连接传输的，所以，在HTTP/2中，发生TCP队头阻塞造成的影响会更大，因为HTTP/2的多路复用技术使得多个请求其实是基于同一个TCP连接的，那如果某一个请求造成了TCP队头阻塞，那么多个请求都会受到影响。 小结HTTP/2底层是采用TCP协议实现的，虽然解决了HTTP队头阻塞的问题，但是对于TCP队头阻塞的问题却无能为力。 另外，TCP这种可靠传输是靠三次握手实现的，TCP三次握手的过程客户端和服务器之间需要交互三次，那么也就是说需要消耗1.5 RTT。如果是HTTPS那么消耗的RTT就更多。 HTTP3/QUIC基于UDP的Http，核心优势是：基于Udp多路复用的同时彻底解决了队头阻塞问题；0-RTT建立连接；连接迁移可以保证网络（比如客户端从 WIFI 切换到蜂窝网络）连接不断。 0-RTT 建立连接 无队头阻塞的多路复用 连接迁移 全应用态协议栈 可以看一下tx实践https://mp.weixin.qq.com/s/Sf8JsZKeZYxT9WBZrh_etg 以及淘宝开源XQUIChttps://mp.weixin.qq.com/s/VTyy20IkAR-QUc1PcHWjrQ QUIC 全称 quick udp internet connection，“快速 UDP 互联网连接”，（和英文 quick 谐音，简称“快”）是由 Google 提出的基于 UDP 进行可靠传输的协议。QUIC 在应用层实现了丢包恢复、拥塞控制、滑窗机制等保证数据传输的可靠性，同时对传输的数据具备前向安全的加密能力。HTTP3 则是 IETF(互联网工程任务组)基于 QUIC 协议基础进行设计的新一代 HTTP 协议。 QUIC/HTTP3 分层模型及与 HTTP2 对比： 0-RTT 建立连接简述：这里说一下GQUIC(Google QUIC)里的实现，基本上安卓实现0-RTT是在应用启动时候就进行加密握手，拿到服务器的加密套件和证书，内存缓存起来。后面用到的时候就不需要再进行握手获取了，直接用新生成的随机数做对称秘钥通信，在第二次发送时带上用服务器公钥加密的该随机数就可以？ QUIC 基于的 UDP 协议本身无需握手，并且它早于 TLS 1.3 协议，就实现了自己的 0-RTT 加密握手。下图分别代表了 1-RTT 握手（首次建连），成功的 0-RTT 握手，以及失败回退的握手。 无队头阻塞的多路复用相比于 HTTP/2 的多路复用，QUIC 不会受到队头阻塞的影响，各个流更独立，多路复用的效果也更好。 连接迁移跟 TCP 用四元组标识一个唯一连接不同，QUIC 使用一个 64 位的 ConnectionID 来标识连接，基于这个特点，QUIC 的使用连接迁移机制，在四元组发生变化时（比如客户端从 WIFI 切换到蜂窝网络），尝试“保留”先前的连接，从而维持数据传输不中断。 全应用态协议栈QUIC 核心逻辑都在用户态，能灵活的修改连接参数、替换拥塞算法、更改传输行为。而 TCP 核心实现在内核态，改造需要修改内核并且进行系统重启，成本极高。 //from chatgpt HTTP/3.0、SPDY 和 QUIC 都与网络通信相关，它们在不同层次上推动了网络协议的发展，并且在一定程度上有一些联系。下面我将详细介绍它们的关系和特点： **SPDY(HTTP2.0前身)**： SPDY（读作”speedy”）是 Google 开发的一种网络协议，旨在优化传输性能，减少网页加载时间。SPDY 被设计为 HTTP/1.1 的替代方案，它引入了多路复用、流优先级、头部压缩等特性，以改进数据传输效率。 关键特点： 多路复用：在单个 TCP 连接上同时传输多个请求和响应，避免了 TCP 连接的建立和拆除开销。 流优先级：允许对不同流设置优先级，确保重要资源的优先传输。 头部压缩：使用首部压缩算法减少请求和响应的头部数据量。 服务器推送：服务器可以主动推送资源，以减少客户端请求的延迟。 **QUIC(Http3.0前身)**： QUIC（Quick UDP Internet Connections）是 Google 开发的一种基于 UDP 协议的传输层协议，旨在解决 TCP 的一些限制和性能瓶颈。QUIC 综合了 TCP、TLS 和 SPDY/HTTP2 的特性，提供了更快的连接建立和传输性能。 关键特点： 连接多路复用：类似于 SPDY，QUIC 允许在同一连接上并发传输多个流。 0-RTT 握手：QUIC 支持零往返时间握手，从而减少了连接建立的延迟。 前向纠错：通过在数据包中引入冗余信息，减少数据包丢失的影响，提高传输可靠性。 动态适应：QUIC 可以根据网络状况自适应地调整拥塞控制和流控制算法。 HTTP/3.0： HTTP/3.0 是在 QUIC 协议基础上进行的新一代 HTTP 协议。它继承了 QUIC 的优势，并在应用层定义了新的特性。HTTP/3.0 的目标是改进用户体验，减少网络延迟，提升性能。 关键特点： 基于 QUIC：HTTP/3.0 使用 QUIC 作为传输层协议，从而具有 QUIC 的优势。 多路复用：类似于 SPDY 和 QUIC，HTTP/3.0 支持多路复用，减少了连接建立和拆除的开销。 零 RTT 握手：HTTP/3.0 利用 QUIC 的 0-RTT 握手功能，进一步减少连接建立的延迟。 综上所述，SPDY 和 QUIC 都是 Google 提出的网络协议，其中 SPDY 作为 HTTP/1.1 的改进版引入了多路复用等特性，而 QUIC 则是基于 UDP 的传输层协议，综合了多路复用、0-RTT 握手等功能。HTTP/3.0 则是在 QUIC 的基础上定义的新一代 HTTP 协议，将 QUIC 的优势引入到应用层。它们的目标都是提升网络传输性能，减少延迟，从而改善用户体验 Other附录：Http各版本及Https使用占比Https: 约95%Http2.0: 约68%Http3.0: 约20%数据来源：https://httparchive.org/reports/state-of-the-web#h2 cookie和session作用与区别 HTTP协议本身是无法判断用户身份。所以需要cookie或者session cookie与session区别 Session是服务器端保持状态的方案，Cookie是客户端保持状态的方案 Cookie保存在客户端本地，客户端请求服务器时会将Cookie一起提交；Session保存在服务端，通过检索Sessionid查看状态。保存Sessionid的方式可以采用Cookie，如果禁用了Cookie，可以使用URL重写机制（把会话ID保存在URL中）。 1）存储位置不同，cookie是保存在客户端的数据；session的数据存放在服务器上 2）存储容量不同，单个cookie保存的数据小，一个站点最多保存20个Cookie；对于session来说并没有上限 3）存储方式不同，cookie中只能保管ASCII字符串；session中能够存储任何类型的数据 4）隐私策略不同，cookie对客户端是可见的；session存储在服务器上，对客户端是透明的 5）有效期上不同，cookie可以长期有效存在；session依赖于名为JSESSIONID的cookie，过期时间默认为-1，只需关闭窗口该session就会失效 6）跨域支持上不同，cookie支持跨域名访问；session不支持跨域名访问 一次HTTP请求，程序一般经历了哪几个步骤？1）解析域名 -&gt; 2）发起TCP三次握手，建立连接 -&gt; 3）基于TCP发起HTTP请求 -&gt; 4）服务器响应HTTP请求，并返回数据 -&gt; 5）客户端解析返回数据 详细点： 从输入网址到获得页面的过程 (越详细越好)？sss 浏览器查询 DNS，首先会访问浏览器缓存，如未命中则进一步访问操作系统缓存，如未命中则访问hosts文件。如未命中，则客户端想本地DNS服务器发起递归查询（本地DNS会将结果也就是ip直接返回），如本地DNS解析服务器未命中，则由本地DNS解析服务器向根域名服务器、顶级域名服务器、管理方域名服务器等依次进行迭代查询（每有一个未命中则返回下一个域名服务器地址给本地域名服务器，比如local dns server向根域名服务器查询未命中，则根域名服务器返回顶级域名服务器地址给local dns server，然后local dns server向收到的这个地址迭代发起查询） 简述：即浏览器缓存 -&gt; 操作系统缓存 -&gt; 本地Host文件 -&gt; 向本地DNS服务器查询 ，最终取得域名对应ip 浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立链接，发起三次握手； TCP/IP链接建立起来后，浏览器向服务器发送HTTP请求； 服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器； 浏览器解析并渲染视图，若遇到对js文件、css文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源； 浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。","link":"/2021/11/19/HttpProtocol/"},{"title":"Image","text":"内存所在位置Android 2.3 之前： 像素数据存在于native heap Android 3.0 ~ 7.1 之间： 存在于 java heap Android 8.0及之后： 存在于 native 为什么 2.3.3 ~ 7.0 要放到 Java 堆? 直接放到 Native 中, 然后在 Java 对象 finalize 调用的时候释放不行吗? Java 层的 Bitmap 对象是一个壳, 非常小, 因此有可能会出现 Native 堆快到了 3G, Java 堆才 10 MB, 10MB 是无法触发 Dalvik GC 的, 因此这个 java 对象的 finalize 并非那么容易调用, 因此可能会出现 Native 堆 OOM 的情况, 故需要我们手动 recycle 像素数据直接放置到 Java 堆, Java 堆就能直接统计到真正的内存数据, 能够根据内存使用情况准确触发 GC 回收数据 隐患便是 Java 堆内存空间比较小, 容器造成 Java 堆的 OOM 为什么 8.0 又放置到了 Native 堆中? 使用 NativeAllocationRegistry 解决了这个问题, 触发 ART 堆 GC 的条件不仅仅是堆占用不足, 通过 VMRuntime.registerNativeAllocation 注册的 Native 内存累计超过了阈值(4MB)之后时也会触发 GC 而且 ART 的 GC 性能比 Dalvik 好的多, 不会轻易造成主线程卡顿 bitmap怎么释放：在 Android 2.3.3 之前开发者必须手动调用 recycle 方法去释放 Native 内存，因为那个时候管理Bitmap内存比较复杂,需要手动维护引用计数器 android6及之前：Bitmap 的内存回收主要是通过 BitmapFinalizer 来完成的，通过覆盖**finalize()**中调用native的析构函数来释放native内存。 Android8及之后：会在 new Bitmap 时会注册 native 的 Finalizer 方法NativeAllocationRegistry.registerNativeAllocation 其实无论是 Android M 前还是之后，释放 Native 层的 Bitmap 对象的思想都是去监听 Java 层的 Bitmap 是否被释放，一旦当 Java 层的 Bitmap 对象被释放则立即去释放 Native 层的 Bitmap 。只不过 Android M 前是基于 Java 的 GC 机制和finalize()，而 Android M 后是注册 native 的 Finalizer 方法。 其中 Fresco 可以留用匿名共享内存 ，在5.0之前像素存在于java heap上时，将像素优化至 Ashmem 匿名共享内存上（近似native） Android 哪个版本之前AS可以在profiler中预览图片 The “view bitmap” feature is still there (for Android 5.0 to 7.1) 因为profiler 分析的 hprof 中，在8.0版本前，bitmap是存在java heap中的，但是由于8.0之后bitmap回到了native heap，而hprof只分析java heap，故而只能在Android 5.0 to 7.1中使用view bitmap 小结：2.3之前的像素存储需要的内存是在native上分配的，并且生命周期不太可控，可能需要用户自己回收。 2.3-7.1之间，Bitmap的像素存储在Dalvik的Java堆上， 当然，4.4之前的甚至能在匿名共享内存上分配（Fresco采用），而8.0之后的像素内存又重新回到native上去分配，不需要用户主动回收，8.0之后图像资源的管理更加优秀，极大降低了OOM。 图片内存尺寸尺寸计算： //PS： 小米8UD 系统赋的dpi为440（计算值401），density为2.75（计算值为2.5） mipmap图片资源计算 inDensity表示该资源来源于哪个密度的文件夹，该值从TypedValue获取； inTargetDensity表示该资源将要显示在哪个密度的设备上。 needSize = (int)(size * ((float)inTargetDensity / inDensity) + 0.5) （四舍五入） 不同目录对应的dpi具体为: 一张172*172的图片放在hdpi目录下，则在dpi为420的设备中尺寸是多少？ 1、hdpi密度是240 因此Options.inDesnity = 240 2、设备密度是420 因此Options.inTargetDensity = 420; 3、设备返回bitmap大小=172 * 420 / 240 = 301px 通过上面对dp的了解，我们知道在设定view大小、间距时使用dp能最大限度地屏蔽设备密度之间的差异。可能你就会问了，那bitmap展示的时候如何适配不同密度的设备呢？ 123456789101112131415161718192021scss复制代码 @Override protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) { setMeasuredDimension(bitmap.getWidth(), bitmap.getHeight()); } private void init() { String path = Environment.getExternalStorageDirectory() + &quot;/Download/photo1.jpg&quot;; bitmap = BitmapFactory.decodeFile(path); paint = new Paint(); paint.setAntiAlias(true); } @Override protected void onDraw(Canvas canvas) { super.onDraw(canvas); Rect src = new Rect(0, 0, bitmap.getWidth(), bitmap.getHeight()); RectF rectF = new RectF(0, 0, bitmap.getWidth(), bitmap.getHeight()); canvas.drawBitmap(bitmap, src, rectF, paint); } 自定义view从磁盘上加载一张图片，并将之显示在view上，view的大小决定于bitmap大小。依旧以上述A、B设备为例，展示结果如下： 左边是A设备，右边是B设备。 明显地看出，在A设备显示比B设备大很多，实际上和我们之前用px来描述view的大小原理是一样的，bitmap的宽、高都是px在描述，而bitmap决定了view的宽、高，最终导致A设备和B设备上的view大小（宽、高像素）是一样的，而它们屏幕密度又不相同，因此产生了差异。 那不会每次都需要我们自己根据屏幕密度来转换bitmap大小吧？幸运的是，Android已经为我们考虑到了。 如上图，在Android Studio创建工程的时候，默认在res下创建mipmap目录，这些mipmap目录按照密度分为mdpi/hdpi/xhdpi/xxhdpi/xxxhdpi，看起来都在“一个“mipmap”目录下，实际上分为不同的目录： 生成不同密度的目录有什么作用？ A设备dpi=240，根据dpi范围，属于hdpi B设备dpi=420，根据dpi范围，属于xxhdpi 图片原始尺寸：photo1.jpg(宽高 172px-172px) 当我们想要在不同密度设备上显示同一张图片并且想要“看起来一样大时”。假设设计的时候以hdpi为准，放置photo1.jpg为172*172，那么根据计算规则在xxhdpi上需要设置photo1.jpg为: scale = 480 / 240 = 2 width = 172 * 2 = 344 height = 172 * 2= 344 注：这里为什么要放大？可以这么理解，因为B设备密度大，通常来说密度越大单位尺寸内需要的像素越多，假设A设备上172*172占据1inch面积，那么为了能够在B设备上填充满相同的面积需要更多的像素，因此B设备上的图片分辨率应该更大（这里说的通常是因为真正决定设备单位尺寸内容纳的像素个数的因素是ppi，有些设备dpi比较大，但是ppi反而小） 现在hdpi和xxhdpi目录下分别存放了同名图片：photo1.jpg，只是大小不同。当程序运行的时候： A设备发现自己密度属于hdpi，它会直接到hdpi下寻找对应的photo1.jpg并显示 B设备发现自己密度属于xxhdpi，它会直接到xxhdpi下寻找对应的photo1.jpg并显示 来看看效果： 左边A设备，右边B设备 针对不同的密度设计不同的图片大小，最大限度保证了同一图片在不同密度设备上表现“看起来差不多大”。 来看看A、B设备上图片占内存大小： A设备 172 * 172 * 4 = 118336 ≈ 116k B设备 344 * 344 * 4 = 473344 ≈ 462k 注：解析bitmap时，默认inPreferredConfig=ARGB_8888，也就是每个像素有4个字节来存储 说明在B设备上显示photo1.jpg需要更多的内存。 上边只是列举了hdpi、xxhdipi，同理对于mdpi、xhdpi、xxxhdpi根据规则放入相应大小的图片，程序会根据不同的设备密度从对应的mipmap文件夹下加载资源。如此一来，我们无需关注bitmap在不同密度设备上显示问题了。 只保留一套尺寸的资源在mipmap各个文件夹下都放置同一套资源的不同尺寸文件似乎有点太占apk大小，能否只放某个密度下图片，其余的靠系统自己适配呢？ 现在只保留hdpi下的photo1.jpg图片，看看在A、B设备上运行情况如何： 看起来和上张图差不多，说明系统会帮我们适配B设备上的图片。 再来看看A、B设备上图片占内存大小： 先看A设备： 再看B设备： A设备 172 * 172 * 4 = 118336 ≈ 116k B设备 301 * 301 * 4 = 362404 ≈ 354k 对比photo1.jpg 分别放在hdpi、xxhdpi和只放在hdpi下可以看出：B设备上图片所占内存变小了。为什么呢？接下来从源码里寻找答案。 构造Bitmap12ini复制代码Bitmap bitmap = BitmapFactory.decodeResource(getContext().getResources(), R.mipmap.photo1); A、B设备同样加载hdpi/photo1.jpg，返回的bitmap大小不相同，我们从这方法开始一探究竟。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public static Bitmap decodeResource(Resources res, int id, BitmapFactory.Options opts) { validate(opts); Bitmap bm = null; InputStream is = null; try { final TypedValue value = new TypedValue(); //根据资源id，构造Value对象，这里面需要关注的变量：density is = res.openRawResource(id, value); bm = decodeResourceStream(res, value, is, null, opts); } catch (Exception e) { /* do nothing. If the exception happened on open, bm will be null. If it happened on close, bm is still valid. */ } finally { try { if (is != null) is.close(); } catch (IOException e) { // Ignore } } if (bm == null &amp;&amp; opts != null &amp;&amp; opts.inBitmap != null) { throw new IllegalArgumentException(&quot;Problem decoding into existing bitmap&quot;); } return bm; }public static Bitmap decodeResourceStream(@Nullable Resources res, @Nullable TypedValue value, @Nullable InputStream is, @Nullable Rect pad, @Nullable BitmapFactory.Options opts) { validate(opts); if (opts == null) { opts = new BitmapFactory.Options(); } if (opts.inDensity == 0 &amp;&amp; value != null) { //通过value里的density给options里的inDensity赋值 final int density = value.density; if (density == TypedValue.DENSITY_DEFAULT) { opts.inDensity = DisplayMetrics.DENSITY_DEFAULT; } else if (density != TypedValue.DENSITY_NONE) { opts.inDensity = density; } } if (opts.inTargetDensity == 0 &amp;&amp; res != null) { //获取设备屏幕密度并赋予opts.inTargetDensity opts.inTargetDensity = res.getDisplayMetrics().densityDpi; } //确定option inDensity、inTargetDensity 后传入jni层加载bitmap return decodeStream(is, pad, opts); } 上面涉及到的关键点是density，分别是TypedValue的density和Options的density。 先来看看TypedValue density: 1234/** * If the Value came from a resource, this holds the corresponding pixel density. * */ public int density; 简单解释：表示该资源从哪个密度文件夹下取的；比如A、B设备取hdpi下的photo1.jpg，那么此时density=240 再来看看Options density 1234567891011* The pixel density to use for the bitmap. This will always result* in the returned bitmap having a density set for itpublic int inDensity;* The pixel density of the destination this bitmap will be drawn to.* This is used in conjunction with {@link #inDensity} and* {@link #inScaled} to determine if and how to scale the bitmap before* returning it.public int inTargetDensity; 简单解释：inDensity表示该资源来源于哪个密度的文件夹，该值从TypedValue获取； inTargetDensity表示该资源将要显示在哪个密度的设备上。在构造Bitmap时，会根据inDensity与inTargetDensity决定Bitmap放大缩写的倍数。 计算公式如下： needSize = (int)(size * ((float)inTargetDensity / inDensity) + 0.5) （四舍五入） 现在分析B设备加载hdpi/photo1.jpg如何做的: 1、hdpi密度是240 因此Options.inDesnity = 240 2、B设备密度是420 因此Options.inTargetDensity = 420; 3、B设备返回bitmap大小=172 * 420 / 240 = 301px 链接：https://juejin.cn/post/7015597280120176676 大图加载：按比例采样缩小，参见https://developer.android.com/topic/performance/graphics/load-bitmap?hl=zh-cn 巨图按区域显示：BitmapRegionDecoder显示区域 + 手势移动显示中心 参见https://blog.csdn.net/lmj623565791/article/details/49300989 图片格式图片格式-webp WEBP相较传统图片格式（jpg/png/gif）会有较大的文件体积优势（25%以上），但会导致解码时间提升1.5倍以上。即webp有更小的体积，节省带宽，apk体积，更快的加载速度（因为体积雄安），但会少许增加cpu压力 “编解码速度上，根据Google的测试，目前WebP与JPG相比较，毫秒级别上，编码速度慢10倍，解码速度慢1.5倍。编码速度即可被没影响，我们只是在上传时生成一份WebP图片。解码速度则需要客户端综合节省下的流量来综合考虑。总之带宽节省比cpu消耗更有价值” 图片格式-JPG/JPEGJPG 和 JPEG是同一个东西，不过是因为window平台早期只支持三个字符的文件格式，将JPEG缩写为JPG。 JPG是有损压缩的，是1600万位颜色，不支持透明度的，存储体积较小的 图片格式-PNGPNG文件利用特殊的编码方法标记重复出现的数据，因而对图像的颜色没有影响，也不可能产生颜色的损失，这样就可以重复保存而不降低图像质量。 PNG是无损压缩的，是1600万位颜色，支持透明度的，存储体积较大的 图片格式-GIF目前使用范围最广的动图格式，具体为GIF87a版本 GIF 格式的文件按块存储，整体上分为三部分： 文件头（Header） GIF 数据流（GIF Data Stream） 文件结尾（Trailer） GIF是无损压缩的，是256位颜色，不支持透明度的，存储提交稍大的 PNG JPEG GIF 压缩算法 无损压缩 有损压缩 无损压缩 透明度 保持图像透明度 不保持图像透明度 不支持透明度 图片尺寸 大 更小 较大 画面质量 更好的 相比PNG不够好 较差 可用颜色 1600万 2^24 1600万 2^24 256 2^8 We will learn more by walking through a sample GIF file. You can see the sample file and its corresponding bytes below. Actual Size Enlarged Bytes (10x10) (100x100) 47 49 46 38 39 61 0A 00 0A 00 91 00 00 FF FF FF FF 00 00 00 00 FF 00 00 00 21 F9 04 00 00 00 00 00 2C 00 00 00 00 0A 00 0A 00 00 02 16 8C 2D 99 87 2A 1C DC 33 A0 02 75 EC 95 FA A8 DE 60 8C 04 91 4C 01 00 3B Header BlockFrom the sample file: 47 49 46 38 39 61 ， ASCII解码即为 GIF89a Logical Screen DescriptorFrom Sample File: 0A 00 0A 00 91 00 00 Global Color TableFrom the sample file: FF FF FF FF 00 00 00 00 FF 00 00 00 Graphics Control ExtensionFrom the sample file: 21 F9 04 00 00 00 00 00 Image DescriptorFrom the sample file: 2C 00 00 00 00 0A 00 0A 00 00 Local Color Table(Opetional)Null Image DataFrom the sample file: 02 16 8C 2D 99 87 2A 1C DC 33 A0 02 75 EC 95 FA A8 DE 60 8C 04 91 4C 01 00 Plain Text ExtensionExample (not in the sample file): 21 01 0C 00 00 00 00 64 00 64 00 14 14 01 00 0B 68 65 6C 6C 6F 20 77 6F 72 6C 64 00 Application ExtensionExample (not in sample file): 21 FF 0B 4E 45 54 53 43 41 50 45 32 2E 30 03 01 05 00 00 Comment ExtensionExample (not in sample file): 21 FE 09 62 6C 75 65 62 65 72 72 79 00 TrailerFrom sample file: 3B //This is the end flag The trailer block indicates when you’ve reached the end of the file. It is always a byte with a value of 3B.","link":"/2021/04/01/Image/"},{"title":"Https","text":"Http和Https 其实HTTPS就是从 HTTP 加上 SSL/TLS （加密处理+认证+完整性保护） 完整的https通信过程，三次RTT：tcp握手一次RTT，TLS握手两次RTT HTTPS工作原理 一、首先客户端发起连接请求，将自身支持的加密（RSA）和哈希算法（sha256）连带发给服务器（服务器端有非对称加密的公钥和私钥） 二、服务器端接受请求，选取一组加密和哈希算法后，将服务器证书（含公钥）发送给客户端 三、客户端收到服务器端证书并使用根证书验证证书后，从中取出公钥，然后本地生成一段随机数，将此随机数用公钥加密后发送给服务器端 四、服务器端用私钥解密出这段随机数作为对称加密的秘钥。之后双方就可以进行对称加密（DES、AES等）。 证书校验过程校验证书的过程： 第一步是校验证书网站域名、有效期等。 第二步是校验证书本身是否可信：主要是依靠验证证书的信任链条完成。 比如根证书A-&gt;B-&gt;服务端证书C，那么首先要验证C是由B签署的，这一步的具体步骤是： 1. **用B证书的公钥解密C证书的签名信息后拿到C证书的hash值（签署时该Hash值由B的私钥加密生成），** 2. **然后再用hash算法（B证书上带的签名算法）计算B证书的&lt;u&gt;待签名数据&lt;/u&gt;后得到计算hash值，** 3. **将证书解密的hash值与计算hash值比较即可。** 第三步是使用CRL（证书吊销列表）或OCSP（在线证书状态协议）确认证书是否已被吊销。 123456789101112证书内容可简化为:待签名数据： 版本: v3 序列号: 123456 签名算法: SHA256withRSA 颁发者信息: CN=A, O=A Corporation, C=US 有效期: 2022-01-01 至 2023-01-01 主题信息: CN=B, O=B Corporation, C=US 主题公钥: (公钥数据) 扩展字段: (可选)签名： 签名: (签名数据) 抓包软件怎么实现的以我熟悉的抓包软件whistle为例，抓包软件能抓https内容的核心是：你的手机安装了whistle的自签名根证书，同时你的请求都是代理给whistle的，然后whistle会发送给客户端经自签名根证书签署过的伪造服务器证书，故而能通过客户端的证书校验，从而拿到请求原文。 手机安装了抓包软件的自签名证书后，抓包工具在作为代理进行HTTPS流量捕获时，实际上充当了中间人。抓包开启后，客户端https请求的握手对象实际上是抓包软件，服务端拿到的请求地址是 抓包软件的地址。手机的请求也实际上是与抓包软件在交互，抓包软件再与服务器交互。故而抓包软件能记录并修改客户端的请求与响应 自签名证书：抓包软件生成一个自签名的证书（自签名证书是一种灵活且方便的SSL/TLS证书解决方案，是由证书的所有者自己签发的，适用于于开发测试环境和内部网络。然而，由于它不是由受信任的三方证书颁发机构即CA签发的，使得它无法提供可靠的身份验证，无法适用于公网） 客户端信任自签名证书： 当用户在设备上安装抓包软件的自签名证书后，这个证书被设备作为受信任的根证书。设备会信任由这个自签名证书签发的所有证书。 中间人代理握手： 抓包软件充当“中间人”，拦截客户端的HTTPS请求。客户端发出的请求首先到达抓包软件。 抓包软件向客户端提供一个由它自己的自签名根证书签署的伪造服务器证书（目标服务器的替身证书）。 因为客户端已经信任抓包软件的自签名证书，所以它会信任这个伪造的服务器证书，并与抓包软件进行TLS握手。 这样，手机上的浏览器或应用程序在连接时实际上是与抓包软件建立的https握手。 抓包软件的主要目的是捕获、分析和调试网络流量。其工作步骤如下： 客户端通过代理发送请求： 抓包软件配置为代理，客户端配置通过此代理发送所有网络请求。 抓包软件生成一个自签名证书，客户端将其安装为受信任的根证书。 代理解析并再发送请求： 客户端的请求首先由抓包软件接收。对于HTTPS请求，抓包软件会使用自签名证书解密这些请求。 抓包软件记录和分析解密后的请求内容，然后重新加密并发送到目标服务器。 服务器响应经过代理返回客户端： 目标服务器返回响应，抓包软件解密并记录这些响应数据。 抓包软件再重新加密这些数据并发送回客户端。 VPN与抓包软件的原理类似，都是通过一层中间人，将客户端的请求实际上代理到中间人层发起请求。 不同的是由于抓包软件使客户端安装的自签名证书，客户端在证书校验时遇到抓包软件自签名证书签署的伪造服务器证书会校验通过，使客户端的请求都能在中间人层解密后查看和修改，之后抓包再转发。 而VPN则是通过加密隧道（加密整个传输链路）：使用协议如IPsec、OpenVPN、L2TP等），在原本就由ssl/tls加密的数据上再加密一层，之后无法感知传输内容原原本本的转发。","link":"/2024/07/08/Https/"},{"title":"InputMangerService","text":"","link":"/2023/03/16/InputMangerService/"},{"title":"Thread","text":"对于dalvik虚拟机而言其检测到执行频率较高的函数时就会进行jit编译将其编译为本地机器码，这样下次此函数执行的时候就会直接执行编译后的机器码，编译后的机器码只存在于内存中并不会以文件的形式保存，app重启后此函数依然会以解释模式执行。在JIT编译函数生成机器码的同时还会生成配置文件profile记录热点函数信息，供AOT守护进程使用编译生成oat文件，以提速执行。 以下为JIT工作流： 但在我们测试中 AE 无论运行多少次启动阶段依然有JIT的运行，但TEMU在启动阶段JIT是无执行的，判断TEMU已做了AOT优化。 AOT事前编译，即在代码运行前进行编译。对于android 7.0之前的art虚拟机而言其会在apk安装的过程中利用dex2oat程序将apk中的dex文件编译为本地机器指令并保存为oat文件，这样在apk启动时直接加载此oat文件并运行，提高了程序了执行效率。但是因为他需要在apk安装的时候使用dex2oat程序进行编译，所以增加了apk在安装过程中的时间。 通过AOT优化的中端机有100ms收益 该优化需要对APP内所有工程做改造，升级AGP后，进行BaselineProfile优化","link":"/2024/08/08/JIT&AOT/"},{"title":"JvmMemoryStructure","text":"程序计数器不会OOM和StackOverflow 有栈的结构（栈 java stack、navtive stack）可能发生 StackOverflowError（栈过深） 和 OOM StackOverFlowError ︰若Java 虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java 虚拟机栈的最大深度的时候，就抛出StackOverFlowError错误。OutOfMemoryError :如果虚拟机栈可以动态扩展（当前大部分的 Java 虚拟机都可动态扩展，只不过 Java 虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出 OutOfMemoryError 异常。 没栈的结构（堆heap、方法区Method Area）只可能发生 OOM java栈帧结构 JavaStackFrame： Java内存比较流行的说法便是堆和栈，这其实是非常粗略的一种划分，这种划分的”堆”对应内存模型的Java堆，”栈”是指虚拟机栈。 JMM (processon.com) 简单聚焦于堆、方法区与栈。 Java Heap java堆是JVM所管理的内存中最大的一块。唯一目的就是存放实例对象，几乎所有的对象实例都在这里分配。Java堆是垃圾收集器管理的主要区域，因此很多时候也被称为“GC堆”。 堆内存是JVM中最大的一块由年轻代和老年代组成（1:2），而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 简述： 1：一开始，Eden,from,to 都是空的，新对象产生被分配到Eden区； 2：Eden满了，开始第一次GC，mark-copy算法，将存活对象复制至from，之后清空Eden，此时Eden，to为空；from保存age1对象； 3：2步骤重复，也就是Eden填满-&gt;GC-&gt;转移存活至from，但注意下GC时如果from中age超过阈值的对象会被送往old； 4：直到from也满了，下一次GC会 HotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。默认比例为8：1,为啥默认会是这个比例，接下来我们会聊到。一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理),这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。 因为年轻代中的对象基本都是朝生夕死的(80%以上)，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。 在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。 Method Area 方法区/非堆存储每个类的结构，例如运行时常量池、字段和方法数据，以及方法和构造函数的代码 per-class structures such as the run-time constant pool, field and method data, and the code for methods and constructors 运行时常量池是类文件中constant_pool表的每个类或每个接口的运行时表示 A run-time constant pool is a per-class or per-interface run-time representation of the constant_pool table in a class file 每个运行时常量池都是从JVM的方法区分配的。类或接口的运行时常量池是在JVM创建类或接口时构造的。 Each run-time constant pool is allocated from the Java Virtual Machine’s method area (§2.5.4). The run-time constant pool for a class or interface is constructed when the class or interface is created (§5.3) by the Java Virtual Machine. 虽然叫方法区，但跟方法是没什么关西的。方法区存储类信息、常量(final static)、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)； 常量池介绍常量池可以看成是一个表，但是有三点需要特别注意。 表头给出的常量池大小比实际大1。假设表头给出的值是n，那么常量池的实际大小是n–1。 有效的常量池索引是1~n–1。0是无效索引，表示不指向任何常量。 CONSTANT_Long_info和CONSTANT_Double_info各占两个位置。 表中的每一项的结构如下： 1234cp_info { u1 tag; u1 info[];} 可以看出，每一项都包含一个 tag，一个 info 数组。info 数组里面的的具体内容与 tag 的值有关。 tag 的值分为以下几种： tag取值很多，就举一个例子，其他的都是类似的。如果 tag 的值为 7，那么 info 数组表示的意义如下： 1234CONSTANT_Class_info { u1 tag; u2 name_index;} name_index 是一个 u2 类型，就相当于info的长度为2。 name_index 的含义根据名称也能猜的出来，是类名，只不过储存的是常量池的索引，索引指向的位置是类名。该位置的常量类型一定是一个 CONSTANT_Utf8_info 类型。 说起来可能有点不太好懂，我们看一个具体的例子： 图中是一个 CONSTANT_Class_info ，它的 name_index 是 34，我们看看常量池的第34项是什么： 可以看到34处，它确实是一个 CONSTANT_Utf8_info 类型，其具体的值就是类的名字。 其他的tag类型也是类似的，具体可以看官方文档，就不详细介绍了，我们现在开始使用代码解析常量池。 上为所有线程共享 ↑下为线程私有 ↓ 栈又分为jvm栈和本地方法栈主要用于方法的执行。 VMStack java方法栈它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 本地方法栈 native方法栈虚拟机栈为虚拟机执行java方法，而本地方法栈为虚拟机使用到的Native方法服务。 程序计数器一块较小的内存，当前线程所执行的字节码的行号指示器。字节码解释器工作时，就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。 ！！记录的是当前线程执行的字节码行号，debug时会被重新映射到对应的代码行数。Debug断点指向的代码行数可能包含多行字节码。 推荐阅读：http://gityuan.com/2015/10/17/java-memory/ DOC2.5. Run-Time Data AreasThe Java Virtual Machine defines various run-time data areas that are used during execution of a program. Some of these data areas are created on Java Virtual Machine start-up and are destroyed only when the Java Virtual Machine exits. Other data areas are per thread. Per-thread data areas are created when a thread is created and destroyed when the thread exits. 2.5.1. The pc RegisterThe Java Virtual Machine can support many threads of execution at once (JLS §17). Each Java Virtual Machine thread has its own pc (program counter) register. At any point, each Java Virtual Machine thread is executing the code of a single method, namely the current method (§2.6) for that thread. If that method is not native, the pc register contains the address of the Java Virtual Machine instruction currently being executed. If the method currently being executed by the thread is native, the value of the Java Virtual Machine’s pc register is undefined. The Java Virtual Machine’s pc register is wide enough to hold a returnAddress or a native pointer on the specific platform. 2.5.2. Java Virtual Machine StacksEach Java Virtual Machine thread has a private Java Virtual Machine stack, created at the same time as the thread. A Java Virtual Machine stack stores frames (§2.6). A Java Virtual Machine stack is analogous to the stack of a conventional language such as C: it holds local variables and partial results, and plays a part in method invocation and return. Because the Java Virtual Machine stack is never manipulated directly except to push and pop frames, frames may be heap allocated. The memory for a Java Virtual Machine stack does not need to be contiguous. In the First Edition of The Java® Virtual Machine Specification, the Java Virtual Machine stack was known as the Java stack. This specification permits Java Virtual Machine stacks either to be of a fixed size or to dynamically expand and contract as required by the computation. If the Java Virtual Machine stacks are of a fixed size, the size of each Java Virtual Machine stack may be chosen independently when that stack is created. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of Java Virtual Machine stacks, as well as, in the case of dynamically expanding or contracting Java Virtual Machine stacks, control over the maximum and minimum sizes. The following exceptional conditions are associated with Java Virtual Machine stacks: If the computation in a thread requires a larger Java Virtual Machine stack than is permitted, the Java Virtual Machine throws a StackOverflowError. If Java Virtual Machine stacks can be dynamically expanded, and expansion is attempted but insufficient memory can be made available to effect the expansion, or if insufficient memory can be made available to create the initial Java Virtual Machine stack for a new thread, the Java Virtual Machine throws an OutOfMemoryError. 2.5.3. HeapThe Java Virtual Machine has a heap that is shared among all Java Virtual Machine threads. The heap is the run-time data area from which memory for all class instances and arrays is allocated. The heap is created on virtual machine start-up. Heap storage for objects is reclaimed by an automatic storage management system (known as a garbage collector); objects are never explicitly deallocated. The Java Virtual Machine assumes no particular type of automatic storage management system, and the storage management technique may be chosen according to the implementor’s system requirements. The heap may be of a fixed size or may be expanded as required by the computation and may be contracted if a larger heap becomes unnecessary. The memory for the heap does not need to be contiguous. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the heap, as well as, if the heap can be dynamically expanded or contracted, control over the maximum and minimum heap size. The following exceptional condition is associated with the heap: If a computation requires more heap than can be made available by the automatic storage management system, the Java Virtual Machine throws an OutOfMemoryError. 2.5.4. Method AreaThe Java Virtual Machine has a method area that is shared among all Java Virtual Machine threads. The method area is analogous to the storage area for compiled code of a conventional language or analogous to the “text” segment in an operating system process. It stores per-class structures such as the run-time constant pool, field and method data, and the code for methods and constructors, including the special methods (§2.9) used in class and instance initialization and interface initialization. The method area is created on virtual machine start-up. Although the method area is logically part of the heap, simple implementations may choose not to either garbage collect or compact it. This specification does not mandate the location of the method area or the policies used to manage compiled code. The method area may be of a fixed size or may be expanded as required by the computation and may be contracted if a larger method area becomes unnecessary. The memory for the method area does not need to be contiguous. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the method area, as well as, in the case of a varying-size method area, control over the maximum and minimum method area size. The following exceptional condition is associated with the method area: If memory in the method area cannot be made available to satisfy an allocation request, the Java Virtual Machine throws an OutOfMemoryError. 2.5.5. Run-Time Constant PoolA run-time constant pool is a per-class or per-interface run-time representation of the constant_pool table in a class file (§4.4). It contains several kinds of constants, ranging from numeric literals known at compile-time to method and field references that must be resolved at run-time. The run-time constant pool serves a function similar to that of a symbol table for a conventional programming language, although it contains a wider range of data than a typical symbol table. Each run-time constant pool is allocated from the Java Virtual Machine’s method area (§2.5.4). The run-time constant pool for a class or interface is constructed when the class or interface is created (§5.3) by the Java Virtual Machine. The following exceptional condition is associated with the construction of the run-time constant pool for a class or interface: When creating a class or interface, if the construction of the run-time constant pool requires more memory than can be made available in the method area of the Java Virtual Machine, the Java Virtual Machine throws an OutOfMemoryError. See §5 (Loading, Linking, and Initializing) for information about the construction of the run-time constant pool. 2.5.6. Native Method StacksAn implementation of the Java Virtual Machine may use conventional stacks, colloquially called “C stacks,” to support native methods (methods written in a language other than the Java programming language). Native method stacks may also be used by the implementation of an interpreter for the Java Virtual Machine’s instruction set in a language such as C. Java Virtual Machine implementations that cannot load native methods and that do not themselves rely on conventional stacks need not supply native method stacks. If supplied, native method stacks are typically allocated per thread when each thread is created. This specification permits native method stacks either to be of a fixed size or to dynamically expand and contract as required by the computation. If the native method stacks are of a fixed size, the size of each native method stack may be chosen independently when that stack is created. A Java Virtual Machine implementation may provide the programmer or the user control over the initial size of the native method stacks, as well as, in the case of varying-size native method stacks, control over the maximum and minimum method stack sizes. The following exceptional conditions are associated with native method stacks: If the computation in a thread requires a larger native method stack than is permitted, the Java Virtual Machine throws a StackOverflowError. If native method stacks can be dynamically expanded and native method stack expansion is attempted but insufficient memory can be made available, or if insufficient memory can be made available to create the initial native method stack for a new thread, the Java Virtual Machine throws an OutOfMemoryError. 2.6. FramesA frame is used to store data and partial results, as well as to perform dynamic linking, return values for methods, and dispatch exceptions. A new frame is created each time a method is invoked. A frame is destroyed when its method invocation completes, whether that completion is normal or abrupt (it throws an uncaught exception). Frames are allocated from the Java Virtual Machine stack (§2.5.2) of the thread creating the frame. Each frame has its own array of local variables (§2.6.1), its own operand stack (§2.6.2), and a reference to the run-time constant pool (§2.5.5) of the class of the current method. A frame may be extended with additional implementation-specific information, such as debugging information. The sizes of the local variable array and the operand stack are determined at compile-time and are supplied along with the code for the method associated with the frame (§4.7.3). Thus the size of the frame data structure depends only on the implementation of the Java Virtual Machine, and the memory for these structures can be allocated simultaneously on method invocation. Only one frame, the frame for the executing method, is active at any point in a given thread of control. This frame is referred to as the current frame, and its method is known as the current method. The class in which the current method is defined is the current class. Operations on local variables and the operand stack are typically with reference to the current frame. A frame ceases to be current if its method invokes another method or if its method completes. When a method is invoked, a new frame is created and becomes current when control transfers to the new method. On method return, the current frame passes back the result of its method invocation, if any, to the previous frame. The current frame is then discarded as the previous frame becomes the current one. Note that a frame created by a thread is local to that thread and cannot be referenced by any other thread. 2.6.1. Local VariablesEach frame (§2.6) contains an array of variables known as its local variables. The length of the local variable array of a frame is determined at compile-time and supplied in the binary representation of a class or interface along with the code for the method associated with the frame (§4.7.3). A single local variable can hold a value of type boolean, byte, char, short, int, float, reference, or returnAddress. A pair of local variables can hold a value of type long or double. Local variables are addressed by indexing. The index of the first local variable is zero. An integer is considered to be an index into the local variable array if and only if that integer is between zero and one less than the size of the local variable array. A value of type long or type double occupies two consecutive local variables. Such a value may only be addressed using the lesser index. For example, a value of type double stored in the local variable array at index n actually occupies the local variables with indices n and n+1; however, the local variable at index n+1 cannot be loaded from. It can be stored into. However, doing so invalidates the contents of local variable n. The Java Virtual Machine does not require n to be even. In intuitive terms, values of types long and double need not be 64-bit aligned in the local variables array. Implementors are free to decide the appropriate way to represent such values using the two local variables reserved for the value. The Java Virtual Machine uses local variables to pass parameters on method invocation. On class method invocation, any parameters are passed in consecutive local variables starting from local variable 0. On instance method invocation, local variable 0 is always used to pass a reference to the object on which the instance method is being invoked (this in the Java programming language). Any parameters are subsequently passed in consecutive local variables starting from local variable 1. 2.6.2. Operand StacksEach frame (§2.6) contains a last-in-first-out (LIFO) stack known as its operand stack. The maximum depth of the operand stack of a frame is determined at compile-time and is supplied along with the code for the method associated with the frame (§4.7.3). Where it is clear by context, we will sometimes refer to the operand stack of the current frame as simply the operand stack. The operand stack is empty when the frame that contains it is created. The Java Virtual Machine supplies instructions to load constants or values from local variables or fields onto the operand stack. Other Java Virtual Machine instructions take operands from the operand stack, operate on them, and push the result back onto the operand stack. The operand stack is also used to prepare parameters to be passed to methods and to receive method results. For example, the iadd instruction (§iadd) adds two int values together. It requires that the int values to be added be the top two values of the operand stack, pushed there by previous instructions. Both of the int values are popped from the operand stack. They are added, and their sum is pushed back onto the operand stack. Subcomputations may be nested on the operand stack, resulting in values that can be used by the encompassing computation. Each entry on the operand stack can hold a value of any Java Virtual Machine type, including a value of type long or type double. Values from the operand stack must be operated upon in ways appropriate to their types. It is not possible, for example, to push two int values and subsequently treat them as a long or to push two float values and subsequently add them with an iadd instruction. A small number of Java Virtual Machine instructions (the dup instructions (§dup) and swap (§swap)) operate on run-time data areas as raw values without regard to their specific types; these instructions are defined in such a way that they cannot be used to modify or break up individual values. These restrictions on operand stack manipulation are enforced through class file verification (§4.10). At any point in time, an operand stack has an associated depth, where a value of type long or double contributes two units to the depth and a value of any other type contributes one unit. 2.6.3. Dynamic LinkingEach frame (§2.6) contains a reference to the run-time constant pool (§2.5.5) for the type of the current method to support dynamic linking of the method code. The class file code for a method refers to methods to be invoked and variables to be accessed via symbolic references. Dynamic linking translates these symbolic method references into concrete method references, loading classes as necessary to resolve as-yet-undefined symbols, and translates variable accesses into appropriate offsets in storage structures associated with the run-time location of these variables. This late binding of the methods and variables makes changes in other classes that a method uses less likely to break this code. 2.6.4. Normal Method Invocation CompletionA method invocation completes normally if that invocation does not cause an exception (§2.10) to be thrown, either directly from the Java Virtual Machine or as a result of executing an explicit throw statement. If the invocation of the current method completes normally, then a value may be returned to the invoking method. This occurs when the invoked method executes one of the return instructions (§2.11.8), the choice of which must be appropriate for the type of the value being returned (if any). The current frame (§2.6) is used in this case to restore the state of the invoker, including its local variables and operand stack, with the program counter of the invoker appropriately incremented to skip past the method invocation instruction. Execution then continues normally in the invoking method’s frame with the returned value (if any) pushed onto the operand stack of that frame. 2.6.5. Abrupt Method Invocation CompletionA method invocation completes abruptly if execution of a Java Virtual Machine instruction within the method causes the Java Virtual Machine to throw an exception (§2.10), and that exception is not handled within the method. Execution of an athrow instruction (§athrow) also causes an exception to be explicitly thrown and, if the exception is not caught by the current method, results in abrupt method invocation completion. A method invocation that completes abruptly never returns a value to its invoker.","link":"/2024/04/19/JMM/"},{"title":"Gradle","text":"Gradle 用户指南官方文档中文版 Gradle基础 生命周期 生命周期监听(HOOK) ProjectGradle的构建由一个或多个Project组成（根目录下setting.gradle决定），一个打印Project所有属性信息的示例如下: 123456789./gradlew app:properties常见如：项目名称: project.name项目目录: project.projectDir构建目录: project.buildDir根项目: project.rootProject版本: project.version组: project.group状态: project.status TaskGradle Plugin 中的Task主要有三种：**普通Task、增量Task、Transform**。 Task一般会继承 DefaultTask 或 **IncrementalTask**，而 @TaskAction 注解的方法，就是此Task做的事。 继承 IncrementalTask 的类为增量Task，这个增量是相对于全量来说的，全量指的是：调用完clean后第一次编译过程，修改代码或资源后再次编译，就是增量编译 123456789101112131415161718public abstract class IncrementalTask extends BaseTask { // 是否需要增量，默认false @Internal protected boolean isIncremental() { } // 需要子类实现，全量时执行的任务 protected abstract void doFullTaskAction() throws Exception; // 增量时执行的任务，默认什么都不执行，参数是增量时修改过的文件 protected void doIncrementalTaskAction(Map&lt;File, FileStatus&gt; changedInputs) throws Exception{ } @TaskAction void taskAction(IncrementalTaskInputs inputs) throws Exception { // 判断是否是增量，是执行doIncrementalTaskAction，否则执行doFullTaskAction ｝ // 获取修改文件 private Map&lt;File, FileStatus&gt; getChangedInputs(IncrementalTaskInputs inputs) { }} 至于 Transform（变换），是Android官方提供给开发者，在.class → .dex转换期间用来修改.class文件的一套API，留意 transform() 方法的实现就好。 Gradle Plugin Version or Gradle VesionGladle插件版本(AGP) build.gradle文件 classpath’com.android.tools.build:gradle:3.0.0’ 指定，是AS用来引入gladle特性的插件 Gladle版本(Gradle)： gradle/wrapper/gradle-wrapper.properties文件中 distributionUrl=https://services.gradle.org/distributions/gradle-x.x.x.zip 指定，也即使gradle本体的版本 简述：这很好理解，gradle-wrapper.properties配置后会下载该版本Gradle本体到/gradle目录下，这就是gradle本体目录了 AGP和gradle的版本对应关系： 插件版本 所需的 Gradle 版本 7.3 7.4 7.2 7.3.3 7.1 7.2 7.0 7.0 4.2.0+ 6.7.1 4.1.0+ 6.5+ 4.0.0+ 6.1.1+ 3.6.0 - 3.6.4 5.6.4+ 3.5.0 - 3.5.4 5.4.1+ lower version lower version Android Studio版本(AS) Dependencies Tree CheckdependenciesTask :app:dependencies用于输出项目依赖项的树状结构 如果 dependencies 信息太多，可以保存到文件：./gradlew :app:dependencies --configuration releaseRuntimeClassPath &gt; dependencies.txt，这样更方便搜索和查看。项目依赖项信息非常有用，可以用来排查依赖冲突、分析库依赖关系等。 全部依赖: gradlew app:dependencies release依赖: gradlew app:dependencies –configuration releaseRuntimeClasspath ./gradlew app:dependencies --configuration debugRuntimeClasspath 123456--configuration 后参数正式环境依赖： releaseRuntimeClasspathdebug依赖: debugRuntimeClasspath编译依赖： compile 后面带有 “(*)” 的库就表示 这个库有被覆盖过（最高的版本覆盖）。 1234567androidx.annotation:annotation:1.1.0 -&gt; 1.3.0org.jetbrains.kotlin:kotlin-stdlib:1.5.31 -&gt; 1.7.10 (*)org.jetbrains.kotlin:kotlin-stdlib:1.7.10 (*)androidx.test:core:{strictly 1.4.0} -&gt; 1.4.0 (c) -&gt;：表示冲突，比如这个1.1.0 -&gt; 1.3.0，-&gt; 后面的版本表示Gradle决议之后的版本，这里表示1.1.0版本被拉高到1.3.0； *：*其实是省略的意思，层级太深，Gradle就省略了一部分，而越深的信息也不太重要，就显的冗余，往往重要的信息都在前几层； c：c是constraints的简称，主要是用来保证当前依赖项所需要的依赖的版本的一致性，白话讲就是为了防止其他依赖项把我需要的依赖给拉高而导致我自己不可用的情况。 strictly：strictly跟force一样表示强制使用该版本，区别在于strictly可以在依赖树里标示出来，而force则没有任何标示，所以force在高版本里也被废弃了。 dependencyInsightTask :app:dependencyInsight 用于输出项目中特定依赖项的详细信息 使用这个 task 的方式是：./gradlew :app:dependencyInsight --configuration someConf --dependency someDep，必须有 –configuration 和 –dependency 选项。对于 –configuration 选项参数，可以通过上面的Task :app:androidDependencies 查看。 1./gradlew module-detail:dependencyInsight --dependency component-media --configuration releaseRuntimeClasspath How Gradle depend on本地库模块依赖项module implementation project(‘:mylibrary’) 这声明了对一个名为“mylibrary”（此名称必须与在您的 settings.gradle 文件中使用 include: 定义的库名称相符）的 Android 库模块的依赖关系。在构建您的应用时，构建系统会编译该库模块，并将生成的编译内容打包到 APK 中。 本地二进制文件依赖项jar java ARchive .class文件+MENIFEST.MF文件 implementation fileTree(dir: ‘libs’, include: [‘*.jar’]) Gradle 声明了对项目的 module_name/libs/ 目录中 JAR 文件的依赖关系（因为 Gradle 会读取 build.gradle 文件的相对路径）。 或者，您也可以按如下方式指定各个文件： implementation files(‘libs/foo.jar’, ‘libs/bar.jar’) 远程二进制文件依赖项aar = jar + AndroidManifest、res、R、public.txt和可能其他 implementation ‘com.example.android:app-magic:12.3’ 这实际上是以下代码的简写形式： implementation group: ‘com.example.android’, name: ‘app-magic’, version: ‘12.3’ 这声明了对“com.example.android”命名空间组内的 12.3 版“app-magic”库的依赖关系。 文件格式.aar实际上.arr中可能只有.jar 和 AndroidManifest.xml Maven依赖1234567891011 allprojects { repositories { google() //Google Maven repository jcenter() //Bintray’s JCenter Maven repository 已不维护 mavenCentral() //central Maven repository maven { url &quot;https://maven.aliyun.com/repository/google&quot; } //Google阿里镜像 maven { url &quot;https://maven.aliyun.com/repository/jcenter&quot; } //JCenter阿里镜像 mavenLocal() // }} Google 的 Maven 代码库中提供了以下 Android 库的最新版本： Android 支持库架构组件库约束布局库AndroidX 测试数据绑定库Android 免安装应用库Wear OSGoogle Play 服务Google Play 结算库Firebase 补充链接https://juejin.cn/post/6950643579643494431 Gradle常用命令12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 命令结构gradle [taskName...] [--option-name...]# 增量编译：同一个项目中, 同一个 task除非有必要, 否则不会被无意义的执行多次；# 缓存：无论是否在同一个项目，只要Task输入没变就复用缓存结果，不必真的执行task；# Tasks执行gradle myTask # 执行某个Taskgradle :my-subproject:taskName # 执行子项目中的Taskgradle my-subproject:taskName # 同上，不指定子项目，会执行所有子项目的此Task，如gradle clean；gradle task1 task2 # 运行多个Taskgradle dist --exclude-task test # 将某个task排除在执行外gradle dist -x test # 同上gradle test --rerun-tasks # 强制执行UP-TO-DATE的Task，即不走增量编译，执行全量编译；gradle test --continue # 默认情况下，一旦Task失败就会构建失败，通过此参数可继续执行；# 常见任务(和插件间的Task约定)gradle buildgradle rungradle checkgradle clean # 删除构建目录# 构建细节gradle projects # 列出所有子项目gradle tasks # 列出所有Task(分配给任务组的Task)gradle tasks --group=&quot;build setup&quot; # 列出特定任务组的Taskgradle tasks --all # 列出所有Taskgradle -q help --task libs # 查看某个Task的详细信息gradle myTask --scan # 生成可视化的编译报告gradle dependencies # 列出项目依赖gradle -q project:properties # 列出项目属性列表# 调试选项-?，-h，--help # 帮助信息-v，--version # 版本信息-s, --stacktrace # 打印出异常堆栈跟踪信息；-S, --full-stacktrace # 比上面更完整的信息；# 性能相关--build-cache # 复用缓存--no-build-cache # 不复用缓存，默认--max-workers # 最大处理器数量--parallel # 并行生成项目--no-parallel # 不并行生成项目--priority # Gradle启动的进程优先级--profile # 生成性能报告# 守护进程--daemon # 使用deamon进程构建--no-daemon # 不使用deamon进程构建--foreground # 前台进程启动deamon进程--status # 查看运行中和最近停止的deamon进程；--stop # 停止所有同一版本的deamon进程；# 日志选项-q, --quiet # 只记录错误-w, --warn-i, --info -d, --debug--console=(auto,plain,rich,verbose) # 指定输出类型--warning-mode=(all,fail,none,summary) # 指定警告级别# 执行选项--include-build # 复合构建--offline # 离线构建--refresh-dependencies # 强制清除依赖缓存--dry-run # 在不实际执行Task的情况下看Task执行顺序--no-rebuild # 不重复构建项目依赖# 环境选项-b, --build-file # 指定构建文件-c, --settings-file # 指定设置文件-g, --gradle-user-home # 指定默认.Gradle目录-p, --project-dir # 指定Gradle的开始目录--project-cache-dir # 指定缓存目录，默认.gradle-D, --system-prop # 设置JVM系统属性-I, --init-script # 指定初始化脚本-P, --project-prop # 指定根项目的项目属性； //gradle build 命令包含了 gradle assemble ， 可通过 gradle build –dry-run查看","link":"/2021/04/02/Gradle/"},{"title":"JsBridage","text":"Js与原生交互的方式：通过注入对象或拦截 URL SCHEME实现JSBridge 原生调用JS（webView.loadUrl） Js调用原生1. 注入对象(webView.addJavaScriptInterface)​ Android4.2前addJavascriptInterface接口存在注入漏洞，即JS可以通过反射获取到native端的其他接口，进行其他非法操作，所以4.2之后升级增加了JS只能访问带有 @JavascriptInterface注解的Java函数的限制。 2. 拦截 URL SCHEME(覆盖shouldOverrideUrlLoading)​ 更好的兼容性，创建请求，需要一定的耗时","link":"/2021/04/10/JsBridage/"},{"title":"Kotlin","text":"kotlin data classdata class会自动生成以下方法： equals() hashCode() 12345public int hashCode() { int var10000 = Integer.hashCode(this.age) * 31; String var10001 = this.name; return var10000 + (var10001 != null ? var10001.hashCode() : 0);} toString() copy() componentN() 编译器会为数据类生成 组件函数(Component function), 有了这些组件函数, 就可以在 解构声明(destructuring declaration) 中使用数据类: 1234val jane = User(&quot;Jane&quot;, 35)val (name, age) = janeprintln(&quot;$name, $age years of age&quot;) // 输出结果为 Jane, 35 years of age 属性的get()/set() val的属性不会有setter constructor() 只有有参构造函数，没有无参构造函数。fastJson解析会抛该异常，需升级到高版本并引入kotlin-reflect依赖 Kotlin Object类其字节码实现是：提供一个类，会在static方法块中实例化的该类的static final 对象。 是饿汉模式的，通过JVM类加载机制确保线程安全的 Kotlin空安全Kotlin空安全原理:String、String?首先通过注解 @Lorg/jetbrains/annotations/NotNull;和@Lorg/jetbrains/annotations/Nullable;来向编译器标示参数是否为空，如果不为空则通过 INVOKESTATIC kotlin/jvm/internal/Intrinsics.checkParameterIsNotNull (Ljava/lang/Object;Ljava/lang/String;)来进行检查，此时如果我们给个空值则编译器出现报错提示。 ?.（elvis猫王表达式）对用使用 ?. 操作符号kotlin会判断是否为null 如果不为null执行对应的逻辑，如果为null则什么也不执行（此时的默认结果也是null） !!.对用使用 !! 操作符号 Kotlin 同样会执行null判断如果不为null 则执行对应的逻辑，如果为null 则抛出异常，即执行 INVOKESTATIC kotlin/jvm/internal/Intrinsics.throwNpe () kotlin 泛型Kotlin 泛型系统继承于 Java泛型，依然是一种语法糖的伪泛型，会在编译时发生类型擦除。但如果是内联函数+reified时，是字节码中保留类型的真泛型 Kotlin高阶函数Kotlin中的高阶函数通过位于kotlin.jvm.functions下的函数接口（SAM）来表示，在编译时将函数类型转换为这些接口的实现。编译器生成相应的字节码来处理高阶函数调用。（由于都是预先写好的函数接口，所以其实高阶函数最大支持的参数数量是有限的，现为22个） 12345/** A function that takes 22 arguments. */public interface Function22&lt;in P1, in P2, in P3, in P4, in P5, in P6, in P7, in P8, in P9, in P10, in P11, in P12, in P13, in P14, in P15, in P16, in P17, in P18, in P19, in P20, in P21, in P22, out R&gt; : Function&lt;R&gt; { /** Invokes the function with the specified arguments. */ public operator fun invoke(p1: P1, p2: P2, p3: P3, p4: P4, p5: P5, p6: P6, p7: P7, p8: P8, p9: P9, p10: P10, p11: P11, p12: P12, p13: P13, p14: P14, p15: P15, p16: P16, p17: P17, p18: P18, p19: P19, p20: P20, p21: P21, p22: P22): R} 例如，以下高阶函数： 123fun doSomeThing(x: Int, predicate: (Int) -&gt; String): String { return predicate(x)} 当编译这个函数时，编译器会生成类似如下的字节码（伪代码，用于说明）： 1234567public final class ExperimentalFiled3 { @NotNull public final String doSomeThing(int x, @NotNull kotlin.jvm.functions.Function1 predicate) { Intrinsics.checkNotNullParameter(predicate, &quot;predicate&quot;); return (String)predicate.invoke(x); }} 只有一个抽象方法的接口称为函数式接口或 单一抽象方法（SAM）接口 Kotlin闭包Lambda表达式和匿名函数在Kotlin中都是闭包，意味着它们可以捕获并持有其定义作用域内的变量。 函数和对其周围状态（lexical environment，词法环境）的引用捆绑在一起构成闭包。 其中包括两个要点： 函数 周围环境（&amp;状态&amp;上下文）比如在a函数里定义了b匿名函数和变量x，b能引用到a的变量x，就叫闭包 这两者的实现原理类似的，通过编译器生成对应的 继承于kotlin.jvm.internal.Lambda并且实现kotlin.jvm.functions下函数接口的类，将表达式或匿名函数类方法体代码塞入该类的invoke方法中，并在被调用处生成该类的实例 比如 1val sum = { a: Int, b: Int -&gt; a + b } 编译器会生成类似如下的字节码（伪代码，用于说明）： 123456789101112public final class SumLambda extends Lambda implements Function2&lt;Integer, Integer, Integer&gt; { public static final SumLambda INSTANCE = new SumLambda(); private SumLambda() { super(2); } @Override public Integer invoke(Integer a, Integer b) { return a + b; }} 使用时： 1val sum = SumLambda.INSTANCE Lambda表达式和匿名函数的区别主要还是在于语法的不同、返回类型是否需要显示声明、非局部返回上。 Kotlin 类、方法为什么默认final为了让程序编写者慎用继承，仅当需要被继承时才手动使用open关键字修饰需要被集成的类或方法。这样可以增加对“降低耦合性、提高灵活性”的考虑 kotlin 嵌套类&amp;内部类java： 只分为 静态内部类 和 非静态内部类， 只要是非静态内部类都会固定持有外部类的对象，只要是静态内部类都是不持有外部类引用的 kotlin： 分为 内部类 inner 修饰的内部类（类成员）， 相当于 java非静态内部类，固定持有外部类引用的（本质上是生成外部类引用的构造参数） 嵌套类 非inner修饰的成员类， 相当于 java静态内部类，不持有外部类引用的 3.1 匿名内部类（常见） 使用对象表达式创建的类（object: Interface{ }），可以访问到外部类成员，但默认不持有外部类引用，只有主动持有外部变量是才会将该外部类对象（如Activity对象）作为构造参数（见字节码）引入 3.2 方法内嵌套类 在方法内定义的非inner修饰的类，可以访问到外部类成员，但默认不持有外部类引用，只有主动持有外部变量是才会将该外部类对象（如Activity对象）作为构造参数（见字节码）引入 Kotlin注解Kotlin代码可以经过编译器转换成VM虚拟机能识别的字节码，所以Java与Kotlin可以互相进行调用。而由于Java与Kotlin语言特性的差异，当Java调用Kotlin代码时，可以在Kotlin代码中适当增加一些注解，从而更方便的调用Kotlin代码。 @JvmOverloads在Kotlin的方法里有多个默认参数时，如果在Java中直接调用，只能调用一个包含完整参数的方法，如果想暴露更多的重载函数给Java，可以使用@JvmOverloads 用于生成重载。对于每一个有默认值的参数，生成的重载会把当前有默认值的参数及其右边的参数都去掉，所以如果方法中所有的参数都有默认值，生成的重载函数中还会有一个无参的重载函数。 @JvmOverloads 主要用于构造函数、方法中，同时不能用于抽象方法、接口中的方法等。 常见应用在自定义View构造函数中 12345VpLoadMoreView @JvmOverloads constructor( context: Context, attrs: AttributeSet? = null, defStyle: Int = 0,) : LinearLayout(context, attrs, defStyle) {} @JvmStatic@JvmStatic用于声明静态方法。在具名对象及伴生对象中使用时，既会在相应对象的类中生成静态方法，也会在对象自身中生成实例方法，如： 123456class KtA { companion object { @JvmStatic fun invokeStatic() {} fun invokeNoStatic() {}} 在Java中调用： 123456public void invokeKt() { KtA.invokeStatic(); //正确，可以直接调用 //KtA.invokeNoStatic(); //错误，这里调用不到 KtA.Companion.invokeStatic(); //正确 KtA.Companion.invokeNoStatic(); //正确 } @JvmField@JvmField使得编译器不再对该字段生成getter/setter并将其作为公开字段 @JvmSynthetic@JvmSynthetic可以修饰于方法上，控制只能在Kotlin中调用，如： 1234class KtA { @JvmSynthetic fun visit() {}} Java中调用： 1234public void invokeKt() { KtA clz = new KtA(); clz.visit(); //错误，这里在Java中调用不到。} 如果想在Java中调用到Kotlin类中的方法，将@JvmSynthetic去掉即可。 @JvmInline12345@Target(AnnotationTarget.CLASS)@Retention(AnnotationRetention.RUNTIME)@MustBeDocumented@SinceKotlin(&quot;1.5&quot;)public actual annotation class JvmInline @JvmInline在1.5.0版本引入，可以指定一个类为内联类，需结合value一起使用；在1.5.0之前使用inline关键字。 1234567//1.5.0之前，inline标记内联类inline class Person(private val name: String = &quot;&quot;)//1.5.0之后，@JvmInline + value 标记内联类@JvmInlinevalue class Person(private val name: String = &quot;&quot;)内联类构造参数中有且只能有一个成员变量，最终被内联到字节码中的value。，上述代码经过内联优化会在字节码中将Person对象转换为String值，从而由堆分配优化为栈分配。 @JvmName 、@JvmMultifileClass@JvmName 注解可以生成类名；如果类名已存在，可以修改已生成的 Java 类的类名。包名相同并且类名相同或者有相同的 @JvmName 注解有会错误，可以通过@JvmMultifileClass把他们合并到一起 Kotlin lateinit 和 by lazy简述： lateinit是用于var的不可空类型属性，是声明延迟初始化，需开发者保证赋值的时序正确 by lazy是用于val的属性，by是用于委托的关键字，lazy是提供线程安全的懒加载的实现 lateinit var适用于你在声明变量时不知道它的初始值是多少的场景，需要保证代码访问时序的正确性 lazy更适用于，「一个对象的创建需要消耗大量的资源，而我不知道它到底会不会被用到」的场景，lazy只有在第一次被调用到的时候才会去赋值 lazy本质是生成了一个SynchronizedLazyImpl对象，这个对象初始化的时候会持有一个函数的引用，当调用它的value的时候，会去检查是不是初始化过了，如果初始化过了直接返回，没有的话调用传入的函数，获取到返回值之后再返回，从而实现了一个懒加载的效果 123456789101112131415161718192021222324252627private class SynchronizedLazyImpl&lt;out T&gt;(initializer: () -&gt; T, lock: Any? = null) : Lazy&lt;T&gt;, Serializable { private var initializer: (() -&gt; T)? = initializer @Volatile private var _value: Any? = UNINITIALIZED_VALUE // final field is required to enable safe publication of constructed instance private val lock = lock ?: this override val value: T get() { val _v1 = _value if (_v1 !== UNINITIALIZED_VALUE) { @Suppress(&quot;UNCHECKED_CAST&quot;) return _v1 as T } return synchronized(lock) { val _v2 = _value if (_v2 !== UNINITIALIZED_VALUE) { @Suppress(&quot;UNCHECKED_CAST&quot;) (_v2 as T) } else { val typedValue = initializer!!() _value = typedValue initializer = null typedValue } } }} 但是上面的代码中，我们可以看到，这个实现它在第一次获取值的时候是有加锁来实现线程安全，但是很多时候我们的代码都是单线程调用的，不需要考虑线程安全问题，这个时候就会有额外的性能开销","link":"/2021/07/30/Kotlin/"},{"title":"LeakType","text":"内存泄漏实质内存泄漏实质上是GC时候，被GC Root引用或间接引用着的对象无法被回收，而可以作为GC Root的对象在java中有几种： 虚拟机栈或叫JVM栈（栈帧中的本地变量表）中引用的对象； （线程泄露） 虚拟机栈是线程私有的，每个java方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 方法区中的类静态属性引用的对象； （static变量） 方法区存储类信息、常量、静态变量等数据，是线程共享的区域 本地方法栈中JNI（即一般说的Native方法）中引用的对象 （Jni持有的对象） 对应虚拟机栈为虚拟机执行java方法服务，而本地方法栈为虚拟机使用到的Native方法服务 方法区中常量引用的对象； （final修饰的int/float/long等基本数据类型和String） 不常见 Android内存泄漏内存泄漏：长周期对象持有短周期对象的引用，而导致短周期的对象在生命周期结束时无法被回收。 即：对象在生命周期结束时被另一个对象通过强引用持有而无法释放 永久性内存泄漏：非静态内部类。 如handler、runnable、asnycTask、Thread等，不管是使用匿名内部类的创建模式，还是定义一个非静态的class的模式，都会导致持有外部类使外部类无法释放。（上1） 静态变量，单例模式（上2） 文件操作、数据库操作等closeable类，它们底层是jni实现的（上4），需要手动释放 ps:一般类似onClickListener的用法虽然会使用匿名内部类的方式创建但不会导致内存泄漏，因为只有异步任务的匿名内部类生命周期不同才可能导致内存泄漏，同步的会被作为一个整体被GC掉。 两种特殊情况： 系统监听LocationListener，系统一直持有而永久性泄漏； 监听回调中有耗时操作，导致临时泄漏（见下）。 临时性内存泄漏：静态handler有消息存在messageQueue中，由于messageQueue持有message，message持有target（handler对象），handler则会无法回收，直到消息被取出处理后，再次GC时回收。（上1）","link":"/2024/07/04/LeakType/"},{"title":"Lifecycle","text":"","link":"/2023/10/10/Lifecycle/"},{"title":"Java","text":"final &amp; finalize()finalfinal修饰的类不可被继承，方法不可被覆盖(或者叫重写)，对象不可被更改。 finalize()finalize()是Object的protected方法，是用来给对象在Gc前一次行动的机会：首先，当对象变成(GC Roots)不可达时，GC会判断该对象是否覆盖了finalize方法，若未覆盖，则直接将其回收。否则，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。 System.gc()与System.runFinalization()方法增加了finalize方法执行的机会，但不可盲目依赖它们 Java语言规范并不保证finalize方法会被及时地执行、而且根本不会保证它们会被执行 finalize方法可能会带来性能问题。因为JVM通常在单独的低优先级线程中完成finalize的执行 对象再生问题：finalize方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的 finalize方法至多由GC执行一次(用户当然可以手动调用对象的finalize方法，但并不影响GC对finalize的行为) 简述：finalize()方法会在对象回收前至多被调用一次，一般可以在这里做一次重新挂到GcRoot链上的保活操作，或者像Android6以前安卓在覆盖的finalize()方法中释放native内存一样。 Object.toStringtoString 默认是个指针，一般需要重写，未重写情况下，返回 1getClass().getName() + '@' + Integer.toHexString(hashCode()) equal &amp; hashcode If o1.equals(o2), then o1.hashCode() == o2.hashCode() should always be true. If o1.hashCode() == o2.hashCode is true, it doesn’t mean that o1.equals(o2) will be true. 也就是equals 是 hashcode的充分不必要条件 equals比较对象是否内容相同，默认和==功能一致 hashcode该对象哈希。hashcode有多种实现，不一定与内存地址相关。目前版本是”当前线程有关的一个随机数+三个确定值，运用xorshift随机数算法得到的一个随机数“ 重写equal 的同时为什么必须重写hashcode？ 注意：当equals方法被重写时，通常有必要重写 hashCode 方法，以维护 hashCode 方法的常规协定，该协定声明相等对象必须具有相等的哈希码。 hashCode是编译器为不同对象产生的不同整数，根据equal方法的定义：如果两个对象是相等（equal）的，那么两个对象调用hashCode必须产生相同的整数结果，即：equal为true，hashCode必须为true，equal为false，hashCode也必须为false，所以必须重写hashCode来保证与equal同步。 finalize()wait() &amp; notify()getClass()clone()面向对象封装：对抽象的事物抽象化成一个对象，并对其对象的属性私有化，同时提供一些能被外界访问属性的方法； 继承：子类扩展新的数据域或功能，并复用父类的属性与功能，单继承，多实现； 多态：通过继承（多个⼦类对同⼀⽅法的重写）、也可以通过接⼝（实现接⼝并覆盖接⼝） 静态绑定与动态绑定，重载Overload与重写Override：重载 一种是在编译期确定，被称为静态分派，比如方法的重载Overload； 重载指在同一个类中定义多个方法，这些方法名称相同，签名不同。**(参数列表必须改，其他无要求)** 多态 一种是在运行时确定，被称为动态分派，比如方法的覆盖Override（重写）和接口的实现。 重写指在子类中的方法的名称和签名都和父类相同，使用override注解。**(参数和返回不能改，其他不能升级)** 多态实现多态的底层实现是动态绑定，即在运行时才把方法调用与方法实现关联起来。在Java中有两种形式可以实现多态：方法的覆盖Override（重写）和接口的实现。 多态的实现原理 虚拟机栈中会存放当前方法调用的栈帧（局部变量表、操作栈、动态连接 、返回地址）。多态的实现过程，就是方法调用动态分派的过程，如果子类覆盖了父类的方法，则在多态调用中，动态绑定过程会首先确定实际类型是子类，从而先搜索到子类中的方法。这个过程便是方法覆盖的本质。 附录：重写Override和重载Overload的区别Overload 在同一个类中，重载指在同一个类中定义多个方法，这些方法名称相同，签名不同。**(参数列表必须改，其他无要求)** Overwirte 集成于父类的子类中，重写指在子类中的方法的名称和签名都和父类相同，使用override注解。**(参数和返回不能改，其他不能升级)** 区别点 重载方法 重写方法 参数列表 必须修改 一定不能修改 返回类型 可以修改 一定不能修改 异常 可以修改 可以减少或删除，一定不能抛出新的或者更广的异常 访问 可以修改 一定不能做更严格的限制（可以降低限制） 面向对象三大特性特性：封装、继承、多态 封装：对抽象的事物抽象化成一个对象，并对其对象的属性私有化，同时提供一些能被外界访问属性的方法； 继承：子类扩展新的数据域或功能，并复用父类的属性与功能，单继承，多实现； 多态：通过继承（多个⼦类对同⼀⽅法的重写）、也可以通过接⼝（实现接⼝并覆盖接⼝） 1、Java与C++区别 不同点：c++支持多继承，并且有指针的概念，由程序员自己管理内存；Java是单继承，可以用接口实现多继承，Java 不提供指针来直接访问内存，程序内存更加安全，并且Java有JVM⾃动内存管理机制，不需要程序员⼿动释放⽆⽤内存 2、多态实现原理多态的底层实现是动态绑定，即在运行时才把方法调用与方法实现关联起来。 静态绑定与动态绑定： 一种是在编译期确定，被称为静态分派，比如方法的重载； 一种是在运行时确定，被称为动态分派，比如方法的覆盖（重写）和接口的实现。 多态的实现 虚拟机栈中会存放当前方法调用的栈帧（局部变量表、操作栈、动态连接 、返回地址）。多态的实现过程，就是方法调用动态分派的过程，如果子类覆盖了父类的方法，则在多态调用中，动态绑定过程会首先确定实际类型是子类，从而先搜索到子类中的方法。这个过程便是方法覆盖的本质。 3、static和final关键字static：可以修饰属性、方法 static修饰属性： 类级别属性，所有对象共享一份，随着类的加载而加载（只加载一次），先于对象的创建；可以使用类名直接调用。 static修饰方法： 随着类的加载而加载；可以使用类名直接调用；静态方法中，只能调用静态的成员，不可用this； final：关键字主要⽤在三个地⽅：变量、⽅法、类。 final修饰变量： 如果是基本数据类型的变量，则其数值⼀旦在初始化之后便不能更改； 如果是引⽤类型的变量，则在对其初始化之后便不能再让其指向另⼀个对象。 final修饰方法： 把⽅法锁定，以防任何继承类修改它的含义（重写）；类中所有的 private ⽅法都隐式地指定为 final。 final修饰类： final 修饰类时，表明这个类不能被继承。final 类中的所有成员⽅法都会被隐式地指定为 final ⽅法。 一个类不能被继承，除了final关键字之外，还有可以私有化构造器。（内部类无效） 4、抽象类和接口抽象类：包含抽象方法的类，即使用abstract修饰的类；抽象类只能被继承，所以不能使用final修饰，抽象类不能被实例化， 接口：接口是一个抽象类型，是抽象方法的集合，接口支持多继承，接口中定义的方法，默认是public abstract修饰的抽象方法 相同点： ① 抽象类和接口都不能被实例化 ② 抽象类和接口都可以定义抽象方法，子类/实现类必须覆写这些抽象方法 不同点： ① 抽象类有构造方法，接口没有构造方法 ③抽象类可以包含普通方法，接口中只能是public abstract修饰抽象方法（Java8之后可以） ③ 抽象类只能单继承，接口可以多继承 ④ 抽象类可以定义各种类型的成员变量，接口中只能是public static final修饰的静态常量 抽象类的使用场景： 既想约束子类具有共同的行为（但不再乎其如何实现），又想拥有缺省的方法，又能拥有实例变量 接口的应用场景： 约束多个实现类具有统一的行为，但是不在乎每个实现类如何具体实现；实现类中各个功能之间可能没有任何联系 5、泛型以及泛型擦除参考：https://blog.csdn.net/baoyinwang/article/details/107341997 泛型： 泛型的本质是参数化类型。这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口和泛型方法。 泛型擦除： Java的泛型是伪泛型，使用泛型的时候加上类型参数，在编译器编译生成的字节码的时候会去掉，这个过程成为类型擦除。 如List等类型，在编译之后都会变成 List。JVM 看到的只是 List，而由泛型附加的类型信息对 JVM 来说是不可见的。 可以通过反射添加其它类型元素 6、反射原理以及使用场景Java反射： 是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且都能够调用它的任意一个方法； 反射原理： 反射首先是能够获取到Java中的反射类的字节码，然后将字节码中的方法，变量，构造函数等映射成 相应的 Method、Filed、Constructor 等类 如何得到Class的实例: 1231.类名.class(就是一份字节码)2.Class.forName(String className);根据一个类的全限定名来构建Class对象3.每一个对象多有getClass()方法:obj.getClass();返回对象的真实类型 使用场景： 开发通用框架 - 反射最重要的用途就是开发各种通用框架。很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 JavaBean、Filter 等），为了保证框架的通用性，需要根据配置文件运行时动态加载不同的对象或类，调用不同的方法。 动态代理 - 在切面编程（AOP）中，需要拦截特定的方法，通常，会选择动态代理方式。这时，就需要反射技术来实现了。 JDK：spring默认动态代理，需要实现接口 CGLIB：通过asm框架序列化字节流，可配置，性能差 自定义注解 - 注解本身仅仅是起到标记作用，它需要利用反射机制，根据注解标记去调用注解解释器，执行行为。 7、Java异常体系 Throwable 是 Java 语言中所有错误或异常的超类。下一层分为 Error 和 Exception Error ： 是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。 Exception 包含：RuntimeException 、CheckedException 编程错误可以分成三类：语法错误、逻辑错误和运行错误。 语法错误（也称编译错误）是在编译过程中出现的错误，由编译器检查发现语法错误 逻辑错误指程序的执行结果与预期不符，可以通过调试定位并发现错误的原因 运行错误是引起程序非正常终端的错误，需要通过异常处理的方式处理运行错误 RuntimeException： 运行时异常，程序应该从逻辑角度尽可能避免这类异常的发生。 如 NullPointerException 、 ClassCastException ； CheckedException：受检异常，程序使用trycatch进行捕捉处理 如IOException、SQLException、NotFoundException； 数据结构 1、ArrayList和LinkedListArrayList： 底层基于数组实现，支持对元素进行快速随机访问，适合随机查找和遍历，不适合插入和删除。（提一句实际上）​ 默认初始大小为10，当数组容量不够时，会触发扩容机制（扩大到当前的1.5倍），需要将原来数组的数据复制到新的数组中；当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。 LinkedList： 底层基于双向链表实现，适合数据的动态插入和删除；​ 内部提供了 List 接口中没有定义的方法，用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用。（比如jdk官方推荐使用基于linkedList的Deque进行堆栈操作） ArrayList与LinkedList区别： 都是线程不安全的，ArrayList 适用于查找的场景，LinkedList 适用于增加、删除多的场景 实现线程安全： 可以使用原生的Vector，或者是Collections.synchronizedList(List list)函数返回一个线程安全的ArrayList集合。​ 建议使用concurrent并发包下的CopyOnWriteArrayList的。 ①Vector: 底层通过synchronize修饰保证线程安全，效率较差 ②CopyOnWriteArrayList：写时加锁，使用了一种叫写时复制的方法；读操作是可以不用加锁的 2、List遍历快速和安全失败①普通for循环遍历List删除指定元素 1234for(int i=0; i &lt; list.size(); i++){ if(list.get(i) == 5) list.remove(i);} ② 迭代遍历,用list.remove(i)方法删除元素 1234567Iterator&lt;Integer&gt; it = list.iterator();while(it.hasNext()){ Integer value = it.next(); if(value == 5){ list.remove(value); }} ③foreach遍历List删除元素 123for(Integer i:list){ if(i==3) list.remove(i);} fail—fast：快速失败 当异常产生时，直接抛出异常，程序终止; fail-fast主要是体现在当我们在遍历集合元素的时候，经常会使用迭代器，但在迭代器遍历元素的过程中，如果集合的结构（modCount）被改变的话，就会抛出异常ConcurrentModificationException，防止继续遍历。这就是所谓的快速失败机制。 fail—safe：安全失败 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。由于在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发ConcurrentModificationException。 缺点：基于拷贝内容的优点是避免了ConcurrentModificationException，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。 场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。 3、详细介绍HashMap角度：数据结构+扩容情况+put查找的详细过程+哈希函数+容量为什么始终都是2^N，JDK1.7与1.8的区别。 参考：https://www.jianshu.com/p/9fe4cb316c05 数据结构： HashMap在底层数据结构上采用了数组＋链表＋红黑树，通过散列映射来存储键值对数据 扩容情况： 默认的负载因子是0.75，如果数组中已经存储的元素个数大于数组长度的75%，将会引发扩容操作。 【1】创建一个长度为原来数组长度两倍的新数组。 【2】1.7采用Entry的重新hash运算，1.8采用高于与运算。 put操作步骤： 1、判断数组是否为空，为空进行初始化; 2、不为空，则计算 key 的 hash 值，通过(n - 1) &amp; hash计算应当存放在数组中的下标 index; 3、查看 table[index] 是否存在数据，没有数据就构造一个Node节点存放在 table[index] 中； 4、存在数据，说明发生了hash冲突(存在二个节点key的hash值一样), 继续判断key是否相等，相等，用新的value替换原数据； 5、若不相等，判断当前节点类型是不是树型节点，如果是树型节点，创造树型节点插入红黑树中； 6、若不是红黑树，创建普通Node加入链表中；判断链表长度是否大于 8，大于则将链表转换为红黑树； 7、插入完成之后判断当前节点数是否大于阈值，若大于，则扩容为原数组的二倍 哈希函数： 通过hash函数（优质因子31循环累加）先拿到 key 的hashcode，是一个32位的值，然后让hashcode的高16位和低16位进行异或操作。该函数也称为扰动函数，做到尽可能降低hash碰撞，通过尾插法进行插入。 容量为什么始终都是2^N： 先做对数组的⻓度取模运算，得到的余数才能⽤来要存放的位置也就是对应的数组下标。这个数组下标的计算⽅法是“ (n - 1) &amp; hash ”。（n代表数组⻓度）。方便数组的扩容和增删改时的取模。 JDK1.7与1.8的区别： JDK1.7 HashMap： 底层是 数组和链表 结合在⼀起使⽤也就是链表散列。如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。扩容翻转时顺序不一致使用头插法会产生死循环，导致cpu100% JDK1.8 HashMap： 底层数据结构上采用了数组＋链表＋红黑树；当链表⻓度⼤于阈值（默认为 8-泊松分布），数组的⻓度大于 64时，链表将转化为红⿊树，以减少搜索时间。（解决了tomcat臭名昭著的url参数dos攻击问题） **4、ConcurrentHashMap ** 可以通过ConcurrentHashMap 和 Hashtable来实现线程安全；Hashtable 是原始API类，通过synchronize同步修饰，效率低下；ConcurrentHashMap 通过分段锁实现，效率较比Hashtable要好； ConcurrentHashMap的底层实现： JDK1.7的 ConcurrentHashMap 底层采⽤ 分段的数组+链表 实现；采用 分段锁（Sagment） 对整个桶数组进⾏了分割分段(Segment默认16个)，每⼀把锁只锁容器其中⼀部分数据，多线程访问容器⾥不同数据段的数据，就不会存在锁竞争，提⾼并发访问率。 JDK1.8的 ConcurrentHashMap 采⽤的数据结构跟HashMap1.8的结构⼀样，数组+链表/红⿊树；摒弃了Segment的概念，⽽是直接⽤ Node 数组+链表+红⿊树的数据结构来实现，通过并发控制 synchronized 和CAS来操作保证线程的安全。 5、序列化和反序列化 序列化的意思就是将对象的状态转化成字节流，以后可以通过这些值再生成相同状态的对象。对象序列化是对象持久化的一种实现方法，它是将对象的属性和方法转化为一种序列化的形式用于存储和传输。反序列化就是根据这些保存的信息重建对象的过程。 序列化：将java对象转化为字节序列的过程。 反序列化：将字节序列转化为java对象的过程。 优点： a、实现了数据的持久化，通过序列化可以把数据永久地保存到硬盘上（通常存放在文件里）Redis的RDB b、利用序列化实现远程通信，即在网络上传送对象的字节序列。 Google的protoBuf 反序列化失败的场景： 序列化ID：serialVersionUID不一致的时候，导致反序列化失败 6、StringString 使用数组存储内容，数组使用 final 修饰，因此 String 定义的字符串的值也是不可变的 StringBuffer 对方法加了同步锁，线程安全，效率略低于 StringBuilder 设计模式与原则1、单例模式 某个类只能生成一个实例，该实例全局访问，例如Spring容器里一级缓存里的单例池。 优点： 唯一访问：如生成唯一序列化的场景、或者spring默认的bean类型。 提高性能：频繁实例化创建销毁或者耗时耗资源的场景，如连接池、线程池。 缺点： 不适合有状态且需变更的 实现方式： 饿汉式：线程安全速度快 懒汉式：双重检测锁，第一次减少锁的开销、第二次防止重复、volatile防止重排序导致实例化未完成 静态内部类：线程安全利用率高 枚举：effictiveJAVA推荐，反射也无法破坏 2、工厂模式 定义一个用于创建产品的接口，由子类决定生产何种产品。 优点：解耦：提供参数即可获取产品，通过配置文件可以不修改代码增加具体产品。 缺点：每增加一个产品就得新增一个产品类 3、抽象工厂模式 提供一个接口，用于创建相关或者依赖对象的家族，并由此进行约束。 优点：可以在类的内部对产品族进行约束 缺点：假如产品族中需要增加一个新的产品，则几乎所有的工厂类都需要进行修改。 面试题构造方法构造方法可以被重载，只有当类中没有显性声明任何构造方法时，才会有默认构造方法。 构造方法没有返回值，构造方法的作用是创建新对象。 初始化块静态初始化块的优先级最高，会最先执行，在非静态初始化块之前执行。 静态初始化块会在类第一次被加载时最先执行，因此在 main 方法之前。 This关键字 this 代表当前对象的引用。当前对象指的是调用类中的属性或方法的对象 关键字 this 不可以在静态方法中使用。静态方法不依赖于类的具体对象的引用 重写Override和重载Overload的区别重载指在同一个类中定义多个方法，这些方法名称相同，签名不同。**(参数列表必须改，其他无要求)** 重写指在子类中的方法的名称和签名都和父类相同，使用override注解。**(参数和返回不能改，其他不能升级)** 区别点 重载方法 重写方法 参数列表 必须修改 一定不能修改 返回类型 可以修改 一定不能修改 异常 可以修改 可以减少或删除，一定不能抛出新的或者更广的异常 访问 可以修改 一定不能做更严格的限制（可以降低限制） Object类方法toString 默认是个指针，一般需要重写 equals 比较对象是否相同，默认和==功能一致 hashCode 散列码，equals则hashCode相同，所以重写equals必须重写hashCode **finalize ** 用于垃圾回收之前做的遗嘱，默认空，子类需重写 clone 深拷贝，类需实现cloneable的接口 getClass 反射获取对象元数据，包括类名、方法、 notify、wait 用于线程通知和唤醒 基本数据类型和包装类 类型 缓存范围 Byte,Short,Integer,Long [-128, 127] Character [0, 127] Boolean [false, true] JVM-DOC-DataType primitive values and reference values. 2.3. Primitive Types and ValuesThe primitive data types supported by the Java Virtual Machine are the numeric types, the boolean type (§2.3.4), and the returnAddress type (§2.3.3). The numeric types consist of the integral types (§2.3.1) and the floating-point types (§2.3.2). The integral types are: byte, whose values are 8-bit signed two’s-complement integers, and whose default value is zero short, whose values are 16-bit signed two’s-complement integers, and whose default value is zero int, whose values are 32-bit signed two’s-complement integers, and whose default value is zero long, whose values are 64-bit signed two’s-complement integers, and whose default value is zero char, whose values are 16-bit unsigned integers representing Unicode code points in the Basic Multilingual Plane, encoded with UTF-16, and whose default value is the null code point ('\\u0000') The floating-point types are: float, whose values are elements of the float value set or, where supported, the float-extended-exponent value set, and whose default value is positive zero double, whose values are elements of the double value set or, where supported, the double-extended-exponent value set, and whose default value is positive zero 2.4. Reference Types and ValuesThere are three kinds of reference types: class types, array types, and interface types. Their values are references to dynamically created class instances, arrays, or class instances or arrays that implement interfaces, respectively.","link":"/2022/01/10/Java/"},{"title":"Linux","text":"进程切换什么是 CPU 上下文CPU 寄存器和程序计数器就是 CPU 上下文，因为它们都是 CPU 在运行任何任务前，必须的依赖环境。 CPU 寄存器是 CPU 内置的容量小、但速度极快的内存。 程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。 什么是 CPU 上下文切换就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。 而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。 CPU 上下文切换的类型根据任务的不同，可以分为以下三种类型 - 进程上下文切换 - 线程上下文切换 - 中断上下文切换 进程上下文切换Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。 内核空间（Ring 0）具有最高权限，可以直接访问所有资源； 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。 进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。 系统调用从用户态到内核态的转变，需要通过系统调用来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成：首先调用 open() 打开文件，然后调用 read() 读取文件内容，并调用 write() 将内容写到标准输出，最后再调用 close() 关闭文件。 在这个过程中就发生了 CPU 上下文切换，整个过程是这样的：1、保存 CPU 寄存器里原来用户态的指令位2、为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。3、跳转到内核态运行内核任务。4、当系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。 所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。（用户态-内核态-用户态） 不过，需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的：进程上下文切换，是指从一个进程切换到另一个进程运行；而系统调用过程中一直是同一个进程在运行。 所以，系统调用过程通常称为特权模式切换，而不是上下文切换。系统调用属于同进程内的 CPU 上下文切换。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的。 进程上下文切换跟系统调用又有什么区别呢首先，进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。 因此，进程的上下文切换就比系统调用时多了一步：在保存内核态资源（当前进程的内核状态和 CPU 寄存器）之前，需要先把该进程的用户态资源（虚拟内存、栈等）保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。 如下图所示，保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。 进程上下文切换潜在的性能问题根据 Tsuna 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是导致平均负载升高的一个重要因素。 另外，我们知道， Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。 发生进程上下文切换的场景 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。 线程切换线程上下文切换线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。 所以，对于线程和进程，我们可以这么理解： - 当进程只有一个线程时，可以认为进程就等于线程。 - 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。 - 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 发生线程上下文切换的场景 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据 中断上下文切换为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。 对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。 另外，跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能。所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题。","link":"/2022/01/24/Linux/"},{"title":"MVXArchitecture","text":"MVC View：XML布局文件。 Model：实体模型（数据的获取、存储、数据状态变化）。 Controller：对应于Activity，处理数据、业务和UI。 从上面这个结构来看，Android本身的设计还是符合MVC架构的，但是Android中纯粹作为View的XML视图功能太弱，我们大量处理View的逻辑只能写在Activity中，这样Activity就充当了View和Controller两个角色，直接导致Activity中的代码大爆炸。相信大多数Android开发者都遇到过一个Acitivty数以千行的代码情况吧！所以，更贴切的说法是，这个MVC结构最终其实只是一个Model-View（Activity:View&amp;Controller）的结构。 MVP **View: **对应于Activity和XML，负责View的绘制以及与用户的交互。 **Model: **依然是实体模型。 **Presenter: **负责完成View与Model间的交互和业务逻辑。 前面我们说，Activity充当了View和Controller两个角色，MVP就能很好地解决这个问题，其核心理念是通过一个抽象的View接口（不是真正的View层）将Presenter与真正的View层进行解耦。Persenter持有该View接口，对该接口进行操作，而不是直接操作View层。这样就可以把视图操作和业务逻辑解耦，从而让Activity成为真正的View层。 但MVP也存在一些弊端： Presenter（以下简称P）层与View（以下简称V）层是通过接口进行交互的，接口粒度不好控制。粒度太小，就会存在大量接口的情况，使代码太过碎版化；粒度太大，解耦效果不好。同时对于UI的输入和数据的变化，需要手动调用V层或者P层相关的接口，相对来说缺乏自动性、监听性。如果数据的变化能自动响应到UI、UI的输入能自动更新到数据，那该多好！ MVP是以UI为驱动的模型，更新UI都需要保证能获取到控件的引用，同时更新UI的时候要考虑当前是否是UI线程，也要考虑Activity的生命周期（是否已经销毁等）。 MVP是以UI和事件为驱动的传统模型，数据都是被动地通过UI控件做展示，但是由于数据的时变性，我们更希望数据能转被动为主动，希望数据能更有活性，由数据来驱动UI。 V层与P层还是有一定的耦合度。一旦V层某个UI元素更改，那么对应的接口就必须得改，数据如何映射到UI上、事件监听接口这些都需要转变，牵一发而动全身。如果这一层也能解耦就更好了。 复杂的业务同时也可能会导致P层太大，代码臃肿的问题依然不能解决。 MVVM **View: **对应于Activity和XML，负责View的绘制以及与用户交互。 **Model: **实体模型。 **ViewModel: **负责完成View与Model间的交互，负责业务逻辑。 MVVM的目标和思想与MVP类似，利用数据绑定(Data Binding)、依赖属性(Dependency Property)、命令(Command)、路由事件(Routed Event)等新特性，打造了一个更加灵活高效的架构。 数据驱动在常规的开发模式中，数据变化需要更新UI的时候，需要先获取UI控件的引用，然后再更新UI。获取用户的输入和操作也需要通过UI控件的引用。在MVVM中，这些都是通过数据驱动来自动完成的，数据变化后会自动更新UI，UI的改变也能自动反馈到数据层，数据成为主导因素。这样MVVM层在业务逻辑处理中只要关心数据，不需要直接和UI打交道，在业务处理过程中简单方便很多。 低耦合度MVVM模式中，数据是独立于UI的。 数据和业务逻辑处于一个独立的ViewModel中，ViewModel只需要关注数据和业务逻辑，不需要和UI或者控件打交道。UI想怎么处理数据都由UI自己决定，ViewModel不涉及任何和UI相关的事，也不持有UI控件的引用。即便是控件改变了（比如：TextView换成EditText），ViewModel也几乎不需要更改任何代码。它非常完美的解耦了View层和ViewModel，解决了上面我们所说的MVP的痛点。 更新UI在MVVM中，数据发生变化后，我们在工作线程直接修改（在数据是线程安全的情况下）ViewModel的数据即可，不用再考虑要切到主线程更新UI了，这些事情相关框架都帮我们做了。 团队协作MVVM的分工是非常明显的，由于View和ViewModel之间是松散耦合的：一个是处理业务和数据、一个是专门的UI处理。所以，完全由两个人分工来做，一个做UI（XML和Activity）一个写ViewModel，效率更高。 可复用性一个ViewModel可以复用到多个View中。同样的一份数据，可以提供给不同的UI去做展示。对于版本迭代中频繁的UI改动，更新或新增一套View即可。如果想在UI上做A/B Testing，那MVVM是你不二选择。 MVVM： MVVM架构介绍MVVM 模式将 Presenter 改名为 ViewModel，基本上与 MVP 模式完全一致。唯一的区别是，它采用双向数据绑定（data-binding）：View的变动，自动反映在 ViewModel，反之亦然。 MVVM架构图如下所示： 可以看出MVVM与MVP的主要区别在于,你不用去主动去刷新UI了，只要Model数据变了，会自动反映到UI上。换句话说，MVVM更像是自动化的MVP。 MVVM的双向数据绑定主要通过DataBinding实现，不过相信有很多人跟我一样，是不喜欢用DataBinding的，这样架构就变成了下面这样。 View观察ViewModel的数据变化并自我更新，这其实是单一数据源而不是双向数据绑定，所以其实MVVM的这一大特性我其实并没有用到 View通过调用ViewModel提供的方法来与ViewModel交互 小结 MVC架构的主要问题在于Activity承担了View与Controller两层的职责，同时View层与Model层存在耦合 MVP引入Presenter层解决了MVC架构的两个问题，View只能与Presenter层交互，业务逻辑放在Presenter层 MVP的问题在于随着业务逻辑的增加，View的接口会很庞大，MVVM架构通过双向数据绑定可以解决这个问题 MVVM与MVP的主要区别在于，你不用去主动去刷新UI了，只要Model数据变了，会自动反映到UI上。换句话说，MVVM更像是自动化的MVP。 MVVM的双向数据绑定主要通过DataBinding实现，但有很多人(比如我)不喜欢用DataBinding，而是View通过LiveData等观察ViewModle的数据变化并自我更新,这其实是单一数据源而不是双向数据绑定 MVVM补充链接：https://juejin.cn/post/6844904176296673287 数据视图互绑 + 长生命周期数据即使将访问数据的细节剥离出Presenter，它依然不单纯。因为它持有 View 层接口，这就要求Presenter需了解 该把哪个数据传递给哪个接口方法，这就是 数据绑定，它在构建视图时就已经确定（无需等到数据返回），所以这个细节可以从业务层剥离，归并到视图层。 Presenter的实例被 Activity 持有，所以它的生命周期和 Activiy 同步，即业务数据和界面同生命周期。在某些场景下，这是一个缺点，比如横竖屏切换。此时，如果数据的生命周期不依赖界面，就可以免去重新获取数据的成本。这势必 需要一个生命周期更长的对象（ViewModel）持有数据。 生命周期更长的 ViewModel 最终的持有链如下：NonConfigurationInstances 持有 ViewModelStore 持有 ViewModel。 所以 ViewModel 生命周期比 Activity 更长。这样 ViewModel 中存放的业务数据就可以在 Activity 销毁重建时被复用。 上一节的例子中，构建 Presenter 是直接在 Activity 中 new，而构建ViewModel是通过ViewModelProvider.get(): 12345678910111213141516171819202122232425public class ViewModelProvider { // ViewModel 实例商店 private final ViewModelStore mViewModelStore; public &lt;T extends ViewModel&gt; T get(@NonNull String key, @NonNull Class&lt;T&gt; modelClass) { // 从商店获取 ViewModel实例 ViewModel viewModel = mViewModelStore.get(key); if (modelClass.isInstance(viewModel)) { return (T) viewModel; } else { ... } // 若商店无 ViewModel 实例 则通过 Factory 构建 if (mFactory instanceof KeyedFactory) { viewModel = ((KeyedFactory) (mFactory)).create(key, modelClass); } else { viewModel = (mFactory).create(modelClass); } // 将 ViewModel 实例存入商店 mViewModelStore.put(key, viewModel); return (T) viewModel; }} ViewModel实例通过ViewModelStore获取: 123456789101112131415161718192021// ViewModel 实例商店public class ViewModelStore { // 存储 ViewModel 实例的 Map private final HashMap&lt;String, ViewModel&gt; mMap = new HashMap&lt;&gt;(); // 存 final void put(String key, ViewModel viewModel) { ViewModel oldViewModel = mMap.put(key, viewModel); if (oldViewModel != null) { oldViewModel.onCleared(); } } // 取 final ViewModel get(String key) { return mMap.get(key); } ...} ViewModelStore将ViewModel实例存储在HashMap中。 而ViewModelStore通过ViewModelStoreOwner获取: 12345678910111213141516public class ViewModelProvider { // ViewModel 实例商店 private final ViewModelStore mViewModelStore; // 构造 ViewModelProvider 时需传入 ViewModelStoreOwner 实例 public ViewModelProvider(@NonNull ViewModelStoreOwner owner, @NonNull Factory factory) { // 通过 ViewModelStoreOwner 获取 ViewModelStore this(owner.getViewModelStore(), factory); } public ViewModelProvider(@NonNull ViewModelStore store, @NonNull Factory factory) { mFactory = factory; mViewModelStore = store; }} 那ViewModelStoreOwner实例又存储在哪？ 123456789101112131415161718192021222324252627282930313233// Activity 基类实现了 ViewModelStoreOwner 接口public class ComponentActivity extends androidx.core.app.ComponentActivity implements LifecycleOwner, ViewModelStoreOwner, SavedStateRegistryOwner, OnBackPressedDispatcherOwner { // Activity 持有 ViewModelStore 实例 private ViewModelStore mViewModelStore; public ViewModelStore getViewModelStore() { if (mViewModelStore == null) { // 获取配置无关实例 NonConfigurationInstances nc =(NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { // 从配置无关实例中恢复 ViewModel商店 mViewModelStore = nc.viewModelStore; } if (mViewModelStore == null) { mViewModelStore = new ViewModelStore(); } } return mViewModelStore; } // 静态的配置无关实例 static final class NonConfigurationInstances { // 持有 ViewModel商店实例 ViewModelStore viewModelStore; ... }} Activity 就是ViewModelStoreOwner实例，且持有ViewModelStore实例，该实例还会被保存在一个静态类中。 最终的持有链如下：NonConfigurationInstances 持有 ViewModelStore 持有 ViewModel。 所以 ViewModel 生命周期比 Activity 更长。这样 ViewModel 中存放的业务数据就可以在 Activity 销毁重建时被复用。 数据绑定 在 MVP 模式中，Presenter 持有 View 层接口并主动向界面推数据。 MVVM 模式中，ViewModel 不再持有 View 层接口，也不主动给界面推数据，而是界面被动地观察数据变化。 MVVM 这种更新界面的方式称为 “数据驱动”，即只需更新数据即可，因为界面会主动观察数据的变化并做出响应。 这使得 ViewModel 只需持有数据并根据业务逻辑更新之即可 MVVM中Activity 属于V层，布局构建以及数据绑定都在这层完成： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class MvvmActivity : AppCompatActivity() { private var rvNews: RecyclerView? = null private var newsAdapter = NewsAdapter() // 构建布局 private val rootView by lazy { ConstraintLayout { TextView { layout_id = &quot;tvTitle&quot; layout_width = wrap_content layout_height = wrap_content textSize = 25f padding_start = 20 padding_end = 20 center_horizontal = true text = &quot;News&quot; top_toTopOf = parent_id } rvNews = RecyclerView { layout_id = &quot;rvNews&quot; layout_width = match_parent layout_height = wrap_content top_toBottomOf = &quot;tvTitle&quot; margin_top = 10 center_horizontal = true } } } // 构建 ViewModel 实例 private val newsViewModel by lazy { // 构造 ViewModelProvider 实例, 通过其 get() 获得 ViewModel 实例 ViewModelProvider(this, NewsFactory(applicationContext)).get(NewsViewModel::class.java) } override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(rootView) initView() bindData() } // 将数据绑定到视图 private fun bindData() { newsViewModel.newsLiveData.observe(this, Observer { newsAdapter.news = it rvNews?.adapter = newsAdapter }) } private fun initView() { rvNews?.layoutManager = LinearLayoutManager(this) }} 其中构建布局 DSL 的详细介绍可以点击这里。它省去了原先V层( Activity + xml )中的 xml。 代码中的数据绑定是通过观察 ViewModel 中的 LiveData 实现的。这不是数据绑定的完全体，所以还需手动地观察 observe 数据变化（只有当引入data-binding包后，才能把视图和控件的绑定都静态化到 xml 中）。但至少它让 ViewModel 无需主动推数据了: 在 MVP 模式中，Presenter 持有 View 层接口并主动向界面推数据。 MVVM 模式中，ViewModel 不再持有 View 层接口，也不主动给界面推数据，而是界面被动地观察数据变化。 MVVM 这种更新界面的方式称为 “数据驱动”，即只需更新数据即可，因为界面会主动观察数据的变化并做出响应。 这使得 ViewModel 只需持有数据并根据业务逻辑更新之即可: 1234567891011121314151617181920212223// 数据访问接口在构造函数中注入class NewsViewModel(var newsRepository: NewsRepository) : ViewModel() { // 持有业务数据 val newsLiveData by lazy { newsRepository.fetchNewsLiveData() }}// 定义构造 ViewModel 方法class NewsFactory(context: Context) : ViewModelProvider.Factory { // 构造 数据访问接口实例 private val newsRepository = NewsRepositoryImpl(context) override fun &lt;T : ViewModel?&gt; create(modelClass: Class&lt;T&gt;): T { // 将数据接口访问实例注入 ViewModel return NewsViewModel(newsRepository) as T }}// 然后就可以在 Activity 中这样构造 ViewModel 了class MvvmActivity : AppCompatActivity() { // 构建 ViewModel 实例 private val newsViewModel by lazy { ViewModelProvider(this, NewsFactory(applicationContext)).get(NewsViewModel::class.java) }} ViewModel只关心业务逻辑和数据，不关心获取数据的细节，所以它们都被数据访问接口隐藏了。","link":"/2021/11/09/MVXArchitecture/"},{"title":"matrix","text":"Matrix Tencent一：TraceCanary插桩：通过插桩，在除了get/set、默认或匿名构造函数等简单函数外的所有方法，入口/出口插入MethodBeat.i()/MethodBeat.o()。 123456789101112131415//AppMethodBeat.javaprivate static void mergeData(int methodId, int index, boolean isIn) { if (methodId == AppMethodBeat.METHOD_ID_DISPATCH) { sCurrentDiffTime = SystemClock.uptimeMillis() - sDiffTime; } long trueId = 0L; if (isIn) { trueId |= 1L &lt;&lt; 63; } trueId |= (long) methodId &lt;&lt; 43; trueId |= sCurrentDiffTime &amp; 0x7FFFFFFFFFFL; sBuffer[index] = trueId; checkPileup(index); sLastIndex = index;} 用一个64位的long型来存储方法的：方法开始/方法结束(最高位63位)、方法id(递增，43到62位)、当前与MethodBeat模块初始化时差（0到42位） during计算：考虑到每个方法执行前后都获取系统时间（System.nanoTime）会对性能影响比较大，而实际上，单个函数执行耗时小于 5ms 的情况，对卡顿来说不是主要原因，可以忽略不计，如果是多次调用的情况，则在它的父级方法中可以反映出来，所以为了减少对性能的影响，通过另一条更新时间的线程每 5ms 去更新一个时间变量，而每个方法执行前后只读取该变量来减少性能损耗。（sTimerUpdateThread） example（初始化时差未体现）： 后面生成调用栈树 输出结果的可以参考（微信团队自研的APM利器，Matrix性能监控日志探索 (qq.com) 的6.2 生成调用栈树） 上述项作为基础 （函数耗时= 每个函数调用上报 + 每个函数统计耗时） EvilMethodTracer： 注册主线程handler 的Looper.looper，printer消息回调，在每一个dispatchBegin与dispatchEnd的差距超过700ms时触发上报 ANRTracer： 注册主线程handler 的Looper.looper，printer消息回调，在每一个dispatchBegin时postDelay一个5s后的ANR上报消息，并在dispatchEnd时候removeCallback这个消息。 如果消息五秒后还没有被移除掉，那就说明发生了ANR，会主动取出当前记录的 buffer 数据进行独立分析并产生上报。如果一切正常（该message5s内执行完成），那么自然会取消掉并继续用这种方式监听下一个消息。 FrameTracer： 向 Choreographer 注册监听，在每一帧 doframe 回调时判断距离上一帧的时间差是否超出阈值（卡顿），如果超出阈值，则获取数组 index 前的所有数据（即两帧之间的所有函数执行信息）进行分析上报。 二：APK Trackerapk体积检测三：Hook黑科技，hook 系统以达到32位设备中获得更大的虚拟内存四：IOCanary","link":"/2021/05/26/Matrix/"},{"title":"leakcanary","text":"线程栈中的局部变量表引用的所有变量，即运行线程中引用到的所有变量，包括线程中方法参数和局部变量 存活的线程对象 native 的 jni引用 class 对象 （classLoader 不会卸载class） 引用类型的静态变量 // 1跟2其实说的是一个东西 Reference queues, to which registered reference objects are appended by the garbage collector after the appropriate reachability changes are detected. 在检测到适当的可达性改变后，垃圾收集器将注册的引用对象（WeakReference）追加到引用队列（ReferenceQueue）。 ​ 核心思路是：​ leakCanary做法是ondestory后手动出发GC，GC过后对象WeakReference一直不被加入 ReferenceQueue，它可能存在内存泄漏。 ​ 利用 双参初始化的弱引用 WeakReference(T referent, ReferenceQueue&lt;? super T&gt; q) 在object对象变成弱可达的时候（可视为已被回收/(其他非强引用也一样)），会将该WeakReference对象入队q中 的特性（也就是queque中最后会存在已经被回收了的weakreference对象），通过在Activity和Fragment的onDestroy()中，将该Activity或Fragment实例的弱引用初始化（双参object,queue）后放入map中（key随机固定uuid），GC后 把map中的 queue包含的对象 移除，map中剩余的即为可能泄露的对象 KOOM由于leakCanary频繁的Gc时带来的STW（stop the world）会导致明显的卡顿，不适合作为线上监控机制 KOOM采用内存阈值监控来触发镜像采集，将对象是否泄漏的判断延迟到了解析时，阈值监控只要在常驻的子线程中每隔五秒获取关注的几个内存指标。达到阈值则直接suspendAndFork主进程，在新进程（由于fork自主进程，copy_on_write机制因此拥有主进程一样的进程信息）进行dump，之后resumeAndWait主进程。新进程会裁剪dump文件保存。 裁剪时KOOM会根据堆类型进行裁剪： 针对system space（Zygote Space、Image Space）：会裁剪PRIMITIVE_ARRAY_DUMP、HEAP_DUMP_INFO、INSTANCE_DUMP和OBJECT_ARRAY_DUMP这4个子TAG，（也就是只保留了CLASS DUMP）会删除这四个子TAG的全部内容（包函子TAG全都会删除）。 针对app space：会处理PRIMITIVE_ARRAY_DUMP这一块数据，但会保留metadata，方便回填。 用于监控应用的 Java 内存泄漏问题，它的核心原理 周期性查询Java堆内存、线程数、文件描述符数等资源占用情况，当连续多次超过设定阈值或突发性连续快速突破高阈值时，触发镜像采集 镜像采集采用虚拟机supend-&gt;fork虚拟机进程-&gt;虚拟机resume-&gt;dump内存镜像的策略，将传统Dump冻结进程20s的时间缩减至20ms以内 基于shark执行镜像解析，并针对shark做了一系列调整用于提升性能，在手机设备测即可执行离线内存泄露判定与引用链查找，生成分析报告 泄露是如何判定的？ 对于Activity和Fragment当对象已经销毁却仍有从GC Root到此对象的引用路径时，认为此对象已经泄露 Activity的销毁判定规则为，mFinished或mDestroyed值为true Fragment的销毁判定规则为，mFragmentManager为空且mCalled为true，mCalled为true表示此fragment已经经历了一些生命周期 //识别到监控的activity在gc后迟迟不加入ReferenceQueue，会触发dump hprof（Android 设备上，要 dump 当前内存快照，一般会调用 Debug.dumpHprofData() 方法） Hprof裁剪主要是用leakcanary的shark组件，LeakCanary 用 shark 组件来实现裁剪 hprof 文件功能，在 shark-cli 工具中，我们可以通过添加 strip-hprof 选项来裁剪 hprof 文件，它的实现思路是：通过将所有基本类型数组替换为空数组（大小不变）。 各家框架基本都会对这份hprof再进行裁剪： Matrix:Matrix 的裁剪思路主要是将除了部分字符串和 Bitmap 以外实例对象中的 buffer 数组。之所以保留 Bitmap 是因为 Matirx 有个检测重复 Bitmap 的功能，会对 Bitmap 的 buffer 数组做一次 MD5 操作来判断是否重复。 KOOM 通过 xhook 实现 PLT hook，通过 hook 两个虚拟机方法 open() 和 writ() 来实现裁剪 hprof KOOM 裁剪时会根据堆类型进行裁剪： 针对system space（Zygote Space、Image Space）：会裁剪PRIMITIVE_ARRAY_DUMP、HEAP_DUMP_INFO、INSTANCE_DUMP和OBJECT_ARRAY_DUMP这4个子TAG，（也就是只保留了CLASS DUMP）会删除这四个子TAG的全部内容（包函子TAG全都会删除）。 针对app space：会处理PRIMITIVE_ARRAY_DUMP这一块数据，但会保留metadata，方便回填。 //注：LeakCanary2 重写了一个解析 hprof 文件的库，叫做 shark，它是用来代替原来的 haha，根据官方的说法，相比于 haha，shark 内存减少了10倍，速度快了6倍。KOOM 除了使用 shark 来解析，还在这个的基础上做了一些优化，减少了内存的占用，具体可以看源码。 Hprof分析Matrix: Hprof文件中包含了Dump时刻内存中的所有对象的信息，包括类的描述，实例的数据和引用关系，线程的栈信息等。具体可参考这份文档中的Binary Dump Format一节。按照文档描述的格式将Hprof中的实例信息解析成描述引用关系的图结构后，套用经典的图搜索算法即可找到泄漏的Activity到GC Root的强引用链了。 大多数时候这样的强引用链不止一条，全部找出来会让一次分析操作的耗时大大增加，延长了整个测试流程的周期，而且对解决问题并没有更多帮助。实际上我们只需要找到最短的那条就可以了。如下图： 这种情况下只要切断蓝色箭头即可使泄漏的Activity与GC Root脱离联系。如果持有泄漏的Activity的GC Root不止一个，或者从GC Root出发的引用不止一条，在Matrix框架成为流程化工具的背景下我们可以通过多次检测来解决，这样至少保证了每次执行ResourceCanary模块的耗时稳定在一个可预计的范围内，不至于在极端情况下耽误其他流程。 本来我们打算自行实现这个算法，幸运的是在阅读LeakCanary的代码时我们发现了一个叫haha的库已经把Hprof文件按照文档描述的格式解析成了结构化的引用关系图，而且LeakCanary也按照与上面的描述类似的思路实现了引用链的提取逻辑，于是我们就不再重复造轮子，直接使用了LeakCanary的这部分代码了。 从Hprof文件中获取所有冗余的Bitmap对象 这个功能Android Monitor已经有完整实现了，原理简单粗暴——把所有未被回收的Bitmap的数据buffer取出来，然后先对比所有长度为1的buffer，找出相同的，记录所属的Bitmap对象；再对比所有长度为2的、长度为3的buffer……直到把所有buffer都比对完，这样就记录下了所有冗余的Bitmap对象了，接着再套用LeakCanary获取引用链的逻辑把这些Bitmap对象到GC Root的最短强引用链找出来即可。 美团Probe Probe 还优化分析泄露对象的链路，因为 Probe 相对于其他方案，理论上它是支持所有对象的内存泄露检测的（排除了原始类型等），而 LeakCanary 和 Matrix 只支持 Activity 和 Fragment 等对象，这个优化是基于 RetainSize 越大的对象对内存的影响也越大，是最有可能造成OOM的“元凶” 这一原则。 首先，在 dump 出所有对象后，创建一个 TOP N 的小根堆，根据 RetainSize 排序，初始 N 默认是 5，这里有个小细节，就是 Probe 会处理 ByteArray 类型的实例： 1234复制代码if (isByteArray(var6)) { var6.parent.addRetainedSize(var1.getHeapIndex(var4), var6.getTotalRetainedSize()); var15.add(var6.parent);} 将 ByteArray 的 RetainSize 加到它的父节点，同时将它的父节点加到堆中。 在初始化小根堆后，继续遍历做动态调整，将大于文件大小 5% 的对象直接加到堆中，同时增大 TOP N 的值，否则，跟堆顶元素做比较。在遍历对象的同时，如果是相同类的不同实例，则只会保存一份实例，同时将它们的 RetainSize 和 Num 计算进去： 12345复制代码if (var3.containsKey(var9)) { InstanceExtra var17 = (InstanceExtra)var3.get(var9); var17.retainSize += var6.getTotalRetainedSize(); ++var17.num;} 还会将在 计数压缩逻辑 中 RetainSize 补回来： 123456789复制代码if (var10 != null) { var16.retainSize += var10.getSize(); long var11 = var16.num; var16.num = (long)var10.getCount() + var11; ClassCountInfo var18 = (ClassCountInfo)AbandonedInstanceManager.getInstance().countMap.get(var9); if (var18 != null &amp;&amp; var18.classId &gt; 0L) { var16.id = var18.classId; } } 关于 OOMOut of memory (OOM) 当系统无法满足申请的内存大小时，就会抛出 OOM 错误。导致 OOM 的原因，除了我们上面说讲的内存泄露以外，可能还会是线程创建超过限制，可以通过 /proc/sys/kernel/threads-max 获取： 12cat /proc/sys/kernel/threads-max26418 还有一种可能是 FD（File descriptor）文件描述符超过限制，可以通过 /proc/pid/limits 获取，其中 Max open files 就是可创建的文件描述符数量： 12Limit Soft Limit Hard Limit UnitsMax open files 4096 4096 files LeakCanary 具体原理​ 具体流程如下： ​ Application中intall（新版本不用，是通过ContenProvider创建时拿到application对象后自动注册）。​​ 然后 通过application.registerActivityLifecycleCallbacks 对每个activity 注册生命周期 onDestroy()回调，​ 并进一步，根据不同的Android API，兼容地对 AndroidX，AndroidO，Support lib等调用 activity.fragmentManager/activity.supportFragmentManager方法，监听fragment的生命周期 的 onDestroyView() 和 onDestroy() ​ 在 activity/fragment 销毁的生命周期时，调用watch方法。执行removeWeaklyReachableObjects()//“移除watchedObjects中含有的queue元素含有的key 然后将该activity/fragment的弱引用对象KeyWeakReference添加入哈希表watchedObjects（RandomUUID 为key，queue 为弱引用的第二参数队列）。 之后在子线程中再来一次移除弱可达对象removeWeaklyReachableObjects，接下来调用gc（休眠100ms），最后留存下来的watchedObjects 即为大概率泄露的对象​ 如果 处于调试状态/已检测泄露对象超过5个/据上一次dump时间小于60s return​ dump时调用Debug.dumpHprofData()方法，获取堆信息存储到本地文件。然后在HeapAnalyzeService中进行分析（”shark库进行分析”） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 //进入destory流程的activity 或 fragment 的弱引用对象map private val watchedObjects = mutableMapOf&lt;String, KeyedWeakReference&gt;() //即将被顺利销毁的activity 或 fragment的弱引用对象队列 private val queue = ReferenceQueue&lt;Any&gt;() @Synchronized fun watch( watchedObject: Any, description: String ) { if (!isEnabled()) { return } removeWeaklyReachableObjects() val key = UUID.randomUUID() .toString() val watchUptimeMillis = clock.uptimeMillis() val reference = KeyedWeakReference(watchedObject, key, description, watchUptimeMillis, queue)//... watchedObjects[key] = reference checkRetainedExecutor.execute { moveToRetained(key) } } @Synchronized private fun moveToRetained(key: String) { removeWeaklyReachableObjects() val retainedRef = watchedObjects[key] if (retainedRef != null) { retainedRef.retainedUptimeMillis = clock.uptimeMillis() onObjectRetainedListeners.forEach { it.onObjectRetained() } } } private fun removeWeaklyReachableObjects() { // WeakReferences are enqueued as soon as the object to which they point to becomes weakly // reachable. This is before finalization or garbage collection has actually happened. var ref: KeyedWeakReference? //do while循环，整体就是将watchObjects Map中 含有的 queue成员key的 元素移除 //意在保留有可能泄露的对象 的 弱引用对象 do { ref = queue.poll() as KeyedWeakReference? if (ref != null) { //排除掉 queue中这些即将被回收的弱引用对象，就是有可能会泄露的弱引用对象 watchedObjects.remove(ref.key) } } while (ref != null) } APIhttps://square.github.io/leakcanary/recipes/#matching-known-library-leaks LeakCanary config val dumpHeap: Boolean = true, val dumpHeapWhenDebugging: Boolean = false, val retainedVisibleThreshold: Int = 5, val referenceMatchers: List = AndroidReferenceMatchers.appDefaults, val onHeapAnalyzedListener: OnHeapAnalyzedListener = DefaultOnHeapAnalyzedListener.create(), val metadataExtractor: MetadataExtractor = AndroidMetadataExtractor, val computeRetainedHeapSize: Boolean = true, val maxStoredHeapDumps: Int = 7, val requestWriteExternalStoragePermission: Boolean = false, val leakingObjectFinder: LeakingObjectFinder = KeyedWeakReferenceFinder, val useExperimentalLeakFinders: Boolean = false AppWatcher config val watchActivities: Boolean = true, val watchFragments: Boolean = true, val watchFragmentViews: Boolean = true, val watchViewModels: Boolean = true, val watchDurationMillis: Long = TimeUnit.SECONDS.toMillis(5), val enabled: Boolean = true 分离进程分析泄漏dependencies { // debugImplementation 'com.squareup.leakcanary:leakcanary-android:${version}' debugImplementation 'com.squareup.leakcanary:leakcanary-android-process:${version}' } 补充 ActivityDestroyWatcher初始化：application注册监听Activity生命周期，并在Activity destroy的时候调用objectWatcher.watch() FragmentDestroyWatcher初始化： 如果android 8.0以上，注册AndroidOFragmentDestroyWatcher监听fragment生命周期 注册AndroidSupportFragmentDestroyWatcher监听fragment生命周期 注册AndroidXFragmentDestroyWatcher监听fragment生命周期 以上三种本质上都是通过传入的Activity.fragmentManager.registerFragmentLifecycleCallbacks进行监听fragment生命周期回调 通过InternalLeakCanary类的invoke函数： 初始化一些检测内存泄露过程中需要的对象。 addOnObjectRetainedListener设置可能存在内存泄漏的回调。 通过AndroidHeapDumper进行内存泄漏之后进行 heap dump 任务。 通过GcTrigger 手动调用 GC 再次确认内存泄露。 启动内存泄漏检查的线程。 通过registerVisibilityListener监听应用程序的可见性。 实践基于LeakCanary2.5。 问题：ViewPager切换Fragment时，业务上会将所有展示过的Fragment都加入列表手动缓存，而ViewPager的默认缓存机制是不超过三个，超出的Fragment根据LRU调用其onDestroyView生命周期移除其中的所有View。但对于业务来说我们不希望用户切换回来之后由于ViewPager的缓存限制而重新等待view的创建加载，同时也不希望开发者针对这种情况调用ViewPager的setOffscreenPageLimit()的方式实现。 解决方案： 通过在初始化时通过配置AppWatcher.config关闭LeakCanary对Fragment的泄露监听，然后自己实现一套（CV原代码改动）关于Fragment的泄露监听。 1234567891011121314151617181920212223242526272829//先配置，将Fragment及FragmentView的泄露从LeakCanary转到以下自己实现逻辑AppWatcher.config = AppWatcher.config.copy(watchFragments = false, watchFragmentViews = false)val fragmentDestroyWatchers = mutableListOf&lt;(Activity) -&gt; Unit&gt;()//LeakCanary针对AndroidO、AndroidX、AndoridSurport分别处理，此处只以使用较多的AndroidX为例getWatcherIfAvailable( &quot;androidx.fragment.app.Fragment&quot;, &quot;com.youself.AndroidXFragmentDestroyWatcher&quot;, objectWatcher, { configProvider() })?.let { fragmentDestroyWatchers.add(it)}app.registerActivityLifecycleCallbacks(object : Application.ActivityLifecycleCallbacks by noOpDelegate() { override fun onActivityCreated( activity: Activity, savedInstanceState: Bundle? ) { for (watcher in fragmentDestroyWatchers) { if (!isIgnoreActivity(activity)) { watcher(activity) } } }}) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//#leakcanary.internal.AndroidXFragmentDestroyWatcher.classpackage leakcanary.internalinternal class AndroidXFragmentDestroyWatcher( private val reachabilityWatcher: ReachabilityWatcher) : (Activity) -&gt; Unit { private val fragmentLifecycleCallbacks = object : FragmentManager.FragmentLifecycleCallbacks() { override fun onFragmentCreated( fm: FragmentManager, fragment: Fragment, savedInstanceState: Bundle? ) { ViewModelClearedWatcher.install(fragment, reachabilityWatcher) } /*其实也没啥，就是注释掉这个方法就行了，其他版本兼容的Fragment监听类同样处理 override fun onFragmentViewDestroyed( fm: FragmentManager, fragment: Fragment ) { val view = fragment.view if (view != null) { reachabilityWatcher.expectWeaklyReachable( view, &quot;${fragment::class.java.name} received Fragment#onDestroyView() callback &quot; + &quot;(references to its views should be cleared to prevent leaks)&quot; ) } } */ override fun onFragmentDestroyed( fm: FragmentManager, fragment: Fragment ) { reachabilityWatcher.expectWeaklyReachable( fragment, &quot;${fragment::class.java.name} received Fragment#onDestroy() callback&quot; ) } } override fun invoke(activity: Activity) { if (activity is FragmentActivity) { val supportFragmentManager = activity.supportFragmentManager supportFragmentManager.registerFragmentLifecycleCallbacks(fragmentLifecycleCallbacks, true) ViewModelClearedWatcher.install(activity, reachabilityWatcher) } }}","link":"/2021/04/06/Leakcanary/"},{"title":"Full-QA","text":"一、基础篇网络基础TCP三次握手 三次握手过程： 客户端——发送带有SYN标志的数据包——服务端 一次握手 Client进入syn_sent状态 服务端——发送带有SYN/ACK标志的数据包——客户端 二次握手 服务端进入syn_rcvd 客户端——发送带有ACK标志的数据包——服务端 三次握手 连接就进入Established状态 为什么三次： 主要是为了建立可靠的通信信道，保证客户端与服务端同时具备发送、接收数据的能力 为什么两次不行？ 1、防止已失效的请求报文又传送到了服务端，建立了多余的链接，浪费资源 2、 两次握手只能保证单向连接是畅通的。（为了实现可靠数据传输， TCP 协议的通信双方， 都必须维 护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 三次握手的过程即是通信双方 相互告知序列号起始值， 并确认对方已经收到了序列号起始值的必经步骤；如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认） **TCP四次挥手过程 ** 四次挥手过程： 客户端——发送带有FIN标志的数据包——服务端，关闭与服务端的连接 ，客户端进入FIN-WAIT-1状态 服务端收到这个 FIN，它发回⼀ 个 ACK，确认序号为收到的序号加1，服务端就进入了CLOSE-WAIT状态 服务端——发送⼀个FIN数据包——客户端，关闭与客户端的连接，客户端就进入FIN-WAIT-2状态 客户端收到这个 FIN，发回 ACK 报⽂确认，并将确认序号设置为收到序号加1，TIME-WAIT状态 为什么四次： 因为需要确保客户端与服务端的数据能够完成传输。 CLOSE-WAIT： 这种状态的含义其实是表示在等待关闭 TIME-WAIT： 为了解决网络的丢包和网络不稳定所带来的其他问题，确保连接方能在时间范围内，关闭自己的连接 如何查看TIME-WAIT状态的链接数量？ netstat -an |grep TIME_WAIT|wc -l 查看连接数等待time_wait状态连接数 为什么会TIME-WAIT过多？解决方法是怎样的？ 可能原因： 高并发短连接的TCP服务器上，当服务器处理完请求后立刻按照主动正常关闭连接 解决：负载均衡服务器；Web服务器首先关闭来自负载均衡服务器的连接 1、OSI与TCP/IP 模型 OSI七层：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层 TCP/IP五层：物理层、数据链路层、网络层、传输层、应用层 2、常见网络服务分层 应用层：HTTP、SMTP、DNS、FTP 传输层：TCP 、UDP 网络层：ICMP 、IP、路由器、防火墙 数据链路层：网卡、网桥、交换机 物理层：中继器、集线器 3、TCP与UDP区别及场景 类型 特点 性能 应用过场景 首部字节 TCP 面向连接、可靠、字节流 传输效率慢、所需资源多 文件、邮件传输 20-60 UDP 无连接、不可靠、数据报文段 传输效率快、所需资源少 语音、视频、直播 8个字节 基于TCP的协议：HTTP、FTP、SMTP 基于UDP的协议：RIP、DNS、SNMP 4、TCP滑动窗口，拥塞控制 TCP通过：应用数据分割、对数据包进行编号、校验和、流量控制、拥塞控制、超时重传等措施保证数据的可靠传输； 拥塞控制目的：为了防止过多的数据注入到网络中，避免网络中的路由器、链路过载 拥塞控制过程：TCP维护一个拥塞窗口，该窗口随着网络拥塞程度动态变化，通过慢开始、拥塞避免等算法减少网络拥塞的发生。 5、TCP粘包原因和解决方法 TCP粘包是指：发送方发送的若干包数据到接收方接收时粘成一包 发送方原因： TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量）： 收集多个小分组，在一个确认到来时一起发送、导致发送方可能会出现粘包问题 接收方原因： TCP将接收到的数据包保存在接收缓存里，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。 解决粘包问题： 最本质原因在与接收对等方无法分辨消息与消息之间的边界在哪，通过使用某种方案给出边界，例如： 发送定长包。每个消息的大小都是一样的，接收方只要累计接收数据，直到数据等于一个定长的数值就将它作为一个消息。 包尾加上\\r\\n标记。FTP协议正是这么做的。但问题在于如果数据正文中也含有\\r\\n，则会误判为消息的边界。 包头加上包体长度。包头是定长的4个字节，说明了包体的长度。接收对等方先接收包体长度，依据包体长度来接收包体。 6、TCP、UDP报文格式 TCP报文格式： 源端口号和目的端口号： 用于寻找发端和收端应用进程。这两个值加上ip首部源端ip地址和目的端ip地址唯一确定一个tcp连接。 序号字段： 序号用来标识从T C P发端向T C P收端发送的数据字节流，它表示在这个报文段中的的第一个数据字节。如果将字节流看作在两个应用程序间的单向流动，则 T C P用序号对每个字节进行计数。序号是32 bit的无符号数，序号到达 2^32-1后又从0开始。 当建立一个新的连接时，SYN标志变1。序号字段包含由这个主机选择的该连接的初始序号ISN（Initial Sequence Number）。该主机要发送数据的第一个字节序号为这个ISN加1，因为SYN标志消耗了一个序号 确认序号： 既然每个传输的字节都被计数，确认序号包含发送确认的一端所期望收到的下一个序号。因此，确认序号应当是上次已成功收到数据字节序号加 1。只有ACK标志为 1时确认序号字段才有效。发送ACK无需任何代价，因为 32 bit的确认序号字段和A C K标志一样，总是T C P首部的一部分。因此，我们看到一旦一个连接建立起来，这个字段总是被设置， ACK标志也总是被设置为1。TCP为应用层提供全双工服务。这意味数据能在两个方向上独立地进行传输。因此，连接的每一端必须保持每个方向上的传输数据序号。 首都长度： 首部长度给出首部中 32 bit字的数目。需要这个值是因为任选字段的长度是可变的。这个字段占4 bit，因此T C P最多有6 0字节的首部。然而，没有任选字段，正常的长度是 2 0字节。 标志字段：在T C P首部中有 6个标志比特。它们中的多个可同时被设置为1. URG紧急指针（u rgent pointer）有效 ACK确认序号有效。 PSH接收方应该尽快将这个报文段交给应用层。 RST重建连接。 SYN同步序号用来发起一个连接。这个标志和下一个标志将在第 1 8章介绍。 FIN发端完成发送任务。 窗口大小： T C P的流量控制由连接的每一端通过声明的窗口大小来提供。窗口大小为字节数，起始于确认序号字段指明的值，这个值是接收端期望接收的字节。窗口大小是一个 16 bit字段，因而窗口大小最大为 65535字节。 检验和： 检验和覆盖了整个的 T C P报文段：T C P首部和T C P数据。这是一个强制性的字段，一定是由发端计算和存储，并由收端进行验证。 紧急指针： 只有当URG标志置1时紧急指针才有效。紧急指针是一个正的偏移量，和序号字段中的值相加表示紧急数据最后一个字节的序号。 T C P的紧急方式是发送端向另一端发送紧急数据的一种方式。 选项： 最常见的可选字段是最长报文大小，又称为 MSS (Maximum Segment Size)。每个连接方通常都在通信的第一个报文段（为建立连接而设置 S Y N标志的那个段）中指明这个选项。它指明本端所能接收的最大长度的报文段。 UDP报文格式： 端口号： 用来表示发送和接受进程。由于 I P层已经把I P数据报分配给T C P或U D P（根据I P首部中协议字段值），因此T C P端口号由T C P来查看，而 U D P端口号由UDP来查看。T C P端口号与UDP端口号是相互独立的。 长度： UDP长度字段指的是UDP首部和UDP数据的字节长度。该字段的最小值为 8字节（发送一份0字节的UDP数据报是 O K）。 检验和： UDP检验和是一个端到端的检验和。它由发送端计算，然后由接收端验证。其目的是为了发现UDP首部和数据在发送端到接收端之间发生的任何改动。 IP报文格式：普通的IP首部长为20个字节，除非含有可选项字段。 4位版本： 目前协议版本号是4，因此IP有时也称作IPV4. 4位首部长度： 首部长度指的是首部占32bit字的数目，包括任何选项。由于它是一个4比特字段，因此首部长度最长为60个字节。 服务类型（TOS）： 服务类型字段包括一个3bit的优先权字段（现在已经被忽略），4bit的TOS子字段和1bit未用位必须置0。4bit的TOS分别代表：最小时延，最大吞吐量，最高可靠性和最小费用。4bit中只能置其中1比特。如果所有4bit均为0，那么就意味着是一般服务。 总长度： 总长度字段是指整个IP数据报的长度，以字节为单位。利用首部长度和总长度字段，就可以知道IP数据报中数据内容的起始位置和长度。由于该字段长16bit，所以IP数据报最长可达65535字节。当数据报被分片时，该字段的值也随着变化。 标识字段： 标识字段唯一地标识主机发送的每一份数据报。通常每发送一份报文它的值就会加1。 生存时间： TTL（time-to-live）生存时间字段设置了数据报可以经过的最多路由器数。它指定了数据报的生存时间。TTL的初始值由源主机设置（通常为 3 2或6 4），一旦经过一个处理它的路由器，它的值就减去 1。当该字段的值为 0时，数据报就被丢弃，并发送 ICMP 报文通知源主机。 首部检验和： 首部检验和字段是根据 I P首部计算的检验和码。它不对首部后面的数据进行计算。 ICMP、IGMP、UDP和TCP在它们各自的首部中均含有同时覆盖首部和数据检验和码。 以太网报文格式： 目的地址和源地址： 是指网卡的硬件地址（也叫MAC 地址），长度是48 位，是在网卡出厂时固化的。 数据： 以太网帧中的数据长度规定最小46 字节，最大1500 字节，ARP 和RARP 数据包的长度不够46 字节，要在后面补填充位。最大值1500 称为以太网的最大传输单元（MTU），不同的网络类型有不同的MTU，如果一个数据包从以太网路由到拨号链路上，数据包度大于拨号链路的MTU了，则需要对数据包进行分片fragmentation）。ifconfig 命令的输出中也有“MTU:1500”。注意，MTU 个概念指数据帧中有效载荷的最大长度，不包括帧首部的长度。 HTTP协议1、HTTP协议1.0_1.1_2.0 HTTP1.0：服务器处理完成后立即断开TCP连接（无连接），服务器不跟踪每个客户端也不记录过去的请求（无状态） HTTP1.1：KeepAlived长连接避免了连接建立和释放的开销；通过Content-Length来判断当前请求数据是否已经全部接受（有状态） HTTP2.0：引入二进制数据帧和流的概念，其中帧对数据进行顺序标识；因为有了序列，服务器可以并行的传输数据。 http1.0和http1.1的主要区别如下：​ 1、缓存处理：1.1添加更多的缓存控制策略（如：Entity tag，If-Match）​ 2、网络连接的优化：1.1支持断点续传​ 3、错误状态码的增多：1.1新增了24个错误状态响应码，丰富的错误码更加明确各个状态​ 4、Host头处理：支持Host头域，不在以IP为请求方标志​ 5、长连接：减少了建立和关闭连接的消耗和延迟。 http1.1和http2.0的主要区别：​ 1、新的传输格式：2.0使用二进制格式，1.0依然使用基于文本格式​ 2、多路复用：连接共享，不同的request可以使用同一个连接传输（最后根据每个request上的id号组合成正常的请求）​ 3、header压缩：由于1.X中header带有大量的信息，并且得重复传输，2.0使用encoder来减少需要传输的hearder大小​ 4、服务端推送：同google的SPDUY（1.0的一种升级）一样 2、HTTP与HTTPS之间的区别 HTTP与HTTPS之间的区别： HTTP HTTPS 默认端口80 HTTPS默认使用端口443 明文传输、数据未加密、安全性差 传输过程ssl加密、安全性较好 响应速度快、消耗资源少 响应速度较慢、消耗资源多、需要用到CA证书 HTTPS链接建立的过程： 1.首先客户端先给服务器发送一个请求 2.服务器发送一个SSL证书给客户端，内容包括：证书的发布机构、有效期、所有者、签名以及公钥 3.客户端对发来的公钥进行真伪校验，校验为真则使用公钥对对称加密算法以及对称密钥进行加密 4.服务器端使用私钥进行解密并使用对称密钥加密确认信息发送给客户端 5.随后客户端和服务端就使用对称密钥进行信息传输 对称加密算法： 双方持有相同的密钥，且加密速度快，典型对称加密算法：DES、AES 非对称加密算法： 密钥成对出现（私钥、公钥），私钥只有自己知道，不在网络中传输；而公钥可以公开。相比对称加密速度较慢，典型的非对称加密算法有：RSA、DSA 3、Get和Post请求区别HTTP请求： 方法 描述 GET 向特定资源发送请求，查询数据，并返回实体 POST 向指定资源提交数据进行处理请求，可能会导致新的资源建立、已有资源修改 PUT 向服务器上传新的内容 HEAD 类似GET请求，返回的响应中没有具体的内容，用于获取报头 DELETE 请求服务器删除指定标识的资源 OPTIONS 可以用来向服务器发送请求来测试服务器的功能性 TRACE 回显服务器收到的请求，用于测试或诊断 CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器 get和Post区别： GET POST 可见性 数据在URL中对所有人可见 数据不会显示在URL中 安全性 与post相比，get的安全性较差，因为所 发送的数据是URL的一部分 安全，因为参数不会被保存在浏览器 历史或web服务器日志中 数据长度 受限制，最长2kb 无限制 编码类型 application/x-www-form-urlencoded multipart/form-data 缓存 能被缓存 不能被缓存 4、HTTP常见响应状态码 100：Continue — 继续。客户端应继续其请求。 200：OK — 请求成功。一般用于GET与POST请求。 301：Moved Permanently — 永久重定向。 302：Found — 暂时重定向。 400：Bad Request — 客户端请求的语法错误，服务器无法理解。 403：Forbideen — 服务器理解请求客户端的请求，但是拒绝执行此请求。 404：Not Found — 服务器无法根据客户端的请求找到资源（网页）。 500：Internal Server Error — 服务器内部错误，无法完成请求。 502：Bad Gateway — 作为网关或者代理服务器尝试执行请求时，从远程服务器接收到了无效的响应。 5、重定向和转发区别 重定向：redirect： 地址栏发生变化 重定向可以访问其他站点（服务器）的资源 重定向是两次请求。不能使用request对象来共享数据 转发：forward： 转发地址栏路径不变 转发只能访问当前服务器下的资源 转发是一次请求，可以使用request对象共享数据 6、Cookie和Session区别。 Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但两者有所区别： Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。 cookie不是很安全，别人可以分析存放在本地的COOKIE并进行欺骗,考虑到安全应当使用session。 Cookie ⼀般⽤来保存⽤户信息，Session 的主要作⽤就是通过服务端记录⽤户的状态 浏览器输入URL过程 过程：DNS解析、TCP连接、发送HTTP请求、服务器处理请求并返回HTTP报文、浏览器渲染、结束 过程 使用的协议 1、浏览器查找域名DNS的IP地址 DNS查找过程（浏览器缓存、路由器缓存、DNS缓存） DNS：获取域名对应的ip 2、根据ip建立TCP连接 TCP：与服务器建立连接 3、浏览器向服务器发送HTTP请求 HTTP：发送请求 4、服务器响应HTTP响应 HTTP 5、浏览器进行渲染 操作系统基础进程和线程的区别 进程：是资源分配的最小单位，一个进程可以有多个线程，多个线程共享进程的堆和方法区资源，不共享栈、程序计数器 线程：是任务调度和执行的最小单位，线程并行执行存在资源竞争和上下文切换的问题 协程：是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程。 1、进程间通信方式IPC管道pipe： 亲缘关系使用匿名管道，非亲缘关系使用命名管道，管道遵循FIFO，半双工，数据只能单向通信； 信号： 信号是一种比较复杂的通信方式，用户调用kill命令将信号发送给其他进程。 消息队列： 消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点。 共享内存(share memory)： 使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。 由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。 信号量(Semaphores) ： 信号量是⼀个计数器，⽤于多进程对共享数据的访问，这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件。 套接字(Sockets) : 简单的说就是通信的两⽅的⼀种约定，⽤套接字中的相关函数来完成通信过程。 2、用户态和核心态用户态：只能受限的访问内存，运行所有的应用程序 核心态：运行操作系统程序，cpu可以访问内存的所有数据，包括外围设备 为什么要有用户态和内核态： 由于需要限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络 用户态切换到内核态的3种方式： a. 系统调用 主动调用，系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。 b. 异常 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，比如缺页异常，这时会触发切换内核态处理异常。 c. 外围设备的中断 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会由用户态到内核态的切换。 3、操作系统的进程空间 栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。 堆区（heap）— 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。 静态区（static）—存放全局变量和静态变量的存储 代码区(text)—存放函数体的二进制代码。 线程共享堆区、静态区 操作系统内存管理存管理方式：页式管理、段式管理、段页式管理 分段管理： 将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片） 分页管理： 在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满） 段页式管理： 段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚，也就是说 段⻚式管理机制 中段与段之间以及段的内部的都是离散的 1、页面置换算法FIFO、LRU置换算法：先进先出FIFO、最近最久未使用LRU、最佳置换算法OPT 先进先出FIFO: 缺点：没有考虑到实际的页面使用频率，性能差、与通常页面使用的规则不符合，实际应用较少 最近最久未使用LRU: 原理：选择最近且最久未使用的页面进行淘汰 优点：考虑到了程序访问的时间局部性，有较好的性能，实际应用也比较多 缺点：没有合适的算法，只有适合的算法，lFU、random都可以 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * @program: Java * @description: LRU最近最久未使用置换算法，通过LinkedHashMap实现 * @author: Mr.Li * @create: 2020-07-17 10:29 **/public class LRUCache { private LinkedHashMap&lt;Integer,Integer&gt; cache; private int capacity; //容量大小 /** *初始化构造函数 * @param capacity */ public LRUCache(int capacity) { cache = new LinkedHashMap&lt;&gt;(capacity); this.capacity = capacity; } public int get(int key) { //缓存中不存在此key，直接返回 if(!cache.containsKey(key)) { return -1; } int res = cache.get(key); cache.remove(key); //先从链表中删除 cache.put(key,res); //再把该节点放到链表末尾处 return res; } public void put(int key,int value) { if(cache.containsKey(key)) { cache.remove(key); //已经存在，在当前链表移除 } if(capacity == cache.size()) { //cache已满，删除链表头位置 Set&lt;Integer&gt; keySet = cache.keySet(); Iterator&lt;Integer&gt; iterator = keySet.iterator(); cache.remove(iterator.next()); } cache.put(key,value); //插入到链表末尾 }}/** * @program: Java * @description: LRU最近最久未使用置换算法，通过LinkedHashMap内部removeEldestEntry方法实现 * @author: Mr.Li * @create: 2020-07-17 10:59 **/class LRUCache { private Map&lt;Integer, Integer&gt; map; private int capacity; /** *初始化构造函数 * @param capacity */ public LRUCache(int capacity) { this.capacity = capacity; map = new LinkedHashMap&lt;Integer, Integer&gt;(capacity, 0.75f, true) { @Override protected boolean removeEldestEntry(Map.Entry eldest) { return size() &gt; capacity; // 容量大于capacity 时就删除 } }; } public int get(int key) { //返回key对应的value值，若不存在，返回-1 return map.getOrDefault(key, -1); } public void put(int key, int value) { map.put(key, value); }} 最佳置换算法OPT: 原理：每次选择当前物理块中的页面在未来长时间不被访问的或未来不再使用的页面进行淘汰 优点：具有较好的性能，可以保证获得最低的缺页率 缺点：过于理想化，但是实际上无法实现（没办法预知未来的页面） 2、死锁条件、解决方式。 死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象； 死锁的条件： 互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待至占有该资源的进程释放该资源； 请求与保持条件：进程获得一定的资源后，又对其他资源发出请求，阻塞过程中不会释放自己已经占有的资源 非剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放 循环等待条件：系统中若干进程组成环路，环路中每个进程都在等待相邻进程占用的资源 解决方法：破坏死锁的任意一条件 乐观锁，破坏资源互斥条件，CAS 资源一次性分配，从而剥夺请求和保持条件、tryLock 可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件，数据库deadlock超时 资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，从而破坏环路等待的条件，转账场景 Java基础面向对象三大特性特性：封装、继承、多态 封装：对抽象的事物抽象化成一个对象，并对其对象的属性私有化，同时提供一些能被外界访问属性的方法； 继承：子类扩展新的数据域或功能，并复用父类的属性与功能，单继承，多实现； 多态：通过继承（多个⼦类对同⼀⽅法的重写）、也可以通过接⼝（实现接⼝并覆盖接⼝） 1、Java与C++区别 不同点：c++支持多继承，并且有指针的概念，由程序员自己管理内存；Java是单继承，可以用接口实现多继承，Java 不提供指针来直接访问内存，程序内存更加安全，并且Java有JVM⾃动内存管理机制，不需要程序员⼿动释放⽆⽤内存 2、多态实现原理多态的底层实现是动态绑定，即在运行时才把方法调用与方法实现关联起来。 静态绑定与动态绑定： 一种是在编译期确定，被称为静态分派，比如方法的重载； 一种是在运行时确定，被称为动态分派，比如方法的覆盖（重写）和接口的实现。 多态的实现 虚拟机栈中会存放当前方法调用的栈帧（局部变量表、操作栈、动态连接 、返回地址）。多态的实现过程，就是方法调用动态分派的过程，如果子类覆盖了父类的方法，则在多态调用中，动态绑定过程会首先确定实际类型是子类，从而先搜索到子类中的方法。这个过程便是方法覆盖的本质。 3、static和final关键字static：可以修饰属性、方法 static修饰属性： 类级别属性，所有对象共享一份，随着类的加载而加载（只加载一次），先于对象的创建；可以使用类名直接调用。 static修饰方法： 随着类的加载而加载；可以使用类名直接调用；静态方法中，只能调用静态的成员，不可用this； final：关键字主要⽤在三个地⽅：变量、⽅法、类。 final修饰变量： 如果是基本数据类型的变量，则其数值⼀旦在初始化之后便不能更改； 如果是引⽤类型的变量，则在对其初始化之后便不能再让其指向另⼀个对象。 final修饰方法： 把⽅法锁定，以防任何继承类修改它的含义（重写）；类中所有的 private ⽅法都隐式地指定为 final。 final修饰类： final 修饰类时，表明这个类不能被继承。final 类中的所有成员⽅法都会被隐式地指定为 final ⽅法。 一个类不能被继承，除了final关键字之外，还有可以私有化构造器。（内部类无效） 4、抽象类和接口抽象类：包含抽象方法的类，即使用abstract修饰的类；抽象类只能被继承，所以不能使用final修饰，抽象类不能被实例化， 接口：接口是一个抽象类型，是抽象方法的集合，接口支持多继承，接口中定义的方法，默认是public abstract修饰的抽象方法 相同点： ① 抽象类和接口都不能被实例化 ② 抽象类和接口都可以定义抽象方法，子类/实现类必须覆写这些抽象方法 不同点： ① 抽象类有构造方法，接口没有构造方法 ③抽象类可以包含普通方法，接口中只能是public abstract修饰抽象方法（Java8之后可以） ③ 抽象类只能单继承，接口可以多继承 ④ 抽象类可以定义各种类型的成员变量，接口中只能是public static final修饰的静态常量 抽象类的使用场景： 既想约束子类具有共同的行为（但不再乎其如何实现），又想拥有缺省的方法，又能拥有实例变量 接口的应用场景： 约束多个实现类具有统一的行为，但是不在乎每个实现类如何具体实现；实现类中各个功能之间可能没有任何联系 5、泛型以及泛型擦除参考：https://blog.csdn.net/baoyinwang/article/details/107341997 泛型： 泛型的本质是参数化类型。这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口和泛型方法。 泛型擦除： Java的泛型是伪泛型，使用泛型的时候加上类型参数，在编译器编译生成的字节码的时候会去掉，这个过程成为类型擦除。 如List等类型，在编译之后都会变成 List。JVM 看到的只是 List，而由泛型附加的类型信息对 JVM 来说是不可见的。 可以通过反射添加其它类型元素 6、反射原理以及使用场景Java反射： 是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且都能够调用它的任意一个方法； 反射原理： 反射首先是能够获取到Java中的反射类的字节码，然后将字节码中的方法，变量，构造函数等映射成 相应的 Method、Filed、Constructor 等类 如何得到Class的实例: 1231.类名.class(就是一份字节码)2.Class.forName(String className);根据一个类的全限定名来构建Class对象3.每一个对象多有getClass()方法:obj.getClass();返回对象的真实类型 使用场景： 开发通用框架 - 反射最重要的用途就是开发各种通用框架。很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 JavaBean、Filter 等），为了保证框架的通用性，需要根据配置文件运行时动态加载不同的对象或类，调用不同的方法。 动态代理 - 在切面编程（AOP）中，需要拦截特定的方法，通常，会选择动态代理方式。这时，就需要反射技术来实现了。 JDK：spring默认动态代理，需要实现接口 CGLIB：通过asm框架序列化字节流，可配置，性能差 自定义注解 - 注解本身仅仅是起到标记作用，它需要利用反射机制，根据注解标记去调用注解解释器，执行行为。 7、Java异常体系 Throwable 是 Java 语言中所有错误或异常的超类。下一层分为 Error 和 Exception Error ： 是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。 Exception 包含：RuntimeException 、CheckedException 编程错误可以分成三类：语法错误、逻辑错误和运行错误。 语法错误（也称编译错误）是在编译过程中出现的错误，由编译器检查发现语法错误 逻辑错误指程序的执行结果与预期不符，可以通过调试定位并发现错误的原因 运行错误是引起程序非正常终端的错误，需要通过异常处理的方式处理运行错误 RuntimeException： 运行时异常，程序应该从逻辑角度尽可能避免这类异常的发生。 如 NullPointerException 、 ClassCastException ； CheckedException：受检异常，程序使用trycatch进行捕捉处理 如IOException、SQLException、NotFoundException； 数据结构 1、ArrayList和LinkedListArrayList： 底层基于数组实现，支持对元素进行快速随机访问，适合随机查找和遍历，不适合插入和删除。（提一句实际上）​ 默认初始大小为10，当数组容量不够时，会触发扩容机制（扩大到当前的1.5倍），需要将原来数组的数据复制到新的数组中；当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。 LinkedList： 底层基于双向链表实现，适合数据的动态插入和删除；​ 内部提供了 List 接口中没有定义的方法，用于操作表头和表尾元素，可以当作堆栈、队列和双向队列使用。（比如jdk官方推荐使用基于linkedList的Deque进行堆栈操作） ArrayList与LinkedList区别： 都是线程不安全的，ArrayList 适用于查找的场景，LinkedList 适用于增加、删除多的场景 实现线程安全： 可以使用原生的Vector，或者是Collections.synchronizedList(List list)函数返回一个线程安全的ArrayList集合。​ 建议使用concurrent并发包下的CopyOnWriteArrayList的。 ①Vector: 底层通过synchronize修饰保证线程安全，效率较差 ②CopyOnWriteArrayList：写时加锁，使用了一种叫写时复制的方法；读操作是可以不用加锁的 2、List遍历快速和安全失败①普通for循环遍历List删除指定元素 1234for(int i=0; i &lt; list.size(); i++){ if(list.get(i) == 5) list.remove(i);} ② 迭代遍历,用list.remove(i)方法删除元素 1234567Iterator&lt;Integer&gt; it = list.iterator();while(it.hasNext()){ Integer value = it.next(); if(value == 5){ list.remove(value); }} ③foreach遍历List删除元素 123for(Integer i:list){ if(i==3) list.remove(i);} fail—fast：快速失败 当异常产生时，直接抛出异常，程序终止; fail-fast主要是体现在当我们在遍历集合元素的时候，经常会使用迭代器，但在迭代器遍历元素的过程中，如果集合的结构（modCount）被改变的话，就会抛出异常ConcurrentModificationException，防止继续遍历。这就是所谓的快速失败机制。 fail—safe：安全失败 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。由于在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发ConcurrentModificationException。 缺点：基于拷贝内容的优点是避免了ConcurrentModificationException，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。 场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。 3、详细介绍HashMap角度：数据结构+扩容情况+put查找的详细过程+哈希函数+容量为什么始终都是2^N，JDK1.7与1.8的区别。 参考：https://www.jianshu.com/p/9fe4cb316c05 数据结构： HashMap在底层数据结构上采用了数组＋链表＋红黑树，通过散列映射来存储键值对数据 扩容情况： 默认的负载因子是0.75，如果数组中已经存储的元素个数大于数组长度的75%，将会引发扩容操作。 【1】创建一个长度为原来数组长度两倍的新数组。 【2】1.7采用Entry的重新hash运算，1.8采用高于与运算。 put操作步骤： 1、判断数组是否为空，为空进行初始化; 2、不为空，则计算 key 的 hash 值，通过(n - 1) &amp; hash计算应当存放在数组中的下标 index; 3、查看 table[index] 是否存在数据，没有数据就构造一个Node节点存放在 table[index] 中； 4、存在数据，说明发生了hash冲突(存在二个节点key的hash值一样), 继续判断key是否相等，相等，用新的value替换原数据； 5、若不相等，判断当前节点类型是不是树型节点，如果是树型节点，创造树型节点插入红黑树中； 6、若不是红黑树，创建普通Node加入链表中；判断链表长度是否大于 8，大于则将链表转换为红黑树； 7、插入完成之后判断当前节点数是否大于阈值，若大于，则扩容为原数组的二倍 哈希函数： 通过hash函数（优质因子31循环累加）先拿到 key 的hashcode，是一个32位的值，然后让hashcode的高16位和低16位进行异或操作。该函数也称为扰动函数，做到尽可能降低hash碰撞，通过尾插法进行插入。 容量为什么始终都是2^N： 先做对数组的⻓度取模运算，得到的余数才能⽤来要存放的位置也就是对应的数组下标。这个数组下标的计算⽅法是“ (n - 1) &amp; hash ”。（n代表数组⻓度）。方便数组的扩容和增删改时的取模。 JDK1.7与1.8的区别： JDK1.7 HashMap： 底层是 数组和链表 结合在⼀起使⽤也就是链表散列。如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。扩容翻转时顺序不一致使用头插法会产生死循环，导致cpu100% JDK1.8 HashMap： 底层数据结构上采用了数组＋链表＋红黑树；当链表⻓度⼤于阈值（默认为 8-泊松分布），数组的⻓度大于 64时，链表将转化为红⿊树，以减少搜索时间。（解决了tomcat臭名昭著的url参数dos攻击问题） **4、ConcurrentHashMap ** 可以通过ConcurrentHashMap 和 Hashtable来实现线程安全；Hashtable 是原始API类，通过synchronize同步修饰，效率低下；ConcurrentHashMap 通过分段锁实现，效率较比Hashtable要好； ConcurrentHashMap的底层实现： JDK1.7的 ConcurrentHashMap 底层采⽤ 分段的数组+链表 实现；采用 分段锁（Sagment） 对整个桶数组进⾏了分割分段(Segment默认16个)，每⼀把锁只锁容器其中⼀部分数据，多线程访问容器⾥不同数据段的数据，就不会存在锁竞争，提⾼并发访问率。 JDK1.8的 ConcurrentHashMap 采⽤的数据结构跟HashMap1.8的结构⼀样，数组+链表/红⿊树；摒弃了Segment的概念，⽽是直接⽤ Node 数组+链表+红⿊树的数据结构来实现，通过并发控制 synchronized 和CAS来操作保证线程的安全。 5、序列化和反序列化 序列化的意思就是将对象的状态转化成字节流，以后可以通过这些值再生成相同状态的对象。对象序列化是对象持久化的一种实现方法，它是将对象的属性和方法转化为一种序列化的形式用于存储和传输。反序列化就是根据这些保存的信息重建对象的过程。 序列化：将java对象转化为字节序列的过程。 反序列化：将字节序列转化为java对象的过程。 优点： a、实现了数据的持久化，通过序列化可以把数据永久地保存到硬盘上（通常存放在文件里）Redis的RDB b、利用序列化实现远程通信，即在网络上传送对象的字节序列。 Google的protoBuf 反序列化失败的场景： 序列化ID：serialVersionUID不一致的时候，导致反序列化失败 6、StringString 使用数组存储内容，数组使用 final 修饰，因此 String 定义的字符串的值也是不可变的 StringBuffer 对方法加了同步锁，线程安全，效率略低于 StringBuilder 设计模式与原则1、单例模式 某个类只能生成一个实例，该实例全局访问，例如Spring容器里一级缓存里的单例池。 优点： 唯一访问：如生成唯一序列化的场景、或者spring默认的bean类型。 提高性能：频繁实例化创建销毁或者耗时耗资源的场景，如连接池、线程池。 缺点： 不适合有状态且需变更的 实现方式： 饿汉式：线程安全速度快 懒汉式：双重检测锁，第一次减少锁的开销、第二次防止重复、volatile防止重排序导致实例化未完成 静态内部类：线程安全利用率高 枚举：effictiveJAVA推荐，反射也无法破坏 2、工厂模式 定义一个用于创建产品的接口，由子类决定生产何种产品。 优点：解耦：提供参数即可获取产品，通过配置文件可以不修改代码增加具体产品。 缺点：每增加一个产品就得新增一个产品类 3、抽象工厂模式 提供一个接口，用于创建相关或者依赖对象的家族，并由此进行约束。 优点：可以在类的内部对产品族进行约束 缺点：假如产品族中需要增加一个新的产品，则几乎所有的工厂类都需要进行修改。 面试题构造方法构造方法可以被重载，只有当类中没有显性声明任何构造方法时，才会有默认构造方法。 构造方法没有返回值，构造方法的作用是创建新对象。 初始化块静态初始化块的优先级最高，会最先执行，在非静态初始化块之前执行。 静态初始化块会在类第一次被加载时最先执行，因此在 main 方法之前。 This关键字 this 代表当前对象的引用。当前对象指的是调用类中的属性或方法的对象 关键字 this 不可以在静态方法中使用。静态方法不依赖于类的具体对象的引用 重写和重载的区别重载指在同一个类中定义多个方法，这些方法名称相同，签名不同。 重写指在子类中的方法的名称和签名都和父类相同，使用override注解 Object类方法toString 默认是个指针，一般需要重写，未重写情况下，返回 1getClass().getName() + '@' + Integer.toHexString(hashCode()) equals 比较对象是否相同，默认和==功能一致 hashCode 散列码，equals则hashCode相同，所以重写equals必须重写hashCode **finalize ** 用于垃圾回收之前做的遗嘱，默认空，子类需重写 clone 深拷贝，类需实现cloneable的接口 getClass 反射获取对象元数据，包括类名、方法、 notify、wait 用于线程通知和唤醒 基本数据类型和包装类 类型 缓存范围 Byte,Short,Integer,Long [-128, 127] Character [0, 127] Boolean [false, true] 二、JVM篇JVM内存划分1、JVM运行时数据区域 堆、方法区（元空间）、虚拟机栈、本地方法栈、程序计数器 Heap(堆)： 对象的实例以及数组的内存都是要在堆上进行分配的，堆是线程共享的一块区域，用来存放对象实例，也是垃圾回收（GC）的主要区域；开启逃逸分析后，某些未逃逸的对象可以通过标量替换的方式在栈中分配 堆细分：新生代、老年代，对于新生代又分为：Eden区和Surviver1和Surviver2区； 方法区： 对于JVM的方法区也可以称之为永久区，它储存的是已经被java虚拟机加载的类信息、常量、静态变量；Jdk1.8以后取消了方法区这个概念，称之为元空间（MetaSpace）； 当应用中的 Java 类过多时，比如 Spring 等一些使用动态代理的框架生成了很多类，如果占用空间超出了我们的设定值，就会发生元空间溢出 虚拟机栈： 虚拟机栈是线程私有的，他的生命周期和线程的生命周期是一致的。里面装的是一个一个的栈帧，每一个方法在执行的时候都会创建一个栈帧，栈帧中用来存放（局部变量表、操作数栈 、动态链接 、返回地址）；在Java虚拟机规范中，对此区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将会抛出StackOverflowError异常；如果虚拟机栈动态扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。 局部变量表：局部变量表是一组变量值存储空间，用来存放方法参数、方法内部定义的局部变量。底层是变量槽（variable slot） 操作数栈：是用来记录一个方法在执行的过程中，字节码指令向操作数栈中进行入栈和出栈的过程。大小在编译的时候已经确定了，当一个方法刚开始执行的时候，操作数栈中是空发的，在方法执行的过程中会有各种字节码指令往操作数栈中入栈和出栈。 动态链接：因为字节码文件中有很多符号的引用，这些符号引用一部分会在类加载的解析阶段或第一次使用的时候转化成直接引用，这种称为静态解析；另一部分会在运行期间转化为直接引用，称为动态链接。 返回地址（returnAddress）：类型（指向了一条字节码指令的地址） JIT即时编译器（Just In Time Compiler），简称 JIT 编译器: 为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，比如锁粗化等 本地方法栈： 本地方法栈和虚拟机栈类似，不同的是虚拟机栈服务的是Java方法，而本地方法栈服务的是Native方法。在HotSpot虚拟机实现中是把本地方法栈和虚拟机栈合二为一的，同理它也会抛出StackOverflowError和OOM异常。 PC程序计数器： PC，指的是存放下一条指令的位置的一个指针。它是一块较小的内存空间，且是线程私有的。由于线程的切换，CPU在执行的过程中，需要记住原线程的下一条指令的位置，所以每一个线程都需要有自己的PC。 2、堆内存分配策略 对象优先分配在Eden区，如果Eden区没有足够的空间进行分配时，虚拟机执行一次MinorGC。而那些无需回收的存活对象，将会进到 Survivor 的 From 区（From 区内存不足时，直接进入 Old 区）。 大对象直接进入老年代（需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄（Age Count）计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，直到达到阀值（默认15次），对象进入老年区。 （动态对象年龄判定：程序从年龄最小的对象开始累加，如果累加的对象大小，大于幸存区的一半，则将当前的对象 age 作为新的阈值，年龄大于此阈值的对象则直接进入老年代） 每次进行Minor GC或者大对象直接进入老年区时，JVM会计算所需空间大小如小于老年区的剩余值大小，则进行一次Full GC。 3、创建一个对象的步骤步骤：类加载检查、分配内存、初始化零值、设置对象头、执行init方法 ①类加载检查： 虚拟机遇到 new 指令时，⾸先去检查是否能在常量池中定位到这个类的符号引⽤，并且检查这个符号引⽤代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执⾏相应的类加载过程。 ②分配内存： 在类加载检查通过后，接下来虚拟机将为新⽣对象分配内存，分配⽅式有 “指针碰撞” 和 “空闲列表” 两种，选择那种分配⽅式由 Java 堆是否规整决定，⽽Java堆是否规整⼜由所采⽤的垃圾收集器是否带有压缩整理功能决定。 ③初始化零值： 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值，这⼀步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使⽤，程序能访问到这些字段的数据类型所对应的零值。 ④设置对象头： 初始化零值完成之后，虚拟机要对对象进⾏必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希吗、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运⾏状态的不同，如是否启⽤偏向锁等，对象头会有不同的设置⽅式。 ⑤执⾏ init ⽅法： 从虚拟机的视⻆来看，⼀个新的对象已经产⽣了，但从Java 程序的视⻆来看， ⽅法还没有执⾏，所有的字段都还为零。所以⼀般来说（除循环依赖），执⾏ new 指令之后会接着执⾏ ⽅法，这样⼀个真正可⽤的对象才算产⽣出来。 4、对象引用普通的对象引用关系就是强引用。 软引用用于维护一些可有可无的对象。只有在内存不足时，系统则会回收软引用对象，如果回收了软引用对象之后仍然没有足够的内存，才会抛出内存溢出异常。 弱引用对象相比软引用来说，要更加无用一些，它拥有更短的生命周期，当 JVM 进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。 虚引用是一种形同虚设的引用，在现实场景中用的不是很多，它主要用来跟踪对象被垃圾回收的活动。 JVM类加载过程过程：加载、验证、准备、解析、初始化 加载阶段： 1.通过一个类的全限定名来获取定义此类的二进制字节流。 2.将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 3.在Java堆中生成一个代表这个类的java.lang.class对象，作为方法区这些数据的访问入口。 验证阶段： 1.文件格式验证（是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理） 2.元数据验证（对字节码描述的信息进行语意分析，以保证其描述的信息符合Java语言规范要求） 3.字节码验证（保证被校验类的方法在运行时不会做出危害虚拟机安全的行为） 4.符号引用验证（虚拟机将符号引用转化为直接引用时，解析阶段中发生） 准备阶段： 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段。将对象初始化为“零”值 解析阶段： 解析阶段时虚拟机将常量池内的符号引用替换为直接引用的过程。 字符串常量池：堆上，默认class文件的静态常量池 运行时常量池：在方法区，属于元空间 初始化阶段： 初始化阶段时加载过程的最后一步，而这一阶段也是真正意义上开始执行类中定义的Java程序代码。 1、双亲委派机制 每⼀个类都有⼀个对应它的类加载器。系统中的 ClassLoder 在协同⼯作的时候会默认使⽤ 双亲委派模型 。即在类加载的时候，系统会⾸先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，⾸先会把该请求委派该⽗类加载器的 loadClass() 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 BootstrapClassLoader 中。当⽗类加载器⽆法处理时，才由⾃⼰来处理。当⽗类加载器为null时，会使⽤启动类加载器 BootstrapClassLoader 作为⽗类加载器。 使用好处： 此机制保证JDK核心类的优先加载；使得Java程序的稳定运⾏，可以避免类的重复加载，也保证了 Java 的核⼼ API 不被篡改。如果不⽤没有使⽤双亲委派模型，⽽是每个类加载器加载⾃⼰的话就会出现⼀些问题，⽐如我们编写⼀个称为 java.lang.Object 类的话，那么程序运⾏的时候，系统就会出现多个不同的Object 类。 破坏双亲委派机制： 可以⾃⼰定义⼀个类加载器，重写loadClass方法； Tomcat 可以加载自己目录下的 class 文件，并不会传递给父类的加载器； Java 的 SPI，发起者 BootstrapClassLoader 已经是最上层了，它直接获取了 AppClassLoader 进行驱动加载，和双亲委派是相反的。 2、tomcat的类加载机制步骤： 先在本地cache查找该类是否已经加载过，看看 Tomcat 有没有加载过这个类。 如果Tomcat 没有加载过这个类，则从系统类加载器的cache中查找是否加载过。 如果没有加载过这个类，尝试用ExtClassLoader类加载器类加载，重点来了，这里并没有首先使用 AppClassLoader 来加载类。这个Tomcat 的 WebAPPClassLoader 违背了双亲委派机制，直接使用了 ExtClassLoader来加载类。这里注意 ExtClassLoader 双亲委派依然有效，ExtClassLoader 就会使用 Bootstrap ClassLoader 来对类进行加载，保证了 Jre 里面的核心类不会被重复加载。 比如在 Web 中加载一个 Object 类。WebAppClassLoader → ExtClassLoader → Bootstrap ClassLoader，这个加载链，就保证了 Object 不会被重复加载。 如果 BoostrapClassLoader，没有加载成功，就会调用自己的 findClass 方法由自己来对类进行加载，findClass 加载类的地址是自己本 web 应用下的 class。 加载依然失败，才使用 AppClassLoader 继续加载。 都没有加载成功的话，抛出异常。 总结一下以上步骤，WebAppClassLoader 加载类的时候，故意打破了JVM 双亲委派机制，绕开了 AppClassLoader，直接先使用 ExtClassLoader 来加载类。 JVM垃圾回收1、存活算法和两次标记过程引用计数法： 给对象添加一个引用计数器，每当由一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0的对象就是不可能再被使用的。 优点：实现简单，判定效率也很高 缺点：他很难解决对象之间相互循环引用的问题，基本上被抛弃 可达性分析法： 通过一系列的成为“GC Roots”(活动线程相关的各种引用，虚拟机栈帧引用，静态变量引用，JNI引用)的对象作为起始点，从这些节点ReferenceChains开始向下搜索，搜索所走过的路径成为引用链，当一个对象到GC ROOTS没有任何引用链相连时，则证明此对象时不可用的； 两次标记过程： 对象被回收之前，该对象的finalize()方法会被调用；两次标记，即第一次标记不在“关系网”中的对象。第二次的话就要先判断该对象有没有实现finalize()方法了，如果没有实现就直接判断该对象可回收；如果实现了就会先放在一个队列中，并由虚拟机建立的一个低优先级的线程去执行它，随后就会进行第二次的小规模标记，在这次被标记的对象就会真正的被回收了。 2、垃圾回收算法垃圾回收算法：复制算法、标记清除、标记整理、分代收集 复制算法：(young) 将内存分为⼤⼩相同的两块，每次使⽤其中的⼀块。当这⼀块的内存使⽤完后，就将还存活的对象复制到另⼀块去，然后再把使⽤的空间⼀次清理掉。这样就使每次的内存回收都是对内存区间的⼀半进⾏回收； 优点：实现简单，内存效率高，不易产生碎片 缺点：内存压缩了一半，倘若存活对象多，Copying 算法的效率会大大降低 标记清除：(cms) 标记出所有需要回收的对象，在标记完成后统⼀回收所有被标记的对象 缺点：效率低，标记清除后会产⽣⼤量不连续的碎⽚，需要预留空间给分配阶段的浮动垃圾 标记整理：(old) 标记过程仍然与“标记-清除”算法⼀样，再让所有存活的对象向⼀端移动，然后直接清理掉端边界以外的内存；解决了产生大量不连续碎片问题 分代收集： 根据各个年代的特点选择合适的垃圾收集算法。 新生代采用复制算法，新生代每次垃圾回收都要回收大部分对象，存活对象较少，即要复制的操作比较少，一般将新生代划分为一块较大的 Eden 空间和两个较小的 Survivor 空间(From Space, To Space)，每次使用Eden 空间和其中的一块 Survivor 空间，当进行回收时，将该两块空间中还存活的对象复制到另一块 Survivor 空间中。 老年代的对象存活⼏率是⽐较⾼的，⽽且没有额外的空间对它进⾏分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进⾏垃圾收集。 Safepoint 当发生 GC 时，用户线程必须全部停下来，才可以进行垃圾回收，这个状态我们可以认为 JVM 是安全的（safe），整个堆的状态是稳定的。如果在 GC 前，有线程迟迟进入不了 safepoint，那么整个 JVM 都在等待这个阻塞的线程，造成了整体 GC 的时间变长 MinorGC、MajorGC、FullGCMinorGC 在年轻代空间不足的时候发生， MajorGC 指的是老年代的 GC，出现 MajorGC 一般经常伴有 MinorGC。 FullGC 1、当老年代无法再分配内存的时候；2、元空间不足的时候；3、显示调用 System.gc 的时候。另外，像 CMS 一类的垃圾回收器，在 MinorGC 出现 promotion failure 的时候也会发生 FullGC。 对象优先在 Eden 区分配大多数情况下，对象在新生代 Eden 区分配，当 Eden 区空间不够时，发起 Minor GC。 大对象直接进入老年代大对象是指需要连续内存空间的对象，比如很长的字符串以及数组。老年代直接分配的目的是避免在 Eden 区和 Survivor 区之间出现大量内存复制。 长期存活的对象进入老年代虚拟机给每个对象定义了年龄计数器，对象在 Eden 区出生之后，如果经过一次 Minor GC 之后，将进入 Survivor 区，同时对象年龄变为 1，增加到一定阈值时则进入老年代（阈值默认为 15） 动态对象年龄判定为了能更好地适应不同程序的内存状况，虚拟机并不总是要求对象的年龄必须达到阈值才能进入老年代。如果在 Survivor 区中相同年龄的所有对象的空间总和大于 Survivor 区空间的一半，则年龄大于或等于该年龄的对象直接进入老年代。 空间分配担保在发生 Minor GC 之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象的空间总和，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立则进行 Full GC。 3、垃圾收集器 JDK3：Serial Parnew 关注效率 Serial： Serial 是一个单线程的收集器，它不但只会使用一个 CPU 或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。适合用于客户端垃圾收集器。 Parnew： ParNew 垃圾收集器其实是 Serial 收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和 Serial 收集器完全一样，ParNew 垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。 JDK5：parallel Scavenge+（Serial old/parallel old）关注吞吐量 parallel Scavenge：(关注吞吐量) Parallel Scavenge收集器关注点是吞吐量（⾼效率的利⽤CPU）。CMS等垃圾收集器的关注点更多的是⽤户线程的停顿时间（提⾼⽤户体验）；高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。 Serial old： Serial收集器的⽼年代版本，它同样是⼀个单线程收集器，使用标记-整理算法。主要有两个用途： 在 JDK1.5 之前版本中与新生代的 Parallel Scavenge 收集器搭配使用。 作为年老代中使用 CMS 收集器的后备垃圾收集方案。 parallel old： Parallel Scavenge收集器的⽼年代版本。使⽤多线程和“标记-整理”算法。 JDK8-CMS：（关注最短垃圾回收停顿时间） CMS收集器是一种年老代垃圾收集器，其最主要目标是获取最短垃圾回收停顿时间，和其他年老代使用标记-整理算法不同，它使用多线程的标记-清除算法。最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验。CMS 工作机制相比其他的垃圾收集器来说更复杂，整个过程分为以下 4 个阶段： 初始标记：只是标记一下 GC Roots 能直接关联的对象，速度很快，STW。 并发标记：进行 ReferenceChains跟踪的过程，和用户线程一起工作，不需要暂停工作线程。 重新标记：为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，STW。 并发清除：清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程。 由于耗时最长的并发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。 优点：并发收集、低停顿 缺点：对CPU资源敏感；⽆法处理浮动垃圾；使⽤“标记清除”算法，会导致⼤量空间碎⽚产⽣。 JDK9-G1：（精准控制停顿时间，避免垃圾碎片） 是⼀款⾯向服务器的垃圾收集器,主要针对配备多颗处理器及⼤容量内存的机器.以极⾼概率满⾜GC停顿时间要求的同时,还具备⾼吞吐量性能特征；相比与 CMS 收集器，G1 收集器两个最突出的改进是： 【1】基于标记-整理算法，不产生内存碎片。 【2】可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 G1 收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。区域划分和优先级区域回收机制，确保 G1 收集器可以在有限时间获得最高的垃圾收集效率。 初始标记：Stop The World，仅使用一条初始标记线程对GC Roots关联的对象进行标记 并发标记：使用一条标记线程与用户线程并发执行。此过程进行可达性分析，速度很慢 最终标记：Stop The World，使用多条标记线程并发执行 筛选回收：回收废弃对象，此时也要 Stop The World，并使用多条筛选回收线程并发执行 **JDK11-ZGC:**（在不关注容量的情况获取最小停顿时间5TB/10ms） 着色笔技术：加快标记过程 读屏障：解决GC和应用之间并发导致的STW问题 支持 TB 级堆内存（最大 4T， JDK13 最大16TB） 最大 GC 停顿 10ms 对吞吐量影响最大，不超过 15% 4、配置垃圾收集器 首先是内存大小问题，基本上每一个内存区域我都会设置一个上限，来避免溢出问题，比如元空间。 通常，堆空间我会设置成操作系统的 2/3，超过 8GB 的堆，优先选用 G1 然后我会对 JVM 进行初步优化，比如根据老年代的对象提升速度，来调整年轻代和老年代之间的比例 依据系统容量、访问延迟、吞吐量等进行专项优化，我们的服务是高并发的，对 STW 的时间敏感 我会通过记录详细的 GC 日志，来找到这个瓶颈点，借用 GCeasy 这样的日志分析工具，定位问题 4、JVM性能调优对应进程的JVM状态以定位问题和解决问题并作出相应的优化 常用命令：jps、jinfo、jstat、jstack、jmap jps：查看java进程及相关信息 123jps -l 输出jar包路径，类全名jps -m 输出main参数jps -v 输出JVM参数 jinfo：查看JVM参数 123jinfo 11666jinfo -flags 11666Xmx、Xms、Xmn、MetaspaceSize jstat：查看JVM运行时的状态信息，包括内存状态、垃圾回收 1jstat [option] LVMID [interval] [count]其中LVMID是进程id，interval是打印间隔时间（毫秒），count是打印次数（默认一直打印） option参数解释：-gc 垃圾回收堆的行为统计-gccapacity 各个垃圾回收代容量(young,old,perm)和他们相应的空间统计-gcutil 垃圾回收统计概述-gcnew 新生代行为统计-gcold 年老代和永生代行为统计 jstack：查看JVM线程快照，jstack命令可以定位线程出现长时间卡顿的原因，例如死锁，死循环 1jstack [-l] &lt;pid&gt; (连接运行中的进程) option参数解释：-F 当使用jstack &lt;pid&gt;无响应时，强制输出线程堆栈。-m 同时输出java和本地堆栈(混合模式)-l 额外显示锁信息 jmap：可以用来查看内存信息(配合jhat使用) 1jmap [option] &lt;pid&gt; (连接正在执行的进程)option参数解释：-heap 打印java heap摘要-dump:&lt;dump-options&gt; 生成java堆的dump文件 5、JDK新特性JDK8 支持 Lamda 表达式、集合的 stream 操作、提升HashMap性能 JDK9 1//Stream API中iterate方法的新重载方法，可以指定什么时候结束迭代IntStream.iterate(1, i -&gt; i &lt; 100, i -&gt; i + 1).forEach(System.out::println); 默认G1垃圾回收器 JDK10 其重点在于通过完全GC并行来改善G1最坏情况的等待时间。 JDK11 ZGC (并发回收的策略) 4TB 用于 Lambda 参数的局部变量语法 JDK12 Shenandoah GC (GC 算法)停顿时间和堆的大小没有任何关系，并行关注停顿响应时间。 JDK13 增加ZGC以将未使用的堆内存返回给操作系统，16TB JDK14 删除cms垃圾回收器、弃用ParallelScavenge+SerialOldGC垃圾回收算法组合 将ZGC垃圾回收器应用到macOS和windows平台 三、多线程篇线程调度1、线程状态 线程是cpu任务调度的最小执行单位，每个线程拥有自己独立的程序计数器、虚拟机栈、本地方法栈 线程状态：创建、就绪、运行、阻塞、死亡 2、线程状态切换 方法 作用 区别 start 启动线程，由虚拟机自动调度执行run()方法 线程处于就绪状态 run 线程逻辑代码块处理，JVM调度执行 线程处于运行状态 sleep 让当前正在执行的线程休眠（暂停执行） 不释放锁 wait 使得当前线程等待 释放同步锁 notify 唤醒在此对象监视器上等待的单个线程 唤醒单个线程 notifyAll 唤醒在此对象监视器上等待的所有线程 唤醒多个线程 yiled 停止当前线程，让同等优先权的线程运行 用Thread类调用 join 使当前线程停下来等待，直至另一个调用join方法的线程终止 用线程对象调用 3、阻塞唤醒过程阻塞： 这三个方法的调用都会使当前线程阻塞。该线程将会被放置到对该Object的请求等待队列中，然后让出当前对Object所拥有的所有的同步请求。线程会一直暂停所有线程调度，直到下面其中一种情况发生： ① 其他线程调用了该Object的notify方法，而该线程刚好是那个被唤醒的线程； ② 其他线程调用了该Object的notifyAll方法； 唤醒： 线程将会从等待队列中移除，重新成为可调度线程。它会与其他线程以常规的方式竞争对象同步请求。一旦它重新获得对象的同步请求，所有之前的请求状态都会恢复，也就是线程调用wait的地方的状态。线程将会在之前调用wait的地方继续运行下去。 为什么要出现在同步代码块中： 由于wait()属于Object方法，调用之后会强制释放当前对象锁，所以在wait() 调用时必须拿到当前对象的监视器monitor对象。因此，wait()方法在同步方法/代码块中调用。 4、wait和sleep区别 wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。 wait 方法会主动释放 monitor 锁，在同步代码中执行 sleep 方法时，并不会释放 monitor 锁。 wait 方法意味着永久等待，直到被中断或被唤醒才能恢复，不会主动恢复，sleep 方法中会定义一个时间，时间到期后会主动恢复。 wait/notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。 5、创建线程方式实现 Runnable 接口（优先使用） 1public class RunnableThread implements Runnable { @Override public void run() {System.out.println('用实现Runnable接口实现线程');}} 实现Callable接口（有返回值可抛出异常） 1class CallableTask implements Callable&lt;Integer&gt; { @Override public Integer call() throws Exception { return new Random().nextInt();}} 继承Thread类（java不支持多继承） 1public class ExtendsThread extends Thread { @Override public void run() {System.out.println('用Thread类实现线程');}} 使用线程池（底层都是实现run方法） 1static class DefaultThreadFactory implements ThreadFactory { DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = &quot;pool-&quot; + poolNumber.getAndIncrement() +&quot;-thread-&quot;; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r,namePrefix + threadNumber.getAndIncrement(),0); if (t.isDaemon()) t.setDaemon(false); //是否守护线程 if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); //线程优先级 return t; }} 线程池优点：通过复用已创建的线程，降低资源损耗、线程可以直接处理队列中的任务加快响应速度、同时便于统一监控和管理。 1、线程池构造函数1/*** 线程池构造函数7大参数*/public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime, TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory, RejectedExecutionHandler handler) {} 参数介绍： 参数 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过 corePoolSize 数目的空闲线程最大存活时间； TimeUnit keepAliveTime 时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 拒绝策略。当提交任务数超过 maxmumPoolSize+workQueue 之和时，任务会交给RejectedExecutionHandler 来处理 2、线程处理任务过程： 当线程池小于corePoolSize，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入 workQueue 中，等待线程池中任务调度执行。 当workQueue已满，且 maximumPoolSize 大于 corePoolSize 时，新提交任务会创建新线程执行任务。 当提交任务数超过 maximumPoolSize 时，新提交任务由 RejectedExecutionHandler 处理。 当线程池中超过corePoolSize 线程，空闲时间达到 keepAliveTime 时，关闭空闲线程 。 3、线程拒绝策略 线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。 JDK 内置的拒绝策略如下： AbortPolicy：直接抛出异常，阻止系统正常运行。可以根据业务逻辑选择重试或者放弃提交等策略。 CallerRunsPolicy ：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。 不会造成任务丢失，同时减缓提交任务的速度，给执行任务缓冲时间。 DiscardOldestPolicy ：丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。 DiscardPolicy ：该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。 4、Execuors类实现线程池 newSingleThreadExecutor()：只有一个线程的线程池，任务是顺序执行，适用于一个一个任务执行的场景 newCachedThreadPool()：线程池里有很多线程需要同时执行，60s内复用，适用执行很多短期异步的小程序或者负载较轻的服务 newFixedThreadPool()：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待，适用执行长期的任务。 newScheduledThreadPool()：用来调度即将执行的任务的线程池 **newWorkStealingPool()**：底层采用forkjoin的Deque，采用独立的任务队列可以减少竞争同时加快任务处理 因为以上方式都存在弊端： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列⻓度为 Integer.MAX_VALUE，会导致OOM。​ CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE，会导致OOM。 手动创建的线程池底层使用的是ArrayBlockingQueue可以防止OOM。 5、线程池大小设置 CPU 密集型（n+1） CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。 CPU 密集型任务尽可能的少的线程数量，一般为 CPU 核数 + 1 个线程的线程池。 IO 密集型（2*n） 由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 CPU * 2 也可以使用公式：CPU 核心数 *（1+平均等待时间/平均工作时间）。 线程安全1、乐观锁，CAS思想java乐观锁机制： 乐观锁体现的是悲观锁的反面。它是一种积极的思想，它总是认为数据是不会被修改的，所以是不会对数据上锁的。但是乐观锁在更新的时候会去判断数据是否被更新过。乐观锁的实现方案一般有两种（版本号机制和CAS）。乐观锁适用于读多写少的场景，这样可以提高系统的并发量。在Java中 java.util.concurrent.atomic下的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁，大多是基于数据版本 (Version)记录机制实现。即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来 实现。 读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提 交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据 版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。 CAS思想： CAS就是compare and swap（比较交换），是一种很出名的无锁的算法，就是可以不使用锁机制实现线程间的同步。使用CAS线程是不会被阻塞的，所以又称为非阻塞同步。CAS算法涉及到三个操作： 需要读写内存值V；进行比较的值A；准备写入的值B 当且仅当V的值等于A的值等于V的值的时候，才用B的值去更新V的值，否则不会执行任何操作（比较和替换是一个原子操作-A和V比较，V和B替换），一般情况下是一个自旋操作，即不断重试 缺点： ABA问题-知乎 高并发的情况下，很容易发生并发冲突，如果CAS一直失败，那么就会一直重试，浪费CPU资源 原子性： 功能限制CAS是能保证单个变量的操作是原子性的，在Java中要配合使用volatile关键字来保证线程的安全；当涉及到多个变量的时候CAS无能为力；除此之外CAS实现需要硬件层面的支持，在Java的普通用户中无法直接使用，只能借助atomic包下的原子类实现，灵活性受到了限制 2、synchronized底层实现使用方法：主要的三种使⽤⽅式 修饰实例⽅法: 作⽤于当前对象实例加锁，进⼊同步代码前要获得当前对象实例的锁 修饰静态⽅法: 也就是给当前类加锁，会作⽤于类的所有对象实例，因为静态成员不属于任何⼀个实例对象，是类成员。 修饰代码块: 指定加锁对象，对给定对象加锁，进⼊同步代码库前要获得给定对象的锁。 总结：synchronized锁住的资源只有两类：一个是对象，一个是类。 底层实现： 对象头是我们需要关注的重点，它是synchronized实现锁的基础，因为synchronized申请锁、上锁、释放锁都与对象头有关。对象头主要结构是由Mark Word 组成，其中Mark Word存储对象的hashCode、锁信息或分代年龄或GC标志等信息。 锁也分不同状态，JDK6之前只有两个状态：无锁、有锁（重量级锁），而在JDK6之后对synchronized进行了优化，新增了两种状态，总共就是四个状态：无锁状态、偏向锁、轻量级锁、重量级锁，其中无锁就是一种状态了。锁的类型和状态在对象头Mark Word中都有记录，在申请锁、锁升级等过程中JVM都需要读取对象的Mark Word数据。 同步代码块是利用 monitorenter 和 monitorexit 指令实现的，而同步方法则是利用 flags 实现的。 3、ReenTrantLock底层实现 由于ReentrantLock是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能 使用方法： 基于API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成 底层实现： ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。 和synchronized区别： 1、底层实现：synchronized 是JVM层面的锁，是Java关键字，通过monitor对象来完成（monitorenter与monitorexit），ReentrantLock 是从jdk1.5以来（java.util.concurrent.locks.Lock）提供的API层面的锁。 2、实现原理****：synchronized 的实现涉及到**锁的升级，具体为无锁、偏向锁、自旋锁、向OS申请重量级锁；ReentrantLock实现则是通过利用CAS（CompareAndSwap）自旋机制保证线程操作的原子性和volatile保证数据可见性以实现锁的功能。 3、是否可手动释放：synchronized 不需要用户去手动释放锁，synchronized 代码执行完后系统会自动让线程释放对锁的占用； ReentrantLock则需要用户去手动释放锁，如果没有手动释放锁，就可能导致死锁现象。 4、是否可中断synchronized是不可中断类型的锁，除非加锁的代码中出现异常或正常执行完成； ReentrantLock则可以中断，可通过trylock(long timeout,TimeUnit unit)设置超时方法或者将lockInterruptibly()放到代码块中，调用interrupt方法进行中断。 5、是否公平锁synchronized为非公平锁 ReentrantLock则即可以选公平锁也可以选非公平锁，通过构造方法new ReentrantLock时传入boolean值进行选择，为空默认false非公平锁，true为公平锁,公平锁性能非常低。 4、公平锁和非公平锁区别公平锁： 公平锁自然是遵循FIFO（先进先出）原则的，先到的线程会优先获取资源，后到的会进行排队等待 优点：所有的线程都能得到资源，不会饿死在队列中。适合大任务 缺点：吞吐量会下降，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销大 非公平锁： 多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。 优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。 缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁 公平锁效率低原因： 公平锁要维护一个队列，后来的线程要加锁，即使锁空闲，也要先检查有没有其他线程在 wait，如果有自己要挂起，加到队列后面，然后唤醒队列最前面线程。这种情况下相比较非公平锁多了一次挂起和唤醒。 线程切换的开销，其实就是非公平锁效率高于公平锁的原因，因为非公平锁减少了线程挂起的几率，后来的线程有一定几率逃离被挂起的开销。 5、使用层面锁优化 【1】减少锁的时间：​ 不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放； 【2】减少锁的粒度：​ 它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间；java中很多数据结构都是采用这种方法提高并发操作的效率，比如： ConcurrentHashMap： java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment 数组：Segment&lt; K,V &gt;[] segments Segment继承自ReenTrantLock，所以每个Segment是个可重入锁，每个Segment 有一个HashEntry&lt; K,V &gt;数组用来存放数据，put操作时，先确定往哪个Segment放数据，只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。 【3】锁粗化：​ 大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度; 假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的； 【4】使用读写锁： ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可并发读，写操作使用写锁，只能单线程写； 【5】使用CAS： 如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择； 6、系统层面锁优化自适应自旋锁： 自旋锁可以避免等待竞争锁进入阻塞挂起状态被唤醒造成的内核态和用户态之间的切换的损耗，它们只需要等一等（自旋），但是如果锁被其他线程长时间占用，一直不释放CPU，死等会带来更多的性能开销；自旋次数默认值是10 对上面自旋锁优化方式的进一步优化，它的自旋的次数不再固定，其自旋的次数由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定，这就解决了自旋锁带来的缺点 锁消除： 锁削除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行削除。Netty中无锁化设计pipeline中channelhandler会进行锁消除的优化。 锁升级： 偏向锁： 如果线程已经占有这个锁，当他在次试图去获取这个锁的时候，他会已最快的方式去拿到这个锁，而不需要在进行一些monitor操作，因为在大部分情况下是没有竞争的，所以使用偏向锁是可以提高性能的； 轻量级锁： 在竞争不激烈的情况下，通过CAS避免线程上下文切换，可以显著的提高性能。 重量级锁： 重量级锁的加锁、解锁过程造成的损耗是固定的，重量级锁适合于竞争激烈、高并发、同步块执行时间长的情况。 7、ThreadLocal原理ThreadLocal简介： 通常情况下，我们创建的变量是可以被任何⼀个线程访问并修改的。如果想实现每⼀个线程都有⾃⼰的专属本地变量该如何解决呢？ JDK中提供的 ThreadLocal 类正是为了解决这样的问题。类似操作系统中的TLAB 原理： 首先 ThreadLocal 是一个泛型类，保证可以接受任何类型的对象。因为一个线程内可以存在多个 ThreadLocal 对象，所以其实是 ThreadLocal 内部维护了一个 Map ，是 ThreadLocal 实现的一个叫做 ThreadLocalMap 的静态内部类。 最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。 我们使用的 get()、set() 方法其实都是调用了这个ThreadLocalMap类对应的 get()、set() 方法。例如下面的 如何使用： 1）存储用户Session 1private static final ThreadLocal threadSession = new ThreadLocal(); 2）解决线程安全的问题 1private static ThreadLocal&lt;SimpleDateFormat&gt; format1 = new ThreadLocal&lt;SimpleDateFormat&gt;() ThreadLocal内存泄漏的场景 实际上 ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，⽽ value 是强引⽤。弱引用的特点是，如果这个对象持有弱引用，那么在下一次垃圾回收的时候必然会被清理掉。 所以如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会被清理掉的，这样一来 ThreadLocalMap中使用这个 ThreadLocal 的 key 也会被清理掉。但是，value 是强引用，不会被清理，这样一来就会出现 key 为 null 的 value。 假如我们不做任何措施的话，value 永远⽆法被GC 回收，如果线程长时间不被销毁，可能会产⽣内存泄露。 ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。如果说会出现内存泄漏，那只有在出现了 key 为 null 的记录后，没有手动调用 remove() 方法，并且之后也不再调用 get()、set()、remove() 方法的情况下。因此使⽤完ThreadLocal ⽅法后，最好⼿动调⽤ remove() ⽅法。 8、HashMap线程安全 死循环造成 CPU 100% HashMap 有可能会发生死循环并且造成 CPU 100% ，这种情况发生最主要的原因就是在扩容的时候，也就是内部新建新的 HashMap 的时候，扩容的逻辑会反转散列桶中的节点顺序，当有多个线程同时进行扩容的时候，由于 HashMap 并非线程安全的，所以如果两个线程同时反转的话，便可能形成一个循环，并且这种循环是链表的循环，相当于 A 节点指向 B 节点，B 节点又指回到 A 节点，这样一来，在下一次想要获取该 key 所对应的 value 的时候，便会在遍历链表的时候发生永远无法遍历结束的情况，也就发生 CPU 100% 的情况。 所以综上所述，HashMap 是线程不安全的，在多线程使用场景中推荐使用线程安全同时性能比较好的 ConcurrentHashMap。 9、String不可变原因 可以使用字符串常量池，多次创建同样的字符串会指向同一个内存地址 可以很方便地用作 HashMap 的 key。通常建议把不可变对象作为 HashMap的 key hashCode生成后就不会改变，使用时无需重新计算 线程安全，因为具备不变性的对象一定是线程安全的 内存模型 Java 内存模型（Java Memory Model，JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了 Java 程序在各种平台下对内存的访问都能保证效果一致的机制及规范。 JMM 是一种规范，是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。 原子性： 在 Java 中，为了保证原子性，提供了两个高级的字节码指令 Monitorenter 和 Monitorexit。这两个字节码，在 Java 中对应的关键字就是 Synchronized。因此，在 Java 中可以使用 Synchronized 来保证方法和代码块内的操作是原子性的。 可见性： Java 中的 Volatile 关键字修饰的变量在被修改后可以立即同步到主内存。被其修饰的变量在每次使用之前都从主内存刷新。因此，可以使用 Volatile 来保证多线程操作时变量的可见性。除了 Volatile，Java 中的 Synchronized 和 Final 两个关键字也可以实现可见性。只不过实现方式不同 有序性 在 Java 中，可以使用 Synchronized 和 Volatile 来保证多线程之间操作的有序性。区别：Volatile 禁止指令重排。Synchronized 保证同一时刻只允许一条线程操作。 1、volatile底层实现作用： 保证数据的“可见性”：被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。 禁止指令重排：在多线程操作情况下，指令重排会导致计算结果不一致 底层实现： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面； 2）它会强制将对缓存的修改操作立即写入主存； 3）如果是写操作，它会导致其他CPU中对应的缓存行无效。 单例模式中volatile的作用： 防止代码读取到instance不为null时，instance引用的对象有可能还没有完成初始化。 1class Singleton{ private volatile static Singleton instance = null; //禁止指令重排 private Singleton() { } public static Singleton getInstance() { if(instance==null) { //减少加锁的损耗 synchronized (Singleton.class) { if(instance==null) //确认是否初始化完成 instance = new Singleton(); } } return instance; }} 2、AQS思想 AQS的全称为（AbstractQueuedSynchronizer）抽象的队列式的同步器，是⼀个⽤来构建锁和同步器的框架，使⽤AQS能简单且⾼效地构造出应⽤⼴泛的⼤量的同步器，如：基于AQS实现的lock, CountDownLatch、CyclicBarrier、Semaphore需解决的问题： 1状态的原子性管理线程的阻塞与解除阻塞队列的管理 AQS核⼼思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是⽤CLH（虚拟的双向队列）队列锁实现的，即将暂时获取不到锁的线程加⼊到队列中。 lock： 是一种可重入锁，除了能完成 synchronized 所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。默认为非公平锁，但可以初始化为公平锁； 通过方法 lock()与 unlock()来进行加锁与解锁操作； CountDownLatch： 通过计数法（倒计时器），让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒；该⼯具通常⽤来控制线程等待，它可以让某⼀个线程等待直到倒计时结束，再开始执⾏。具体可以使用countDownLatch.await()来等待结果。多用于多线程信息汇总。 CompletableFuture： 通过设置参数，可以完成CountDownLatch同样的多平台响应问题，但是可以针对其中部分返回结果做更加灵活的展示。 CyclicBarrier： 字面意思是可循环(Cyclic)使用的屏障（Barrier）。他要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CyclicBarrier的await()方法。可以用于批量发送消息队列信息、异步限流。 Semaphore： 信号量主要用于两个目的，一个是用于多个共享资源的互斥作用，另一个用于并发线程数的控制。SpringHystrix限流的思想 3、happens-before 用来描述和可见性相关问题：如果第一个操作 happens-before 第二个操作，那么我们就说第一个操作对于第二个操作是可见的 常见的happens-before：volatile 、锁、线程生命周期。","link":"/2022/07/05/Full-QA/"},{"title":"mmkv","text":"MMKV 是基于 mmap 内存映射的 key-value 组件，底层序列化/反序列化使用 protobuf 实现，性能高，稳定性强。多进程同步实现是依靠文件锁 Android 存储优化 —— MMKV 集成与原理 - 掘金 (juejin.cn) design · Tencent/MMKV Wiki (github.com) android_ipc · Tencent/MMKV Wiki (github.com) 一些对比： 虽然 MMKV 一些场景下比 SP 稍慢(如: 首次实例化会进行数据的复写剔除重复数据, 比 SP 稍慢, 查询数据时存在 ProtocolBuffer 解码, 比 SP 稍慢), 但其逆天的数据写入速度、mmap Linux 内核保证数据的同步, 以及 ProtocolBuffer 编码带来的更小的本地存储空间占用等都是非常棒的闪光点 mmap： 官方简述：MMKV 本质上是将文件 mmap 到内存块中，将新增的 key-value 统统 append 到内存中；到达边界后，进行重整回写以腾出空间，空间还是不够的话，就 double 内存空间；对于内存文件中可能存在的重复键值，MMKV 只选用最后写入的作为有效键值。 ProtocolBuffer: 多进程同步： MMKV 是采用 文件锁 的方式来进行进程间的同步操作 LOCK_SH(共享锁): 多个进程可以使用同一把锁, 常被用作读共享锁 LOCK_EX(排他锁): 同时只允许一个进程使用, 常被用作写锁 LOCK_UN: 释放锁","link":"/2021/10/28/Mmkv/"},{"title":"okhttp","text":"链接：https://juejin.cn/post/6887896333685161992 简述： 通过对外提供的OkHttpClient和Request的builder实现基础信息和必要信息的配置，直到封装构建成了RealCall对象（RealCall implement Call）并新建CallBack实例传入realCall.equeue(callback)，才真正完成了请求实体的实例化。 之后realCall.enqueue(call)方法的调用才是实际上开始进行请求：先判断是否call已经执行过了（executed = AtomicBoolean()），若未执行则继续 之后由Dispatcher调用enqueue进行判断当前正在执行的请求数及当前网络请求的主机数是否超过了最大值。要是超过了最大值，就将请求放到等待队列中，要是没超过，就放到正在执行的队列中，然后调用线程池（默认单例初始化了一个缓存线程池(即无核心线程、无限线程池数量、SynchronousQueue)）执行它调度，执行的过程也就是asyncCall的run()方法通过责任链五大拦截器进行层层处理的过程。 如 RetryAndFollowUpInterceptor是在一个死循环中进行最大次数为20(MAX_FOLLOW_UPS)的重试（超过抛ProtocolException(“Too many follow-up requests: $followUpCount”)）, 每次重试根据不同的responseCode进行补偿【比如30x（除304外，304为协商缓存）进行重定向，503】，对于不必要的情况也会直接终止(HTTP_CLIENT_TIMEOUT 408)。 CacheInterceptor是当请求发起时，先检查是否命中缓存（强制缓存或协商缓存），无命中缓存或缓存失效，则将请求向下传递给下一个拦截器。 获得了响应数据后，检查响应头的Cache-Control，Expires，no-store不存储，immutable等判断是否写入缓存 用了 责任链设计模式 ,它将请求一层一层向下传，直到有一层能够得到Resposne就停止向下传递，并 Response 向上面的拦截器传递，然后各个拦截器会对 respone 进行一些处理，最后会传到 RealCall 类中通过 execute 来得到 Response 。 3.1.1 通过 OkHttpClient 实例化 初始化我们需要初始化的 http连接协议 代理地址 缓存控制 Cookie 证书连接 代理选择器等 3.1.2 通过 Request Builder模式 拿到我们传入的 url method Headers RequestBody 以及 tags 在 OkHttpClient 我们用RealCall接口回调执行Dispacher的 回调实现,入: equeqe(同步) ennque(异步请求) 其中 Dispacher 的同步请求 是 将我们的请求塞到同步队列里面,这个有可能会导致线程阻塞 ennque(异步请求) 是 生产者消费者模型 会将满足 小于并发64 同host请求小于4 的请求塞到我们的 运行队列里面 执行,不满足该条件放到 等待队列里面 然后交给线程池 去执行具体请求事宜 ,拿到响应后 3.1.3 我们 会将 响应 通过 getResourceChainPain 通过拦截器网下透传到 重定向拦截器, 桥拦截器 ,缓存拦截器 ,连接池拦截器,网络拦截器,请求拦截器 如果中间有被拦截,就进行一系列的拦截处理,追钟会返回我们客户端,我们客户端再通过 Response 去解析 code message Header ReponseBody 这些参数信息 代码解析：一：构建realCall1、2、3步其实都是基础信息和必要信息的配置，基本用构建者模式来完成，直到最后构建成了realCall，才真正完成了请求实体，之后realCall.enqueue方法的调用才是实际上开始为请求调度线程，开始通过责任链一节节的处理请求发起。 二：封装CallBack成AsyncCall，通过dispatcher.equeue调度在call.enqueue(new Callback(){ … }) 执行之后，首先做的是 1. 调用RealCall.enqueue()方法，判断当前call是否已经被执行过了，被执行过了，就抛出异常，如果没有执行过，就先将callback封装成AsyncCall，然后调用dispatcher.enqueue()方法（dispatcher调度器，在okHttpClient里面创建的） 2. 在dispatcher.enqueue()方法中，判断当前正在执行的请求数及当前网络请求的主机数是否超过了最大值。要是超过了最大值，就将请求放到等待队列中，要是没超过，就放到正在执行的队列中，然后调用线程池执行它。 三 .realcall的异步请求的执行通过getResponseWithInterceptorChain()责任链处理并最终发起请求接收处理回调 1 executorService.execute吃过了午饭，继续分析源码，承接上文，我们分析到了，如果符合条件，就用线程池去执行它，也就是这句 1executorService().execute(call); 看一下我们的线程池 12345678910111213141516public synchronized ExecutorService executorService() { if (executorService == null) { 1.executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), Util.threadFactory(&quot;OkHttp Dispatcher&quot;, false)); } return executorService;}//实际上就是一个缓存线程池，但是由于dispatcher的enqueue中已经对请求数做了限定，故不会由太大的性能负担。//无核心线程、MAX_VALUE个最大线程、闲置60秒回收。//Excutors.classpublic static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } 无核心线程、MAX_VALUE个最大线程、非核心线程闲置60秒回收。于dispatcher的enqueue中已经对请求数做了限定，故不会由太大的性能负担。 好，继续再看下线程池executorService.execute(call)方法 它会执行里面call方法的run()方法，也就是AsyncCall的run方法，实际上是调用了execute()，该方法由子类实现，也就是调用了AsyncCall.execute() 简单来说，就是executorService.execute(call) -&gt; AsyncCall.run() -&gt; AsyncCall.execute() 看到这个写法，内心中就想吐槽一句话，真鸡儿秀！ 来继续看下，AsyncCall.execute() 2 AsyncCall.execute()看源码 文件位置：realcall.java 1234567891011121314151617181920212223@Overrideprotected void execute() { boolean signalledCallback = false; try { 1.Response response = getResponseWithInterceptorChain(); 2.if (retryAndFollowUpInterceptor.isCanceled()) { signalledCallback = true; responseCallback.onFailure(RealCall.this, new IOException(&quot;Canceled&quot;)); } else { signalledCallback = true; 3.responseCallback.onResponse(RealCall.this, response); } } catch (IOException e) { if (signalledCallback) { // Do not signal the callback twice! Platform.get().log(INFO, &quot;Callback failure for &quot; + toLoggableString(), e); } else { responseCallback.onFailure(RealCall.this, e); } } finally { 4.client.dispatcher().finished(this); } } 执行拦截器链，返回Response 判断拦截器链中的重定向拦截器是否已经取消了，如果取消了，就执行responseCallback.onFailure() ，这个也就是我们在外边在第3步，传过来的回调方法Callback()中的onFailure()方法。 如果没取消，则走onResponse也就是Callback()中的onResponse()方法。返回结果。当然这里都是在子线程里面的。 这句其实就是调用了，dispatcher方法中的finished方法。下面我们看下 3 dispatcher.finished()123456789101112131415161718void finished(RealCall call) { finished(runningSyncCalls, call, false);}private &lt;T&gt; void finished(Deque&lt;T&gt; calls, T call, boolean promoteCalls) { int runningCallsCount; Runnable idleCallback; synchronized (this) { 1.if (!calls.remove(call)) throw new AssertionError(&quot;Call wasn't in-flight!&quot;); 2.if (promoteCalls) promoteCalls(); 3.runningCallsCount = runningCallsCount(); idleCallback = this.idleCallback; } if (runningCallsCount == 0 &amp;&amp; idleCallback != null) { idleCallback.run(); }} 将该请求从正在执行的任务队列里面删除 调用promoteCalls() 调整请求队列 重新计算请求数量 4 dispatcher.promoteCalls()12345678910111213141516private void promoteCalls() { if (runningAsyncCalls.size() &gt;= maxRequests) return; // Already running max capacity. if (readyAsyncCalls.isEmpty()) return; // No ready calls to promote. for (Iterator&lt;AsyncCall&gt; i = readyAsyncCalls.iterator(); i.hasNext(); ) { AsyncCall call = i.next(); if (runningCallsForHost(call) &lt; maxRequestsPerHost) { i.remove(); runningAsyncCalls.add(call); executorService().execute(call); } if (runningAsyncCalls.size() &gt;= maxRequests) return; // Reached max capacity. } } 很简单，这里无非就是遍历等待队列中的请求，然后加入到执行请求队列中，直到并发数和当前网络请求的主机数达到上限。 至此，okhttp的异步已经分析完毕了 面试题 1.什么是dispatcher? dispatcher作用是为维护请求的状态，并维护一个线程池。用于执行请求。 小伙子，是不是很简单呀？是不是已经完了？你想多了，来分析最核心的一部分 细说 getResponseWithInterceptorChain()123456789101112131415161718192021222324252627282930313233343536Response getResponseWithInterceptorChain() throws IOException { // 添加拦截器，责任链模式 List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); // 在配置okhttpClient 时设置的intercept 由用户自己设置 interceptors.addAll(client.interceptors()); // 负责处理失败后的重试与重定向 interceptors.add(retryAndFollowUpInterceptor); /** 负责把用户构造的请求转换为发送到服务器的请求 、把服务器返回的响应转换为用户友好的响应 处理 配置请求头等信息. 从应用程序代码到网络代码的桥梁。首先，它根据用户请求构建网络请求。然后它继续呼叫网络。最后，它根据网络响应构建用户响应。 */ interceptors.add(new BridgeInterceptor(client.cookieJar())); // 处理 缓存配置 根据条件(存在响应缓存并被设置为不变的或者响应在有效期内)返回缓存响应 // 设置请求头(If-None-Match、If-Modified-Since等) 服务器可能返回304(未修改) // 可配置用户自己设置的缓存拦截器 interceptors.add(new CacheInterceptor(client.internalCache())); // 连接服务器 负责和服务器建立连接 这里才是真正的请求网络 interceptors.add(new ConnectInterceptor(client)); if (!forWebSocket) { interceptors.addAll(client.networkInterceptors()); } // 执行流操作(写出请求体、获得响应数据) 负责向服务器发送请求数据、从服务器读取响应数据 // 进行http请求报文的封装与请求报文的解析 interceptors.add(new CallServerInterceptor(forWebSocket)); // 责任链，将上述的拦截器添加到责任链里面 Interceptor.Chain chain = new RealInterceptorChain(interceptors, null, null, null, 0, originalRequest); return chain.proceed(originalRequest); } 拦截器 作用 Interceptor应用拦截器 拿到的是原始请求，可以添加一些自定义header、通用参数、参数加密、网关接入等等。 RetryAndFollowUpInterceptor 处理错误重试和重定向 BridgeInterceptor 应用层和网络层的桥接拦截器，主要工作是为请求添加cookie、添加固定的header，比如Host、Content-Length、Content-Type、User-Agent等等，然后保存响应结果的cookie，如果响应使用gzip压缩过，则还需要进行解压。 CacheInterceptor 缓存拦截器，如果命中缓存则不会发起网络请求。 ConnectInterceptor 连接拦截器，内部会维护一个连接池，负责连接复用、创建连接（三次握手等等）、释放连接以及创建连接上的socket流。 networkInterceptors（网络拦截器） 用户自定义拦截器，通常用于监控网络层的数据传输。 CallServerInterceptor 请求拦截器，在前置准备工作完成后，真正发起了网络请求。 OtheraddInterceptor与addNetworkInterceptor的区别二者通常的叫法为应用拦截器和网络拦截器，从整个责任链路来看，应用拦截器是最先执行的拦截器，也就是用户自己设置request属性后的原始请求，而网络拦截器位于ConnectInterceptor和CallServerInterceptor之间，此时网络链路已经准备好，只等待发送请求数据。 首先，应用拦截器在RetryAndFollowUpInterceptor和CacheInterceptor之前，所以一旦发生错误重试或者网络重定向，网络拦截器可能执行多次，因为相当于进行了二次请求，但是应用拦截器永远只会触发一次。另外如果在CacheInterceptor中命中了缓存就不需要走网络请求了，因此会存在短路网络拦截器的情况。 其次，如上文提到除了CallServerInterceptor，每个拦截器都应该至少调用一次realChain.proceed方法。实际上在应用拦截器这层可以多次调用proceed方法（本地异常重试）或者不调用proceed方法（中断），但是网络拦截器这层连接已经准备好，可且仅可调用一次proceed方法。 最后，从使用场景看，应用拦截器因为只会调用一次，通常用于统计客户端的网络请求发起情况；而网络拦截器一次调用代表了一定会发起一次网络通信，因此通常可用于统计网络链路上传输的数据。 网络缓存机制CacheInterceptor这里的缓存是指基于Http网络协议的数据缓存策略，侧重点在客户端缓存，所以我们要先来复习一下Http协议如何根据请求和响应头来标识缓存的可用性。 提到缓存，就必须要聊聊缓存的有效性、有效期。 HTTP缓存原理在HTTP 1.0时代，响应使用Expires头标识缓存的有效期，其值是一个绝对时间，比如Expires:Thu,31 Dec 2020 23:59:59 GMT。当客户端再次发出网络请求时可比较当前时间 和上次响应的expires时间进行比较，来决定是使用缓存还是发起新的请求。 使用Expires头最大的问题是它依赖客户端的本地时间，如果用户自己修改了本地时间，就会导致无法准确的判断缓存是否过期。 因此，从HTTP 1.1 开始使用Cache-Control头表示缓存状态，它的优先级高于Expires，常见的取值为下面的一个或多个。 private，默认值，标识那些私有的业务逻辑数据，比如根据用户行为下发的推荐数据。该模式下网络链路中的代理服务器等节点不应该缓存这部分数据，因为没有实际意义。 public 与private相反，public用于标识那些通用的业务数据，比如获取新闻列表，所有人看到的都是同一份数据，因此客户端、代理服务器都可以缓存。 no-cache 可进行缓存，但在客户端使用缓存前必须要去服务端进行缓存资源有效性的验证，即下文的对比缓存部分，我们稍后介绍。 max-age 表示缓存时长单位为秒，指一个时间段，比如一年，通常用于不经常变化的静态资源。 no-store 任何节点禁止使用缓存。 强制缓存在上述缓存头规约基础之上，强制缓存是指网络请求响应header标识了Expires或Cache-Control带了max-age信息，而此时客户端计算缓存并未过期，则可以直接使用本地缓存内容，而不用真正的发起一次网络请求。 协商缓存强制缓存最大的问题是，一旦服务端资源有更新，直到缓存时间截止前，客户端无法获取到最新的资源（除非请求时手动添加no-store头），另外大部分情况下服务器的资源无法直接确定缓存失效时间，所以使用对比缓存更灵活一些。 使用Last-Modify / If-Modify-Since头实现协商缓存，具体方法是服务端响应头添加Last-Modify头标识资源的最后修改时间，单位为秒，当客户端再次发起请求时添加If-Modify-Since头并赋值为上次请求拿到的Last-Modify头的值。 服务端收到请求后自行判断缓存资源是否仍然有效，如果有效则返回状态码304同时body体为空，否则下发最新的资源数据。客户端如果发现状态码是304，则取出本地的缓存数据作为响应。 使用这套方案有一个问题，那就是资源文件使用最后修改时间有一定的局限性： Last-Modify单位为秒，如果某些文件在一秒内被修改则并不能准确的标识修改时间。 资源修改时间并不能作为资源是否修改的唯一依据，比如资源文件是Daily Build的，每天都会生成新的，但是其实际内容可能并未改变。 因此，HTTP 还提供了另外一组头信息来处理缓存，ETag/If-None-Match。流程与Last-Modify一样，只是把服务端响应的头变成Last-Modify，客户端发出的头变成If-None-Match。ETag是资源的唯一标识符 ，服务端资源变化一定会导致ETag变化。具体的生成方式有服务端控制，场景的影响因素包括，文件最终修改时间、文件大小、文件编号等等。 OKHttp的缓存实现上面讲了这么多，实际上OKHttp就是将上述流程用代码实现了一下，即： 第一次拿到响应后根据头信息决定是否缓存。 下次请求时判断是否存在本地缓存，是否需要使用对比缓存、封装请求头信息等等。 如果缓存失效或者需要对比缓存则发出网络请求，否则使用本地缓存。 OKHttp内部使用Okio来实现缓存文件的读写。 缓存文件分为CleanFiles和DirtyFiles，CleanFiles用于读，DirtyFiles用于写，他们都是数组，长度为2，表示两个文件，即缓存的请求头和请求体；同时记录了缓存的操作日志，记录在journalFile中。 开启缓存需要在OkHttpClient创建时设置一个Cache对象，并指定缓存目录和缓存大小，缓存系统内部使用LRU作为缓存的淘汰算法。 1234567## Cache.ktclass Cache internal constructor( directory: File, maxSize: Long, fileSystem: FileSystem): Closeable, Flushable复制代码 OkHttp早期的版本有个一个InternalCache接口，支持自定义实现缓存，但到了4.x的版本后删减了InternalCache，Cache类又为final的，相当于关闭了扩展功能。 具体源码实现都在CacheInterceptor类中，大家可以自行查阅。 通过OkHttpClient设置缓存是全局状态的，如果我们想对某个特定的request使用或禁用缓存，可以通过CacheControl相关的API实现： 123456//禁用缓存Request request = new Request.Builder() .cacheControl(new CacheControl.Builder().noCache().build()) .url(&quot;http://publicobject.com/helloworld.txt&quot;) .build();复制代码 OKHttp不支持的缓存情况最后需要注意的一点是，OKHttp默认只支持get请求的缓存。 12345678910111213141516171819# okhttp3.Cache.java@Nullable CacheRequest put(Response response) { String requestMethod = response.request().method(); ... //缓存仅支持GET请求 if (!requestMethod.equals(&quot;GET&quot;)) { // Don't cache non-GET responses. We're technically allowed to cache // HEAD requests and some POST requests, but the complexity of doing // so is high and the benefit is low. return null; } //对于vary头的值为*的情况，统一不缓存 if (HttpHeaders.hasVaryAll(response)) { return null; } ...}复制代码 这是当网络请求响应后，准备进行缓存时的逻辑代码，当返回null时表示不缓存。从代码注释中不难看出，我们从技术上可以缓存method为HEAD和部分POST请求，但实现起来的复杂性很高而收益甚微。这本质上是由各个method的使用场景决定的。 我们先来看看常见的method类型及其用途。 GET 请求资源，参数都在URL中。 HEAD 与GET基本一致，只不过其不返回消息体，通常用于速度或带宽优先的场景，比如检查资源有效性，可访问性等等。 POST 提交表单，修改数据，参数在body中。 PUT 与POST基本一致，最大不同为PUT是幂等的。 DELETE 删除指定资源。 可以看到对于标准的RESTful请求，GET就是用来获取数据，最适合使用缓存，而对于数据的其他操作缓存意义不大或者根本不需要缓存。 也是基于此在仅支持GET请求的条件下，OKHTTP使用request URL作为缓存的key（当然还会经过一系列摘要算法）。 OkHttp的线程池OkHttp中的线程池是定义在分发器中的，即定义在Dispatcher 1234567public synchronized ExecutorService executorService() { if (executorService == null) { executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;&gt;(), Util.threadFactory(&quot;OkHttp Dispatcher&quot;, false)); } return executorService;} 高并发，最大吞吐量。SynchronousQueue队列是无容量队列， 在OkHttp中，配置的线程池的核心线程数为0，最大线程数为Integer.MAX_VALUE，线程的存活时间为60s，采用的队列是SynchronousQueue。 okhttp 默认同时支持 64 个异步请求(不考虑同步请求)，一个 host 同时最多请求 5 个 okhttp 内部的线程池都是 CacheThreadPool：核心线程数为 0，非核心线程数无限，永远添加不到等待队列中 okhttpClient 如果不单例，会出现 oom：因为大量的 Dispatcher 对象，不同的对象会使用不同的线程去发起网络请求，从而导致线程过多，OOM","link":"/2021/04/07/Okhttp/"},{"title":"HighFrequencyIssue","text":"操作系统：（1）线程和进程的区别？ （2）线程之间怎么共享资源？ （3）进程之间怎么通信？ （4）进程池的原理是什么？ 进程与线程的概念，以及为什么要有进程线程，其中有什么区别，他们各自又是怎么同步的?1. 基本概念：进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发； 线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。 2. 区别： 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。） 进程是资源分配的最小单位，线程是CPU调度的最小单位； 系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。 通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预 进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。 进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉 进程适应于多核、多机分布；线程适用于多核 进程间通信的方式：进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。 1.管道：管道主要包括匿名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，命名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信 1.1 匿名管道PIPE： 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间） 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。 1.2 命名管道FIFO： FIFO可以在无关的进程之间交换数据 FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。 2. 系统IPC： 2.1 消息队列 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。 (消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息； 特点： 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。 2.2 信号量semaphore 信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 特点： 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。 支持信号量组。 2.3 信号signal信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 2.4 共享内存（Shared Memory）它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等 特点： 共享内存是最快的一种IPC，因为进程是直接对内存进行存取 因为多个进程可以同时操作，所以需要进行同步 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问 3.套接字SOCKET：socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。 线程间通信的方式: 临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问； 互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作进程间通信的方式： 进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。 算法105. 从前序与中序遍历序列构造二叉树 - LeetCode 用栈实现队列二叉树层序遍历K个一组翻转链表https://leetcode-cn.com/problems/reverse-nodes-in-k-group/LeetCode 680. 验证回文字符串 ⅡLeetcode easy 617. 合并二叉树 求根节点到叶节点数字之和","link":"/2021/11/22/HighFrequencyIssue/"},{"title":"LiveData","text":"简述： 数据实时更新、安全更新：当liveData的setValue被调用时，会遍历自身所有observer并considerNotify，此时会判断observer的活跃状态（shouldBeActive）和内部版本，决定是否向其发送通知。 避免内存泄漏：传入lifeCycleOwner即走observe()的LiveData会在lifeCycleOwner回调onStateChanged为DESTROYED的时候移除掉observer防止内存泄露，而相对的observeForever则由于没有owner而无此特性。 解决Configuration Change问题、粘性数据：一般而言observer是在onCreate中调用的，liveData.observer方法在调用时也会立即被推送liveData中最后一次数据。（会导致所谓的数据倒灌）。Configuration Change时会ViewModel会从当前Activity或fragmentManager的viewModelStore的缓存中重新取出，而ViewModel中的liveData自然也会保留。 https://zhuanlan.zhihu.com/p/593472898 Featrue UI和实时数据保持一致 因为LiveData采用的是观察者模式，这样一来就可以在数据发生改变时获得通知，更新UI。 避免内存泄漏 观察者被绑定到组件的生命周期上，当被绑定的组件销毁（destroy）时，观察者会立刻自动清理自身的数据。 不会再产生由于Activity处于stop状态而引起的崩溃，例如：当Activity处于后台状态时，是不会收到LiveData的任何事件的。 不需要再解决生命周期带来的问题 LiveData可以感知被绑定的组件的生命周期，只有在活跃状态才会通知数据变化。 实时数据刷新 当组件处于活跃状态或者从不活跃状态到活跃状态时总是能收到最新的数据。 解决Configuration Change问题 在屏幕发生旋转或者被回收再次启动，立刻就能收到最新的数据。 常用实现类https://chatgpt.com/c/21580ee8-b685-48be-a510-712388ae346e LiveData常用于MVVM中，ViewModel向View层提供订阅的单向数据源。一般实践中会根据”单一数据源真相”原则，在ViewModel层中收敛所有的可变MutableLiveData，只对View层提供不可变的LiveData。View层行为应通过调用ViewModel的方法变更数据。 在MVVM架构中，View层不应该直接改变ViewModel中的数据状态。这是为了保持清晰的职责分离和确保数据的一致性。具体来说： View层：主要负责显示数据和处理用户交互。它可以观察LiveData并根据数据变化更新UI。 ViewModel层：负责准备和管理与UI相关的数据。它通过MutableLiveData更新数据，并暴露LiveData给View层以供观察。 Model层：负责数据操作，如网络请求和数据库操作。 工作流程 View观察ViewModel中的LiveData：View层通过观察ViewModel中暴露的LiveData，接收数据变化并更新UI。 用户交互通过View通知ViewModel：当用户与UI交互时，View层调用ViewModel中的方法，传递用户动作或输入。 ViewModel更新数据：ViewModel处理用户的输入，进行必要的业务逻辑处理，并通过更新MutableLiveData来改变数据状态。 View层收到更新并更新UI：由于View观察了LiveData，当ViewModel中的数据状态发生变化时，View会自动收到通知并更新UI。 假设你有一个按钮点击事件来更新数据： 12345678// 在View层（例如Activity或Fragment）中viewModel.buttonClicked.observe(this, Observer { newText -&gt; textView.text = newText})button.setOnClickListener { viewModel.onButtonClicked()} 在ViewModel中： 123456789class TestViewModel : ViewModel() { private val _buttonClicked: MutableLiveData&lt;String&gt; = MutableLiveData() val buttonClicked: LiveData&lt;String&gt; = _buttonClicked fun onButtonClicked() { // 更新数据 _buttonClicked.value = &quot;按钮点击了&quot; }} 关键点 View层不直接修改数据：View层通过调用ViewModel中的方法来请求数据更新，而不是直接修改LiveData。 ViewModel负责数据更新：ViewModel接收View层的请求，更新MutableLiveData中的数据。 数据变化通知View层：LiveData的数据变化会通知观察者（View层），并更新UI。 通过这种方式，确保了View层与ViewModel层之间的职责清晰分离，并且数据状态的管理是集中且可控的。 LiveData 不可变的（一般作为ViewModel对View层提供的单向数据源） MutableLiveData可变的（一般用于ViewModel层内部变更数据，会用对外提供LiveData同名加下划线前缀命名） https://developer.android.com/reference/android/arch/lifecycle/MutableLiveData MediatorLiveData可变的、监听多源的 https://developer.android.com/reference/android/arch/lifecycle/MediatorLiveData 原理我们知道 livedata 的使用很简单，它是采用观察者模式实现的 添加观察者 在数据改变的时候设置 value，这样会回调 Observer 的 onChanged 方法 1234567public interface Observer&lt;T&gt; { /** * Called when the data is changed. * @param t The new data */ void onChanged(T t);} observe方法LiveData包含两个用于添加数据观察者（Observer）的方法，分别是 observe(LifecycleOwner , Observer) 生命周期安全的 observeForever(Observer) 两个方法的区别对于外部来说只在于是否提供了生命周期安全的保障。 生命周期安全的observe12345678910111213141516171819202122232425262728@MainThread public void observe(@NonNull LifecycleOwner owner, @NonNull Observer&lt;? super T&gt; observer) { //限定只能在主线程调用 observe 方法 assertMainThread(&quot;observe&quot;); //当 Lifecycle 已经处于 DESTROYED 状态时，此时进行 observe 是没有意义的，直接返回 if (owner.getLifecycle().getCurrentState() == DESTROYED) { // ignore return; } //根据传入参数构建一个新的代理 Observer LifecycleBoundObserver wrapper = new LifecycleBoundObserver(owner, observer); //将 observer 作为 key，wrapper 作为 value 进行存储 //当 mObservers 不包含该 key 时，调用 putIfAbsent 会返回 null //当 mObservers 已包含该 key 时，调用 putIfAbsent 不会存储 key-value，并会返回之前保存的 value ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing != null &amp;&amp; !existing.isAttachedTo(owner)) { //走到此步，说明之前 LiveData 内部已经持有了 observer 对象， //且该 observer 对象已经绑定了其它的 LifecycleOwner 对象 //此时直接抛出异常 throw new IllegalArgumentException(&quot;Cannot add the same observer&quot; + &quot; with different lifecycles&quot;); } if (existing != null) { //observer 之前已经传进来过了，此处直接返回 return; } owner.getLifecycle().addObserver(wrapper); } 传入的LifecycleOwner参数意味着携带了Lifecycle对象，LiveData内部就根据 Lifecycle的生命周期事件的回调变化在合适的时机进行数据通知，并在 Lifecycle对象处于DESTROYED状态时自动移除Observer，这也是LiveData避免内存泄漏的最重要的一个点。 上面的代码使用到了LifecycleBoundObserver，它是抽象类ObserverWrapper的实现类。ObserverWrapper用于包装外部传进来的Observer对象，为子类定义好特定的抽象方法和共用逻辑，主要是提供了共用的状态分发函数。 1234567891011121314151617181920212223242526272829303132333435363738394041class LifecycleBoundObserver extends ObserverWrapper implements LifecycleEventObserver { @NonNull final LifecycleOwner mOwner; LifecycleBoundObserver(@NonNull LifecycleOwner owner, Observer&lt;? super T&gt; observer) { super(observer); mOwner = owner; } @Override boolean shouldBeActive() { //只有当 Lifecycle 的当前状态是 STARTED 或者 RESUMED 时 //才认为 Lifecycle 是处于活跃状态 return mOwner.getLifecycle().getCurrentState().isAtLeast(STARTED); } //LifecycleEventObserver 的实现方法 //当 Lifecycle 的生命周期状态发生变化时就会调用此方法 @Override public void onStateChanged(@NonNull LifecycleOwner source, @NonNull Lifecycle.Event event) { //如果 Lifecycle 已经处于 DESTROYED 状态了,则主动移除 mObserver //这就是 LiveData 可以避免内存泄露最重要的一个点 if (mOwner.getLifecycle().getCurrentState() == DESTROYED) { removeObserver(mObserver); return; } activeStateChanged(shouldBeActive()); } @Override boolean isAttachedTo(LifecycleOwner owner) { return mOwner == owner; } @Override void detachObserver() { //移除 mObserver mOwner.getLifecycle().removeObserver(this); }} LifecycleBoundObserver会保证当LiveData依赖的生命周期转到非活跃时，不进行通知（如果DESTROY会直接移除Observer）；当转到活跃时且数据版本更新了则向其发起回调。 LifecycleBoundObserver的整个事件流程是这样的： Lifecycle的生命周期发生变化，从而回调了onStateChanged函数 onStateChanged函数首先判断Lifecycle是否已处于DESTROYED状态，是的话则直接移除Observer，整个回调流程结束，否则则继续以下流程 onStateChanged调用了activeStateChanged()函数，activeStateChanged()函数判断Lifecycle的活跃状态是否发生了变化，如果从非活跃状态切换到了活跃状态，是的话则调用dispatchingValue()函数来分发值，最终再根据ObserverWrapper内部的value版本号mLastVersion来判断是否有新值需要向其回调，是的话则向其回调新值，否则则返回 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private abstract class ObserverWrapper { //外部传进来的对 LiveData 进行数据监听的 Observer final Observer&lt;? super T&gt; mObserver; //用于标记 mObserver 是否处于活跃状态 boolean mActive; //用于标记 Observer 内最后一个被回调的 value 的新旧程度 int mLastVersion = START_VERSION; ObserverWrapper(Observer&lt;? super T&gt; observer) { mObserver = observer; } //用于获取当前 Lifecycle 是否处于活跃状态 abstract boolean shouldBeActive(); //用于判断 mObserver 是否和 LifecycleOwner（即 Lifecycle）有绑定关系 boolean isAttachedTo(LifecycleOwner owner) { return false; } //移除 mObserver void detachObserver() { } void activeStateChanged(boolean newActive) { if (newActive == mActive) { return; } // immediately set active state, so we'd never dispatch anything to inactive // owner mActive = newActive; //判断当前 LiveData 所有的 Observer 是否都处于非活跃状态 boolean wasInactive = LiveData.this.mActiveCount == 0; //更新 LiveData 当前所有处于活跃状态的 Observer 的数量 LiveData.this.mActiveCount += mActive ? 1 : -1; if (wasInactive &amp;&amp; mActive) { //如果 LiveData 处于活跃状态的 Observer 数量从 0 变成了 1, //则回调 onActive 方法 onActive(); } if (LiveData.this.mActiveCount == 0 &amp;&amp; !mActive) { //如果 LiveData 处于活跃状态的 Observer 数量从 1 变成了 0, //则回调 onInactive 方法 onInactive(); } if (mActive) { //如果 mObserver 变成了活跃状态，则向其回调新值 dispatchingValue(this); } }} ObserverWrapper一共有两个子类： LifecycleBoundObserver和AlwaysActiveObserver，两者的差别就在于是否和生命周期相绑定。 非生命周期安全的observeForever12345678910111213141516171819@MainThreadpublic void observeForever(@NonNull Observer&lt;? super T&gt; observer) { //限定只能在主线程调用 observe 方法 assertMainThread(&quot;observeForever&quot;); AlwaysActiveObserver wrapper = new AlwaysActiveObserver(observer); ObserverWrapper existing = mObservers.putIfAbsent(observer, wrapper); if (existing instanceof LiveData.LifecycleBoundObserver) { //会走到这一步，是因为之前已经先用该 observer 对象调用了 observe(LifecycleOwner,Observer) //这里直接抛出异常 throw new IllegalArgumentException(&quot;Cannot add the same observer&quot; + &quot; with different lifecycles&quot;); } if (existing != null) { //如果之前已经添加过 observer 对象了的话，则直接返回 return; } //主动触发 activeStateChanged 函数，因为当前 LiveData 可能已经被设置值了 wrapper.activeStateChanged(true);} 上面代码使用到了AlwaysActiveObserver，它也是抽象类ObserverWrapper的实现类，其shouldBeActive()返回值固定为true，意味着只要有数据变化都会进行回调。所以使用observeForever()函数一定要在过后主动移除Observer，避免内存泄露和NPE。 更新LiveData的值更新LiveData的值的方法一共有两个，分别是： setValue(T value) postValue(T value) setValuesetValue(T)函数被限定在只能主线程进行调用。 123456789101112131415161718/** * Sets the value. If there are active observers, the value will be dispatched to them. * &lt;p&gt; * This method must be called from the main thread. If you need set a value from a background * thread, you can use {@link #postValue(Object)} * * @param value The new value */@MainThreadprotected void setValue(T value) { assertMainThread(&quot;setValue&quot;); //更新当前 value 的版本号，即 value 的新旧程度 mVersion++; mData = value; dispatchingValue(null);} dispatchingValue()函数设计得比较巧妙，用两个全局的布尔变量mDispatchingValue和mDispatchInvalidated就实现了新旧值判断、旧值舍弃、新值重新全局发布的逻辑。 123456789101112131415161718192021222324252627//initiator 为 null 则说明需要遍历回调整个 mObservers//initiator 不为 null 则说明仅回调 initiator 本身void dispatchingValue(@Nullable ObserverWrapper initiator) { //如果当前正处于向 mObservers 发布 mData 的过程中（即 mDispatchingValue 为 true） //则将 mDispatchInvalidated 置为 true，用于标明有新值到来，正在回调的值是已经过时的了 if (mDispatchingValue) { mDispatchInvalidated = true; return; } mDispatchingValue = true; do { mDispatchInvalidated = false; if (initiator != null) { considerNotify(initiator); initiator = null; } else { for (Iterator&lt;Map.Entry&lt;Observer&lt;? super T&gt;, ObserverWrapper&gt;&gt; iterator = mObservers.iteratorWithAdditions(); iterator.hasNext(); ) { considerNotify(iterator.next().getValue()); if (mDispatchInvalidated) { break; } } } } while (mDispatchInvalidated); mDispatchingValue = false;} 123456789101112131415161718192021// 判断是否要将数据分发到指定的 ObserverWrapperprivate void considerNotify(ObserverWrapper observer) { //如果 observer 处于非活跃状态，则直接返回 if (!observer.mActive) { return; } //此处判断主要是为了照顾 LifecycleBoundObserver //由于 Lifecycle 有可能状态值 State 已经切换到了非活跃状态，但 LifecycleBoundObserver 还未收到事件通知 //所以为了避免意外情况，此处主动检查 observer 的活跃状态并判断是否需要更新其活跃状态 if (!observer.shouldBeActive()) { observer.activeStateChanged(false); return; } //根据 observer 本部的 value 版本号 mLastVersion 来决定是否需要向其进行回调 //为了避免重复向某个 observer 回调值，所以此处需要判断下 if (observer.mLastVersion &gt;= mVersion) { return; } observer.mLastVersion = mVersion; observer.mObserver.onChanged((T) mData);} postValue1234567891011121314151617181920212223242526/** * Posts a task to a main thread to set the given value. So if you have a following code * executed in the main thread: * &lt;pre class=&quot;prettyprint&quot;&gt; * liveData.postValue(&quot;a&quot;); * liveData.setValue(&quot;b&quot;); * &lt;/pre&gt; * The value &quot;b&quot; would be set at first and later the main thread would override it with * the value &quot;a&quot;. * &lt;p&gt; * If you called this method multiple times before a main thread executed a posted task, only * the last value would be dispatched. * * @param value The new value */protected void postValue(T value) { boolean postTask; synchronized (mDataLock) { postTask = mPendingData == NOT_SET; mPendingData = value; } if (!postTask) { return; } ArchTaskExecutor.getInstance().postToMainThread(mPostValueRunnable);} postValue(T)函数不限定调用者所在线程，不管是主线程还是子线程都可以调用，因此是存在多线程竞争的可能性的，postValue(T)函数的重点旧在于需要理解其从子线程切换到主线程之间的状态变化。 在mPostValueRunnable被执行前，所有通过postValue(T)函数传递的value都会被保存到变量mPendingData上，且只会保留最后一个，直到mPostValueRunnable被执行后mPendingData才会被重置，所以使用 postValue(T) 函数在多线程同时调用或者单线程连续调用的情况下是存在丢值（外部的 Observer 只能接收到最新值）的可能性的。 Issue粘性事件LiveData 本身被设计为粘性事件，也即，一旦 LiveData 持有数据，那么在观察者订阅该 LiveData 时，会被推送最后一次数据。（当observe时会立即回调onChange推送数据） 数据倒灌（其实就是粘性事件，在多级页面中）当页面重建时或多级fragment订阅其activity的ShareViewModel的liveData时 被 LiveData 回推脏数据 https://xiaozhuanlan.com/topic/6719328450 https://medium.com/@kunminx/livedata-%E6%95%B0%E6%8D%AE%E5%80%92%E7%81%8C-%E5%88%AB%E9%97%AE-%E9%97%AE%E5%B0%B1%E6%98%AF%E4%B8%8D%E5%8F%AF%E9%A2%84%E6%9C%9F-5fc02fec76e0 e.g:设想一下这样的场景，一级页面是列表，二级页面是只读的详情预览，三级页面是可编辑的详情， 当我们在编辑页修改完信息时，我们通常会通过回调来通知一二级页面刷新信息。此时如是通过 LiveData 来通知，便存在隐患， 因为跨页面通信使用的是 Activity 级作用域的 SharedViewModel，其生命周期长于 Fragment，乃至当 “编辑页”、“预览页” 出栈时，SharedViewModel 和其旗下的 LiveData 还存在于内存中， 那么下一次从 “列表页” 跳到 “预览页”，“预览页” 一注册 LiveData，就会因为粘性设定，而收到上一次从 “编辑页” 发来的旧信息，这明显不符合预期， 现有解决方案及各自缺陷或应参考这篇文章https://juejin.cn/post/7268622342728171572，其中评论中提出 个人见解，方式是好方式，看了许多解决数据倒灌的文章，但是数据倒灌感觉并不是一个问题。livedata本身是用于描述状态的，而不是事件的。描述事件一般用publishsubject或shareflow或eventbus，再不济自己写个listener也行。 //ps:上flow因此感觉用livedata描述事件本身违背了livedata的设计初衷。 在《Jetpack MVVM 精讲》中我分别提到了 Event 事件包装器、反射方式、SingleLiveEvent 这三种方式来解决 “数据倒灌” 的问题。它们分别来自上文我们提到的外网、美团的文章，和官方最新 demo。 分别存在如下问题： Event 事件包装器对于多观察者的情况，只允许第一个观察者消费，这不符合现实需求； 而且手写 Event 事件包装器，在 Java 中存在 null 安全的一致性问题。 反射干预 Version 的方式：美团LiveDataBus存在延迟，无法用于对实时性有要求的场景； 并且数据会随着 SharedViewModel 长久滞留在内存中得不到释放。 https://github.com/JeremyLiao/LiveDataBus 官方最新 demo 中的 SingleLiveEvent （已移除）是对 Event 事件包装器 一致性问题的改进，但未解决多观察者消费的问题； 而且额外引入了消息未能从内存中释放的问题。 UnPeekLiveData 特点UnPeekLiveData 通过 独创的 “延时自动清理消息” 的设计，来满足： 1.消息被分发给多个观察者时，*不会因第一个观察者消费了而直接被置空* 2.时限到了，*消息便不再会被倒灌* 3.时限到了，*消息自动从内存中清理释放* 4.使非入侵的设计成为可能，并最终结合官方 SingleLiveEvent 的设计实现了 ***遵循开闭原则的非入侵重写***。 连续postValue()吞数据Google在postValue的注释上说明了 If you called this method multiple times before a main thread executed a posted task, only the last value would be dispatched.如果在主线程执行一个已发布的任务之前多次调用此方法，则只会分派最后一个值。 只有第一次调用时会走到postToMainThread(mPostValueRunnable)，后面所有执行的postValue在执行完postTask = mPendingData == NOT_SET 和 mPendingData = value 后，直接由于之后postTask == false，所以return掉了，也就不会再postToMainThread一次而是只修改mPendingData数据。 直到主线程中mPostValueRunable执行方法中会将真正调用setValue并将mPendingData重置为NOT_SET. 这个实现其实听起来很像View的刷新，比如TextView连续设置两次文本，也是只有当Vsync到来时取最新的文本设置到TextView中","link":"/2022/02/24/LiveData/"},{"title":"Mmap","text":"Binder | 内存拷贝的本质和变迁芦半山 虚拟地址和数据的关系所有的数据都存储在物理内存中，而进程访问内存只能通过虚拟地址。因此，若是想成功访问必须得有个前提： 虚拟地址和物理内存之间建立映射关系 若是这层映射关系不建立，则访问会出错。信号11(SIGSEGV)的MAPERR就是专门用来描述这种错误的。 虚拟地址和物理地址间建立映射关系通过mmap完成。这里我们不考虑file-back的mapping，只考虑anonymous mapping。当mmap被调用(flag=MAP_ANONYMOUS)时，实际上会做以下两件事： 分配一块连续的虚拟地址空间。 更新这些虚拟地址对应的PTE(Page Table Entry)。 mmap做完这两件事后，就会返回连续虚拟地址空间的起始地址。在mmap调用结束后，其实并不会立即分配物理页。如果此时不分配物理页，那么就会有如下两个问题： 没有新的物理页分配，那么PTE都更新了哪些内容？ 如果后续使用mmap返回的虚拟地址访问内存，会有什么情况产生呢？ 1.1.1 没有新的物理页分配，那么PTE都更新了些什么内容呢？PTE也即页表的条目，它的内容反映了一个虚拟地址到物理地址之间的映射关系。如果没有新的物理页分配，那这些新的虚拟地址都和哪些物理地址之间建立了映射关系呢？答案是所有的虚拟地址都和同一个zero page（页内容全为0）建立了映射关系。 1.1.2 如果后续使用mmap返回的虚拟地址访问内存，会有什么情况产生呢？拿到mmap返回的虚拟地址后，并不会有新的物理页分配。此时若是直接读取虚拟地址中的值，则会通过PTE追踪到刚刚建立映射关系的zero page，因此读取出来的值都是0。 如果此时往虚拟地址中写入数据，将会在page fault handler中触发一个正常的copy-on-write机制。需要写多少页，就会新分配多少物理页。所以我们可以看到，真实的物理页是符合lazy(on-demand) allocation原则的。这一点，极大地保证了物理资源的合理分配和使用。","link":"/2022/02/16/Mmap/"},{"title":"OperatingSystem","text":"操作系统 进程和线程 进程和线程有什么区别？ 进程间通信有哪些方式？ 进程同步问题 进程有哪几种状态？ 进程调度策略有哪些？ 什么是僵尸进程？ 线程同步有哪些方式？ 什么是协程？ 进程的异常控制流：陷阱、中断、异常和信号 什么是IO多路复用？怎么实现？ 什么是用户态和内核态？ 死锁 什么是死锁？ 死锁产生的必要条件？ 死锁有哪些处理方法？ 内存管理 分页和分段有什么区别？ 什么是虚拟内存？ 有哪些页面置换算法？ 缓冲区溢出问题 磁盘调度 参考 进程和线程有什么区别？ 进程（Process）是系统进行资源分配和调度的基本单位，线程（Thread）是CPU调度和分派的基本单位； 线程依赖于进程而存在，一个进程至少有一个线程； 进程有自己的独立地址空间，线程共享所属进程的地址空间； 进程是拥有系统资源的一个独立单位，而线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，和其他线程共享本进程的相关资源如内存、I/O、cpu等； 在进程切换时，涉及到整个当前进程CPU环境的保存环境的设置以及新被调度运行的CPU环境的设置，而线程切换只需保存和设置少量的寄存器的内容，并不涉及存储器管理方面的操作，可见，进程切换的开销远大于线程切换的开销； 线程之间的通信更方便，同一进程下的线程共享全局变量等数据，而进程之间的通信需要以进程间通信(IPC)的方式进行； 多线程程序只要有一个线程崩溃，整个程序就崩溃了，但多进程程序中一个进程崩溃并不会对其它进程造成影响，因为进程有自己的独立地址空间，因此多进程更加健壮 进程操作代码实现，可以参考：多进程 - 廖雪峰的官方网站 同一进程中的线程可以共享哪些数据？ 展开 进程代码段 进程的公有数据（全局变量、静态变量…） 进程打开的文件描述符 进程的当前目录 信号处理器/信号处理函数：对收到的信号的处理方式 进程ID与进程组ID 线程独占哪些资源？ 展开 线程ID 一组寄存器的值 线程自身的栈（堆是共享的） 错误返回码：线程可能会产生不同的错误返回码，一个线程的错误返回码不应该被其它线程修改； 信号掩码/信号屏蔽字(Signal mask)：表示是否屏蔽/阻塞相应的信号（SIGKILL,SIGSTOP除外） 进程间通信有哪些方式？ 管道(Pipe) 展开 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道； 一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据； 只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程) 命名管道 消息队列 信号(Signal) 共享内存 信号量(Semaphore)：初始化操作、P操作、V操作；P操作：信号量-1，检测是否小于0，小于则进程进入阻塞状态；V操作：信号量+1，若小于等于0，则从队列中唤醒一个等待的进程进入就绪态 套接字(Socket) 更详细的可以参考（待整理）： https://imageslr.github.io/2020/02/26/ipc.html https://www.jianshu.com/p/c1015f5ffa74 进程同步问题 进程的同步是目的，而进程间通信是实现进程同步的手段 管程 Monitor 管程将共享变量以及对这些共享变量的操作封装起来，形成一个具有一定接口的功能模块，这样只能通过管程提供的某个过程才能访问管程中的资源。进程只能互斥地使用管程，使用完之后必须释放管程并唤醒入口等待队列中的进程。 当一个进程试图进入管程时，在入口等待队列等待。若P进程唤醒了Q进程，则Q进程先执行，P在紧急等待队列中等待。（HOARE管程） wait操作：执行wait操作的进程进入条件变量链末尾，唤醒紧急等待队列或者入口队列中的进程；signal操作：唤醒条件变量链中的进程，自己进入紧急等待队列，若条件变量链为空，则继续执行。（HOARE管程） MESA管程：将HOARE中的signal换成了notify（或者broadcast通知所有满足条件的），进行通知而不是立马交换管程的使用权，在合适的时候，条件队列首位的进程可以进入，进入之前必须用while检查条件是否合适。优点：没有额外的进程切换 生产者-消费者问题 问题描述：使用一个缓冲区来存放数据，只有缓冲区没有满，生产者才可以写入数据；只有缓冲区不为空，消费者才可以读出数据 代码实现： 1234567891011121314151617181920212223242526272829// 伪代码描述 // 定义信号量 full记录缓冲区物品数量 empty代表缓冲区空位数量 mutex为互斥量semaphore full = 0, empty = n, mutex = 1;// 生产者进程void producer(){ do{ P(empty); P(mutex); // 生产者进行生产 V(mutex); V(full); } while(1);}void consumer(){ do{ P(full); P(mutex); // 消费者进行消费 V(mutex); V(empty); } while(1);} 哲学家就餐问题 问题描述：有五位哲学家围绕着餐桌坐，每一位哲学家要么思考，要么吃饭。为了吃饭，哲学家必须拿起两双筷子（分别放于左右两端）不幸的是，筷子的数量和哲学家相等，所以每只筷子必须由两位哲学家共享。 代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142#define N 5 // number of philosopher#define LEFT (i + N - 1)%N // number of i's left neighbors#define RIGHT (i + 1)%N // number of i's right neighbors#define THINKING 0#define HUNGRY 1#define EATING 2typedef int semaphore;int state[N]; // array to keep track of everyone's statesemaphore mutex = 1; // mutual exclusion of critical regionsemaphore s[N]; void philosopher(int i) { while (TRUE) { think(); take_forks(i); eat(); put_forks(i); }}void take_forks(int i) { down(&amp;mutex); // enter critical region state[i] = HUNGRY; // record that i is hungry test_forks(i); // try to acquire two forks up(&amp;mutex); // exit critical region down(&amp;s[i]); // block if forks are not acquired}void put_forks(int i) { down(&amp;mutex); // enter critical region state[i] = THINKING; // record that has finished eating test_forks(LEFT); // see if left neighbor can now eat test_forks(RIGHT); // see if right neighbor can now eat up(&amp;mutex); // exit critical region}void test_forks(int i) { if (state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING) { state[i] = EATING; up(&amp;s[i]); }} 读者-写者问题 临界区的概念？ 展开 各个进程中对临界资源（互斥资源/共享变量，一次只能给一个进程使用）进行操作的程序片段 同步与互斥的概念？ 展开 同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态； 互斥：多个进程在同一时刻只有一个进程能进入临界区 并发、并行、异步的区别？ 展开 并发：在一个时间段中同时有多个程序在运行，但其实任一时刻，只有一个程序在CPU上运行，宏观上的并发是通过不断的切换实现的； 多线程：并发运行的一段代码。是实现异步的手段 并行（和串行相比）：在多CPU系统中，多个程序无论宏观还是微观上都是同时执行的 异步（和同步相比）：同步是顺序执行，异步是在等待某个资源的时候继续做自己的事 进程有哪几种状态？ 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数 阻塞状态： 进程等待某种条件，在条件满足之前无法执行 进程调度策略有哪些？ 批处理系统： 先来先服务 first-come first-serverd（FCFS） 按照请求的顺序进行调度。非抢占式，开销小，无饥饿问题，响应时间不确定（可能很慢）； 对短进程不利，对IO密集型进程不利。 最短作业优先 shortest job first（SJF） 按估计运行时间最短的顺序进行调度。非抢占式，吞吐量高，开销可能较大，可能导致饥饿问题； 对短进程提供好的响应时间，对长进程不利。 最短剩余时间优先 shortest remaining time next（SRTN） 按剩余运行时间的顺序进行调度。(最短作业优先的抢占式版本)。吞吐量高，开销可能较大，提供好的响应时间； 可能导致饥饿问题，对长进程不利。 最高响应比优先 Highest Response Ratio Next（HRRN） 响应比 = 1+ 等待时间/处理时间。同时考虑了等待时间的长短和估计需要的执行时间长短，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，提供好的响应时间，无饥饿问题。 交互式系统交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。 时间片轮转 Round Robin 将所有就绪进程按 FCFS 的原则排成一个队列，用完时间片的进程排到队列最后。抢占式（时间片用完时），开销小，无饥饿问题，为短进程提供好的响应时间； 若时间片小，进程切换频繁，吞吐量低；若时间片太长，实时性得不到保证。 优先级调度算法 为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。 多级反馈队列调度算法 Multilevel Feedback Queue 设置多个就绪队列1、2、3…，优先级递减，时间片递增。只有等到优先级更高的队列为空时才会调度当前队列中的进程。如果进程用完了当前队列的时间片还未执行完，则会被移到下一队列。 抢占式（时间片用完时），开销可能较大，对IO型进程有利，可能会出现饥饿问题。 什么叫优先级反转？如何解决？ 展开 高优先级的进程等待被一个低优先级进程占用的资源时，就会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。此处详细解释优先级反转带来的问题：如果有一个中等优先级的进程将低优先级的进程抢占，那么此时低优先级的进程无法正常进行并在后续释放被占用的资源，导致高优先级的任务一直被挂起，直到中等优先级的进程完成后，低优先级的进程才可以继续并在后续释放占用的资源，最后高优先级的进程才可以执行。导致的问题就是高优先级的进程在中等优先级的进程调度之后。 解决方法： 优先级天花板(priority ceiling)：当任务申请某资源时，把该任务的优先级提升到可访问这个资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。简单易行。 优先级继承(priority inheritance)：当任务A申请共享资源S时，如果S正在被任务C使用，通过比较任务C与自身的优先级，如发现任务C的优先级小于自身的优先级，则将任务C的优先级提升到自身的优先级，任务C释放资源S后，再恢复任务C的原优先级。 什么是僵尸进程？一个子进程结束后，它的父进程并没有等待它（调用wait或者waitpid），那么这个子进程将成为一个僵尸进程。僵尸进程是一个已经死亡的进程，但是并没有真正被销毁。它已经放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。 危害：占用进程号，而系统所能使用的进程号是有限的；占用内存。 以下情况不会产生僵尸进程： 该进程的父进程先结束了。每个进程结束的时候，系统都会扫描是否存在子进程，如果有则用Init进程接管，成为该进程的父进程，并且会调用wait等待其结束。 父进程调用wait或者waitpid等待子进程结束（需要每隔一段时间查询子进程是否结束）。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入WNOHANG(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。同时，waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程； 子进程结束时，系统会产生SIGCHLD(signal-child)信号，可以注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（注意：一般都需要循环调用waitpid，因为在信号处理函数开始执行之前，可能已经有多个子进程结束了，而信号处理函数只执行一次，所以要循环调用将所有结束的子进程回收）； 也可以用signal(SIGCLD, SIG_IGN)(signal-ignore)通知内核，表示忽略SIGCHLD信号，那么子进程结束后，内核会进行回收。 什么是孤儿进程？ 展开 一个父进程已经结束了，但是它的子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程会被Init（进程ID为1）接管，当这些孤儿进程结束时由Init完成状态收集工作。 线程同步有哪些方式？ 为什么需要线程同步：线程有时候会和其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源的时候，可能会发生冲突。因此需要线程的同步，多个线程按顺序访问资源。 互斥量 Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当前拥有互斥对象的线程处理完任务后必须将互斥对象交出，以便其他线程访问该资源； 信号量 Semaphore：信号量是内核对象，它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了最大资源计数和当前可用资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就减1，只要当前可用资源计数大于0，就可以发出信号量信号，如果为0，则将线程放入一个队列中等待。线程处理完共享资源后，应在离开的同时通过ReleaseSemaphore函数将当前可用资源数加1。如果信号量的取值只能为0或1，那么信号量就成为了互斥量； 事件 Event：允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。事件分为手动重置事件和自动重置事件。手动重置事件被设置为激发状态后，会唤醒所有等待的线程，而且一直保持为激发状态，直到程序重新把它设置为未激发状态。自动重置事件被设置为激发状态后，会唤醒一个等待中的线程，然后自动恢复为未激发状态。 临界区 Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其它试图访问该资源的线程将被挂起，直到临界区对象被释放。 互斥量和临界区有什么区别？ 展开 互斥量是可以命名的，可以用于不同进程之间的同步；而临界区只能用于同一进程中线程的同步。创建互斥量需要的资源更多，因此临界区的优势是速度快，节省资源。 什么是协程？协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 协程多与线程进行比较？ 展开 一个线程可以拥有多个协程，一个进程也可以单独拥有多个协程，这样python中则能使用多核CPU。 线程进程都是同步机制，而协程则是异步 协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态 进程的异常控制流：陷阱、中断、异常和信号陷阱是有意造成的“异常”，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现系统调用。比如，进程可以执行 syscall n 指令向内核请求服务。当进程执行这条指令后，会中断当前的控制流，陷入到内核态，执行相应的系统调用。内核的处理程序在执行结束后，会将结果返回给进程，同时退回到用户态。进程此时继续执行下一条指令。 中断由处理器外部的硬件产生，不是执行某条指令的结果，也无法预测发生时机。由于中断独立于当前执行的程序，因此中断是异步事件。中断包括 I/O 设备发出的 I/O 中断、各种定时器引起的时钟中断、调试程序中设置的断点等引起的调试中断等。 异常是一种错误情况，是执行当前指令的结果，可能被错误处理程序修正，也可能直接终止应用程序。异常是同步的。这里特指因为执行当前指令而产生的错误情况，比如除法异常、缺页异常等。有些书上为了区分，也将这类“异常”称为“故障”。 信号是一种更高层的软件形式的异常，同样会中断进程的控制流，可以由进程进行处理。一个信号代表了一个消息。信号的作用是用来通知进程发生了某种系统事件。 更详细的可以参考：https://imageslr.github.io/2020/07/09/trap-interrupt-exception.html 什么是IO多路复用？怎么实现？IO多路复用（IO Multiplexing）是指单个进程/线程就可以同时处理多个IO请求。 实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。一旦有文件描述符就绪（读就绪或写就绪），或者超时（设置timeout），函数就会返回，然后该进程可以进行相应的读/写操作。 select/poll/epoll三者的区别？ select：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：每次都要复制，开销大），由内核根据就绪状态修改该集合的内容。（缺点2）集合大小有限制，32位机默认是1024（64位：2048）；采用水平触发机制。select函数返回后，需要通过遍历这个集合，找到就绪的文件描述符（缺点3：轮询的方式效率较低），当文件描述符的数量增加时，效率会线性下降； poll：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制； epoll：通过内核和用户空间共享内存，避免了不断复制的问题；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，采用回调机制，避免了轮询（回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。 总结，区别主要在于： 一个线程/进程所能打开的最大连接数 文件描述符传递方式（是否复制） 水平触发 or 边缘触发 查询就绪的描述符时的效率（是否轮询） 什么时候使用select/poll，什么时候使用epoll？ 当连接数较多并且有很多的不活跃连接时，epoll的效率比其它两者高很多；但是当连接数较少并且都十分活跃的情况下，由于epoll需要很多回调，因此性能可能低于其它两者。 什么是文件描述符？ 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。 内核通过文件描述符来访问文件。文件描述符指向一个文件。 什么是水平触发？什么是边缘触发？ 展开 水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知； 边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。 区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。 为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。 有哪些常见的IO模型？ 展开 同步阻塞IO（Blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够； 同步非阻塞IO（Non-blocking IO）：发起IO请求之后可以立即返回，如果没有就绪的数据，需要不断地发起IO请求直到数据就绪；不断重复请求消耗了大量的CPU资源； IO多路复用 异步IO（Asynchronous IO）：用户线程发出IO请求之后，继续执行，由内核进行数据的读取并放在用户指定的缓冲区内，在IO完成之后通知用户线程直接使用。 什么是用户态和内核态？为了限制不同程序的访问能力，防止一些程序访问其它程序的内存数据，CPU划分了用户态和内核态两个权限等级。 用户态只能受限地访问内存，且不允许访问外围设备，没有占用CPU的能力，CPU资源可以被其它程序获取； 内核态可以访问内存所有数据以及外围设备，也可以进行程序的切换。 所有用户程序都运行在用户态，但有时需要进行一些内核态的操作，比如从硬盘或者键盘读数据，这时就需要进行系统调用，使用陷阱指令，CPU切换到内核态，执行相应的服务，再切换为用户态并返回系统调用的结果。 为什么要分用户态和内核态？ 展开 （我自己的见解：） 安全性：防止用户程序恶意或者不小心破坏系统/内存/硬件资源； 封装性：用户程序不需要实现更加底层的代码； 利于调度：如果多个用户程序都在等待键盘输入，这时就需要进行调度；统一交给操作系统调度更加方便。 如何从用户态切换到内核态？ 展开 系统调用：比如读取命令行输入。本质上还是通过中断实现 用户程序发生异常时：比如缺页异常 外围设备的中断：外围设备完成用户请求的操作之后，会向CPU发出中断信号，这时CPU会转去处理对应的中断处理程序 什么是死锁？在两个或者多个并发进程中，每个进程持有某种资源而又等待其它进程释放它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁(deadlock)。 死锁产生的必要条件？ 互斥：一个资源一次只能被一个进程使用； 占有并等待：一个进程至少占有一个资源，并在等待另一个被其它进程占用的资源； 非抢占：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务之后自愿释放； 循环等待：若干进程之间形成一种头尾相接的环形等待资源关系，该环路中的每个进程都在等待下一个进程所占有的资源。 死锁有哪些处理方法？ 鸵鸟策略 直接忽略死锁。因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。 死锁预防 基本思想是破坏形成死锁的四个必要条件： 破坏互斥条件：允许某些资源同时被多个进程访问。但是有些资源本身并不具有这种属性，因此这种方案实用性有限； 破坏占有并等待条件： 实行资源预先分配策略（当一个进程开始运行之前，必须一次性向系统申请它所需要的全部资源，否则不运行）； 或者只允许进程在没有占用资源的时候才能申请资源（申请资源前先释放占有的资源）； 缺点：很多时候无法预知一个进程所需的全部资源；同时，会降低资源利用率，降低系统的并发性； 破坏非抢占条件：允许进程强行抢占被其它进程占有的资源。会降低系统性能； 破坏循环等待条件：对所有资源统一编号，所有进程对资源的请求必须按照序号递增的顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。这样避免了占有大号资源的进程去申请小号资源。 死锁避免 动态地检测资源分配状态，以确保系统处于安全状态，只有处于安全状态时才会进行资源的分配。所谓安全状态是指：即使所有进程突然请求需要的所有资源，也能存在某种对进程的资源分配顺序，使得每一个进程运行完毕。 银行家算法 死锁解除 如何检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法。 死锁解除的方法： 利用抢占：挂起某些进程，并抢占它的资源。但应防止某些进程被长时间挂起而处于饥饿状态； 利用回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。要求系统保持进程的历史信息，设置还原点； 利用杀死进程：强制杀死某些进程直到死锁解除为止，可以按照优先级进行。 分页和分段有什么区别？ 页式存储：用户空间划分为大小相等的部分称为页（page），内存空间划分为同样大小的区域称为页框，分配时以页为单位，按进程需要的页数分配，逻辑上相邻的页物理上不一定相邻； 段式存储：用户进程地址空间按照自身逻辑关系划分为若干个段（segment）（如代码段，数据段，堆栈段），内存空间被动态划分为长度不同的区域，分配时以段为单位，每段在内存中占据连续空间，各段可以不相邻； 段页式存储：用户进程先按段划分，段内再按页划分，内存划分和分配按页。 区别： 目的不同：分页的目的是管理内存，用于虚拟内存以获得更大的地址空间；分段的目的是满足用户的需要，使程序和数据可以被划分为逻辑上独立的地址空间； 大小不同：段的大小不固定，由其所完成的功能决定；页的大小固定，由系统决定； 地址空间维度不同：分段是二维地址空间（段号+段内偏移），分页是一维地址空间（每个进程一个页表/多级页表，通过一个逻辑地址就能找到对应的物理地址）； 分段便于信息的保护和共享；分页的共享收到限制； 碎片：分段没有内碎片，但会产生外碎片；分页没有外碎片，但会产生内碎片（一个页填不满） 什么是虚拟内存？每个程序都拥有自己的地址空间，这个地址空间被分成大小相等的页，这些页被映射到物理内存；但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由操作系统将缺失的部分装入物理内存。这样，对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分是存储在磁盘上，因此叫做虚拟内存。 虚拟内存的优点是让程序可以获得更多的可用内存。 虚拟内存的实现方式、页表/多级页表、缺页中断、不同的页面淘汰算法：答案。 如何进行地址空间到物理内存的映射？ 展开 内存管理单元（MMU）管理着逻辑地址和物理地址的转换，其中的页表（Page table）存储着页（逻辑地址）和页框（物理内存空间）的映射表，页表中还包含包含有效位（是在内存还是磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。 有哪些页面置换算法？在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。 最佳页面置换算法OPT（Optimal replacement algorithm）：置换以后不需要或者最远的将来才需要的页面，是一种理论上的算法，是最优策略； 先进先出FIFO：置换在内存中驻留时间最长的页面。缺点：有可能将那些经常被访问的页面也被换出，从而使缺页率升高； 第二次机会算法SCR：按FIFO选择某一页面，若其访问位为1，给第二次机会，并将访问位置0； 时钟算法 Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免了移动页面的开销； 最近未使用算法NRU（Not Recently Used）：检查访问位R、修改位M，优先置换R=M=0，其次是（R=0, M=1）； 最近最少使用算法LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。 最不经常使用算法NFU：置换出访问次数最少的页面 局部性原理 时间上：最近被访问的页在不久的将来还会被访问； 空间上：内存中被访问的页周围的页也很可能被访问。 什么是颠簸现象 颠簸本质上是指频繁的页调度行为。进程发生缺页中断时必须置换某一页。然而，其他所有的页都在使用，它置换一个页，但又立刻再次需要这个页。因此会不断产生缺页中断，导致整个系统的效率急剧下降，这种现象称为颠簸。内存颠簸的解决策略包括： 修改页面置换算法； 降低同时运行的程序的数量； 终止该进程或增加物理内存容量。 缓冲区溢出问题 什么是缓冲区溢出？ C 语言使用运行时栈来存储过程信息。每个函数的信息存储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C 对于数组引用不进行任何边界检查，因此**对越界的数组元素的写操作会破坏存储在栈中的状态信息**，这种现象称为缓冲区溢出。缓冲区溢出会破坏程序运行，也可以被用来进行攻击计算机，如使用一个指向攻击代码的指针覆盖返回地址。 缓冲区溢出的防范方式 防范缓冲区溢出攻击的机制有三种：随机化、栈保护和限制可执行代码区域。 随机化：包括栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout Randomization，ASLR，即每次运行时程序的不同部分，包括代码段、数据段、栈、堆等都会被加载到内存空间的不同区域），但只能增加攻击一个系统的难度，不能完全保证安全。 栈保护：在每个函数的栈帧的局部变量和栈状态之间存储一个随机产生的特殊的值，称为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测这个金丝雀值是否被改变了，如果是，那么程序异常终止。 限制可执行代码区域：内存页的访问形式有三种：可读、可写、可执行，只有编译器产生的那部分代码所处的内存才是可执行的，其他页限制为只允许读和写。 更详细的可以参考：https://imageslr.github.io/2020/07/08/tech-interview.html#stackoverflow 磁盘调度过程：磁头（找到对应的盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减小寻道时间的调度算法： 先来先服务 最短寻道时间优先 电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。 参考 进程间通信IPC – 简书 面试/笔试第二弹 —— 操作系统面试问题集锦 - CSDN博客 线程同步与并发 - - SegmentFault 彻底搞懂epoll高效运行的原理 用户态与内核态的切换 待完成 IPC 进程同步问题：生产者-消费者问题… 银行家算法 文件与文件系统、文件管理？","link":"/2021/11/22/OperatingSystem/"},{"title":"PackageManager","text":"PackageManger的核心作用： 在系统启动过程中，通过**PackageManagerService(PKMS)*对特定系统文件(如package.list, package.xml)进行扫描解析后，将所有app的信息整合存储，通过IPackageManger*对外暴露 通过PackageInstallerService提供Apk/Apex的安装、更新、卸载等操作(IPackageInstaller) 应用运行过程中的权限检查 启动时PKMS解析过程： PackageInstallerService的安装过程：","link":"/2022/02/16/PackageManager/"},{"title":"插件化&#x2F;热修复","text":"插件化和热修复不是同一个概念，虽然站在技术实现的角度来说，他们都是从系统加载器的角度出发，无论是采用hook方式，亦或是代理方式或者是其他底层实现，都是通过“欺骗”Android 系统的方式来让宿主正常的加载和运行插件（补丁）中的内容；但是二者的出发点是不同的。插件化顾名思义，更多是想把需要实现的模块或功能当做一个独立的提取出来，减少宿主的规模，当需要使用到相应的功能时再去加载相应的模块。热修复则往往是从修复bug的角度出发，强调的是在不需要二次安装应用的前提下修复已知的bug。 PathClassLoader：只能加载已经安装到Android系统中的apk文件（/data/app目录），是Android默认使用的类加载器。 DexClassLoader：可以加载任意目录下的dex/jar/apk/zip文件，也就是我们一开始提到的补丁。 BaseDexClassLoader: 是 PathClassLoader 和 DexClassLoader 的父类，其内有一个 DexPathList 属性，实现了 findClass 方法逻辑，PathClassLoader 和 DexClassLoader 都只是在构造函数上对其做了简单封装而已。 类加载器 每个类编译后产生一个Class对象，存储在.class文件中，JVM使用类加载器（Class Loader）来加载类的字节码文件（.class），类加载器实质上是一条类加载器链，一般的，我们只会用到一个原生的类加载器，它只加载Java API等可信类，通常只是在本地磁盘中加载，这些类一般就够我们使用了。如果我们需要从远程网络或数据库中下载.class字节码文件，那就需要我们来挂载额外的类加载器。 一般来说，类加载器是按照树形的层次结构组织的，每个加载器都有一个父类加载器。另外，每个类加载器都支持代理模式，即可以自己完成Java类的加载工作，也可以代理给其它类加载器。 类加载器的加载顺序有两种，一种是父类优先策略，一种是是自己优先策略，父类优先策略是比较一般的情况（如JDK采用的就是这种方式），在这种策略下，类在加载某个Java类之前，会尝试代理给其父类加载器，只有当父类加载器找不到时，才尝试自己去加载。自己优先的策略与父类优先相反，它会首先尝试子经济加载，找不到的时候才要父类加载器去加载，这种在web容器（如tomcat）中比较常见。 插件化： 插件化：插件化是体现在功能拆分方面的，它将某个功能独立提取出来，独立开发，独立测试，再插入到主应用中。依次来较少主应用的规模。 旧插件化框架方案核心解决两个问题： 一、插件类class的加载问题这个问题各家的解决方案都是统一的，也就是通过dexclassloader，加载插件apk。 二、activity为主的生命周期问题这个问题分为两种解决方式： 1、通过壳Activity通过在宿主工程预注册 壳Activity，通过壳Activity 持有并转调 插件Activity的每个生命周期 a. 插件Activity继承Activity类（需要反射）然后壳Activity通过反射转调各个生命周期甚至还可能需要避免它的super方法被调用。 这样做要解决一个额外的问题。 Activity被系统构造出实例之后，并不是直接调用onCreate方法的。首先会调用它的attach方法。attach方法实际上就是Activity的初始化方法，系统通过这个方法向Activity注入一些私有变量，比如Window、ActivityThread等等。插件Activity由于是我们壳子Activity自己new出来的，所以系统不会调用插件Activity的attach方法初始化它。Activity如果没有初始化就被调用了onCreate会有什么问题呢？我们前面说了我们的一个前提是插件Activity要求也要能正常编译安装运行，所以插件Activity的onCreate方法里一定写了super.onCreate()调用。我们还要求对插件代码无侵入性，所以也不能在这个调用外面包一层“if (不是插件模式)”。那么在插件环境下，这个super.onCreate()就一定会执行。Activity基类的onCreate方法就会使用那些应该初始化过的私有变量，但是现在它们没有初始化。所以这一类插件框架方案就要解决这个问题。所以要么是反射调用attach方法，传入从壳子Activity拿到的私有变量，比如说反射出壳子Activity的ActivityThread对象，传给插件Activity的attach方法。要么就干脆直接用反射枚举读写壳子Activity和插件Activity的私有变量，把它们写成一样的完成这个初始化。所以这就是为什么旧框架需要使用反射和私有API。 b. 插件Activity继承 普通插件基类 （无需反射）Shadow使用AOP的方式替换所有插件中的activity类为普通插件基类，但插件基类申明各个activity的实现 2、hook framework，包括Activity启动流程a .比如virtualApk是替换系统的instrumentation（替换成自定义的子类），在走到AMS前的execStartActivity中把传入的intent的component改成壳Activity，然后在AMS回调回来后的performLaunchActivity中，再把intent的conponent改回去。达到欺骗系统的目的。 b.比如Replugin比如RePlugin为首的hook 系统classLoader改成自定义ClassLoader，然后hook了 —————————————— 旧框架就是 壳Activity 转调 插件Activity的方案，市面上还有很多插件框架也是这种方案。大家只是在实现转调的手段上不一样。 Android9.0之后限制了反射的使用，黑名单直接禁止了，腾讯开源的Shadow解决Activity等组件生命周期的方法解析 - 掘金 (juejin.cn) shadow框架基于 第一种壳代理Activity的方式，但是第一种代理Activity的方式为了实现插件也能独立运行的特性，需要插件Activity继承Activity，shadow其实就是把 把一个插件Activity套在一个宿主Activity之中，然后想办法实现一个转调关系。如果插件Activity是一个真的Activity，那这个插件就可以正常编译安装运行，对开发插件或者直接上架插件App非常有利。但是由于它是个系统的Activity子类，它就有很多方法不能直接调用，甚至还可能需要避免它的super方法被调用。如果插件Activity不是一个真的Activity，只是一个跟Activity有差不多方法的普通类，这件事就简单多了，只需要让壳子Activity持有它，转调它就行了。但这种插件的代码正常编译成独立App安装运行会比较麻烦，代码中可能会出现很多插件相关的if-else，也不好。 热修复 热修复：热修复是体现在bug修复方面的，它实现的是不需要重新发版和重新安装，就可以去修复已知的bug。 Tinker实现原理简介： 在 DexPathList.findClass() 过程，一个Classloader可以包含多个dex文件，每个dex文件被封装到一个Element对象，这些Element对象排列成有序的数组dexElements。当查找某个类时，会遍历所有的dex文件，如果找到则直接返回，不再继续遍历dexElements。也就是说当两个类在不同的dex中出现，会优先处理排在前面的dex文件，这便是热修复的核心精髓，将需要修复的类所打包的dex文件插入到dexElements前面。 利用PathClassLoader和DexClassLoader去加载与bug类同名的类，替换掉bug类，进而达到修复bug的目的，原理是在app打包的时候阻止类打上CLASS_ISPREVERIFIED标志，然后在热修复的时候动态改变BaseDexClassLoader对象间接引用的dexElements，替换掉旧的类","link":"/2021/04/10/Pluggable-Hotfix/"},{"title":"serializable","text":"","link":"/2021/04/01/Serializable/"},{"title":"retrofit","text":"原理-动态代理*Retrofit通过 反射构建一个 接口的 实现类（动态代理本质就是反射），其中每个重写方法被调用时，都会回调到InvocationHandler.invoke中，invoke回调时（只要是不是object类中的方法）都会通过 获取到的方法的注解、方法的名称、方法的返回值、方法参数的注解、方法参数类型等等所需信息， 解析成一个ServiceMethod对象(放入缓存池)，ServiceMethod根据获取到的方法信息，构建OkHttp请求，并将结果通过converter转换后回调给最初传入的Callback* val service = retrofit.create(GitHubService::class.java) 123456789101112131415161718192021222324252627public &lt;T&gt; T create(final Class&lt;T&gt; service) { //校验数据，是否不是默认方法（公共非抽象方法） validateServiceInterface(service); return (T) //代理模式，通过反射 构建一个 实现了所有 传入interface的方法 的类，该类中每个方法都调用了传入InvacationHandler对象中invoke方法。 //即反射 构建一个 interfaces的实现类，该实现类中每个重写方法都由将自身的信息传给invoke方法，由invoke方法代理执行。 Proxy.newProxyInstance( service.getClassLoader(), new Class&lt;?&gt;[] {service}, new InvocationHandler() { private final Platform platform = Platform.get(); private final Object[] emptyArgs = new Object[0]; @Override public @Nullable Object invoke(Object proxy, Method method, @Nullable Object[] args) throws Throwable { // If the method is a method from Object then defer to normal invocation. if (method.getDeclaringClass() == Object.class) { return method.invoke(this, args); } args = args != null ? args : emptyArgs; return platform.isDefaultMethod(method) ? platform.invokeDefaultMethod(method, service, proxy, args) : loadServiceMethod(method).invoke(args); } });} 动态代理原理核心 API 是 Proxy 类和 InvocationHandler 接口。 它的原理是利用反射机制在运行时生成代理类的字节码。 动态代理的原理就是一个代理类文件的动态加载过程，由于JVM可以通过.class文件的二进制信息加载class对象的，那么如果我们在代码运行时，遵循.class文件的格式和结构，生成相应的二进制数据，然后再把这个二进制数据通过JVM加载成对应的class对象，有了class对象，我们就可以在运行时通过反射创建出代理对象的实例，这样就完成了在代码运行时，动态的创建一个代理对象的能力，这就是动态代理的原理。 https://juejin.cn/post/6974018412158664734 使用 创建一个interface作为Web Service 的请求集合，在里面用注解（Annotation)写入需要配置的请求方法 1234public interface GitHubService { @GET(&quot;users/{user}/repos&quot;) Call&lt;List&lt;Repo&gt;&gt; listRepos(@Path(&quot;user&quot;) String user);} 在正式代码里用 Retrofit 创建出interface的实例 1234Retrofit retrofit = new Retrofit.Builder() .baseUrl(&quot;https://api.github.com/&quot;) .build();GitHubService service = retrofit.create(GitHubService.class); 调用创建出的Service实例的对应方法，创建出相应的可以用来发起网络请求的call 对象Call&lt;List&lt;Repo&gt;&gt; repos = service.listRepos(&quot;octocat&quot;); 使用Call.execute()或者call.enqueue()来发起请求repos.enqueue(callback);","link":"/2021/04/08/Retrofit/"},{"title":"ServiceManager","text":"ServiceManager的启动ServiceManager进程service_manager.c并没有使用libbinder框架代码，而是自行编写了binder.c直接和Binder驱动来通信，ServiceManager是单线程的进程， 不断地循环在binder_loop()过程来读取和处理事务，从而对外提供查询和注册服务的功能，这样的好处是简单而高效。 123456789101112131415161718192021222324// service_manager.cint main(int argc, char **argv) { struct binder_state *bs; char *driver; if (argc &gt; 1) { driver = argv[1]; } else { driver = &quot;/dev/binder&quot;; // 默认的Binder设备节点 } //Step 1: 打开binder驱动，申请128k字节内存 bs = binder_open(driver, 128*1024); ... //Step 2: 成为上下文管理者 if (binder_become_context_manager(bs)) { return -1; } ... //Step 3: 进入无限循环，处理client端发来的请求 binder_loop(bs, svcmgr_handler); return 0;} 启动过程主要划分为以下几个阶段：(每个阶段具体见5.2.1 启动ServiceManager服务) 首先，打开设备驱动：调用binder_open()方法来打开binder驱动，默认地采用/dev/binder设备节点，申请地内存空间大小为128KB； 其次，注册成为大管家：调用binder_become_context_manager()方法，将自己注册成为binder服务的唯一管家； 通过ioctl系统调用向Binder驱动发送命令BINDER_SET_CONTEXT_MGR，成为上下文的管理者，由于servicemanager进程启动非常早（先于Zygote），可以确定在Binder整体机制正式投入产线之前，就能完成向Binder驱动注册成为大管家的工作。 关于驱动层处理BINDER_SET_CONTEXT_MGR命令的主要任务： 保证每个Binder上下文有且仅有一个binder管家实体，如果已存在则不再创建 创建binder管家实体，初始化异步事务和binder工作两个队列，并分别增加其强弱引用计数 初始化当前binder_context的管家实体（binder_context_mgr_node）和管家uid(binder_context_mgr_uid)信息 handle等于0的服务实体都是指servicemanager管家实体 最后，等待客户请求：调用binder_loop()方法进入无限循环，作为守护进程，随时待命等待处理client端发来的请求。 servicemanager先向Binder驱动发送BC_ENTER_LOOPER协议，让ServiceManager进入循环。然后再向驱动发送BINDER_WRITE_READ命令， 进入内核态，等待客户端的请求数据。若没有数据，则进入等待状态，直到收到数据后返回用户态，解析并处理，周而复始地不断循环该过程。 123456789101112131415161718192021222324// servicemanager/binder.cvoid binder_loop(struct binder_state *bs, binder_handler func) { int res; struct binder_write_read bwr; uint32_t readbuf[32]; bwr.write_size = 0; bwr.write_consumed = 0; bwr.write_buffer = 0; readbuf[0] = BC_ENTER_LOOPER; //向binder驱动发送BC_ENTER_LOOPER协议 binder_write(bs, readbuf, sizeof(uint32_t)); for (;;) { bwr.read_size = sizeof(readbuf); bwr.read_consumed = 0; bwr.read_buffer = (uintptr_t) readbuf; //等待客户的数据 res = ioctl(bs-&gt;fd, BINDER_WRITE_READ, &amp;bwr); //解析binder信息 res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func); }} ServiceManager提供的服务ServiceManager对外提供查询/注册功能，通过接收到客户端进程发送过来的BR_TRANSACTION协议。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// service_manager.cint svcmgr_handler(struct binder_state *bs, struct binder_transaction_data *txn, struct binder_io *msg, struct binder_io *reply){ struct svcinfo *si; uint16_t *s; size_t len; uint32_t handle; uint32_t strict_policy; int allow_isolated; ... strict_policy = bio_get_uint32(msg); s = bio_get_string16(msg, &amp;len); ... switch(txn-&gt;code) { case SVC_MGR_GET_SERVICE: case SVC_MGR_CHECK_SERVICE: s = bio_get_string16(msg, &amp;len); //服务名 //根据名称查找相应服务 handle = do_find_service(bs, s, len, txn-&gt;sender_euid, txn-&gt;sender_pid); bio_put_ref(reply, handle); return 0; case SVC_MGR_ADD_SERVICE: s = bio_get_string16(msg, &amp;len); //服务名 handle = bio_get_ref(msg); //服务实体在servicemanager中的handle allow_isolated = bio_get_uint32(msg) ? 1 : 0; //注册指定服务 if (do_add_service(bs, s, len, handle, txn-&gt;sender_euid, allow_isolated, txn-&gt;sender_pid)) return -1; break; case SVC_MGR_LIST_SERVICES: { uint32_t n = bio_get_uint32(msg); if (!svc_can_list(txn-&gt;sender_pid)) { return -1; } si = svclist; while ((n-- &gt; 0) &amp;&amp; si) si = si-&gt;next; if (si) { bio_put_string16(reply, si-&gt;name); return 0; } return -1; } } bio_put_uint32(reply, 0); return 0;} 该方法的功能：查询服务，注册服务，以及列举所有服务。不同的code对应不同的工作，定义在IBinder.h文件，跟IServiceManager.h中定义的code具有一一对应关系，具体关系如下所示。 code IBinder.h IServiceManager.h 1 SVC_MGR_GET_SERVICE GET_SERVICE_TRANSACTION 2 SVC_MGR_CHECK_SERVICE CHECK_SERVICE_TRANSACTION 3 SVC_MGR_ADD_SERVICE ADD_SERVICE_TRANSACTION 4 SVC_MGR_LIST_SERVICES LIST_SERVICES_TRANSACTION ServiceManagerservicemanager进程里面有一个链表svclist，记录着所有注册的服务svcinfo，每一个服务用svcinfo结构体来表示，该handle值是在注册服务的过程中，由服务所在进程那一端所确定的。svcinfo结构体如下所示。 123456789struct svcinfo{ struct svcinfo *next; uint32_t handle; //服务的handle值 struct binder_death death; int allow_isolated; size_t len; //服务名的长度 uint16_t name[0]; //服务名}; 整个ServiceManager启动过程的完整流程，这里整个过程都的都离不开Binder驱动层的实现。 Othervndservicemanager以前，Binder 服务通过 servicemanager 注册，其他进程可从中检索这些服务。在 Android 8 中，servicemanager 现在专供框架使用，而应用进程和供应商进程无法再对其进行访问。 不过，供应商服务现在可以使用 vndservicemanager，这是一个使用 /dev/vndbinder（作为构建基础的源代码与框架 servicemanager 的相同）而非 /dev/binder 的 servicemanager 的新实例。供应商进程无需更改即可与 vndservicemanager 通信；当供应商进程打开 /dev/vndbinder 时，服务查询会自动转至 vndservicemanager。 vndservicemanager 二进制文件包含在 Android 的默认设备 Makefile 中。","link":"/2023/12/20/ServiceManager/"},{"title":"Socket","text":"Socket1 什么是Socket 网络上的两个程序通过一个双向的通讯连接实现数据的交换，这个双向链路的一端称为一个Socket。Socket通常用来实现客户方和服务方的连接。Socket是TCP/IP协议的一个十分流行的编程界面，一个Socket由一个IP地址和一个端口号唯一确定。 但是，Socket所支持的协议种类也不光TCP/IP、UDP，因此两者之间是没有必然联系的。在Java环境下，Socket编程主要是指基于TCP/IP协议的网络编程。 socket连接就是所谓的长连接，客户端和服务器需要互相连接，理论上客户端和服务器端一旦建立起连接将不会主动断掉的，但是有时候网络波动还是有可能的 Socket偏向于底层。一般很少直接使用Socket来编程，框架底层使用Socket比较多， 2 socket属于网络的那个层面 Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个外观模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。 3 Socket通讯的过程 基于TCP：服务器端先初始化Socket，然后与端口绑定(bind)，对端口进行监听(listen)，调用accept阻塞，等待客户端连接。在这时如果有个客户端初始化一个Socket，然后连接服务器(connect)，如果连接成功，这时客户端与服务器端的连接就建立了。客户端发送数据请求，服务器端接收请求并处理请求，然后把回应数据发送给客户端，客户端读取数据，最后关闭连接，一次交互结束。 基于UDP：UDP 协议是用户数据报协议的简称，也用于网络数据的传输。虽然 UDP 协议是一种不太可靠的协议，但有时在需要较快地接收数据并且可以忍受较小错误的情况下，UDP 就会表现出更大的优势。我客户端只需要发送，服务端能不能接收的到我不管 4 TCP协议Socket代码示例：先运行服务端，在运行客户端 服务端： 123456789101112131415161718192021222324252627282930313233343536373839package com.test.io;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;//TCP协议Socket使用BIO进行通行：服务端public class BIOServer { // 在main线程中执行下面这些代码 public static void main(String[] args) { //1单线程服务 ServerSocket server = null; Socket socket = null; InputStream in = null; OutputStream out = null; try { server = new ServerSocket(8000); System.out.println(&quot;服务端启动成功，监听端口为8000，等待客户端连接...&quot;); while (true){ socket = server.accept(); //等待客户端连接 System.out.println(&quot;客户连接成功，客户信息为：&quot; + socket.getRemoteSocketAddress()); in = socket.getInputStream(); byte[] buffer = new byte[1024]; int len = 0; //读取客户端的数据 while ((len = in.read(buffer)) &gt; 0) { System.out.println(new String(buffer, 0, len)); } //向客户端写数据 out = socket.getOutputStream(); out.write(&quot;hello!&quot;.getBytes()); } } catch (IOException e) { e.printStackTrace(); } }} 客户端： 12345678910111213141516171819202122232425package com.test.io;import java.io.IOException;import java.io.OutputStream;import java.net.Socket;import java.util.Scanner;//TCP协议Socket：客户端public class Client01 { public static void main(String[] args) throws IOException { //创建套接字对象socket并封装ip与port Socket socket = new Socket(&quot;127.0.0.1&quot;, 8000); //根据创建的socket对象获得一个输出流 OutputStream outputStream = socket.getOutputStream(); //控制台输入以IO的形式发送到服务器 System.out.println(&quot;TCP连接成功 \\n请输入：&quot;); while(true){ byte[] car = new Scanner(System.in).nextLine().getBytes(); outputStream.write(car); System.out.println(&quot;TCP协议的Socket发送成功&quot;); //刷新缓冲区 outputStream.flush(); } }} 先运行服务端，在运行客户端。测试结果发送成功： · 5 UDP协议Socket代码示例：1先运行服务端，在运行客户端 服务端： 1234567891011121314151617181920212223//UDP协议Socket：服务端public class Server1 { public static void main(String[] args) { try { //DatagramSocket代表声明一个UDP协议的Socket DatagramSocket socket = new DatagramSocket(8888); //byte数组用于数据存储。 byte[] car = new byte[1024]; //DatagramPacket 类用来表示数据报包DatagramPacket DatagramPacket packet = new DatagramPacket(car, car.length); // //创建DatagramPacket的receive()方法来进行数据的接收,等待接收一个socket请求后才执行后续操作； System.out.println(&quot;等待UDP协议传输数据&quot;); socket.receive(packet); //packet.getLength返回将要发送或者接收的数据的长度。 int length = packet.getLength(); System.out.println(&quot;啥东西来了：&quot; + new String(car, 0, length)); socket.close(); System.out.println(&quot;UDP协议Socket接受成功&quot;); } catch (IOException e) { e.printStackTrace(); } }} 客户端： 123456789101112131415161718192021//UDP协议Socket：客户端public class Client1 { public static void main(String[] args) { try { //DatagramSocket代表声明一个UDP协议的Socket DatagramSocket socket = new DatagramSocket(2468); //字符串存储人Byte数组 byte[] car = &quot;UDP协议的Socket请求，有可能失败哟&quot;.getBytes(); //InetSocketAddress类主要作用是封装端口 InetSocketAddress address = new InetSocketAddress(&quot;127.0.0.1&quot;, 8888); //DatagramPacket 类用来表示数据报包DatagramPacket DatagramPacket packet = new DatagramPacket(car, car.length, address); //send() 方法发送数据包。 socket.send(packet); System.out.println(&quot;UDP协议的Socket发送成功&quot;); socket.close(); } catch (Exception e) { e.printStackTrace(); } }} 先运行服务端，在运行客户端。测试结果成功发送成功： 6 Socket的常用类 类名 用于 作用 Socket TCP协议 Socket类同时工作于客户端和服务端，所有方法都是通用的，这个类三个主要作用，校验包信息，发起连接（Client），操作流数据（Client/Server） ServerSocket TCP协议 ServerSocket表示为服务端，主要作用就是绑定并监听一个服务器端口，为每个建立连接的客户端“克隆/映射”一个Socket对象，具体数据操作都是通过这个Socket对象完成的，ServerSocket只关注如何和客户端建立连接 DatagramSocket UDP协议 DatagramSocket 类用于表示发送和接收数据报包的套接字。 DatagramPacket UDP协议 DatagramPacket 类用来表示数据报包，数据报包用来实现无连接包投递服务。 InetAddress IP+端口号 Java提供了InetAddress类来代表互联网协议（IP）地址，InetAddress类没有提供构造器，而是提供了如下两个静态方法来获取InetAddress实例： InetSocketAddress IP+端口号 在使用Socket来连接服务器时最简单的方式就是直接使用IP和端口，但Socket类中并未提供这种方式，而是靠SocketAddress的子类InetSocketAddress来实现 IP 地址 + 端口号的创建，不依赖任何协议。","link":"/2021/11/11/Socket/"},{"title":"recyclerView","text":"缓存机制简述： 一级缓存为屏内缓存，分为没有变化的可以直接复用的ViewHolder和被notifyXXX标记为需要重新绑定的ViewHolder； 二级缓存为离屏2个的ViewHolder缓存，直接复用 三级缓存为自定义缓存，较少用 四级缓存为超出上述缓存的需要重新绑定的ViewHolder Recyclerview缓存集合可以分为 4 个级别，按优先级从高到底为： 一级缓存：mAttachedScrap 和 mChangedScrap ，用来缓存还在屏幕内的 ViewHolder mAttachedScrap 存储的是当前还在屏幕中的 ViewHolder；按照 id 和 position 来查找 ViewHolder mChangedScrap 表示数据已经改变的 ViewHolder 列表, 存储 notifyXXX 方法时需要改变的 ViewHolder 二级缓存：mCachedViews ，用来缓存移除屏幕之外的 ViewHolder，默认情况下缓存容量是 2，可以通过 setViewCacheSize 方法来改变缓存的容量大小。如果 mCachedViews 的容量已满，则会根据 FIFO 的规则移除旧 ViewHolder 三级缓存：ViewCacheExtension ，开发给用户的自定义扩展缓存，需要用户自己管理 View 的创建和缓存。个人感觉这个拓展脱离了 Adapter.createViewHolder 使用的话会造成 View 创建 与 数据绑定及其它代码太分散，不利于维护，使用场景很少仅做了解 四级缓存：RecycledViewPool ，ViewHolder 缓存池，在有限的 mCachedViews 中如果存不下新的 ViewHolder 时，就会把 ViewHolder 存入RecyclerViewPool 中。 按照 Type 来查找 ViewHolder 每个 Type 默认最多缓存 5 个 可以多个 RecyclerView 共享 RecycledViewPool 1.1、四级缓存Recycler缓存ViewHolder对象有4个等级，优先级从高到底依次为： 一级、mAttachedScrap：缓存屏幕中可见范围的ViewHolder；二级、mCachedViews：缓存滑动时即将与RecyclerView分离的ViewHolder，默认最大2个；三级、ViewCacheExtension：自定义实现的缓存；四级、RecycledViewPool ：ViewHolder缓存池，可以支持不同的ViewType； 一级缓存：mAttachedScrap与mChangedScrap1.1.1 mAttachedScrap （完全复用）mAttachedScrap存储的是当前屏幕中的ViewHolder，mAttachedScrap的对应数据结构是ArrayList，在调用LayoutManager#onLayoutChildren方法时对views进行布局，此时会将RecyclerView上的Views全部暂存到该集合中，该缓存中的ViewHolder的特性是，如果和RV上的position或者itemId匹配上了那么可以直接拿来使用的，无需调用onBindViewHolder方法。 1.1.2 mChangedScrap （需要onBindViewHolder）mChangedScrap和mAttachedScrap属于同一级别的缓存，不过mChangedScrap的调用场景是notifyItemChanged和notifyItemRangeChanged，只有发生变化的ViewHolder才会放入到mChangedScrap中。mChangedScrap缓存中的ViewHolder是需要调用onBindViewHolder方法重新绑定数据的。 二级缓存： mCachedViews （完全复用）mCachedViews缓存滑动时即将与RecyclerView分离的ViewHolder，按子View的position或id缓存，默认最多存放2个。mCachedViews对应的数据结构是ArrayList，但是该缓存对集合的大小是有限制的。 该缓存中ViewHolder的特性和mAttachedScrap中的特性是一样的，只要position或者itemId对应就无需重新绑定数据。开发者可以调用setItemViewCacheSize(size)方法来改变缓存的大小，该层级缓存触发的一个常见的场景是滑动RecyclerView。当然调用notify()也会触发该缓存。 三级缓存： ViewCacheExtensionViewCacheExtension是需要开发者自己实现的缓存，基本上页面上的所有数据都可以通过它进行实现。 四级缓存： RecyclerViewPool （重新onBindViewHolder）ViewHolder缓存池，本质上是一个SparseArray，其中key是ViewType(int类型)，value存放的是 ArrayList&lt; ViewHolder&gt;，默认每个ArrayList中最多存放5个ViewHolder。 1.2 四级缓存对比 缓存级别 涉及对象 说明 是否重新创建视图View 是否重新绑定数据 一级缓存 mAttachedScrap mChangedScrap 缓存屏幕中可见范围的ViewHolder false mAttachedScrap不需要mChangedScrap需要 二级缓存 mCachedViews 缓存滑动时即将与RecyclerView分离的ViewHolder，按子View的position或id缓存 false false 三级缓存 mViewCacheExtension 开发者自行实现的缓存 四级缓存 mRecyclerPool ViewHolder缓存池，本质上是一个SparseArray，其中key是ViewType(int类型)，value存放的是 ArrayList&lt; ViewHolder&gt;，默认每个ArrayList中最多存放5个ViewHolder false true ItemDecorationgetItemOffsets()view之间的分割距离 1234567891011121314151617181920212223242526RecyclerView.java { Rect getItemDecorInsetsForChild(View child) { final LayoutParams lp = (LayoutParams) child.getLayoutParams(); if (!lp.mInsetsDirty) { return lp.mDecorInsets; } if (mState.isPreLayout() &amp;&amp; (lp.isItemChanged() || lp.isViewInvalid())) { // changed/invalid items should not be updated until they are rebound. return lp.mDecorInsets; } final Rect insets = lp.mDecorInsets; insets.set(0, 0, 0, 0); final int decorCount = mItemDecorations.size(); for (int i = 0; i &lt; decorCount; i++) { mTempRect.set(0, 0, 0, 0); mItemDecorations.get(i).getItemOffsets(mTempRect, child, this, mState); insets.left += mTempRect.left; insets.top += mTempRect.top; insets.right += mTempRect.right; insets.bottom += mTempRect.bottom; } lp.mInsetsDirty = false; return insets; }} onDraw、onDrawOver由于View绘制顺序是(忽视未标出的不常用步骤)： 1234567891011121314151617181920212223View.java { public void draw(Canvas canvas) { // Step 1, draw the background, if needed drawBackground(canvas); // Step 3, draw the content onDraw(canvas); // Step 4, draw the children dispatchDraw(canvas); // Step 6, draw decorations (foreground, scrollbars) onDrawForeground(canvas); }}RecyclerView.java { public void onDraw(Canvas c) { super.onDraw(c); final int count = mItemDecorations.size(); for (int i = 0; i &lt; count; i++) { mItemDecorations.get(i).onDraw(c, this, mState); } }} 其中，RecyclerView.onDraw会先绘制ItemDecoration.onDraw，然后再走dispatchDraw绘制子View（即itemView) 故而，ItemDecoration的onDraw内容是会被itemView所遮挡，如有需要，调用onDrawOver可覆盖itemView的onDraw内容。 ​ 优化措施：1、预取机制Prefetch : 引入RenderThread后，在UI线程将页面数据交由Render线程渲染以后，UI线程会出现大量的空闲时间这些空闲等待时间就被浪费了。Prefetch的核心思想就是利用这部分空闲时间来预先处理 item的创建（如果没有缓存）和数据绑定。 对比一下使用了Prefetch以后的渲染时序图如下： 在UI线程将页面数据交由Render线程渲染以后，会出现大量的空闲时间。如下图所示： 时空上的复用，会大大提高页面渲染的效率，提高页面流畅度。 该机制是默认打开的，但如果出现rv嵌套rv的情况，由于情况较为复杂，需要我们手动调用setInitialPrefetchItemCount 就是指定这个recyclerview预取时的数量（合适的），来达到更好的加载效果。 setInitialPrefetchItemCount这个API可以设置预加载的Item数，使用这个API有三个前提： 1：当前recyclerview是嵌套在另一个Recyclerview之中的； 2：当前recyclerview是LinearLayoutManager并且横向的（只有LinearLayoutManager 才有这个API）； 3：Android 5.0（引入RenderThread，并默认打开recyclerview的mItemPrefetchEable） 2、setHasFixedSize(true)如果Recyclerview的宽高不会随着它的内容改变而改变，则可以用这个API，避免不必要的requestLayout带来的性能消耗。（notifydatasetchange无效） 1234567void onItemsInsertedOrRemoved() { if (hasFixedSize) layoutChildren(); else requestLayout(); } 3、尽量使用notifyItemChange而非notifyDataSetChange数据变化有两种情况： 一种是item change 一种是 structure change； 前者是单个item数据更新但不会导致位置变换； 后者是数据集中items 发生插入，删除，移动的情况下。 Notifydatasetchange认为现有所有的现有项和结构不再有效，会使Layoutmanager强制完全重新绑定和重新布局所有的可见item。 Google建议尽量使用刷新特定itemchange的高效方法。而把此方法视为可以用的最后的手段。 4、RecyclerView RecycledViewPool复用其实就是让一个Recyclerview 可以复用其他具有相同ViewType的Recyclerview。 5、DiffUtil DifferResult.dispatchUpdatesTo(final RecyclerView.Adapter adapter) 或者 AysncListData.submitList() 走到最后其实也是 notifyItemChanged(); ​ notifyItemInserted(); ​ notifyItemRangeRemoved(); ​ notifyItemMoved(); 6、other 如果发现item因为measure任务过重，可以通过自定义view来优化此item，比如说一个ViewHolder里面有很多标签的情况。 在快速滑动时不加载网络图片或停止gif图和视频的播放 设置合适的缓存策略","link":"/2021/10/15/RecyclerView/"},{"title":"Surface","text":"SurfaceView: View 的子类，但不与宿主 Window 共享 Surface, 而是有自己独立的 Surface, 且可以在一个独立的线程中进行绘制，因此 SurfaceView 一般用来实现比较复杂的图像或动画/视频的显示。可以参考 Android双缓存与SurfaceView。由于其内容是绘制在一个独立的 Surface 上，因此无法用 scrollTo/By 等方法去移动操作 Canvas 里的内容，但是可对整个 View 进行平移，缩放，旋转等变换操作。 GLSurfaceView: 基于 SurfaceView 再次进行扩展，在 SurfaceView 基础上封装了 EGL 环境管理以及 Render 线程，专门为 OpenGl 显示渲染使用。参考 Android-OpenGL-ES笔记。 TextrueView: Android 4.0 后引入 TextureView, 它将 SurfaceTexture 和 View 结合到了一起。与 SurfaceView 相比，它并没有创建一个单独的 Surface 来绘制，解决了 SurfaceView 无法在 Canvas 内容上做动画的问题。另外 TextureView 必须在硬件加速开启的窗口中使用。 View的完整工作流程，从cpu计算控件数据，到surfaceFlinger合成这些数据，再到vsync信号达到后开始绘制（见/ScreenDraw章）； SurfaceWindow的核心变量。 Android 系统采用一种称为 Surface 的图形架构，简而言之，每一个 Activity 都关联有至少一个 Window（窗口），每一个 Window 都对应有一个 Surface。 Surface 这里直译过来叫做 绘图表面 ，顾名思义，其可在内存中生成一个图形缓冲区队列，用于描述 UI，经与系统服务的WindowServiceManager 通信后、通过 SurfaceFlinger 服务持续合成并送显到显示屏。 由此可见，通常情况下，一个 Activity 的 UI 渲染本质是 系统提供一块内存，并创建一个图形缓冲区进行维护；这块内存就是 Surface，最终页面所有 View 的 UI 状态数据，都会被填充到同一个 Surface 中。 SurfaceView &amp; TextureViewSurfaceView 本身的输出不是通过 Android 的 UI Renderer（HWUI），而是直接走系统的窗口合成器 SurfaceFlinger， //暂时CV，待完善 1 SurfaceSurface 就是“表面”的意思，可以简单理解为内存中的一段绘图缓冲区。在 SDK 的文档中，对 Surface 的描述是这样的：“Handle onto a raw buffer that is being managed by the screen compositor”，意思是“由屏幕显示内容合成器（screen compositor）所管理的原生缓冲器的句柄”， 这句话包括下面两个意思： 通过 Surface（因为 Surface 是句柄）就可以获得原生缓冲器以及其中的内容。就像在C语言中，可以通过一个文件的句柄，就可以获得文件的内容一样； 原生缓冲器（rawbuffer）是用于保存当前窗口的像素数据的。 简单的说 Surface 对应了一块屏幕缓冲区，每个 Window 对应一个 Surface，任何 View 都是画在 Surface 上的，传统的 view 共享一块屏幕缓冲区，所有的绘制必须在 UI 线程中进行。我们不能直接操作 Surface 实例，要通过 SurfaceHolder，在 SurfaceView 中可以通过 getHolder() 方法获取到 SurfaceHolder 实例。 Surface 是一个用来画图形的地方，但是我们知道画图都是在一个 Canvas 对象上面进行的，Surface 中的 Canvas 成员，是专门用于提供画图的地方，就像黑板一样，其中的原始缓冲区是用来保存数据的地方。 Surface 本身的作用类似一个句柄，得到了这个句柄就可以得到其中的Canvas、原始缓冲区以及其他方面的内容，所以简单的说 Surface 是用来管理数据的（句柄）。 说完 surface 就可以说 SurfaceView 了。 2 SurfaceView2.1 SurfaceView 简介简单的说 SurfaceView 就是一个有 Surface 的 View，SurfaceView 控制这个 Surface 的格式和尺寸以及绘制位置。传统 View 及其派生类的更新只能在 UI 线程，然而 UI 线程还同时处理其他交互逻辑，这就无法保证 view 更新的速度和帧率了，而 SurfaceView 可以用独立的线程来进行绘制。因此可以提供更高的帧率，例如游戏，摄像头取景等场景就比较适合用 SurfaceView 来实现。 SurfaceView 的核心在于提供了两个线程：UI线程和渲染线程，两个线程通过“双缓冲”机制来达到高效的界面刷新效果。 2.2 SurfaceView 实现机制SurfaceView 继承自 View，所以它也是一个 View。但是这个 View 和普通的 View 有点不同。SurfaceView 有自己的 Surface，在 Android 中，一个 View 有自己的 Surface，在 WMS 中中就有对应的 WindowState，对应在 SurfaceFlinger 中就有 Layer。 一般的 Activity 包含的多个 View 会组成 View hierachy 的树形结构，只有最顶层的 DectorView 才是对 WMS 可见的，这个 DecorView 在 WMS 中有一个对应的 WindowState，相应的，在 SurfaceFlinger 中有对应的 Layer。而 SurfaceView 正因为它有自己的 Surface，有自己的 Window，它在 WMS 中有对应的 WindowState，在 SurfaceFlinger 中有 Layer。 虽然在 App 端它仍在 View hierachy 中，但在 Server 端（WMS 和 SurfaceFlinger）中，它与宿主窗口是分离的。这样的好处是对这个 Surface 的渲染可以放到单独的线程中去做，渲染时可以有自己的 GL context。这对于一些游戏、视频等性能相关的应用非常有益，因为它不会影响主线程对事件的响应。 但是这也有缺点，因为这个 Surface 不在 View hierachy 中，它的显示也不受 View 的属性控制，所以不能进行平移、缩放等动画，它也不能放在其它 ViewGroup 中，SurfaceView 不能嵌套使用，而且不能使用某些 View 的特性，例如 View.setAlpha()。 从 Android7.0 开始，SurfaceView 的窗口位置与其他 View 渲染同步更新。这意味着在屏幕上平移和缩放 SurfaceView 不会导致渲染失真。 3 TextureView因为上面所说的 SurfaceView 不在主窗口中，它没法做动画没法使用一些 View 的特性方法，所以在 Android 4.0中引入了 TextureView，它是一个结合了 View 和 SurfaceTexture 的 View 对象。 TextureView 是一个可以把内容流作为外部纹理输出在上面的 View，和 SurfaceView 不同，它不会在 WMS 中单独创建窗口，而是作为 View hierachy 中的一个普通 view，因此它可以和其他普通 View 一样进行平移、旋转、缩放等动画。但是 TextureView 必须在硬件加速的窗口中，它显示的内容流数据可以来自 App 进程或者远程进程。 TextureView 继承自 View，它与其它的 View 一样在 View hierachy 中管理与绘制。TextureView 重载了 draw() 方法，其中主要 SurfaceTexture 中收到的图像数据作为纹理更新到对应的 HardwareLayer 中。 SurfaceTexture.OnFrameAvailableListener 用于通知 TextureView 内容流有新图像到来。SurfaceTextureListener 接口用于让 TextureView 的使用者知道 SurfaceTexture 已准备好，这样就可以把 SurfaceTexture 交给相应的内容源。 Surface 为 BufferQueue 的 Producer 接口实现类，使生产者可以通过它的软件或硬件渲染接口为 SurfaceTexture 内部的 BufferQueue 提供 graphic buffer。 SurfaceTexture 可以用作非直接输出的内容流，这样就提供二次处理的机会。与 SurfaceView 直接输出相比，这样会有若干帧的延迟。同时，由于它本身管理 BufferQueue，因此内存消耗也会稍微大一些。 4 SurfaceTextureSurfaceTexture 是 Surface 和 OpenGL ES(GLES) 纹理的组合。SurfaceTexture 用于提供输出到 GLES 纹理的 Surface。 SurfaceTexture 是从 Android 3.0(API level 11)开始加入，与 SurfaceView 不同的是，它对图像流的处理并不直接显示，而是转为 GL 外部纹理，因此用于图像流数据的二次处理。 比如 Camera 的预览数据，变成纹理后可以交给 GLSurfaceView 直接显示，也可以通过 SurfaceTexture 交给TextureView 作为 View heirachy 中的一个硬件加速层来显示。 首先，SurfaceTexture 从图像流 （来自 Camera 预览、视频解码、GL 绘制场景等）中获得帧数据，当调用updateTexImage()时，根据内容流中最近的图像更新 SurfaceTexture 对应的 GL 纹理对象。 SurfaceTexture 包含一个应用是其使用方的 BufferQueue。当生产方将新的缓冲区排入队列时，onFrameAvailable() 回调会通知应用。然后，应用调用 updateTexImage()，这会释放先前占有的缓冲区，从队列中获取新缓冲区并执行 EGL 调用，从而使 GLES 可将此缓冲区作为外部纹理使用。 5 SurfaceView 与 TextureView 的对比 项目 SurfaceView TextureView 内存 低 高 耗电 低 高 绘制 及时 1-3帧延迟 动画和截图 不支持 支持 从性能和安全性角度出发，优先选 SurfaceView，TextureView 是一个不得已的选择： 在 Android 7.0 上系统 Surfaceview 的性能比 TextureView 更有优势，支持对象的内容位置和包含的应用内容同步更新，平移、缩放不会产生黑边。 在7.0以下系统如果使用场景有动画效果，可以选择性使用TextureView。 由于失效（invalidation）和缓冲的特性，TextureView 增加了额外1~3帧的延迟显示画面更新。 TextureView 总是使用 GL 合成，而 SurfaceView 可以使用硬件 overlay 后端，可以占用更少的内存。 TextureView 的内部缓冲队列导致比 SurfaceView 使用更多的内存。 SurfaceView 内部自己持有 Surface，Surface 创建、销毁、大小改变时系统来处理的，通过 SurfaceHolder 的 callback 回调通知。 当画布创建好时，可以将 surface 绑定到 MediaPlayer 中。SurfaceView 如果为用户可见的时候，创建 SurfaceView 的 SurfaceHolder 用于显示视频流解析的帧图片，如果发现 SurfaceView 变为用户不可见的时候，则立即销毁 SurfaceView 的 SurfaceHolder，以达到节约系统资源的目的。 作者：ByteSaid链接：https://juejin.cn/post/7156157715230752782来源：稀土掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 SurfaceFlinger SurfaceFlinger 接受缓冲区，对它们进行合成，然后发送到屏幕。WindowManager 为 SurfaceFlinger 提供缓冲区和窗口元数据，而 SurfaceFlinger 可使用这些信息将 Surface 合成到屏幕。 SurfaceFlinger 用来管理消费当前可见的 Surface, 所有被渲染的可见 Surface 都会被 SurfaceFlinger 通过 WindowManager 提供的信息合成(使用 OpenGL 和 HardWare Composer)提交到屏幕的后缓冲区，等待屏幕的下一个 Vsync 信号到来，再显示到屏幕上。SufaceFlinger 通过屏幕后缓冲区与屏幕建立联系，同时通过 Surface 与上层建立联系，起到了一个承上启下的作用。 启动在 SurfaceFlinger 的启动流程中： 首先会创建 SurfaceFlinger 对象，在构造器中创建了 DispSync 同步模型对象； 然后执行初始化 SurfaceFlinger 的逻辑： 注册监听，接收 HWC 的相关事件。 启动 APP 和 SF 的 EventThread 线程，用来管理基于 DispSync 创建的两个 DispSyncSource 延时源对象，分别是用于绘制(app–mEventThreadSource)和合成(SurfaceFlinger–mSfEventThreadSource)。启动了 EventThread 线程后，会一直阻塞在 waitForEventLocked 方法中(期间会根据需要设置监听器)，直到接收到 Vsync 信号且至少有一个连接正在等待 Vsync 信号才会继续执行线程逻辑，即通知监听者； 通过 MessageQueue.setEventThread 方法创建了一个连接，并通过 Looper.addFd 方法监听 BitTube 数据。 创建 HWComposer 对象(通过 HAL 层的 HWComposer 硬件模块 或 软件模拟产生 Vsync 信号)，现在的 Android 系统基本上都可以看成是通过硬件 HWComposer 产生 Vsync 信号，而不使用软件模拟，所以下面解析都只谈及硬件 HWComposer 的 Vsync 信号； 初始化非虚拟的显示屏； 启动开机动画服务； 最后执行 SurfaceFlinger.run 逻辑，该方法会在 SurfaceFlinger 主线程通过死循环执行 MessageQueue.waitMessage 方法等待消息的到来，其内部调用了 Looper.pollOnce 方法，该方法会从 Looper.addFd 方法监听的 BitTube 中读取数据，当有数据到来时执行对应的回调方法。 当硬件或软件模拟发出 Vsync 信号时： 回调 SF 相关方法，SF 调用 DispSync 同步模型的方法处理 Vsync 信号(统计和计算模型的偏移和周期)，并根据返回值判断是否使能/关闭 HWC Vsync 信号的发出。 DispSync 根据计算的偏移和周期计算下次 Vsync 信号发生时间，并通知监听者 Vsync 信号到达的事件，传递给 DispSyncSource 延时源，延时源通过 EventThread 来管理 Vsync 信号的收发。 EventThread 调用连接 Connection 对象向 BitTube 发送数据，触发 addFd 函数中设置的回调方法，回调方法进而调用 SF.onMessageReceived 函数，然后进行图像的合成等工作。 另一方面，Choreographer 会通过上面创建的 APP 延时源 mEventThreadSource 对象及其对应的 EventThread 线程来监听同步模拟发出的 Vsync 信号，然后进行绘制(measure/layout/draw)操作。具体逻辑见 Android-Choreographer原理。 将 SurfaceFlinger 的工作流程总结如下图： 合成BufferQueue","link":"/2021/07/29/Surface/"},{"title":"SystemStartProcess","text":"简述： 开机后系统将Rom文件加载进Ram内存中，loader检查Ram，kernel启动Swapper进程和kthreadd进程（创建内核守护进程）。 NativeFramework中init.cpp运行后启动init进程，init进程解析init.rc文件后，孵化如installd、logd、adbd等用户守护进程、启动servicemanager、surfaceflinger、bootanim等服务、孵化出Zygote虚拟机进程(java进程)。 JavaFramework中Zygote注册ZygoteSocket、加载虚拟机、预加载通用类、资源；之后孵化system_server进程，启动如AMS(startService可监听RootPhase)、WMS、PKMS、PMS等服务。 App：由Zygote孵化的第一个App——Launcher(桌面)，用户点击Launcher上的app图片，通过JNI调用AMS从Zygote进程中fork出新的App。 ps:ServiceManager.addService()启动WMS、PKMS、IMS等服务，SystemServiceManager.startService()启动AMS、PMS 系统启动流程：BootRom-&gt;BootLoader-&gt;Linux Kernel-&gt;Init-&gt;Zygote-&gt;SystemServer-&gt;Launcher(UI) BootLoader层：主要包括Boot Rom和Boot Loader Kernel层：主要是Android内核层 Native层：主要是包括init进程以及其fork出 来的用户空间的守护进程、HAL层、开机动画等 JAVA Framework层：主要是AMS、WMS、PMS等Service的初始化 Application层：主要指SystemUI、Launcher的启动 电源键按下 -&gt; Loader &amp; Kernel BootLoader 加载 rom 到 ram linux内核进程 - 创建swapper(pid=0) ;内核守护进程kthreadd(pid=2) 与 各类驱动如binder driver -&gt; native framework init(pid=1)进程， 解析并运行所有的init.rc相关文件，孵化出installd、adbd等用户守护进程；启动zygote、servicemanager和surfaceflinger服务进程；孵化Zygote进程(java) init进程会孵化出ueventd、logd、healthd、installd、adbd、lmkd等用户守护进程； init进程还启动servicemanager、surfaceflinger、bootanim(开机动画)等重要服务进程 init进程孵化出Zygote进程，Zygote进程是Android系统的第一个Java进程(即虚拟机进程) (Native FrameWork层)Media Server进程，是由init进程fork而来，负责启动和管理整个C++ framework，包含AudioFlinger，Camera Service等服务。 -&gt; java framework - Zygote Zygote （创建虚拟机AndroidRunTime/VM + 预加载类和资源 ，同时所有app进程，包括”第一个app：桌面/Launch”，由zygote fork出，继承zygote拥有的一切） Zygote进程，是由init进程通过解析init.rc文件后fork生成的，Zygote进程主要包含： 加载ZygoteInit类，注册Zygote Socket服务端套接字 加载虚拟机 Dalivk/ART 提前加载类preloadClasses 提前加载资源preloadResouces -&gt; java framework - system_server system_server (因从zygote fork而来，故具有AndroidRunTime/VM 与预加载的类与资源 copy on write机制 ，由此开始启动线程承载ActivityManager，WindowManager，PackageManager，PowerManager等服务。管理所有app) System Server进程，是由Zygote进程fork而来，System Server是Zygote孵化的第一个进程，System Server负责启动和管理整个Java framework，包含ActivityManager，WindowManager，PackageManager，PowerManager等服务（通过context.getSystemService(String)可获得）。 附录 init启动过程init.cpp进程解析的init.rc文件 init进程是Linux系统中用户空间的第一个进程，进程号固定为1。Kernel启动后，在用户空间启动init进程，并调用init中的main()方法执行init进程的职责。对于init进程的功能分为4部分： 创建一块共享的内存空间，用于属性服务器; 解析并运行所有的init.rc相关文件（孵化出ueventd、logd、healthd、installd、adbd、lmkd等用户守护进程；启动zygote、servicemanager和surfaceflinger服务进程） //注：7.0之前的版本，服务进程的启动都是直接写在init.rc中的，7.0之后init.rc被拆分成多个，比如bootanimation.rc,surfacefligner.rc等 【epoll机制】进入死循环epoll_wait等待消息，直到系统属性变化事件(property_set改变属性值)，或者收到子进程的信号SIGCHLD，再或者keychord 键盘输入事件则唤醒 附录 Zygote启动过程Zygote是由init进程通过解析init.zygote.rc文件而创建的，zygote所对应的可执行程序app_process，所对应的源文件是App_main.cpp，进程名为zygote。 Zygote进程 ， 它由 init进程 启动，启动时会创建一个Davlik虚拟机实例，并把Java运行时库加载到进程中，并注册一些Android核心类的JNI到前面创建的Dalvik虚拟机实例中。 123456789101112131415service zygote /system/bin/app_process -Xzygote /system/bin --zygote --start-system-server class main socket zygote stream 660 root system onrestart write /sys/android_power/request_state wake onrestart write /sys/power/state on onrestart restart media onrestart restart netd //service → ATL语言语法，启动一个服务进程；zygote → 启动的程序名称，这指zygote进程；/system/bin/app_process → 可执行文件路径( app_main.cpp )；-Xzygote /system/bin → 指定参数传到app_main.cpp中；--zygote --start-system-server → 传的具体参数值；简单点说就是：启动了Zygote进程，传递的参数可在 /frameworks/base/cmds/app_process/app_main.cpp 中找到. //app_main.cpp: 对传进来的参数做匹配，zygote、startSystem标志位设置为true，接着定位下哪里用到了zygote这个标记： 跟下：**runtime.start()** 定位到 frameworks/base/core/jni/**AndroidRuntime.cpp**，关键代码如下： 1234567891011121314151617181920212223242526272829303132// ① 初始化jni接口JniInvocation jni_invocation;jni_invocation.Init(NULL);// ② 创建VM虚拟机JNIEnv* env;if (startVm(&amp;mJavaVM, &amp;env) != 0) { return;}onVmCreated(env);// ③ 注册JNI方法if (startReg(env) &lt; 0) { ALOGE(&quot;Unable to register all android natives\\n&quot;); return;}// ④ 调用className类的static void main(String args[]) 方法slashClassName = toSlashClassName(className);jclass startClass = env-&gt;FindClass(slashClassName);// 找到main函数jmethodID startMeth = env-&gt;GetStaticMethodID(startClass, &quot;main&quot;, &quot;([Ljava/lang/String;)V&quot;);if (startMeth == NULL) { ALOGE(&quot;JavaVM unable to find main() in '%s'\\n&quot;, className); /* keep going */} else { // 通过 JNI 调用 main 函数，从 C++ 到 Java env-&gt;CallStaticVoidMethod(startClass, startMeth, strArray); if (env-&gt;ExceptionCheck()) threadExitUncaughtException(env);} 所以这里创建了一个虚拟机，注册JNI方法，然后调用 com.android.internal.os.ZygoteInit 的 **main()，跟下frameworks/base/core/java/com/android/internal/os/ZygoteInit.java**： 123456789101112131415161718192021222324252627282930313233public static void main(String argv[]) { try { ... // ① 注册一个name为zygote的socket，用于和其他进程通信 registerZygoteSocket(socketName); // ② 预加载所需资源到VM中，如class、resource、OpenGL、公用Library等； // 所有fork的子进程共享这份空间而无需重新加载，减少了应用程序的启动时间， // 但也增加了系统的启动时间，Android启动最耗时的部分之一。 preload(); // ③ 初始化gc，只是通知VM进行垃圾回收，具体回收时间、怎么回收，由VM内部算法决定。 // gc()需在fork前完成，这样将来复制的子进程才能有尽可能少的垃圾内存没释放； gcAndFinalize(); // ④ 启动system_server，即fork一个Zygote子进程 if (startSystemServer) { startSystemServer(abiList, socketName); } // ⑤ 进入循环模式，获取客户端连接并处理 runSelectLoop(abiList); // ⑥ 关闭和清理zygote socket closeServerSocket(); } catch (MethodAndArgsCaller caller) { caller.run(); } catch (RuntimeException ex) { Log.e(TAG, &quot;Zygote died with exception&quot;, ex); closeServerSocket(); throw ex; }} 跟下 **startSystemServer()**： 1234567891011121314151617181920212223242526272829private static boolean startSystemServer(String abiList, String socketName) throws MethodAndArgsCaller, RuntimeException { int pid; try { ... // fork出system_server进程，返回pid，此处pid为0 pid = Zygote.forkSystemServer( parsedArgs.uid, parsedArgs.gid, parsedArgs.gids, parsedArgs.debugFlags, null, parsedArgs.permittedCapabilities, parsedArgs.effectiveCapabilities); } catch (IllegalArgumentException ex) { throw new RuntimeException(ex); } /* 进入子进程 */ if (pid == 0) { // Android 5.0上有两个Zygote进程：zygote 和 zygote64 // 对于有两个zygote进程的情况，需等待第二个zygote创建完成； if (hasSecondZygote(abiList)) { waitForSecondaryZygote(socketName); } // 完成system_server进程的剩余工作 handleSystemServerProcess(parsedArgs); } return true;} Tips：fork()方法被调用一次，返回两次，区别是：子进程的返回值是0，父进程的返回值是子进程的进程id，可以保证子进程的进程id不可能为0。 解析init.zygote.rc中的参数，创建AppRuntime并调用AppRuntime.start()方法； 调用AndroidRuntime的startVM()方法创建虚拟机，再调用startReg()注册JNI函数； 通过JNI方式调用ZygoteInit.main()，第一次进入Java世界； registerZygoteSocket()建立socket通道，zygote作为通信的服务端，用于响应客户端请求； preload()预加载通用类、drawable和color资源、openGL以及共享库以及WebView，用于提高app启动效率； zygote完毕大部分工作，接下来再通过**startSystemServer()**，fork得力帮手system_server进程，也是上层JavaFramework的运行载体。 所有APP进程都是由Zygote进程孵化(fork) 而来的，fork时不仅仅会获得Zygote进程中的Dalvik虚拟机实例拷贝，还会与Zygote一起 **共享Java运行时库**。 zygote功成身退，调用runSelectLoop()，随时待命，当接收到请求创建新进程请求时立即唤醒并执行相应工作。 附录 system_server启动的服务12345678try { startBootstrapServices(); // 启动引导服务:AMS、PKMS startCoreServices(); // 启动核心服务 startOtherServices(); // 启动其他服务:WMS } catch (Throwable ex) { Slog.e(&quot;System&quot;, &quot;************ Failure starting system services&quot;, ex); throw ex; } 引导服务(7个)：ActivityManagerService、PowerManagerService、LightsService、DisplayManagerService、PackageManagerService、UserManagerService、SensorService； 核心服务(3个)：BatteryService、UsageStatsService、WebViewUpdateService； 其他服务(70个+)：WindowManagerService、AlarmManagerService、VibratorService等。 合计总大约80个系统服务： ActivityManagerService PackageManagerService WindowManagerService PowerManagerService BatteryService BatteryStatsService DreamManagerService DropBoxManagerService SamplingProfilerService UsageStatsService DiskStatsService DeviceStorageMonitorService SchedulingPolicyService AlarmManagerService DeviceIdleController ThermalObserver JobSchedulerService AccessibilityManagerService DisplayManagerService LightsService GraphicsStatsService StatusBarManagerService NotificationManagerService WallpaperManagerService UiModeManagerService AppWidgetService LauncherAppsService TextServicesManagerService ContentService LockSettingsService InputMethodManagerService InputManagerService MountService FingerprintService TvInputManagerService DockObserver NetworkManagementService NetworkScoreService NetworkStatsService NetworkPolicyManagerService ConnectivityService BluetoothService WifiP2pService WifiService WifiScanningService AudioService MediaRouterService VoiceInteractionManagerService MediaProjectionManagerService MediaSessionService DevicePolicyManagerService PrintManagerService BackupManagerService UserManagerService AccountManagerService TrustManagerService SensorService LocationManagerService VibratorService CountryDetectorService GestureLauncherService PersistentDataBlockService EthernetService WebViewUpdateService ClipboardService TelephonyRegistry TelecomLoaderService NsdService UpdateLockService SerialService SearchManagerService CommonTimeManagementService AssetAtlasService ConsumerIrService MidiServiceCameraService TwilightService RestrictionsManagerService MmsServiceBroker RttService UsbService system_server进程，从源码角度划分为引导服务、核心服务、其他服务3类。 以下这些系统服务的注册过程, 见Android系统服务的注册方式方式1. ServiceManager.addService(): 功能：向ServiceManager注册该服务. 特点：服务往往直接或间接继承于Binder服务； 举例：input, window, package； 方式2. SystemServiceManager.startService: 功能： 创建服务对象； 执行该服务的onStart()方法；该方法会执行上面的SM.addService()； 根据启动到不同的阶段会回调onBootPhase()方法； 另外，还有多用户模式下用户状态的改变也会有回调方法；例如onStartUser(); 特点：服务往往自身或内部类继承于SystemService； 举例：power, activity； 两种方式真正注册服务的过程都会调用到ServiceManager.addService()方法. 对于方式2多了一个服务对象创建以及 根据不同启动阶段采用不同的动作的过程。可以理解为方式2比方式1的功能更丰富。 附录 BootPhase系统开机启动过程, 当执行到system_server进程时, 将启动过程划分了几个阶段, 定义在SystemService.java文件 123456public static final int PHASE_WAIT_FOR_DEFAULT_DISPLAY = 100; public static final int PHASE_LOCK_SETTINGS_READY = 480;public static final int PHASE_SYSTEM_SERVICES_READY = 500;public static final int PHASE_ACTIVITY_MANAGER_READY = 550;public static final int PHASE_THIRD_PARTY_APPS_CAN_START = 600;public static final int PHASE_BOOT_COMPLETED = 1000; 这些阶段跟系统服务大致的顺序图,如下: PHASE_BOOT_COMPLETED=1000，该阶段是发生在Boot完成和home应用启动完毕, 对于系统服务更倾向于监听该阶段，而非监听广播ACTION_BOOT_COMPLETED 附录 Android系统架构 第一步：手机开机后，引导芯片启动，引导芯片开始从固化在ROM里的预设代码执行，加载引导程序到到RAM，bootloader检查RAM，初始化硬件参数等功能； 第二步：硬件等参数初始化完成后，进入到Kernel层，Kernel层主要加载一些硬件设备驱动，初始化进程管理等操作。在Kernel中首先启动swapper进程（pid=0），用于初始化进程管理、内管管理、加载Driver等操作，再启动kthread进程(pid=2),这些linux系统的内核进程，kthread是所有内核进程的鼻祖； 第三步：Kernel层加载完毕后，硬件设备驱动与HAL层进行交互。初始化进程管理等操作会启动INIT进程 ，这些在Native层中； 第四步：init进程(pid=1，init进程是所有进程的鼻祖，第一个启动)启动后，会启动adbd，logd等用户守护进程，并且会启动servicemanager(binder服务管家)等重要服务，同时孵化出zygote进程，这里属于C++ Framework，代码为C++程序； 第五步：zygote 进程是由 **init进程解析init.rc文件后fork生成，它会加载虚拟机，启动System Server(zygote孵化的第一个进程)**；System Server负责启动和管理整个Java Framework，包含ActivityManager，WindowManager，PackageManager，PowerManager等服务； 第六步：zygote同时会启动相关的APP进程，它启动的第一个APP进程为Launcher(UI) ，然后启动Email，SMS等进程，所有的APP进程都有zygote fork生成。 关键概念厘清swapper进程是唯一一个不由其他进程fork/clone出来的进程，它是直接由内核创建，pid为0； swapper进程fork出两个关键进程： Init进程(pid=1)，一切用户空间进程鼻祖 kthreadd进程(pid=2)，一切内核空间进程鼻祖 子进程的创建Init进程采用被动创建的方式来创建子进程：哪些子进程需要创建，那就使用脚本语言.rc来配置相应的信息，Init进程会在LoadBootScripts方法中把所有的配置好信息都收集起来，当init进程启动后会根据配置信息来创建子进程。 xxx.rc 配置子进程基础信息：这一步主要用来配置子进程的基础信息，比如子进程的名字、可执行文件路径等，init进程就可以立马明白是哪个子进程被创建 配置触发条件：主要配置子进程何时或者满足什么条件的情况下被创建，因为不同子进程的创建条件都是不一样的，因此init进程可以从这一步得知是在“什么时候”或者“什么条件满足”的时候来创建子进程 配置前置命令：主要配置子进程在创建之前需要执行一些提前操作或者提前执行的命令，比如有的子进程在创建之前需要提前创建一些目录等操作 配置创建子进程命令：这一步非常的简单，init进程遇到这个命令，就开始执行创建子进程的操作 用init脚本语言来配置创建子进程的步骤如下： 首先子进程在以.rc的脚本文件中，使用service关键字来配置子进程相关的信息 其次 在init.rc文件中使用import关键字引入脚本文件，使用on关键字来配置子进程的触发条件 触发条件配置完毕后，如若子进程在创建之前需要配置一些前置操作或命令，则基于触发条件下配置这些信息 最后使用start关键字来配置创建子进程的命令。 Init进程的运行Init进程进入循环工作模式 是否有关机或重启的消息，有的话执行关机或重启 调用ActionManager的ExecuteOneCommand方法，ActionManager会检查是否有触发器，有的话触发对应的Action执行，有些Action会包含创建子进程的start命令，根据start命令后面的servicename，开始创建对应的子进程 若有control类型的message，则把它交给对应的Service 子进程的销毁上面谈到了子进程”生“的问题，那现在咱们聊聊子进程”死“的问题。作为Android用户空间所有进程的鼻祖，从生物学的角度来看，我肯定比我的孩子、孙子们要先死掉，但是在Android系统却恰恰相反，我的生命周期尽然是最长的，我的很多子子孙孙都死了很多次了，我还依然活着，因此我创建的子进程万一死掉的话，那它的善后事情需要我来处理（真是白发人送黑发人啊）。 那有人就会问了，你是如何知道你创建的子进程死掉的，这是个好问题，那我就来讲给大家听。 监听子进程死掉监听子进程死掉非常的简单，主要是用到了Linux的以下知识点：signal机制。它的主要作用是实现进程之间的通信，signal机制是最“吝啬”的、但是是最简单的进程之间的通信方式。为啥要说它是最“吝啬”呢？主要原因是signal对进程之间传递的数据仅且只能只能传递一个int类型的信号，但是像socket等通信方案对传递的数据并没有这样的限制，你说它“吝啬”不。 简单主要体现在：若对哪个信号有兴趣，可以使用sigaction函数注册这个信号，当这个信号发生时，注册的函数就会被调用。这里一直在提信号，监听子进程状态有一个信号是SIGCHLD，父进程可以注册这个SIGCHLD来监听子进程的状态，状态主要包括死掉（死掉包含正常死掉或者异常死掉比如crash）、停止、继续等。 epoll机制 epoll是“多路复用“技术最好的实现方案，“多路复用”看到这种专业性的词是不是一头雾水啊，咱们举个例子：正常咱们进行阻塞类型的IO读操作（比如从一个socket中读取数据），是不是都会创建一个单独的线程来监听是否有数据到达，如果没有数据到达则线程进入阻塞状态，有的话则线程就开始读取数据。那假如有20个甚至更多的阻塞IO读操作，是不是需要创建对应个数的线程。 这些线程如果大部分都没有可读数据的情况下是不是都处于阻塞状态，这难道不是大大得浪费吗？因此“多路复用”技术就出现了，它的设计理念是：启动一个线程，谁有需要监听IO是否有可读数据到达的操作都可以交给这个线程。这里的“多路”指的就是上面例子中创建的多个线程，“复用”指的就是指用一个线程来进行监听操作。 epoll机制在Android中使用非常的广泛，比如Handler的MessageQueue在没有Message的情况下进入阻塞，以及input事件从systemserver进程传递到app进程，甚至vsyn信号从surfaceflinger传递到app进程都用到了epoll机制。 好了，有了上面的知识，那我就来介绍下我监听子进程死掉的思路： 首先我先使用sigaction函数来注册SIGCHLD信号，这样就可以监听到子进程的状态了 其次使用signalfd函数为SIGCHLD信号生成一个fd（文件描述符） 再次使用epoll来见监听上一步生成的fd是否有可读数据 如监听到fd上有可读数据，则证明子进程的状态发生了变化，还需要使用waitpid函数来获取是哪个子进程死掉了 如上4步就可以监听到子进程死掉了，下面是具体的代码，有兴趣的同学可以看下。 system/core/init/init.cpp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485static void InstallSignalFdHandler(Epoll* epoll) { //初始化sigaction，SIG_DFL：代表使用默认的信号处理行为。 const struct sigaction act { .sa_handler = SIG_DFL, .sa_flags = SA_NOCLDSTOP }; //注册SIGCHLD信号 sigaction(SIGCHLD, &amp;act, nullptr); //声明mask信号集 sigset_t mask; //初始化并清空一个信号集，使其不包含任何信号 sigemptyset(&amp;mask); //把SIGCHLD信号加入mask信号集中 sigaddset(&amp;mask, SIGCHLD); 省略代码...... //SIG_BLOCK：代表将mask添加到当前的信号屏蔽集中 if (sigprocmask(SIG_BLOCK, &amp;mask, nullptr) == -1) { PLOG(FATAL) &lt;&lt; &quot;failed to block signals&quot;; } // Register a handler to unblock signals in the child processes. //在子进程创建成功后，恢复SIGCHLD为非屏蔽 const int result = pthread_atfork(nullptr, nullptr, &amp;UnblockSignals); if (result != 0) { LOG(FATAL) &lt;&lt; &quot;Failed to register a fork handler: &quot; &lt;&lt; strerror(result); } //调用signalfd函数为mask生成一个fd signal_fd = signalfd(-1, &amp;mask, SFD_CLOEXEC); if (signal_fd == -1) { PLOG(FATAL) &lt;&lt; &quot;failed to create signalfd&quot;; } constexpr int flags = EPOLLIN | EPOLLPRI; //使用epoll来监听signal_fd上的数据 if (auto result = epoll-&gt;RegisterHandler(signal_fd, HandleSignalFd, flags); !result.ok()) { LOG(FATAL) &lt;&lt; result.error(); }}//如果fd上有数据就会调用这个方法static void HandleSignalFd() { //读取到siginfo信息 signalfd_siginfo siginfo; ssize_t bytes_read = TEMP_FAILURE_RETRY(read(signal_fd, &amp;siginfo, sizeof(siginfo))); if (bytes_read != sizeof(siginfo)) { PLOG(ERROR) &lt;&lt; &quot;Failed to read siginfo from signal_fd&quot;; return; } //判断当前的ssi_signo switch (siginfo.ssi_signo) { case SIGCHLD: //只看SIGCHLD ReapAnyOutstandingChildren(); break; 省略无关代码...... }}system/core/init/sigchld_handler.cppvoid ReapAnyOutstandingChildren() { while (ReapOneProcess() != 0) { }}static pid_t ReapOneProcess() { siginfo_t siginfo = {}; //调用waitpid方法来获取死掉的子进程的信息 if (TEMP_FAILURE_RETRY(waitid(P_ALL, 0, &amp;siginfo, WEXITED | WNOHANG | WNOWAIT)) != 0) { PLOG(ERROR) &lt;&lt; &quot;waitid failed&quot;; return 0; } const pid_t pid = siginfo.si_pid; if (pid == 0) { DCHECK_EQ(siginfo.si_signo, 0); return 0; } 省略无关代码......} 如上面监听到子进程死掉的时候会通过waitpid方法获取到子进程的pid，还记得在创建子进程的时候，子进程的配置信息都会放在Service类中，根据pid可以找到对应的Service，Service持有了创建子进程的时候持有的各种socket等资源，这些资源会被清除掉，并且会通知kernel层杀掉子进程，进而在kernel层清除掉子进程占据的各种资源。","link":"/2021/06/30/SystemStartProcess/"},{"title":"ScreenDraw","text":"当手指点击了桌面的App图标时发生了什么 - ProcessOn Android 屏幕刷新机制主要参考 https://juejin.cn/post/6863756420380196877#heading-12 省流版： 双缓存：为了解决画面撕裂；画面撕裂来自于只有一个buffer时，正在display的那一帧数据被后一帧的数据覆盖了 Vsync：系统在收到VSync pulse（Vsync脉冲）后，将马上开始下一帧的渲染，（CPU开始计算数据）。 三缓冲：当显示器正在写入FrameBuffer同时GPU也正在写入BackBuffer时，下一次渲染开始了，此时CPU可以使用新增的GraphicBuffer进行计算。减少了Jank。（更多缓冲需要耗费更大的内存） ChoreoGrapher机制：规定了数据计算开始（measure、layout、draw）的时机（vsync信号），使计算到渲染图像数据能有一个完整的16.6ms：更新ui（request()/invalidate()）后编舞者注册vsync信号回调，在下一个vsync信号到时候立刻进行view的测量布局绘制 一、缓冲和Vsynchttps://juejin.cn/post/6863756420380196877 1、单缓冲，tearing 由于Gpu跟显示器使用同一个缓冲，导致可能屏幕扫描刷新时，可能读取到的不是同一帧里的图像数据，造成画面撕裂 2、↓ 双缓冲 ↓双缓冲是为了解决“由于Gpu跟显示器使用同一个缓冲，导致可能屏幕扫描刷新时，可能读取到的不是同一帧里的图像数据，造成画面撕裂”，让绘制和显示器拥有各自的buffer： GPU 的图像数据写入到 Back Buffer，而显示器使用 Frame Buffer，当屏幕刷新时，Frame Buffer 并不会发生变化，当Back buffer准备就绪后，它们才进行地址交换。（缓存区交换被称为BufferSwap，帧传递。） 上面说到的Back Buffer 跟 Frame Buffer地址交换，时间点选择在了 Back buffer完整写入之后，在之后屏幕扫描完一个屏幕（从左到右，从上到下逐行显示每一个像素点，整个过程以60Hz屏为例是16.6ms）后，设备从右下回到左上的这个时间区间（即VBI VerticalBlackingInterval垂直同步间隙），而垂直同步脉冲（vertical sync pulse）就是在VBI时期发出的，脉冲发出时间时立即进行帧传递。 总结下就是：垂直同步脉冲是在屏幕扫描到右下最后一个像素后，重置回到左上的这个时间空隙发出的，所以每16.6ms（60HZ屏）发出一个脉冲信号。收到脉冲信号后，如果GPU的缓冲已经准备好了，就会立即进行帧传递。 但是，双缓存只是规定了图像数据数据写入BackBuffer完成后，FrameBuffer与BackBuffer交换的时机，而数据开始计算时间的不确定，则导致了下一帧中，CPU/GPU未能在帧开始的时候就进行计算，进而导致帧结束时CPU/GPU工作未完成（明明CPU/GPU工作时长小于16.6ms），却还是造成掉帧（jank）。 3、↓ 三缓冲 + Vsync ↓Android 4.x版本的黄油工程 project butter引入三缓冲与Vsync，提升了性能，促使了Android的普及 3.1、 VSync 机制Android实现即下述第二节choreographer机制 系统在收到VSync pulse（Vsync脉冲）后，将马上开始下一帧的渲染。即一旦收到VSync通知（16ms触发一次），CPU和GPU 才立刻开始计算然后把数据写入buffer。VSync同步使得CPU/GPU充分利用了16.6ms时间，减少jank 3.2、 三缓冲 CPU、GPU、显示器都能尽快拿到 buffer，减少不必要的等待。如果显示器和 GPU 现在都使用着一个 buffer，如果下一次渲染开始了，因为还有一个 buffer 可以用于 CPU 数据的写入，所以可以马上开始下一帧数据的渲染。 三缓冲就是在双缓冲机制基础上增加了一个 Graphic Buffer 缓冲区，这样可以最大限度的利用空闲时间，带来的坏处是多使用的一个 Graphic Buffer 所占用的内存。三缓冲有效利用了等待vysnc的时间，减少了jank，但是带来了延迟。 二、Choreographer机制 或称 “drawing with vysnc” -&gt; requestLayout() / invalidate() 所有UI的变化都是走到ViewRootImpl的scheduleTraversals()方法。 -&gt; scheduleTraversals() 123456789101112131415161718void scheduleTraversals() { if (!mTraversalScheduled) { // 保证同时间多次更改只会刷新一次，例如TextView连续两次setText()也只会走一次绘制流程 mTraversalScheduled = true; // 添加同步屏障，保证 Vsync 到来立即执行绘制 mTraversalBarrier = mHandler.getLooper().getQueue().postSyncBarrier(); mChoreographer.postCallback(Choreographer.CALLBACK_TRAVERSAL, mTraversalRunnable, null); // ... }}// mTraversalRunnable 是Vsync信号回调后执行的Runnable 实例final class TraversalRunnable implements Runnable { @Override public void run() { doTraversal(); }} mChoreographer.postCallback() // 注册监听Vsync信号（只有注册了监听的Vsync才会回调执行）回调处理内容为mTraversalRunnable，事件类型为CALLBACK_TRAVERSAL（CALLBACK_INPUT输入事件、CALLBACK_ANIMATION动画、CALLBACK_INSETS_ANIMATION插入更新动画、CALLBACK_TRAVERSAL绘制、CALLBACK_COMMIT提交，五种类型顺序执行） postCallbackDelayedInternal if (dueTime &lt;= now) ： 直接执行scheduleFrameLocked else ： msg.setAsynchronous(true); 发送延迟到点后的异步消息执行scheduleFrameLocked -&gt; scheduleFrameLocked() 根据 版本未开启VSYN（4.1以下）直接走doFrame 确认并切换到Choreographer的handler（异步消息）执行 scheduleVsyncLocked() -&gt; scheduleVsncLocked() -&gt; scheduleVsync() -&gt; nativeScheduleVsync(mReceiverPtr); 注册VSYNC信号回调，只有注册监听的那一个Vsync信号才会接收回调最后在onVsync() 这里不应该为软件申请了Vsync信号，Vsync信号是由屏幕/显示设备发出的，无论choreographer是否监听都会在固定的时间间隔发出（60fps-&gt;16.6ms），View更新后由choreographer注册监听后才会对下一个Vsync信号回调回来后处理，走doCallbacks ，也就是最初由choreographer注册的回调mChoreographer.postCallback() -&gt; doTraversal() -&gt; 移除同步屏障并真正执行View的measure、layout、draw流程 所以每16ms都会发出Vsync信号，每16ms屏幕都在刷新，但不是每16ms都会走measure、layout、draw native层注册监听Vsync回调，DisplayEventReceiver::requestNextVsync() 123456789101112131415161718192021222324252627// frameworks/base/core/jni/android_view_DisplayEventReceiver.cppstatic void nativeScheduleVsync(JNIEnv* env, jclass clazz, jlong receiverPtr) { sp&lt;NativeDisplayEventReceiver&gt; receiver = reinterpret_cast&lt;NativeDisplayEventReceiver*&gt;(receiverPtr); status_t status = receiver-&gt;scheduleVsync(); // ...}// frameworks/base/libs/androidfw/DisplayEventDispatcher.cppstatus_t DisplayEventDispatcher::scheduleVsync() { if (!mWaitingForVsync) { // ... // mReceiver 是 DisplayEventReceiver 实例 status_t status = mReceiver.requestNextVsync(); mWaitingForVsync = true; } return OK;}// frameworks/native/libs/gui/DisplayEventReceiver.cppstatus_t DisplayEventReceiver::requestNextVsync() { if (mEventConnection != NULL) { // 请求接收下一次Vsync信号的回调 mEventConnection-&gt;requestNextVsync(); return NO_ERROR; } return NO_INIT;} native Vsync信号回调回来了，由FrameDisplayEventReceiver的onVsync方法接收： -&gt; onVsync() -&gt; doFrame() 123456789101112131415161718192021222324252627282930313233void doFrame(long frameTimeNanos, int frame) { final long startNanos; synchronized (mLock) { if (!mFrameScheduled) { return; // no work to do } //... // 计算掉帧情况 frameTimeNanos是onVsync()的参数，即vsync信号开始时间，以frameTimeNanos为start_time， //以doFrame方法执行开始时间为end_time， start_time - end_time为帧延迟，以此 时间差/标准帧时间 计算掉帧情况 //标准帧时间 = 1000000000 / 屏幕帧率 单位纳秒 （1纳秒=0.000 000 001秒 ） //... try { // 按类型顺序 执行任务 Trace.traceBegin(Trace.TRACE_TAG_VIEW, &quot;Choreographer#doFrame&quot;); AnimationUtils.lockAnimationClock(frameTimeNanos / TimeUtils.NANOS_PER_MS); mFrameInfo.markInputHandlingStart(); doCallbacks(Choreographer.CALLBACK_INPUT, frameTimeNanos); //输入事件，即熟悉的事件分发体系 mFrameInfo.markAnimationsStart(); doCallbacks(Choreographer.CALLBACK_ANIMATION, frameTimeNanos); //动画 doCallbacks(Choreographer.CALLBACK_INSETS_ANIMATION, frameTimeNanos); //动画 mFrameInfo.markPerformTraversalsStart(); doCallbacks(Choreographer.CALLBACK_TRAVERSAL, frameTimeNanos); //测绘 doCallbacks(Choreographer.CALLBACK_COMMIT, frameTimeNanos); //提交，处理绘制后的帧更新 } finally { AnimationUtils.unlockAnimationClock(); Trace.traceEnd(Trace.TRACE_TAG_VIEW); }} doFrame()-&gt; 按callbacktype依次执行将doCallbacks()，即执行doCallbacks(0、1、2、3、4,? frameTimeNanos) doCallbacks(int callbackType, long frameTimeNanos)-&gt; 根据传入的callbackType从mCallbackQuesu中取出对应的队列，执行队列中到达执行时间的CallbackRecord 即依次 将 输入队列、 动画队列、绘制队列、提交队列 中所有的到达执行时间的 元素（CallbackRecord）执行其中的action（viewRootImpl 中mChoreographer.mpostCallback时传递的mTraversalsRunnable） 12345678910111213141516171819202122void doCallbacks(int callbackType, long frameTimeNanos) { CallbackRecord callbacks; synchronized (mLock) { final long now = System.nanoTime(); // 根据指定的类型CallbackkQueue中查找到达执行时间的CallbackRecord callbacks = mCallbackQueues[callbackType].extractDueCallbacksLocked(now / TimeUtils.NANOS_PER_MS); //... try { // 迭代执行队列所有任务 for (CallbackRecord c = callbacks; c != null; c = c.next) { // 回调CallbackRecord的run，其内部回调Callback的run c.run(frameTimeNanos); } } finally { synchronized (mLock) { //... //递归回收CallbackRecord //... } } } callbacktype分为5种（实际上是四种，新版本Android合并后只剩四种事件：输入、动画、遍历traversal、提交）： 123456789//输入事件，首先执行 public static final int CALLBACK_INPUT = 0; //动画合并成一种//动画，第二执行 public static final int CALLBACK_ANIMATION = 1;//插入更新的动画，第三执行 public static final int CALLBACK_INSETS_ANIMATION = 2; //绘制，第四执行 public static final int CALLBACK_TRAVERSAL = 3; //提交，最后执行， public static final int CALLBACK_COMMIT = 4; 优先级的高低和处理顺序有关，每当收到 VSYNC 信号时，Choreographer 将首先处理 INPUT 类型的任务，然后是 ANIMATION 类型，最后才是 TRAVERSAL 类型。 -&gt; doCallbacks() -&gt; mTraversalRunnable -&gt; doTraversal() 123456789void doTraversal() { if (mTraversalScheduled) { mTraversalScheduled = false; // 移除同步屏障 mHandler.getLooper().getQueue().removeSyncBarrier(mTraversalBarrier); // 真正执行View的measure，layout，draw流程 performTraversals(); }} 附录 Choreographer部分源码（Android4.1新增）Choreographer 是线程单例的（ThreadLocal实现），而且必须要和一个 Looper 绑定，因为其内部有一个 Handler 需要和 Looper 绑定，一般是 App 主线程的 Looper 绑定 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//Choreographer.class //postCallback(int callbackType, Object action, Object token) 会一步步走到postCallbackDelayedInternal(delayMills = 0) private void postCallbackDelayedInternal(int callbackType, Object action, Object token, long delayMillis) { //... synchronized (mLock) { // 当前时间 final long now = SystemClock.uptimeMillis(); // 加上延迟时间 final long dueTime = now + delayMillis; //取对应类型的CallbackQueue添加任务 mCallbackQueues[callbackType].addCallbackLocked(dueTime, action, token); if (dueTime &lt;= now) { //立即执行 scheduleFrameLocked(now); } else { //延迟运行，最终也会走到scheduleFrameLocked() Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_CALLBACK, action); msg.arg1 = callbackType; msg.setAsynchronous(true); mHandler.sendMessageAtTime(msg, dueTime); } } } private void scheduleFrameLocked(long now) { if (!mFrameScheduled) { mFrameScheduled = true; //开启了VSYNC if (USE_VSYNC) { if (DEBUG_FRAMES) { Log.d(TAG, &quot;Scheduling next frame on vsync.&quot;); } //当前执行的线程，是否是mLooper所在线程 if (isRunningOnLooperThreadLocked()) { //申请 VSYNC 信号 scheduleVsyncLocked(); } else { // 若不在，就用mHandler发送消息到原线程，最后还是调用scheduleVsyncLocked方法 Message msg = mHandler.obtainMessage(MSG_DO_SCHEDULE_VSYNC); msg.setAsynchronous(true);//异步 mHandler.sendMessageAtFrontOfQueue(msg); } } else { // 如果未开启VSYNC则直接doFrame方法（4.1后默认开启） final long nextFrameTime = Math.max( mLastFrameTimeNanos / TimeUtils.NANOS_PER_MS + sFrameDelay, now); if (DEBUG_FRAMES) { Log.d(TAG, &quot;Scheduling next frame in &quot; + (nextFrameTime - now) + &quot; ms.&quot;); } Message msg = mHandler.obtainMessage(MSG_DO_FRAME); msg.setAsynchronous(true);//异步 mHandler.sendMessageAtTime(msg, nextFrameTime); } }} 三、invalidate/requestLayout流程invalidate/postInvalidat/requestLayout简要区别: invalidate只会调onDraw方法且必须在UI线程中调用 postInvalidate只会调onDraw方法，可在非UI线程中回调 requestLayout会调onMeasure、onLayout和onDraw(特定条件下)方法 invalidate调用 View.invalidate() 方法后会逐级往上调用父 View 的相关方法，最终在 Choreographer 的控制下调用 ViewRootImpl.performTraversals() 方法。只有满足 可见性、尺寸发生变化时 等条件才会执行 measure 和 layout 流程，否则只执行 draw 流程，draw 流程的执行过程与是否开启硬件加速有关： 关闭硬件加速则从 DecorView 开始往下的所有子 View 都会被重新绘制。开启硬件加速则只有调用 invalidate 方法的 View 才会重新绘制。 requestLayout调用 View.requestLayout 方法后会依次调用 performMeasure, performLayout 和 performDraw 方法，调用者 View 及其父 View 会重新从上往下进行 measure, layout 流程，一般情况下不会执行 draw 流程(子 View 会通过判断其尺寸/顶点是否发生改变而决定是否重新 measure/layout/draw 流程)。 小结：因此，当只需要进行重绘时可以使用 invalidate 方法，如果需要重新测量和布局则可以使用 requestLayout 方法，而 requestLayout 方法不一定会重绘，因此如果要进行重绘可以再手动调用 invalidate 方法。 子线程更新UI1、为啥会崩： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455-&gt; 视图更新操作invalidata-&gt; View.invalidate -&gt; View.invalidateInternal -&gt; ViewGroup.invalidateChild //正常情况View上一层级为ViewGroup，如果上一层直接时ViewRootImpl则没有这层-&gt; ViewParent.invalidateChildInParent //这里会不断do while去取上一个结点的mParent，从ViewGroup一直到ViewRootImpl为止-&gt; ViewRootImpl.invalidateChildInParent //DecorView的mParent是ViewRootImpl-&gt; ViewRootImpl.checkThread //在这里执行checkThread，如果非ViewRootImpl创建线程则抛出异常 ViewRootImpl.class final Thread mThread; ...public ViewRootImpl(Context context, Display display) { mcontext = context; mWindowSession = WindowMangerGlobal.getWindowSession(); ... mThread = Thread.currentThread(); ...} ... @Override //override from ViewParent interfacepublic ViewParent invalidateChildInParent(int[] location, Rect dirty) { checkThread(); if (DEBUG_DRAW) Log.v(mTag, &quot;Invalidate child: &quot; + dirty); if (dirty == null) { invalidate(); return null; } else if (dirty.isEmpty() &amp;&amp; !mIsAnimating) { return null; } if (mCurScrollY != 0 || mTranslator != null) { mTempRect.set(dirty); dirty = mTempRect; if (mCurScrollY != 0) { dirty.offset(0, -mCurScrollY); } if (mTranslator != null) { mTranslator.translateRectInAppWindowToScreen(dirty); } if (mAttachInfo.mScalingRequired) { dirty.inset(-1, -1); } } invalidateRectOnScreen(dirty); return null;} 123456789101112-&gt; 视图更新操作requestLayout-&gt; mParent.reqeustLayout // 不断向父控件(mparent即ViewParent接口，ViewGroup与ViewRootImpl都实现了该接口,可做为view的parent)请求布局，最后调用到ViewRootImpl的requestLayout-&gt; ViewRootImpl.requestLayoutViewRootImpl.classpublic void requestLayout() { if (!mHandlingLayoutInLayoutRequest) { checkThread(); mLayoutRequested = true; scheduleTraversals(); }} 123456void checkThread() { if (mThread != Thread.currentThread()) { throw new CalledFromWrongThreadException( &quot;Only the original thread that created a view hierarchy can touch its views.&quot;); }} 2、子线程更新UI怎么不崩： 子线程在ViewRootImpl初始化之前（handleResumeActivity之后初始化） ViewRootImpl创建线程 只需要与 View的更新线程 是同一个就行（初始化在子线程，更新在主线程一样会崩） View.post与getHandler.postview.post在内部类AttachInfo未实例化之前是会将action通过getRunQueue().post(action)缓存起来，延后到handleResumeActivity中初始化ViewRootImp时调用setView时，会从顶向下调用View/ViewGroup的dispatchAttachToWindow方法，在此方法内缓存的action会被执行 Activity的ViewRootImpl在onResume方法中创建的，具体见下 四、同步消息屏障在invalidate/requestLayout执行时，最后都会走向ViewRootImpl的scheduleTraversals()方法中，这个方法中会调用mHandler.getLooper().getQueue().postSyncBarrier();，本质上是往主线程Looper中post一个target==null的消息，作为同步消息屏障，过滤掉所有非异步的消息，只执行异步消息。 同时Choreographer注册Vsync回调，下一个Vsync消息发出后回调回来移除同步消息屏障并执行 performTraversals(也就是measure、layout、draw) 五、ChoreoGrapher什么时候初始化Activity启动后，执行完ActivitityThread.performResumeActivity()，再执行WindowManagerImpl.addView()，在其内部会执行ViewRootImpl的初始化。Choreographer的初始化就是在ViewRootImpl的构造方法中执行的。 ViewRootImpl的关键全局变量除了Choreographer（掌管绘制相关）外，还有attachInfo（）","link":"/2021/04/01/ScreenDraw/"},{"title":"","text":"JMM30 张图，以 DEBUG 方式深入理解线程的底层运行原理https://cloud.tencent.com/developer/article/1818100 JVM栈20张图助你了解JVM运行时数据区，你还觉得枯燥吗？https://cloud.tencent.com/developer/article/1823397?areaId=106001","link":"/2024/04/19/TempEdit/"},{"title":"tcp","text":"简述： Tcp是 面向链接的面向字节流的可靠的（几个点） 保证可靠的手段： 数据分块——握手时协商确定MSS，大于MSS的tcp数据包分段（也就是拆包）；序列号；校验和；确认ack包； 超时重传——发送方使用一个保守估计的时间作为收到数据包的确认的超时上限RTO。如果超过这个上限仍未收到确认包，发送方将重传这个数据包。每当发送方收到确认包后，会重置这个重传定时器。 超时重传会触发拥塞控制之重置拥塞窗口为1个MSS，阈值减为当前cwnd一半，执行慢启动每轮往返拥塞倍增 滑动窗口实现的流量控制；接收方在ack包中设置rwnd控制发送方发送速度。 拥塞控制算法——小于阈值之前从1开始每轮往返拥塞窗口cwnd倍增（慢启动），拥塞窗口大于阈值后步长为一的递增（拥塞避免）。接收方收到失序报文段后立即发出重复确认ack包，发送方连续三次重复确认则直接发送缺乏ack的丢包（快速重传），同时把阈值减为cwnd/2并调整拥塞窗口为新阈值而后执行拥塞避免算法（快速恢复）； Ps: 超时重传会触发拥塞控制之重置拥塞窗口为1个MSS，阈值减为当前cwnd一半，执行慢启动每轮往返拥塞倍增； 三次重复确认会执行快速重传快速恢复，阈值减为当前cwnd一半，拥塞窗口为新阈值值，执行拥塞避免，每轮往返递增； First of All废话少说，首先，我们需要知道TCP在网络OSI的七层模型中的第四层——Transport层，IP在第三层——Network层，ARP在第二层——Data Link层，在第二层上的数据，我们叫Frame，在第三层上的数据叫Packet，第四层的数据叫Segment。 首先，我们需要知道，我们程序的数据首先会打到TCP的Segment中，然后TCP的Segment会打到IP的Packet中，然后再打到以太网Ethernet的Frame中，传到对端后，各个层解析自己的协议，然后把数据交给更高层的协议处理。 TCP segment（段）, IP packet（包） UDP 和 TCP 的特点与区别用户数据报协议 UDP（User Datagram Protocol） 是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。效率高。 传输控制协议 TCP（Transmission Control Protocol） 是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。效率低。 Tcp协议是怎么保证可靠传输 数据分块：应用数据被分割成 TCP 认为最适合发送的数据块（MTU=1500= MSS1460 + TCP头20+IP头20）。 大于一个MSS的会被拆包，小于MSS的相连发出的包会粘包。 序列号：TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 首部中的seq字段32位，如果SYN标记位打开，则为握手时初始化随机序列号。保证每个包的有序 校验和：发送的数据包的二进制相加然后取反，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。 确认应答：TCP 传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送 ACK 报文。这个 ACK 报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。 ACK包=ack标记位置1接受到的seq+1 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 首部中的16位WIN字段，由接收方返回给发送端的ack中携带，通知发送端自身缓冲区还能接纳的数据。 拥塞控制： 当网络拥塞时，减少数据的发送。 一为慢启动和拥塞避免算法（小于阈值倍增大于阈值加一递增，超时重传触发重置cwnd为1并慢启动） 二为快速重传和快速回复（连续三次重复确认会触发快速恢复，即阈值减半，cwnd=新阈值，拥塞避免） 超时重传： 当 TCP 发出一个段后，它启动一个定时器（一个超时时间RTO），等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 如果一个已经发送的报文段在超时时间RTO内没有收到确认，那么就重传这个报文段，阈值减半，重置cwnd为1后慢启动 Tcp的连接和断开过程三次握手和四次挥手tcp握手挥手和状态机 三次握手：即：client发起一个Syn包包含client序列号 -&gt; server收到后返回ack(client序列号+1)包和Syn包包含server序列号 -&gt; client回馈一个ack包(server序列号+1)，三次之后client和server都确认了对方的读写能力 TCP 进行握手初始化一个连接的目标是：**分配资源、初始化序列号(通知 peer 对端我的初始序列号是多少)**，知道初始化连接的目标，那么要达成这个目标的过程就简单了，握手过程可以简化为下面的四次交互： 第一次握手：1）client 端首先发送一个 SYN 包告诉 Server 端我的初始序列号是 X； 第二次握手：2）Server 端收到 SYN 包后回复给 client 一个 ACK 确认包，告诉 client 说我收到了； 3）接着 Server 端也需要告诉 client 端自己的初始序列号，于是 Server 也发送一个 SYN 包告诉 client 我的初始序列号是 Y； 第三次握手：4）Client 收到后，回复 Server 一个 ACK 确认包说我知道了。 其中2）3）合并在一起形成第二次握手，也就是server回一个SYN+ACK包，序列号为Y，ack为X+1； Question: 一定是三次吗？ 大部分情况下建立连接需要三次握手，也不一定都是三次，有可能出现四次握手来建立连接的。如下图，当 Peer 两端同时发起 SYN 来建立连接的时候，就出现了四次握手来建立连接(对于有些 TCP/IP 的实现，可能不支持这种同时打开的情况)。 初始化序列号 X、Y 是可以是写死固定的吗，为什么不能呢？ 不能，假如序列号固定的话，假设为1，如果刚开始client给server发送的10个包被缓存住了，又恰好client掉了。过了一会，client又用同样的端口重连回来了，序列号重新从1开始发送，连发5个包。这时候又恰好之前被路由器缓存住的10个包全部被路由到server端了，然后server给client回ack=10的包。那么client就乱了，才发了5个（重连后的）server就返回了确认号为10的？故显然不行。 ISN是不能hard code的，不然会出问题的——比如：如果连接建好后始终用1来做ISN，如果client发了30个segment过去，但是网络断了，于是 client重连，又用了1做ISN，但是之前连接的那些包到了，于是就被当成了新连接的包，此时，client的Sequence Number 可能是3，而Server端认为client端的这个号是30了。全乱了。RFC793中说，ISN会和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始。这样，一个ISN的周期大约是4.55个小时。因为，我们假设我们的TCP Segment在网络上的存活时间不会超过Maximum Segment Lifetime（缩写为MSL – Wikipedia语条），所以，只要MSL的值小于4.55小时，那么，我们就不会重用到ISN。 如 Client 发送一个 SYN 包给 Server 后就挂了或是不管了，这个时候这个连接处于什么状态呢？会超时吗？为什么呢？ 重试5次，从1s开始，每次是之前的2倍，1s + 2s +4s+ 8s+ 16s + 32s =63s Linux 下默认会进行 5 次重发 SYN-ACK 包，重试的间隔时间从 1s 开始，下次的重试间隔时间是前一次的双倍，5 次的重试时间间隔为 1s,2s, 4s, 8s,16s，总共 31s，第 5 次发出后还要等 32s 都知道第 5 次也超时了，所以，总共需要 1s + 2s +4s+ 8s+ 16s + 32s =63s，TCP 才会把断开这个连接。 关于SYN Flood攻击。一些恶意的人就为此制造了SYN Flood攻击——给服务器发了一个SYN后，就下线了，于是服务器需要默认等63s才会断开连接，这样，攻击者就可以把服务器的syn连接的队列耗尽，让正常的连接请求不能处理。于是，Linux下给了一个叫tcp_syncookies的参数来应对这个事——当SYN队列满了后，TCP会通过源地址端口、目标地址端口和时间戳打造出一个特别的Sequence Number发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过cookie建连接（即使你不在SYN队列中）。请注意，请先千万别用tcp_syncookies来处理正常的大负载的连接的情况。因为，synccookies是妥协版的TCP协议，并不严谨。对于正常的请求，你应该调整三个TCP参数可供你选择，第一个是：tcp_synack_retries 可以用他来减少重试次数；第二个是：tcp_max_syn_backlog，可以增大SYN连接数；第三个是：tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。 四次挥手即：client发起FIN包 -&gt; server回一个ack包 -&gt; server数据发完了就也发一个FIN包 -&gt; client回一个ack包同时进入TIME_WAIT防止ack包丢失 TCP 进行断开连接的目标是：回收资源、终止数据传输。由于 TCP 是全双工的，需要 Peer 两端分别各自拆除自己通向 Peer 对端的方向的通信信道。这样需要四次挥手来分别拆除通信信道，就比较清晰明了了。 第一次挥手： 1）Client 发送一个 FIN 包来告诉 Server 我已经没数据需要发给 Server 了； 第二次挥手： 2）Server 收到后回复一个 ACK 确认包说我知道了； 第三次挥手： 3）然后 server 在自己也没数据发送给 client 后，Server 也发送一个 FIN 包给 Client 告诉 Client 我也已经没数据发给 client 了； 第四次挥手： 4）Client 收到后，就会回复一个 ACK 确认包说我知道了。 TCP 主动关闭连接的那一方(Client)会最后进入 TIME_WAIT（超时设置是 2*MS，即Linux为30s） Question: 为什么建立连接是三次握手，关闭连接确是四次挥手呢？ 简单来讲就是第二三次挥手不能像第二三次握手的时候一样合并成一个，因为可能server端还有数据没有发完。所以需要在可能的数据发完之后再进行第三次挥手 为什么主动关闭连接的一方要进入TIME_WAIT？为什么是2MS 主动关闭方需要进入 TIME_WAIT 以便能够重发丢掉的被动关闭方 FIN 包的 ACK。 TIME_WAIT状态也成为2MSL等待状态。每个具体TCP实现必须选择一个报文段最大生存时间MSL（Maximum Segment Lifetime），它是任何报文段被丢弃前在网络内的最长时间。也就是一来一回的时间。 第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。 MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。 数据传输中的Sequence Number下图是我从Wireshark中截了个我在访问coolshell.cn时的有数据传输的图给你看一下，SeqNum是怎么变的。（使用Wireshark菜单中的Statistics -&gt;Flow Graph… ） 你可以看到，SeqNum的增加是和传输的字节数相关的。上图中，三次握手后，来了两个Len:1440的包，而第二个包的SeqNum就成了1441。然后第一个ACK回的是1441，表示第一个1440收到了。 注意：如果你用Wireshark抓包程序看3次握手，你会发现SeqNum总是为0，不是这样的，Wireshark为了显示更友好，使用了Relative SeqNum——相对序号，你只要在右键菜单中的protocol preference 中取消掉就可以看到“Absolute SeqNum”了 数据分块&amp;面向字节流分块传输我们可以发现，运输层在传输数据的时候，并不是把整个数据包加个首部直接发送过去，而是会拆分成多个报文分开发送；那他这样做原因是什么？ 有读者可能会想到：数据链路层限制了数据长度只能有1460（MSS）。那数据链路层为什么要这么限制？他的本质原因就是：网络是不稳定的。如果报文太长，那么极有可能在传输一般的时候突然中断了，这个时候就要整个数据重传，效率就降低了。把数据拆分成多个数据报，那么当某个数据报丢失，只需要重传该数据报即可。 那是不是拆分得越细越好？报文中数据字段长度太低，会使得首部的占比太大，这样首部就会成为网络传输最大的负担了。例如1000字节，每个报文首部是40字节，如果拆分成10个报文，那么只需要传输400字节的首部；而如果拆分成1000个，那么需要传输40000字节的首部，效率就极大地降低了。 面向字节流TCP并不是把应用层传输过来的数据直接加上首部然后发送给目标，而是把数据看成一个字节 流，给他们标上序号之后分部分发送。这就是TCP的 面向字节流 特性： TCP会以流的形式从应用层读取数据并存放在自己的发送缓存区中，同时为这些字节标上序号 TCP会从发送方缓冲区选择适量的字节组成TCP报文，通过网络层发送给目标 目标会读取字节并存放在自己的接收方缓冲区中，并在合适的时候交付给应用层 TCP的粘包和拆包程序需要发送的数据大小和TCP报文段能发送MSS（Maximum Segment Size，最大报文长度）是不一样的大于MSS时，而需要把程序数据拆分为多个TCP报文段，称之为拆包；小于时，则会考虑合并多个程序数据为一个TCP报文段，则是粘包；在IP协议层或者链路层、物理层，都存在拆包、粘包现象 解决粘包和拆包的方法都有哪些？1）在数据尾部增加特殊字符进行分割2）将数据定为固定大小3）将数据分为两部分， 流量控制：滑动窗口TCP头里有一个字段叫Window，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。 TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。将窗口字段设置为 0，则发送方不能发送数据。 由接收方 向 发送方通知自己还有多少缓冲区接受数据 设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd = 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。 从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd = 300 ，第二次又减到了 rwnd = 100 ，最后减到 rwnd = 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK = 1 ，只有在ACK=1时确认号字段才有意义。 零窗口(Zero Window) 如果Window变成0了，TCP会怎么样？是不是发送端就不发数据了？是的，发送端就不发数据了，你可以想像成“Window Closed”，那你一定还会问，如果发送端不发数据了，接收方一会儿Window size 可用了，怎么通知发送端呢？ 解决这个问题，TCP使用了零窗口探测Zero Window Probe（ZWP）技术，也就是说，发送端在窗口变成0后，会发ZWP的包给接收方，让接收方来ack他的Window尺寸，一般这个值会设置成3次，每次大约30-60秒（不同的实现可能会不一样）。如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。 糊涂窗口综合症(Silly Window Syndrome) 如果我们的接收方太忙了，来不及取走Receive Windows里的数据，那么，就会导致发送方越来越小。到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的window，而我们的发送方会义无反顾地发送这几个字节。要知道，我们的TCP+IP头有40个字节，为了几个字节，要达上这么大的开销，这太不经济了。要解决这个问题也不难，就是避免对小的window size做出响应，直到有足够大的window size再响应，这个思路可以同时实现在sender和receiver两端。 如果这个问题是由接收端引起的（比如接收端处理缓冲区数据处理不过来，太忙了），那么就会使用 Clark 方案。在receiver端，如果收到的数据导致window size小于某个值，可以直接ack(0)回sender，这样就把window给关闭了，也阻止了sender再发数据过来，等到receiver端处理了一些数据后windows size 大于等于了MSS，或者，receiver buffer有一半为空，就可以把window打开让send 发送数据过来。 （简述：接收端引起的SWS，Clark方案：接收到的数据导致滑窗过小，ack(window=0)让发送端先暂停发送，直到接收端处理完一些数据后window大于MSS了或者缓冲区一半空了，就可以ack(新值)了） 如果这个问题是由发送端引起的（比如发送端的内容是一个字节一个字节产生的），那么就会使用著名的 Nagle’s algorithm。这个算法的思路也是延时处理，他有两个主要的条件：1）要等到 Window Size&gt;=MSS 或是 Data Size &gt;=MSS，2）收到之前发送数据的ack回包，他才会发数据，否则就是在攒数据。 （简述：发送端引起的SWS，nagle算法：攒数据直到WindowSize &gt;= MSS或者Data Szie &gt;= MSS，同时要收到之前发送数据的ack回包） 另外，Nagle算法默认是打开的，所以，对于一些需要小包场景的程序——比如像telnet或ssh这样的交互性比较强的程序，你需要关闭这个算法。你可以在Socket设置TCP_NODELAY选项来关闭这个算法（关闭Nagle算法没有全局参数，需要根据每个应用自己的特点来关闭） 拥塞控制：慢开始门限ssthresh状态变量（假设为8个MSS） swnd = min(rwnd, cwnd) 发送方的窗口上限，是取值滑动窗口和拥塞窗口两者的最小值 滑动窗口和拥塞窗口区别：相同点都是控制丢包现象，实现机制都是让发送方发得慢一点 不同点在于控制的对象不同1）流量控制的对象是接收方，怕发送方发的太快，使得接收方来不及处理2）拥塞控制的对象是网络拥塞，怕发送方发的太快，造成网络拥塞，使得网络来不及处理 慢启动即：拥塞窗口从1MSS开始，每轮往返(即发送的TCP段都收到了ack)加倍，直到ssthresh值为止，切换拥塞避免 当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。 因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。 通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。 ​ cwnd窗口 1 -&gt; 2 -&gt; 4 -&gt; 8 ​ 每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 拥塞避免算法即：大于ssthresh值时拥塞窗口每轮往返加一 让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。 ​ （假装有图） ​ cwnd窗口 8 -&gt; 9 -&gt; 10 -&gt; 11 慢热启动算法 – Slow Start首先，我们来看一下TCP的慢热启动。慢启动的意思是，刚刚加入网络的连接，一点一点地提速，不要一上来就像那些特权车一样霸道地把路占满。新同学上高速还是要慢一点，不要把已经在高速上的秩序给搞乱了。 慢启动的算法如下(cwnd全称Congestion Window)： 1）连接建好的开始先初始化cwnd = 1，表明可以传一个MSS大小的数据。 2）每当收到一个ACK，cwnd++; 呈线性上升 3）每当过了一个RTT，cwnd = cwnd*2; 呈指数让升 4）还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”（后面会说这个算法） 所以，我们可以看到，如果网速很快的话，ACK也会返回得快，RTT也会短，那么，这个慢启动就一点也不慢。下图说明了这个过程。 这里，我需要提一下的是一篇Google的论文《An Argument for Increasing TCP’s Initial Congestion Window》Linux 3.0后采用了这篇论文的建议——把cwnd 初始化成了 10个MSS。 而Linux 3.0以前，比如2.6，Linux采用了RFC3390，cwnd是跟MSS的值来变的，如果MSS&lt; 1095，则cwnd = 4；如果MSS&gt;2190，则cwnd=2；其它情况下，则是3。 拥塞避免算法 – Congestion Avoidance前面说过，还有一个ssthresh（slow start threshold），是一个上限，当cwnd &gt;= ssthresh时，就会进入“拥塞避免算法”。一般来说ssthresh的值是65535，单位是字节，当cwnd达到这个值时后，算法如下： 1）收到一个ACK时，cwnd = cwnd + 1/cwnd 2）当每过一个RTT时，cwnd = cwnd + 1 这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。很明显，是一个线性上升的算法。 快速重传和快速恢复接收方每收到一个失序报文段就立即发出重复确认，发送方如果一连三次收到重复确认立即重传，ssthresh值减半，并cwnd窗口变更为新ssthresh，接下来执行拥塞避免算法加法增大 快速重传即：接收方每收到一个失序报文段就立即发出重复确认，发送方如果一连三次收到重复确认立即重传 首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。 发送方只要一连收到三个重复确认M2就应当立即重传对方尚未收到的报文段M3 快速恢复(Reno算法)即发送方接受到三个重复确认时，ssthresh值减半，并cwnd窗口变更为新ssthresh，接下来执行加法增大 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半，cwnd窗口变更为新ssthresh值（旧值的一半）。（即不执行“慢开始指数增大”，窗口不重置为1，而是设置为ssthresh二分之一，后面执行拥塞避免算法“加法增大”） 超时重传简述：如果一个已经发送的报文段在超时时间RTO内没有收到确认，那么就重传这个报文段。 往返时间Round Trip Time——RTT：客户到服务器往返所花时间，常说的延迟 超时时间Retransmission TimeOut——RTO：由RTT加权计算出来的超时时间，超出RTO没有ack则重传 等到RTO超时，重传数据包。TCP认为这种情况太糟糕，反应也很强烈。 sshthresh = cwnd /2 cwnd 重置为 1 进入慢启动过程 一个报文段从发送再到接收到确认所经过的时间称为往返时间 RTT，加权平均往返时间 RTTs 计算如下： 其中，0 ≤ a ＜ 1，RTTs 随着 a 的增加更容易受到 RTT 的影响。超时时间 RTO 应该略大于 RTTs，TCP 使用的超时时间计算如下： 其中 RTTd 为偏差的加权平均值。 快速重传和超时重传区别超时重传：如果一个已经发送的报文段在超时时间RTO内没有收到确认，那么就重传这个报文段，阈值减半，重置cwnd为1后慢启动 快速重传：客户端连续收到三次重复确认（即服务器连续三次收到乱序的包），立即重传对应丢失包，阈值减半，cwnd设为新阈值后拥塞避免 快速重传机制「RFC5681」基于接收端的反馈信息来引发重传，而非重传计时器超时。基于计时器的重传往往要等待很长时间，而快速重传使用了很巧妙的方法来解决这个问题：服务器如果收到乱序的包，也给客户端回复 ACK，只不过是重复的 ACK。就拿刚刚的例子来说，收到乱序的包 6,7,8,9 时，服务器全都发 ACK = 5。这样，客户端就知道 5 发生了空缺。一般来说，如果客户端连续三次收到重复的 ACK，就会重传对应包，而不需要等到计时器超时。 附录一： MSL、ttl及RTT&amp;RTO的区别MSL（30s）最大报文生存时间Maximum Segment Lifetime 简述：最大报文生存时间，一般是30s，用于关闭链接TIME_WAIT状态停留2MSL 每个TCP实现必须选择一个MSL。它是任何报文段被丢弃前在网络内的最长时间。这个时间是有限的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL时间。RFC 793指出MSL为2分钟，Linux为30s 2MSL（2*30s）当TCP执行主动关闭，并发出最后一个ACK，该链接必须在TIME_WAIT状态下停留的时间为2MSL。这样可以（1）让TCP再次发送最后的ACK以防这个ACK丢失（被动关闭的一方超时并重发最后的FIN）；保证TCP的可靠的全双工连接的终止。（2）允许老的重复分节在网络中消失。参考文章《unix网络编程》（3）TCP连接的建立和终止 RTT往返时间，RTO超时时间round-trip-time 简述：RTT客户到服务器往返所花时间，RTO由RTT加权计算出的用于超时重传的超时时间用于 往返时间Round Trip Time——RTT：客户到服务器往返所花时间，常说的延迟，Ping命令出来的 超时时间Retransmission TimeOut——RTO：由RTT加权计算出来的超时时间，超出RTO没有ack则重传 TCP超时重传中最重要的部分就是对一个给定连接的往返时间RTT的测量。由于路由器和网络流量均会变化，因此这个时间可能经常会变化，TCP应该跟踪这些变化并相应地改变其超时时间。 TTL生存时间字段time-to-live 在IP首部中的8位字段。该字段不是存的具体时间，而是设置了数据报可以经过的最多路由器数。它制定了数据报的生存时间。TTL的初始值由源主机设置（通常为32或64），一旦经过一个处理它的路由器，它的值就减去1.当该字段值为0时，数据报就被丢弃，并发送ICMP报文通知源主机。 附录二：MSS、MTU你需要知道网络上有个MTU，对于以太网来说，MTU是1500字节，除去TCP+IP头的40个字节，真正的数据传输可以有1460，这就是所谓的MSS（Max Segment Size）注意，TCP的RFC定义这个MSS的默认值是536，这是因为 RFC 791里说了任何一个IP设备都得最少接收576尺寸的大小（实际上来说576是拨号的网络的MTU，而576减去IP头的20个字节就是536）。 附录三：UDP 、TCP 首部格式UDP首部：8个字节 UDP 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。 TCP首部：20个字节以上 TCP 首部格式比 UDP 复杂。 序号：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 控制位：八位从左到右分别是 CWR，ECE，URG，ACK，PSH，RST，SYN，FIN。 CWR：CWR 标志与后面的 ECE 标志都用于 IP 首部的 ECN 字段，ECE 标志为 1 时，则通知对方已将拥塞窗口缩小； ECE：若其值为 1 则会通知对方，从对方到这边的网络有阻塞。在收到数据包的 IP 首部中 ECN 为 1 时将 TCP 首部中的 ECE 设为 1； URG：该位设为 1，表示包中有需要紧急处理的数据，对于需要紧急处理的数据，与后面的紧急指针有关； ACK：该位设为 1，确认应答的字段有效，TCP规定除了最初建立连接时的 SYN 包之外该位必须设为 1； PSH：该位设为 1，表示需要将收到的数据立刻传给上层应用协议，若设为 0，则先将数据进行缓存； RST：该位设为 1，表示 TCP 连接出现异常必须强制断开连接； SYN：用于建立连接，该位设为 1，表示希望建立连接，并在其序列号的字段进行序列号初值设定； FIN：该位设为 1，表示今后不再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位置为 1 的 TCP 段。 每个主机又对对方的 FIN 包进行确认应答之后可以断开连接。不过，主机收到 FIN 设置为 1 的 TCP 段之后不必马上回复一个 FIN 包，而是可以等到缓冲区中的所有数据都因为已成功发送而被自动删除之后再发 FIN 包； 窗口：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP头格式接下来，我们来看一下TCP头的格式 TCP头格式（图片来源） 你需要注意这么几点： TCP的包是没有IP地址的，那是IP层上的事。但是有源端口和目标端口。 一个TCP连接需要四个元组来表示是同一个连接（src_ip, src_port, dst_ip, dst_port）准确说是五元组，还有一个是协议。但因为这里只是说TCP协议，所以，这里我只说四元组。 注意上图中的四个非常重要的东西： Sequence Number是包的序号，用来解决网络包乱序（reordering）问题。 Acknowledgement Number就是ACK——用于确认收到，用来解决不丢包的问题。 Window又叫Advertised-Window，也就是著名的滑动窗口（Sliding Window），用于解决流控的。 TCP Flag ，也就是包的类型，主要是用于操控TCP的状态机的。 关于其它的东西，可以参看下面的图示 （图片来源） IP首部：20个字节以上 1、第一个4字节（也就是第一行）：（1）版本号（Version），4位；用于标识IP协议版本，IPv4是0100，IPv6是0110，也就是二进制的4和6。（2）首部长度（Internet Header Length），4位；用于标识首部的长度，单位为4字节，所以首部长度最大值为：(2^4 - 1) * 4 = 60字节，但一般只推荐使用20字节的固定长度。（3）服务类型（Type Of Service），8位；用于标识IP包的优先级，但现在并未使用。（4）总长度（Total Length），16位；标识IP数据报的总长度，最大为：2^16 -1 = 65535字节。2、第二个四字节：（1）标识（Identification），16位；用于标识IP数据报，如果因为数据链路层帧数据段长度限制（也就是MTU，支持的最大传输单元），IP数据报需要进行分片发送，则每个分片的IP数据报标识都是一致的。（2）标识（Flag），3位，但目前只有2位有意义；最低位为MF，MF=1代表后面还有分片的数据报，MF=0代表当前数据报已是最后的数据报。次低位为DF，DF=1代表不能分片，DF=0代表可以分片。（3）片偏移（Fragment Offset），13位；代表某个分片在原始数据中的相对位置。3、第三个四字节：（1）生存时间（TTL），8位；以前代表IP数据报最大的生存时间，现在标识IP数据报可以经过的路由器数。（2）协议（Protocol），8位；代表上层传输层协议的类型，1代表ICMP，2代表IGMP，6代表TCP，17代表UDP。（3）校验和（Header Checksum），16位；用于验证数据完整性，计算方法为，首先将校验和位置零，然后将每16位二进制反码求和即为校验和，最后写入校验和位置。4、第四个四字节：源IP地址5、第五个四字节：目的IP地址 附录：参考QA网络篇：朋友面试之TCP/IP，回去等通知吧 - 掘金 (juejin.cn) TCP 的那些事儿（上） | 酷 壳 - CoolShell TCP 的那些事儿（下） | 酷 壳 - CoolShell","link":"/2021/11/11/Tcp/"},{"title":"TaskPerFrame","text":"16ms 内都需要完成什么？from : https://juejin.cn/post/7062552765117136903 // Vsync顶层 Vsync 调度：硬件每隔16.6ms发出硬件Vsync信号，需要经过软件调度，类似注册，才能收到回调 消息调度：主要是 doframe 的消息调度，如果消息被阻塞，会直接造成卡顿； input 处理：触摸事件的处理； 动画处理：animator 动画执行和渲染； view 处理：主要是 view 相关的遍历和三大流程； measure、layout、draw：view 三大流程的执行； //Vsync底层 DisplayList 更新：view 硬件加速后的 draw op； OpenGL 指令转换：canvas指令转换为 OpenGL 指令； 指令 buffer 交换：OpenGL 的指令交换到 GPU 内部执行； GPU 处理：GPU 对数据的处理过程； layer 合成：surface buffer 合成屏幕显示 buffer 的流程； 光栅化：将矢量图转换为位图； Display：显示控制； buffer 切换：切换屏幕显示的帧 buffer； Google 将这个过程划分为：其他时间/VSync 延迟、输入处理、动画、测量/布局、绘制、同步和上传、命令问题、交换缓冲区。也就是我们常用的 GPU 严格模式，其实道理是一样的。到这里，我们也就回答出来了第二个问题： 准确地说，这里仍可以进一步细化：16ms 内完成 APP 侧数据的生产；16ms 内完成 sf layer 的合成 View 的视觉效果正是通过这一整条复杂的链路一步步展示出来的，有了这个前提，那就可以得出一个结论：上述任意链路发生卡顿，均会造成卡顿。 *常见问题：红色（Command Issue）：太多display lists 浅蓝色（upload）：加载了大量图形(bitmap, graphics) 深蓝色（Draw）：大概率在onDraw中执行了有点耗时的任务 最浅的绿色（测绘）:需要排查view树层级 view hierarchy 过深 浅绿色（处理输入和动画）：需要排查滚动中的view Binding，如RV 的onBindViewHolder 深绿色（延迟VSync）：直接在主线程中执行了耗时任务","link":"/2022/03/16/TaskPerFrame/"},{"title":"ThreadLocal","text":"ThreadLocal：ThreadLocal： 线程本地存储区（Thread Local Storage，简称为TLS），每个线程都有自己的私有的本地存储区域，不同线程之间彼此不能访问对方的TLS区域。 ThreadLocal类不过是为了执行set/get，确定泛型的工具人而已。真正数据是靠的每个Thread内部维护。 实际上就是 每个Thread对象中 维护了一个 叫ThreadLocal.ThreadLocalMap的 **key为 ThreadLocal对象, value为 存储的值 ** 的key-vale映射结构，(实际上是一个键值对组成entry的唯一环形数组，线性探测，初始值3/4容量扩容) 当调用threadLocalInstance.set(value)时，其实时调用的CurrentThread.threadLocalMap.set(threadLocalInstance, value) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class Main { public static void main(String[] args) { ThreadLocal&lt;String&gt; threadLocalOne = new ThreadLocal&lt;&gt;(); ThreadLocal&lt;String&gt; threadLocalTwo = new ThreadLocal&lt;&gt;(); new Thread(new Runnable() { @Override public void run() { threadLocalOne.set(&quot;线程一的数据 --- threadLocalOne&quot;); threadLocalTwo.set(&quot;线程一的数据 --- threadLocalTwo&quot;); System.out.println(threadLocalOne.get()); System.out.println(threadLocalTwo.get()); } }).start(); new Thread(new Runnable() { @Override public void run() { System.out.println(threadLocalOne.get()); System.out.println(threadLocalTwo.get()); threadLocalOne.set(&quot;线程二的数据 --- threadLocalOne&quot;); threadLocalTwo.set(&quot;线程二的数据 --- threadLocalTwo&quot;); System.out.println(threadLocalOne.get()); System.out.println(threadLocalTwo.get()); } }).start(); }}//线程一的数据 --- threadLocalOne//线程一的数据 --- threadLocalTwo//null//null//线程二的数据 --- threadLocalOne//线程二的数据 --- threadLocalTwo#ThreadLocal.class { //存数据，若当前线程未曾调用过ThreadLocal.set,则为thread初始化一个ThreadLocalMap public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } //获取当前Thread的threadLocalMap变量,以ThreadLocal为key，从threadLocalMap中取值 public T get() { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) { ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; } } //当线程对应ThreadLocalMap未存储该key时，返回null return setInitialValue(); } ThreadLocalMap getMap(Thread t) { return t.threadLocals; } void createMap(Thread t, T firstValue) { t.threadLocals = new ThreadLocalMap(this, firstValue); }} 12Entry[] tab = table;tab[i] = new Entry(key, value); 1234567891011121314public class ThreadLocal&lt;T&gt; { ... static class ThreadLocalMap { ... private static int nextIndex(int i, int len) { return ((i + 1 &lt; len) ? i + 1 : 0); } ... }} 应用场景1：每个线程对应一个LooperLooper.prepare()：在每个线程只允许执行一次，该方法会创建Looper对象，Looper的构造方法中会创建一个MessageQueue对象，再将Looper对象保存到当前线程TLS 12345678private static void prepare(boolean quitAllowed) { //每个线程只允许执行一次该方法，第二次执行时线程的TLS已有数据，则会抛出异常。 if (sThreadLocal.get() != null) { throw new RuntimeException(&quot;Only one Looper may be created per thread&quot;); } //创建Looper对象，并保存到当前线程的TLS区域 sThreadLocal.set(new Looper(quitAllowed));} 应用场景2：Choreographer是主线程的ThradLocal变量123456789101112131415161718192021222324252627public final class Choreographer { // Thread local storage for the choreographer. private static final ThreadLocal&lt;Choreographer&gt; sThreadInstance = new ThreadLocal&lt;Choreographer&gt;() { @Override protected Choreographer initialValue() { Looper looper = Looper.myLooper(); if (looper == null) { throw new IllegalStateException(&quot;The current thread must have a looper!&quot;); } // 创建 Choreographer 对象 Choreographer choreographer = new Choreographer(looper, VSYNC_SOURCE_APP); if (looper == Looper.getMainLooper()) { mMainInstance = choreographer; } return choreographer; } }; private static volatile Choreographer mMainInstance; public static Choreographer getInstance() { return sThreadInstance.get(); } } 从 Choreographer 的 getInstance 方法中, 我们可以看到它调用 ThreadLocal.get 方法, 从当前线程的 ThreadLocalMap 散列表中获取以这个 ThreadLocal 为 Key 的 Value 值, 若 Value 不存在, 则会调用 initialValue 创建 Choreographer 实例对象 由此我们可以得出 Choreographer 是线程单例的, 并且它只能运行在存在 Looper 的线程中,","link":"/2021/05/14/ThreadLocal/"},{"title":"Throwable","text":"","link":"/2022/08/10/Throwable/"},{"title":"sharePreference","text":"SharedPreferences原理-xmind \u0010SharedPreferences是系统提供的一种简易数据持久化的手段，适合单进程、小批量的数据存储与访问。以键值对的形式存储在xml文件中。文件存储路径为data/data/package_name/shared_prefs/目录。 源码解析 源码解析 获取SharedPerferences对象 获取SharedPerferences对象 获取方法从getSharedPreferences(name,mode)开始，此时就需要去加载对应name的xml文件 12345678910class MainActivity : AppCompatActivity() { lateinit var sharedPreferences: SharedPreferences override fun onCreate(savedInstanceState: Bundle?) { super.onCreate(savedInstanceState) setContentView(R.layout.activity_main) sharedPreferences = getSharedPreferences(&quot;test&quot;, MODE_PRIVATE); }}Copytest`表示生成的xml文件名为`test.xml mode对应的是xml文件的访问权限以及数据的写入方式 权限控制格式 作用 备注 Context.MODE_PRIVATE 代表该文件是私有数据，只能被当前应用访问。 写入的内容会覆盖源文件的内容。 默认操作模式 Context.MODE_WORLD_READABLE 表示当前文件可以被其他应用读取 Context.MODE_WORLE_WRITEABLE 表示当前文件可以被其他应用写入 Context.MODE_APPEND 会检查当前是否有文件存在？ 在在后面追加内容 不存在则去创建新文件 Context.MODE_MULTI_PROCESS 部分支持跨进程使用 原理就是重新读取xml文件内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//ContextImpl.javaprivate static ArrayMap&lt;String, ArrayMap&lt;File, SharedPreferencesImpl&gt;&gt; sSharedPrefsCache;private ArrayMap&lt;String, File&gt; mSharedPrefsPaths; public SharedPreferences getSharedPreferences(String name, int mode) { File file; synchronized (ContextImpl.class) { if (mSharedPrefsPaths == null) { mSharedPrefsPaths = new ArrayMap&lt;&gt;(); } file = mSharedPrefsPaths.get(name); if (file == null) { //根据名字 获取对应路径文件 file = getSharedPreferencesPath(name); mSharedPrefsPaths.put(name, file); } } return getSharedPreferences(file, mode); } @Override public File getSharedPreferencesPath(String name) { return makeFilename(getPreferencesDir(), name + &quot;.xml&quot;); } public SharedPreferences getSharedPreferences(File file, int mode) { SharedPreferencesImpl sp; //保证创建过程线程安全 synchronized (ContextImpl.class) { final ArrayMap&lt;File, SharedPreferencesImpl&gt; cache = getSharedPreferencesCacheLocked(); //获取缓存sp sp = cache.get(file); if (sp == null) { checkMode(mode); ... //新建SP对象 sp = new SharedPreferencesImpl(file, mode); //存入缓存 cache.put(file, sp); return sp; } } if ((mode &amp; Context.MODE_MULTI_PROCESS) != 0 || getApplicationInfo().targetSdkVersion &lt; android.os.Build.VERSION_CODES.HONEYCOMB) { //重新加载XML文件 sp.startReloadIfChangedUnexpectedly(); } return sp; }Copy 主要执行了三步： 根据传入的name在对应路径下生成对应的xml文件，并存入mSharedPrefsPaths进行缓存。 创建文件完毕后，再去创建对应的SharedPreferencesImpl对象，创建完成后缓存到cache中。每一个xml文件都会对应一个SP对象 若设置了mode为Context.MODE_MULTI_PROCESS，就需要重新去加载一次xml文件。 初始化SP对象最后都是由SharedPreferencesImpl进行构建 12345678910111213SharedPreferencesImpl(File file, int mode) { mFile = file; //构建备份文件 mBackupFile = makeBackupFile(file); mMode = mode; mLoaded = false; //缓存当前SP存储的键值对 mMap = null; mThrowable = null; //开始加载磁盘的xml文件 startLoadFromDisk();}Copy 加载文件 加载文件 开启一个异步线程去加载xml文件，防止阻塞主线程 123456789101112private void startLoadFromDisk() { //上锁保证线程安全 synchronized (mLock) { mLoaded = false; } new Thread(&quot;SharedPreferencesImpl-load&quot;) { public void run() { loadFromDisk(); } }.start();}Copy loadFromDisk()时，需要判断当前是否存在备份文件，若存在备份文件就意味着上一次写入文件的过程出现了异常，导致写入失败。 123456789101112131415161718192021222324252627282930313233343536private void loadFromDisk() { synchronized (mLock) { if (mLoaded) { return; } if (mBackupFile.exists()) { //删除源文件 mFile.delete(); //备份文件重命名为 源文件 mBackupFile.renameTo(mFile); } } ... synchronized (mLock) { mLoaded = true; mThrowable = thrown; try { if (thrown == null) { if (map != null) { //解析成功 赋值到mMap进行缓存 mMap = map; mStatTimestamp = stat.st_mtim; mStatSize = stat.st_size; } else { mMap = new HashMap&lt;&gt;(); } } } catch (Throwable t) { mThrowable = t; } finally { //释放锁 通知其他线程可以开始使用SP对象 mLock.notifyAll(); } }}Copy 这里就表现了SP的文件损坏时的备份机制，当文件写入异常时，启用备份文件保证之前的数据不会出现异常。 获取数据 获取数据 123... 初始化完成 sp对象sp.getString(&quot;a&quot;,&quot;b&quot;); //从sp获取a的值Copy 获取数据支持部分数据类型，例如int、long、String等 123456789101112131415161718192021222324252627282930//SharedPreferencesImpl.javapublic String getString(key){}public Set&lt;String&gt; getStringSet(key){}public int getInt(key){}public long getLong(key){}public float getFloat(key){}public boolean getBoolean(key){}//以下拿 getString() 举例分析获取数据流程 public String getString(String key, @Nullable String defValue) { synchronized (mLock) { awaitLoadedLocked(); String v = (String)mMap.get(key); return v != null ? v : defValue; } } private void awaitLoadedLocked() { while (!mLoaded) { try { //等待mLock释放 mLock.wait(); } catch (InterruptedException unused) { } } if (mThrowable != null) { throw new IllegalStateException(mThrowable); } }Copy getXX()都是运行在主线程的，并且想要获取数据就必须等待加载文件这一步完成。等待mLock.notifyAll()才可以继续向下执行。 如果需要读取一个很大的文件，在调用getXX()之后，就需要一直进行等待，而导致主线程发生阻塞。 xml文件加载完毕后，getXX()从mMap获取数据，就不需要重新读取文件。 获取数据异常SP中进行存储时，可能会导致同一个key存储不同类型的值，导致获取数据的时候抛出ClassCastException异常。 写入数据 写入数据 12345... 初始化完成 sp对象SharedPreferences.Editor mEditor = sharedPreferences.edit();//写入数据mEditor.putString(&quot;a&quot;,&quot;c&quot;);Copy 写入数据同样支持部分数据类型。但是不是通过SP对象，而是通过Editor对象进行数据的写入 Editor对象写入数据的相关操作都要通过Editor，本体是一个接口 1234567891011121314151617//SharedPreferences.javapublic interface Editor { //放入对应类型的对象 Editor putString(String key, @Nullable String value); Editor putStringSet(String key, @Nullable Set&lt;String&gt; values); Editor putInt(String key, int value); Editor putLong(String key, long value); Editor putFloat(String key, float value); Editor putBoolean(String key, boolean value); //删除数据 Editor remove(String key); Editor clear(); //提交数据 boolean commit(); void apply();}Copy Editor只是一个接口，EditorImpl才是具体的实现类。 123456789101112131415161718//SharedPreferencesImpl.java public final class EditorImpl implements Editor { private final Object mEditorLock = new Object(); @GuardedBy(&quot;mEditorLock&quot;) private final Map&lt;String, Object&gt; mModified = new HashMap&lt;&gt;(); @Override public Editor putString(String key, @Nullable String value) { //通过synchronized修饰保证线程安全。 synchronized (mEditorLock) { //存入临时map中，后续有用 mModified.put(key, value); return this; } } }Copy mModified保存的是用户通过putXX()新增的数据，数据有效期位于第一次putXX 到\u0010 commit()/apply(). 提交数据上面写入数据完毕后，最后要调用一次commit()/apply()准备把数据写入到对应xml文件中。 “半同步”提交数据——commit commit 12345678910111213141516171819202122232425262728293031... 初始化完成 sp对象SharedPreferences.Editor mEditor = sharedPreferences.edit();//写入数据mEditor.putString(&quot;a&quot;,&quot;c&quot;);//提交数据mEditor.commit();Copy//SharedPreferencesImpl.java @Override public boolean commit() { long startTime = 0; if (DEBUG) { startTime = System.currentTimeMillis(); } MemoryCommitResult mcr = commitToMemory();//写入内存 SharedPreferencesImpl.this.enqueueDiskWrite( mcr, null /* sync write on this thread okay */);//写入磁盘 try { //等待写入磁盘任务执行完毕 此处可能导致主线程阻塞 mcr.writtenToDiskLatch.await(); } catch (InterruptedException e) { return false; } finally { } notifyListeners(mcr);//通知监听 return mcr.writeToDiskResult; }Copy commit()先后调用了commitToMemory()/*写入数据到mMap中，等待写入磁盘*/、enqueueDiskWrite()/*将数据写入到磁盘中*/，通过writeToFile()写入到磁盘中并会返回对应写入结果。 commit()如果当前没有线程在写入文件时，就会直接在当前线程开启写入磁盘任务，导致主线程阻塞(可能发生ANR)，等待线程执行完毕。如果在写入文件，就会通过QueuedWork开启异步执行。(这就是半同步的原因) commit()执行都是同步的，而且每次都是写入全量的数据，会导致主线程阻塞。 SharedPreferences-commit 异步提交数据——apply apply 1234567891011121314151617181920212223242526272829303132333435363738... 初始化完成 sp对象SharedPreferences.Editor mEditor = sharedPreferences.edit();//写入数据mEditor.putString(&quot;a&quot;,&quot;c&quot;);//提交数据mEditor.apply();Copy@Overridepublic void apply() { final long startTime = System.currentTimeMillis(); final MemoryCommitResult mcr = commitToMemory();//写入内存 final Runnable awaitCommit = new Runnable() { @Override public void run() { try { mcr.writtenToDiskLatch.await();//等待磁盘写入任务完成 } catch (InterruptedException ignored) { } } }; //添加 QueuedWork执行完毕的回调监听 QueuedWork.addFinisher(awaitCommit); Runnable postWriteRunnable = new Runnable() { @Override public void run() { awaitCommit.run(); QueuedWork.removeFinisher(awaitCommit); } }; //开启异步线程执行写入任务 SharedPreferencesImpl.this.enqueueDiskWrite(mcr, postWriteRunnable); notifyListeners(mcr);}Copy apply()也先调用commitToMemory()将更改提交到内存，之后调用enqueueDiskWriter()开启写入磁盘任务。 apply()是提交任务到线程池后，就直接通知写入成功，不需要等待线程执行完成。 虽然apply()是异步执行的，但是存在某些场景下也会发生ANR。后文会分析 缓存写入内存 写入内存 将缓存文件写入内存 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Returns true if any changes were madeprivate MemoryCommitResult commitToMemory() { long memoryStateGeneration; List&lt;String&gt; keysModified = null; Set&lt;OnSharedPreferenceChangeListener&gt; listeners = null; Map&lt;String, Object&gt; mapToWriteToDisk; synchronized (SharedPreferencesImpl.this.mLock) { if (mDiskWritesInFlight &gt; 0) { mMap = new HashMap&lt;String, Object&gt;(mMap); } //软拷贝 mapToWriteToDisk = mMap; mDiskWritesInFlight++; synchronized (mEditorLock) { boolean changesMade = false; //调用了 clear() 清理的是所有数据 if (mClear) { if (!mapToWriteToDisk.isEmpty()) { changesMade = true; mapToWriteToDisk.clear(); } mClear = false; } //mModified的值写入到 mapToWriteToDisk中，准备写入到文件中 for (Map.Entry&lt;String, Object&gt; e : mModified.entrySet()) { String k = e.getKey(); Object v = e.getValue(); // &quot;this&quot; is the magic value for a removal mutation. In addition, // setting a value to &quot;null&quot; for a given key is specified to be // equivalent to calling remove on that key. if (v == this || v == null) { if (!mapToWriteToDisk.containsKey(k)) { continue; } mapToWriteToDisk.remove(k); } else { if (mapToWriteToDisk.containsKey(k)) { Object existingValue = mapToWriteToDisk.get(k); if (existingValue != null &amp;&amp; existingValue.equals(v)) { continue; } } mapToWriteToDisk.put(k, v); } //发生了变化 changesMade = true; } //执行完毕后 mMap和 mapToWriteToDisk内容一致 //写入内存后，清除原先未写入的数据 mModified.clear(); if (changesMade) { //差异计数 +1 mCurrentMemoryStateGeneration++; } } } return new MemoryCommitResult(memoryStateGeneration, keysModified, listeners, mapToWriteToDisk);}Copy 将mModified的值写入到mapToWriteToDisk，其实mMap中也是一样的内容，然后清空mModified的数据，拼接得到一个MemoryCommitResult对象，里面持有的就是要写入xml文件的内容。 内存写入磁盘 写入磁盘 把存入内存的数据mapToWriteToDisk写入到对应的xml文件。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788private void enqueueDiskWrite(final MemoryCommitResult mcr, //commit() 传入为null apply() 传入不为null final Runnable postWriteRunnable) { final boolean isFromSyncCommit = (postWriteRunnable == null);//commit 为 true apply为false final Runnable writeToDiskRunnable = new Runnable() { @Override public void run() { synchronized (mWritingToDiskLock) { //写入内容到文件 writeToFile(mcr, isFromSyncCommit); } synchronized (mLock) { mDiskWritesInFlight--; } if (postWriteRunnable != null) { //直接执行传入的 任务 postWriteRunnable.run(); } } }; //当前为 commit() if (isFromSyncCommit) { boolean wasEmpty = false; synchronized (mLock) { //当前是否只有一个写入硬盘的需求 wasEmpty = mDiskWritesInFlight == 1; } if (wasEmpty) { //只有一个硬盘写入请求，在当前线程执行任务 writeToDiskRunnable.run(); return; } } //存在多个写入硬盘请求，都要通过 QueuedWork 执行写入任务 QueuedWork.queue(writeToDiskRunnable, !isFromSyncCommit); }Copy/* * 写入数据到磁盘中 * 把已存在的文件进行重命名 添加.bak后缀，作为备份文件存在。删除源文件 * 新建 源文件，重新写入所有数据，同时记录写入时间 * 如果写入文件失败，删除新建的文件，并返回失败 * 如果写入文件成功，删除备份文件，返回成功 */private void writeToFile(MemoryCommitResult mcr, boolean isFromSyncCommit) { //把当前文件做一份备份文件 if (!backupFileExists) { if (!mFile.renameTo(mBackupFile)) { Log.e(TAG, &quot;Couldn't rename file &quot; + mFile + &quot; to backup file &quot; + mBackupFile); mcr.setDiskWriteResult(false, false); return; } } else { mFile.delete(); } ... } void setDiskWriteResult(boolean wasWritten, boolean result) { this.wasWritten = wasWritten; writeToDiskResult = result; //比较两次请求的版本号，版本号不一致表示发生了改变 if (mDiskStateGeneration &lt; mcr.memoryStateGeneration) { if (isFromSyncCommit) { needsWrite = true; } else { synchronized (mLock) { // No need to persist intermediate states. Just wait for the latest state to // be persisted. if (mCurrentMemoryStateGeneration == mcr.memoryStateGeneration) { needsWrite = true; } } } } //版本号一致，就不重复执行写入磁盘任务 if (!needsWrite) { mcr.setDiskWriteResult(false, true); return; } //执行完毕一次任务 自动-1 writtenToDiskLatch.countDown(); }Copy 写入到xml文件之前，会把原有的数据保存在.bak文件进行备份，用于写入磁盘过程中发生任何异常都可以恢复原有数据。 根据上述流程commit()/apply()提交数据 -&gt; 写入内存 -&gt; 写入硬盘，每次调用都会走一遍完整流程，导致频繁的IO使用。 官方更建议将数据的更新合并到一次写操作中，即多次写入一次提交。 commit与apply的比较 apply()没有返回值，commit()有返回值可以知道文件是否写入成功 apply()将修改提交内存，再异步写入文件；commit()同步写入文件。 并发commit()时，需要等待正在执行的数据写入到文件后才会继续往下执行；apply()先更新到内存，后面再次调用会覆盖原有的内存数据，接下来再异步写入文件即可。 删除数据12345678910111213141516171819202122232425262728293031323334SharedPreferences sp = getSharedPreferences(&quot;a&quot;,MODE_PRIVATE);SharedPreferences.Editor editor = sp.edit();//写入数据editor.putString(&quot;a&quot;,&quot;b&quot;);//通过remove 清除单个数据editor.remove(&quot;a&quot;);//提交数据editor.commit();//清除所有数据editor.clear();editor.commit();Copy private MemoryCommitResult commitToMemory() { Map&lt;String, Object&gt; mapToWriteToDisk; ... synchronized (SharedPreferencesImpl.this.mLock) { //赋值原有数据 mapToWriteToDisk = mMap; ... synchronized (mEditorLock) { boolean changesMade = false; if (!mapToWriteToDisk.isEmpty()) { changesMade = true; //清除原有数据 mapToWriteToDisk.clear(); } mClear = false; } } }//最后写入的就是一个空map，导致所有存储的数据都被清空Copy 数据改变监听SP支持监听数据的改变，返回的是修改的内容 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556SharedPreferences sp = getSharedPreferences(&quot;a&quot;,MODE_PRIVATE);SharedPreferences.Editor editor = sp.edit();SharedPreferences.OnSharedPreferenceChangeListener listener = new SharedPreferences.OnSharedPreferenceChangeListener() { @Override public void onSharedPreferenceChanged(SharedPreferences sharedPreferences, String key) { //打印发生了改变的值 } };//对应的需要在 页面销毁时，及时取消监听sp.unregisterOnSharedPreferenceChangeListener(listener);Copy//SharedPreferencesImpl.java public void registerOnSharedPreferenceChangeListener(OnSharedPreferenceChangeListener listener) { synchronized(mLock) { mListeners.put(listener, CONTENT); } } private MemoryCommitResult commitToMemory() { ... boolean hasListeners = mListeners.size() &gt; 0; if (hasListeners) { keysModified = new ArrayList&lt;String&gt;(); //转化 去重 listeners = new HashSet&lt;OnSharedPreferenceChangeListener&gt;(mListeners.keySet()); } ... //作为参数 传入 MCR return new MemoryCommitResult(memoryStateGeneration, keysModified, listeners, mapToWriteToDisk); }//发生变化后通知回调 private void notifyListeners(final MemoryCommitResult mcr) { if (mcr.listeners == null || mcr.keysModified == null || mcr.keysModified.size() == 0) { return; } if (Looper.myLooper() == Looper.getMainLooper()) { //在主线程直接回调 for (int i = mcr.keysModified.size() - 1; i &gt;= 0; i--) { final String key = mcr.keysModified.get(i); for (OnSharedPreferenceChangeListener listener : mcr.listeners) { if (listener != null) { listener.onSharedPreferenceChanged(SharedPreferencesImpl.this, key); } } } } else { // 不在主线程切换到主线程回调 ActivityThread.sMainThreadHandler.post(() -&gt; notifyListeners(mcr)); } }Copy commit()需要在数据写入文件后，才可以回调到notifyListeners()通知数据发生变化。 apply()只要数据在写入内存后，就会直接回调。 QueuedWork SP-QueuedWork 系统提供的异步工具类，内部通过HandlerThread作为工作线程，用于跟踪那些未完成或尚未结束的全局任务。 初始化1234567891011121314private static Handler getHandler() { synchronized (sLock) { if (sHandler == null) { //新建HandlerThread执行任务 HandlerThread handlerThread = new HandlerThread(&quot;queued-work-looper&quot;, Process.THREAD_PRIORITY_FOREGROUND); handlerThread.start(); sHandler = new QueuedWorkHandler(handlerThread.getLooper()); } return sHandler; }}Copy queue()向QueuedWork中添加任务 1234567891011121314public static void queue(Runnable work, boolean shouldDelay) { Handler handler = getHandler(); synchronized (sLock) { sWork.add(work); if (shouldDelay &amp;&amp; sCanDelay) { handler.sendEmptyMessageDelayed(QueuedWorkHandler.MSG_RUN, DELAY); } else { handler.sendEmptyMessage(QueuedWorkHandler.MSG_RUN); } }}Copy commit()时，shouldDelay为false，直接发送消息 apply()时，shouldDelay为true，需要延迟100ms再发送消息，避免频繁的磁盘写入操作 addFinisher()添加完成任务完成回调 12345678910@GuardedBy(&quot;sLock&quot;)private static final LinkedList&lt;Runnable&gt; sFinishers = new LinkedList&lt;&gt;();public static void addFinisher(Runnable finisher) { synchronized (sLock) { //将完成任务后的Runnable添加进去，等待任务完成后执行 sFinishers.add(finisher); }}Copy processPendingWork()执行写入磁盘任务 123456789101112131415161718192021private static void processPendingWork() { long startTime = 0; synchronized (sProcessingWork) { LinkedList&lt;Runnable&gt; work; synchronized (sLock) { work = (LinkedList&lt;Runnable&gt;) sWork.clone(); sWork.clear(); getHandler().removeMessages(QueuedWorkHandler.MSG_RUN); } if (work.size() &gt; 0) { for (Runnable w : work) { //执行任务 w.run(); } } }}Copy QueuedWork执行流程 * waitToFinish()等待任务完成。这里也就是ANR发生的根本原因 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//主线程调用 public static void waitToFinish() { long startTime = System.currentTimeMillis(); boolean hadMessages = false; Handler handler = getHandler(); try { //执行未完成的任务 processPendingWork(); } finally { StrictMode.setThreadPolicy(oldPolicy); } try { while (true) { Runnable finisher; synchronized (sLock) { finisher = sFinishers.poll();//取出 任务完成后的回调 } if (finisher == null) { break; } //此处会导致阻塞的发生 finisher.run();//执行 任务完成后的回调 对应执行的就是 writtenToDiskLatch.await() } } finally { sCanDelay = true; } }//SharedPreferencesImpl.javaapply(){ final Runnable awaitCommit = new Runnable() { @Override public void run() { try { //需要等待主线程写入任务完毕 mcr.writtenToDiskLatch.await();//等待磁盘写入任务完成 } catch (InterruptedException ignored) { } } }; //添加 QueuedWork执行完毕的回调监听 QueuedWork.addFinisher(awaitCommit);}Copy 调用waitToFinish()时，会主动调用processPendingWork()去执行任务，在HandlerThread执行写入磁盘任务。 waitToFinish()会一直等待写入任务执行完毕，其他什么都不做，当存在很多写入任务时，会依次执行，文件很大时效率很低，就有可能导致ANR。 线程安全 线程安全 SP的线程安全分为两部分分析 读线程安全1234567891011 @GuardedBy(&quot;mLock&quot;) private Map&lt;String, Object&gt; mMap;//通过注解的形式 告知该对象由哪把锁控制public String getString(String key, @Nullable String defValue) { synchronized (mLock) { String v = (String)mMap.get(key); return v != null ? v : defValue; }}Copy 读操作主要是从mMap读取缓存的值，避免其他线程执行写操作导致线程不安全，通过mLock保证线程安全。 写线程安全写操作，主要分为三步，每一步都有不同的锁进行控制。 写入对象1234567891011@GuardedBy(&quot;mEditorLock&quot;)private final Map&lt;String, Object&gt; mModified = new HashMap&lt;&gt;();@Overridepublic Editor putString(String key, @Nullable String value) { synchronized (mEditorLock) { mModified.put(key, value); return this; }}Copy 第一把锁mEditorLock保证写入到mModified线程安全 写入内存123456789101112131415synchronized (SharedPreferencesImpl.this.mLock) { //控制mMap赋值 if (mDiskWritesInFlight &gt; 0) { mMap = new HashMap&lt;String, Object&gt;(mMap); } mapToWriteToDisk = mMap; synchronized (mEditorLock) { boolean changesMade = false; //保证mModified 与 mapToWriteToDisk的合并安全 for (Map.Entry&lt;String, Object&gt; e : mModified.entrySet()) { mapToWriteToDisk.put(k, v); } }Copy 写入内存时，需要把mModify待添加的数据合并到mapToWriteToDisk中，这时需要通过两把锁保证线程安全。 保证mapToWriteToDisk赋值时数据正确 保证mModified合并到mapToWriteToDisk时线程安全 写入硬盘12345//将mapToWriteToDisk的内容写入到 xml文件中synchronized (mWritingToDiskLock) { writeToFile(mcr, isFromSyncCommit);}Copy 写入硬盘时，保证写入时内容不会发生改变。 进程安全 进程安全 SharedPreferences不是进程安全的。 MODE_MULTI_PROCESS123456if ((mode &amp; Context.MODE_MULTI_PROCESS) != 0 || getApplicationInfo().targetSdkVersion &lt; android.os.Build.VERSION_CODES.HONEYCOMB) { //重新加载XML文件 sp.startReloadIfChangedUnexpectedly();}Copy 唯一的作用就是 切换进程时重新加载XML文件内容。 当在频繁跨进程读写时就会有数据丢失的可能。 ContentProvider(官方推荐)ContentProvider是Android提供的跨进程组件，可以替换其底层实现为SP，来保证SP的进程安全。 //TODO 实现待添加 文件锁SharedPreferences 本质是对xml文件的读写，可以通过对xml文件添加文件锁，就能保证进程安全。 FileLock(文件锁)用来表示文件区域锁定标记，可以通过对一个可写文件加锁，保证同时只有一个进程可以拿到文件的锁，这个进程就可以对文件进行访问；其他拿不到锁的进程要么选择被挂起等待，要么去做一些其他的事情。 可以保证众进程可以顺序访问文件，并且可以通过FileLock进行并发控制，保证进程的顺序执行。 获取锁 FileChannel.lock()：阻塞直至获得文件锁。默认锁定整个文件 FileChannel.lock(position,size,shared)：阻塞直至获取文件的部分数据的文件锁 FileChannel.tryLock()：立即返回，要么返回锁，要么返回null(获取锁失败) 释放锁 FileLock.release()：释放当前文件锁 检测锁 FileLock.isValid()：检测文件锁的有效性 //TODO 实现待添加 ANR分析 ANR分析 在上面有提到QueuedWork.waitToFinish()是要在写入文件的操作完成后才会结束，且这个方法会运行在当前线程，极有可能导致阻塞/ANR。 waitToFinish()调用场景通过全局搜索QueuedWork.waitToFinish()找到在ActivityThread使用的较多 12345678910111213141516171819202122//ActivityThread.java public void handleStopActivity(IBinder token, boolean show, int configChanges, PendingTransactionActions pendingActions, boolean finalStateRequest, String reason) { ... if (!r.isPreHoneycomb()) { QueuedWork.waitToFinish(); } } private void handleSleeping(IBinder token, boolean sleeping) { ... if (sleeping) { if (!r.stopped &amp;&amp; !r.isPreHoneycomb()) { callActivityOnStop(r, true /* saveState */, &quot;sleeping&quot;); } // Make sure any pending writes are now committed. if (!r.isPreHoneycomb()) { QueuedWork.waitToFinish(); } }Copy 会在onStop()时调用QueuedWork.waitToFinish()等待当前未执行完毕的写入任务结束，才可以释放锁。此时就会阻塞主线程，可能导致ANR。 解决方案 反射在ActivityThread中的H变量添加一个callback，可以拦截Handler的事件分发。在几个关键的节点例如stop、pause及时通过反射清理QueuedWork中的sFinishers请求等待队列。 开启一个异步线程在其内部调用commit()去写入数据 使用注意事项 建议不要在SP里存储特别大的key/value,因为内容都是一次性加载到内存中，过大会导致卡顿/ANR。 不要频繁调用commit()/apply()，SP的数据每次都是全量写入文件，尤其是commit()直接同步操作，更容易卡顿。建议批量写一次提交 MODE_MULTI_PROCESS是在每次getSharedPreferences时检查磁盘上配置文件上次修改时间和文件大小，一旦所有修改则会重新从磁盘加载文件，所以并不能保证多进程数据的实时同步。 高频写操作的key与高频读操作的key可以适当的拆分文件，减少同步锁的竞争。 最好写入轻量级的数据，不要存储大量的数据。 替换方案MMKV 通过mmap内存映射文件，提供一段可随时写入的内存块，APP只管往里写数据，由操作系统负责将内存回写到文件，而不必担心Crash导致数据丢失。 写入的数据格式为 Protobuf Github-MMKV MMKV原理 MMKV for Android 多进程设计与实现 参考链接全面解析SharedPReferences SharedPreferences的设计与实现 Jetpack DataStore 分析 剖析 SharedPreference apply 引起的 ANR 问题 Android 源码仓库","link":"/2021/11/15/SharePreference/"},{"title":"Tools","text":"AOSPAndroid 代码搜索 ( cs.android.com ) 代码搜索文档。 ClipBoardDownload the application apk and manually install application on your android device. 12# am broadcast -a clipper.set -e text &quot;this can be pasted now&quot;# am broadcast -a clipper.get BookMarkProcessOn 语法 API Levels | Android versions, SDK/API levels, version codes, codenames, and cumulative usage QRCode生成 Android内存分析命令 - Gityuan博客 | 袁辉辉的技术博客 Color Converter - RGB, HEX, HSL, ARGB, RGBA Unix Time Stamp - Epoch Converter Time 洛杉矶: 01:04 chatGpt-New chat Watching TechPlatform软件包列表Linux命令大全(手册) – 真正好用的Linux命令在线查询网站Learning the shell - Lesson 1: What is the shell?字节跳动技术团队 的团队主页InfoQ - 促进软件开发及相关领域知识与创新的传播-极客邦极客时间-轻松学习，高效学习-极客邦 Input系统—ANR原理分析 - Gityuan博客 | 袁辉辉的技术博客 微信Android客户端的ANR监控方案 今日头条 ANR 优化实践系列 - 设计原理及影响因素 深入理解 Android ANR 触发原理以及信息收集过程 - huansky - 博客园 一文读懂直播卡顿优化那些事儿 - 掘金 一文读懂 Android FFmpeg 视频解码过程与实战分析 - 掘金 btrace 开源！基于 Systrace 高性能 Trace 工具 - 掘金 深入剖析虚拟内存工作原理 - 云+社区 - 腾讯云 OutOfMemoryError 可以被 try catch 吗？ - 掘金 Android高性能高稳定性代码覆盖率方案探索实践 - ATA word list 1_哔哩哔哩_bilibili 面向贡献者的 AOSP 代码样式指南 | Android 开源项目 | Android Open Source Project Docdoc Articles technology Other","link":"/2023/03/14/Tools/"},{"title":"ThreadPool","text":"https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html 12345678910111213141516171819202122232425262728293031323334/** * Creates a new {@code ThreadPoolExecutor} with the given initial * parameters. * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless {@code allowCoreThreadTimeOut} is set * 核心线程数量，线程常驻即使空闲，除非设置了allowCoreThreadTimeOut * @param maximumPoolSize the maximum number of threads to allow in the * pool * 最大线程数，整个线程池的线程数量（核心线程数+普通线程数） * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * 超过核心线程数后的空闲线程存活时间 * @param unit the time unit for the {@code keepAliveTime} argument * 时间单位 * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the {@code Runnable} * tasks submitted by the {@code execute} method. * 工作队列：任务被执行前的存放队列 * @param threadFactory the factory to use when the executor * creates a new thread * executor创建线程的工厂 * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * ... */public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 通过Executors工具类可以创建多种类型的线程池，包括： FixedThreadPool：固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。核心线程数为n，最大线程数为n，任务队列长度为Interger.MAX_VALUE的LinkedBlockingQueue SingleThreadExecutor： 只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。核心线程数、最大线程数都为1，任务队列长度为Interger.MAX_VALUE的LinkedBlockingQueue CachedThreadPool： 可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。核心线程数为0，最大线程数为Interger.MAX_VAULE，任务队列为无容量的SynchronousQueue ScheduledThreadPool：给定的延迟后运行任务或者定期执行任务的线程池。核心线程为n，最大线程为Interger.MAX_VALUE，任务队列长度为最大Interger_MAX_VALUE的DelayQueue 《阿里巴巴 Java 开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 构造函数的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor:使用的是无界的 LinkedBlockingQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 CachedThreadPool:使用的是同步队列 SynchronousQueue, 允许创建的线程数量为 Integer.MAX_VALUE ，如果任务数量过多且执行速度较慢，可能会创建大量的线程，从而导致 OOM。 ScheduledThreadPool 和 SingleThreadScheduledExecutor:使用的无界的延迟阻塞队列DelayedWorkQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。 ThreadPoolExecutor使用详解其实java线程池的实现原理很简单，说白了就是一个线程集合workerSet和一个阻塞队列workQueue。当用户向线程池提交一个任务(也就是线程)时，线程池会先将任务放入workQueue中。workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行。 # Execute原理https://excalidraw.com/#json=Y7a8uMRrIrZNGfr7GnQ0M,2qUB-ZmXM-hwP0a3MWnA1A 当一个任务提交至线程池之后: 线程池首先当前运行的线程数量是否少于corePoolSize。如果是，则创建一个新的工作线程来执行任务。如果都在执行任务，则进入2. 判断BlockingQueue是否已经满了，倘若还没有满，则将线程放入BlockingQueue。否则进入3. 如果创建一个新的工作线程将使当前运行的线程数量超过maximumPoolSize，则交给RejectedExecutionHandler来处理任务。 运行机制（当任务来了之后的执行流程）： 判断核心线程数是否已满；如果未满创建核心线程执行任务；如果满了执行后续操作。 判断任务队列是否已满；如果未满将任务添加到队列；如果满了执行后续流程。 判断最大线程数是否已满；如果未满创建临时线程执行任务；如果满了执行后续流程。 执行拒绝策略（内置4种拒绝策略+自定义的拒绝策略）。 当ThreadPoolExecutor创建新线程时，通过CAS来更新线程池的状态ctl. # 参数123456public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) corePoolSize 线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize, 即使有其他空闲线程能够执行新来的任务, 也会继续创建线程；如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。 workQueue 用来保存等待被执行的任务的阻塞队列. 在JDK中提供了如下阻塞队列: 具体可以参考JUC 集合: BlockQueue详解 ArrayBlockingQueue: 基于数组结构的有界阻塞队列，按FIFO排序任务； LinkedBlockingQueue: 基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQueue； SynchronousQueue: 一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue； PriorityBlockingQueue: 具有优先级的无界阻塞队列； LinkedBlockingQueue比ArrayBlockingQueue在插入删除节点性能方面更优，但是二者在put(), take()任务的时均需要加锁，SynchronousQueue使用无锁算法，根据节点的状态判断执行，而不需要用到锁，其核心是Transfer.transfer(). maximumPoolSize 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize；当阻塞队列是无界队列, 则maximumPoolSize则不起作用, 因为无法提交至核心线程池的线程会一直持续地放入workQueue. keepAliveTime 线程空闲时的存活时间，即当线程没有任务执行时，该线程继续存活的时间；默认情况下，该参数只在线程数大于corePoolSize时才有用, 超过这个时间的空闲线程将被终止； unit keepAliveTime的单位 threadFactory 创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名。默认为DefaultThreadFactory handler 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略: AbortPolicy: 直接抛出异常，默认策略； CallerRunsPolicy: 用调用者所在的线程来执行任务； DiscardOldestPolicy: 丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy: 直接丢弃任务； 当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。 ※线程池ThreadPoolExecutor常见的线程池有：无缓存线程· 定长线程池（最常见，如Glide）FixedThreadPool：根据入参决定有多少个核心线程，无缓存线程。 可重用固定线程数的线程池。（适用于负载比较重的服务器） FixedThreadPool使用无界队列LinkedBlockingQueue作为线程池的工作队列，该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列 中的任务。 · 单线程线程池SingleThreadExecutor：只有一个核心线程，最大线程也为1，无缓存线程。所有任务在此线程中FIFO进行只会创建一个线程执行任务。（适用于需要保证顺序执行各个任 务；并且在任意时间点，没有多线程活动的场景。） SingleThreadExecutorl也使用无界队列LinkedBlockingQueue作为工作队列 若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先 出的顺序执行队列中的任务。 · 定时线程池ScheduledThreadPool：只有入参数量的核心线程，无缓存线程。继承自ThreadPoolExecutor。它主要用来在给定的延迟之后运行 任务，或者定期执行任务。使用DelayQueue作为任务队列。如newScheduledThreadPool，用于定时任务。 无核心线程· 缓存线程池CachedThreadPool：无核心线程，无限制地增加执行完成就销毁(根据keepaliveTime决定)的缓存线程，是一个会根据需要调整线程数量的线程池。（大小无界，适用于执行很 多的短期异步任务的小程序，或负载较轻的服务器） CachedThreadPool使用没有容量的SynchronousQueue作为线程池的工作队列，但 CachedThreadPool的maximumPool是无界的。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线 程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕 后，将返回线程池进行复用。 作用 降低资源消耗：通过重复利用现有的线程来执行任务，避免多次创建和销毁线程。一个线程保留1M大小的内存空间，有效降低OOM 提高相应速度：因为省去了创建线程这个步骤，所以在拿到任务时，可以立刻开始执行。 线程数应该怎么设置 如果任务是IO密集型，一般线程数需要设置2倍CPU数以上（2N），以此来尽量利用CPU资源。 如果任务是CPU密集型，一般线程数量只需要设置CPU数加1即可，更多的线程数也只能增加上下文切换，不能增加CPU利用率。 在计算密集型任务中，将线程池大小设置为 CPU 核心数 + 1 的原因是为了应对可能出现的阻塞情况。 虽然计算密集型任务主要消耗 CPU 资源，但在实际应用中，任务内部可能仍然存在一些阻塞操作， 例如：同步 IO： 如果任务需要进行磁盘读写或网络通信等 IO 操作，并且这些操作是同步阻塞的，那么当前线程会被阻塞， 无法继续执行计算任务。锁竞争： 如果任务中存在对共享资源的访问，并且使用了锁机制进行同步， 那么当多个线程同时竞争锁时， 部分线程会被阻塞， 等待获取锁。页面错误： 当线程访问的内存页面不在物理内存中时，会发生页面错误， 导致线程被阻塞， 等待操作系统将页面从磁盘加载到内存。 如果线程池大小刚好等于 CPU 核心数，那么当一个线程被阻塞时，CPU 就无法充分利用，导致整体性能下降。 而增加一个额外的线程，可以确保在某个线程被阻塞时， 仍然有足够的线程可以继续执行计算任务， 从而提高 CPU 利用率和整体性能。 当然，这只是一个经验法则，并不是绝对的。 在某些情况下， 如果任务中不存在阻塞操作， 或者阻塞情况非常少见， 那么将线程池大小设置为 CPU 核心数也可能足够。 最佳的线程池大小仍然需要根据你的具体应用场景和硬件环境进行调整和测试。 简单来说就是 io多，则用更多线程充分利用cpu；计算多，则用少的线程数减少线程切换，但仍存在的io操作使数量应为n+1; Android一般认为多数操作是IO密集，如网络io，本地文件io，所以会设置2N Android系统对每个进程线程数限制root 下adb shell cat /proc/sys/kernel/threads-max 结果如：57439 但每个线程1M左右，基本上几百个线程就可能OOM了 常见的三方库线程池默认数量OkhttpOkHttp中的线程池是定义在分发器中的，即定义在Dispatcher 1234567public synchronized ExecutorService executorService() { if (executorService == null) { executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;&gt;(), Util.threadFactory(&quot;OkHttp Dispatcher&quot;, false)); } return executorService;} 用的其实相当于就是一个无核心线程，最大线程池为Integer.MAX_VALUE，任务队列为SynchronousQueue的缓存线程池 高并发，最大吞吐量。SynchronousQueue队列是无容量队列， 在OkHttp中，配置的线程池的核心线程数为0，最大线程数为Integer.MAX_VALUE，线程的存活时间为60s，采用的队列是SynchronousQueue。 okhttp 默认同时支持 64 个异步请求(不考虑同步请求)，一个 host 同时最多请求 5 个 okhttp 内部的线程池都是 CacheThreadPool：核心线程数为 0，非核心线程数无限，永远添加不到等待队列中 okhttpClient 如果不单例，会出现 oom：因为大量的 Dispatcher 对象，不同的对象会使用不同的线程去发起网络请求，从而导致线程过多，OOM GlideGlide用的都是核心线程数与最大线程数一致（cpu数量与4的最小值），任务队列为PriorityBlockingQueue的定长线程池。（所以Glide的最大并发量是四个图片?） glide加载的线程池的配置，使用cpu数量与4的最小值，即线程池的核心线程和最大线程数不超过4个 线程池关闭方法区别shutdown() 、 shutdownNow() 、 awaitTermination() 的用法和区别 shutdown()将线程池状态置为SHUTDOWN,并不会立即停止： 停止接收外部submit的任务 内部正在跑的任务和队列里等待的任务，会执行完 等到第二步完成后，才真正停止 shutdownNow()将线程池状态置为STOP。企图立即停止，事实上不一定： 跟shutdown()一样，先停止接收外部提交的任务 忽略队列里等待的任务 尝试将正在跑的任务interrupt中断 返回未执行的任务列表 awaitTermination()awaitTermination(long timeOut, TimeUnit unit) 当前线程阻塞，直到 等所有已提交的任务（包括正在跑的和队列中等待的）执行完 或者等超时时间到 或者线程被中断，抛出InterruptedException 然后返回true（shutdown请求后所有任务执行完毕）或false（已超时） 小结： 优雅的关闭，用shutdown()，停止接受任务并等待进行中的和队列中的任务都执行完后停止。 想立马中断并关闭，并得到未执行任务列表，用shutdownNow()，会interrupt正在进行的任务并忽略队列中任务，返回未执行的任务队列 优雅的关闭，并允许关闭声明后新任务能提交，用awaitTermination() 线程池都有哪几种工作队列？ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。 LinkedBlockingQueue：是一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量 通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()、newSingleThreadExecutor使用了 这个队列。 SynchronousQueue：是一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用 移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue。 DelayedWorkQueue：是一个阻塞队列。保证添加到队列中的任务，会按照任务的延时时间进行排序，延时时间少的任务首先被获取。newScheduledThreadPool使用了这个队列。 假设向线程池提交任务时，核心线程都被占用的情况下： ArrayBlockingQueue：基于数组的阻塞队列，初始化需要指定固定大小。 ​ 当使用此队列时，向线程池提交任务，会首先加入到等待队列中，当等待队列满了之后，再次提交任务，尝试加入队列就会失败，这时就会检查如果当前线程池中的线程数未达到最大线程，则会新建线程执行新提交的任务。所以最终可能出现后提交的任务先执行，而先提交的任务一直在等待。 LinkedBlockingQueue：基于链表实现的阻塞队列，初始化可以指定大小，也可以不指定。 ​ 当指定大小后，行为就和ArrayBlockingQueu一致。而如果未指定大小，则会使用默认的Integer.MAX_VALUE作为队列大小。这时候就会出现线程池的最大线程数参数无用，因为无论如何，向线程池提交任务加入等待队列都会成功。最终意味着所有任务都是在核心线程执行。如果核心线程一直被占，那就一直等待。 SynchronousQueue : 无容量的队列。 ​ 使用此队列意味着希望获得最大并发量。因为无论如何，向线程池提交任务，往队列提交任务都会失败。而失败后如果没有空闲的非核心线程，就会检查如果当前线程池中的线程数未达到最大线程，则会新建线程执行新提交的任务。完全没有任何等待，唯一制约它的就是最大线程数的个数。因此一般配合Integer.MAX_VALUE就实现了真正的无等待。 //lqr:TODO https://juejin.cn/post/6847902225730109454 拒绝策略rejectHander当 Executor 已关闭时，以及当 Executor 对最大线程和工作队列容量使用有限界限且已饱和时，在方法execute(Runnable)中提交的新任务将被拒绝。在任一情况下， execute方法都会调用其RejectedExecutionHandler的RejectedExecutionHandler.rejectedExecution(Runnable, ThreadPoolExecutor)方法。提供了四种预定义的处理程序策略： 在默认的ThreadPoolExecutor.AbortPolicy中，处理程序在被拒绝时会抛出运行时RejectedExecutionException 。 123throw new RejectedExecutionException(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + e.toString()); 在ThreadPoolExecutor.CallerRunsPolicy中，调用execute的线程本身会运行任务。这提供了一种简单的反馈控制机制，可以减慢提交新任务的速度。 123if (!e.isShutdown()) { r.run();} 在ThreadPoolExecutor.DiscardPolicy中，无法执行的任务将被直接丢弃。 1//do nothing 在ThreadPoolExecutor.DiscardOldestPolicy中，如果执行器未关闭，则工作队列头部的任务将被删除，然后重试执行（这可能会再次失败，导致重复此操作。） 1234if (!e.isShutdown()) { e.getQueue().poll(); e.execute(r);} 如果提交任务时，线程池队列已满，会发生什么如果使用的LinkedBlockingQueue，也就是无界队列的话，继续添加任务到阻塞队列中等待执行，因为LinkedBlockingQueue可以无限存放任务；如果使用的是有界队列比方说ArrayBlockingQueue的话，则会使用拒绝策略RejectedExecutionHandler处理满了的任务。","link":"/2024/04/24/ThreadPool/"},{"title":"ViewModel","text":"简述：fragment或componentActivity实现了ViewModelStoreOwner接口，实现该接口方法getViewModelStore()，当调用ViewModelProvider(ViewModelStoreOwner owner).get(Class&lt;T&gt; modelClass)时，会使用工厂模式创建viewModel，之后将其以canonicalName（全限定名）为key存入mViewModelStore中，ViewModelStore内部是个HashMap&lt;String, ViewModel&gt;。 当屏幕旋转或切换系统语言等配置修改的行为发生时，Activity 生命周期从销毁再重建，在销毁时（系统杀死或配置修改），如果判断系统配置没有变化（即!isChangingConfigurations）清空保存的ViewModel（即 getViewModelStore().clear();） 如果发生变化则调用onRetainNonConfigurationInstance() 方法将 viewModelStore 保存起来，当Activity重建时则从getLastNonConfigurationInstance()中获取保存的mViewModelStore ps：如果ViewModelProvider传入Activity，则取得是Activity的ViewModelStore，如果传入了fragment，则根据以下代码取ViewModelStore，即先取父fragment的FragmentManager的ViewModelStore，再取hostActivty的ViewModelStore，最后才是新建一个。 12345678if (parent != null) { this.mNonConfig = parent.mFragmentManager.getChildNonConfig(parent);} else if (host instanceof ViewModelStoreOwner) { ViewModelStore viewModelStore = ((ViewModelStoreOwner)host).getViewModelStore(); this.mNonConfig = FragmentManagerViewModel.getInstance(viewModelStore);} else { this.mNonConfig = new FragmentManagerViewModel(false);} 当屏幕旋转或者切换系统语言时，Activity 生命周期从销毁再重建，但是ViewModel里面的变量值不受到影响，说明ViewModel中的变量在屏幕旋转前进行了存储，在屏幕旋转后又进行了恢复。 里面的原理是怎么实现的呢？ 一、获取ViewModel实例12// MainActivity.ktval viewModel = ViewModelProvider(this).get(MainViewModel::class.java) 这个代码拆分成2段来分析：ViewModelProvider(this)和get(MainViewModel::class.java) 二、ViewModelProvider(this)用于获取 ViewModelProvider 实例 123456789101112131415161718192021222324252627282930313233// ViewModelProvider.javapublic ViewModelProvider(@NonNull ViewModelStoreOwner owner) { this(owner.getViewModelStore(), owner instanceof HasDefaultViewModelProviderFactory ? ((HasDefaultViewModelProviderFactory) owner).getDefaultViewModelProviderFactory() : NewInstanceFactory.getInstance());}// ComponentActivity.java public ViewModelStore getViewModelStore() { if (getApplication() == null) { throw new IllegalStateException(&quot;Your activity is not yet attached to the &quot; + &quot;Application instance. You can't request ViewModel before onCreate call.&quot;); } ensureViewModelStore(); return mViewModelStore;}@SuppressWarnings(&quot;WeakerAccess&quot;) /* synthetic access */void ensureViewModelStore() { if (mViewModelStore == null) { // 先从 NonConfigurationInstances 获取 NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { // Restore the ViewModelStore from NonConfigurationInstances // 从缓存中恢复 mViewModelStore = nc.viewModelStore; } // 如果缓存里面没有，直接创建新的 if (mViewModelStore == null) { mViewModelStore = new ViewModelStore(); } }} 代码很简单，可以看出，最后调用的是ComponentActivity中的ensureViewModelStore()方法，这个方法很重要。 这个方法涉及2个很重要的类：ViewModelStore 和 NonConfigurationInstances。 ViewModelStoreViewModelStore从名字可以看出，是用来存储ViewModle对象的，做一个缓存的作用，底层用Map实现。源码： 123456789101112131415161718192021222324252627282930// ViewModelStore.javapublic class ViewModelStore { private final HashMap&lt;String, ViewModel&gt; mMap = new HashMap&lt;&gt;(); final void put(String key, ViewModel viewModel) { ViewModel oldViewModel = mMap.put(key, viewModel); if (oldViewModel != null) { oldViewModel.onCleared(); } } final ViewModel get(String key) { return mMap.get(key); } Set&lt;String&gt; keys() { return new HashSet&lt;&gt;(mMap.keySet()); } /** * Clears internal storage and notifies ViewModels that they are no longer used. */ public final void clear() { for (ViewModel vm : mMap.values()) { vm.clear(); } mMap.clear(); }} 代码很简单，可以看出ViewModelStore 里面就是一个HashMap，用于缓存ViewModel实例对象。 NonConfigurationInstances12345// ComponentActivity$NonConfigurationInstances.javastatic final class NonConfigurationInstances { Object custom; ViewModelStore viewModelStore;} 这其实就是一个Java Bean类，里面存在2个字段，包过 viewModelStore 字段。 三、get(MainViewModel::class.java)12345678910111213141516171819202122232425262728293031323334// ViewModelProvider.javaprivate static final String DEFAULT_KEY =&quot;androidx.lifecycle.ViewModelProvider.DefaultKey&quot;;public &lt;T extends ViewModel&gt; T get(@NonNull Class&lt;T&gt; modelClass) { String canonicalName = modelClass.getCanonicalName(); if (canonicalName == null) { throw new IllegalArgumentException(&quot;Local and anonymous classes can not be ViewModels&quot;); } return get(DEFAULT_KEY + &quot;:&quot; + canonicalName, modelClass);}// ViewModelProvider.javapublic &lt;T extends ViewModel&gt; T get(@NonNull String key, @NonNull Class&lt;T&gt; modelClass) { ViewModel viewModel = mViewModelStore.get(key); if (modelClass.isInstance(viewModel)) { if (mFactory instanceof OnRequeryFactory) { ((OnRequeryFactory) mFactory).onRequery(viewModel); } return (T) viewModel; } else { //noinspection StatementWithEmptyBody if (viewModel != null) { // TODO: log a warning. } } if (mFactory instanceof KeyedFactory) { viewModel = ((KeyedFactory) mFactory).create(key, modelClass); } else { viewModel = mFactory.create(modelClass); } mViewModelStore.put(key, viewModel); return (T) viewModel;} 先根据key从mViewModelStore获取缓存中的ViewModel，如果存在，则返回viewModel实例。 如果mViewModelStore缓存中不存在当前modelClass的实例，则用工厂方法创建一个，再将新创建的加入缓存。 我们在Activity中并没有设置key，默认的key又是一个常量，猜测： 屏幕旋转前后，mViewModelStore应该是同一个对象，得到的跟viewModel也是同一份实例对象。 所以我们只要找出屏幕旋转前后，mViewModelStore如何保存和恢复即可。 验证猜测最直接的方法就是log打印： 12val viewModel = ViewModelProvider(this).get(MainViewModel::class.java)Log.i(&quot;wutao--&gt; &quot;, &quot;viewModel--&gt; $viewModel&quot; + &quot; getViewModelStore--&gt; ${getViewModelStore()}&quot;) 屏幕旋转后，mViewModelStore和viewModel对象地址确实是同一个。 四、mViewModelStore 的恢复获取 mViewModelStore 代码如下： 123456789101112131415// ComponentActivity.javavoid ensureViewModelStore() { if (mViewModelStore == null) { NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { // Restore the ViewModelStore from NonConfigurationInstances // 屏幕旋转在这里恢复 mViewModelStore = nc.viewModelStore; } // 屏幕旋转后，数据恢复不是new出来的对象 if (mViewModelStore == null) { mViewModelStore = new ViewModelStore(); } }} 屏幕旋转前后，mViewModelStore 在屏幕旋转前后都是同一个对象，这个对象不可能是new出来的，那就是走的 mViewModelStore = nc.viewModelStore;，也就是从getLastNonConfigurationInstance() 得到的屏幕旋转前保存的数据。 屏幕旋转后，Activity重建后从 getLastNonConfigurationInstance() 中获取到了屏幕旋转前保存的 NonConfigurationInstances 实例对象，然后从nc对象中获取存储的mViewModelStore对象。 我们一般是在 onCreate() 中去获取ViewModel 实例对象的，说明getLastNonConfigurationInstance()这个方法在 onCreate() 方法前调用。 那当屏幕旋转前， mViewModelStore 实例是在哪存储的呢？ 五、mViewModelStore 的存储从上面可以看出，屏幕旋转完成，Activity重建后mViewModelStore是从NonConfigurationInstances获取的，那屏幕旋转前肯定也是在这里存储的。 搜索调用的地方： 从上图片可以看到是在第二处，代码如下： 12345678910111213141516171819202122232425// ComponentActivity.javapublic final Object onRetainNonConfigurationInstance() { // Maintain backward compatibility. Object custom = onRetainCustomNonConfigurationInstance(); ViewModelStore viewModelStore = mViewModelStore; if (viewModelStore == null) { // No one called getViewModelStore(), so see if there was an existing // ViewModelStore from our last NonConfigurationInstance NonConfigurationInstances nc = (NonConfigurationInstances) getLastNonConfigurationInstance(); if (nc != null) { viewModelStore = nc.viewModelStore; } } if (viewModelStore == null &amp;&amp; custom == null) { return null; } // 在这里存储的 NonConfigurationInstances nci = new NonConfigurationInstances(); nci.custom = custom; nci.viewModelStore = viewModelStore; return nci;} 可以得出结论：屏幕旋转前，数据在 onRetainNonConfigurationInstance() 保存，Activity 重建后，在 getLastNonConfigurationInstance() 中恢复。 Activity生命周期调用如下： 继续跟一下源码，寻找数据具体存储在哪里？ 六、一探到底Activity重启后数据的恢复Activity 重建后，在 getLastNonConfigurationInstance() 中恢复。 12345// Activity.javapublic Object getLastNonConfigurationInstance() { return mLastNonConfigurationInstances != null ? mLastNonConfigurationInstances.activity : null;} mLastNonConfigurationInstances 赋值的地方： 1234567891011121314// Activity.javafinal void attach(Context context, ActivityThread aThread, Instrumentation instr, IBinder token, int ident, Application application, Intent intent, ActivityInfo info, CharSequence title, Activity parent, String id, NonConfigurationInstances lastNonConfigurationInstances, Configuration config, String referrer, IVoiceInteractor voiceInteractor, Window window, ActivityConfigCallback activityConfigCallback, IBinder assistToken) { attachBaseContext(context); ··· mLastNonConfigurationInstances = lastNonConfigurationInstances; ··· } 从Activity的启动流程可知，Activity$attach()方法是在ActivityThread调用的： 123456789101112// ActivityThread.javaActivity.NonConfigurationInstances lastNonConfigurationInstances;/** Core implementation of activity launch. */private Activity performLaunchActivity(ActivityClientRecord r, Intent customIntent) { activity.attach(appContext, this, getInstrumentation(), r.token, r.ident, app, r.intent, r.activityInfo, title, r.parent, r.embeddedID, r.lastNonConfigurationInstances, config, r.referrer, r.voiceInteractor, window, r.configCallback, r.assistToken); } 从上得知，数据存储在ActivityClientRecord中，在Activity启动时将ActivityClientRecord中的lastNonConfigurationInstances通过attach()方法赋值到对应的Activity中，然后通过getLastNonConfigurationInstance()恢复数据。 屏幕旋转前数据的存储屏幕旋转前，数据在 onRetainNonConfigurationInstance() 保存。 在Activity的retainNonConfigurationInstances()方法中被调用。 那retainNonConfigurationInstances()方法又是在哪调用的呢？肯定也跟ActivityThread有关，在ActivityThread搜索下，代码如下： 12345678910111213141516// ActivityThread.java ActivityClientRecord performDestroyActivity(IBinder token, boolean finishing, int configChanges, boolean getNonConfigInstance, String reason) { ActivityClientRecord r = mActivities.get(token); ··· if (getNonConfigInstance) { try { r.lastNonConfigurationInstances = r.activity.retainNonConfigurationInstances(); } catch (Exception e) { ··· } } ··· return r;} 从上得知，performDestroyActivity() 调用了retainNonConfigurationInstances() 方法并把数据保存到了ActivityClientRecord的lastNonConfigurationInstances中。 七、特例-系统杀后台由于上文已经做过实验了，我这里直接贴上实验的打印结果 第一张图是模拟杀后台的生命周期打印，第二张图是屏幕旋转。 可以看出： 系统杀后台，Activity不会走onDestory()和onRetainCustomNonConfigurationInstance()方法。 可以说杀掉后台，Activity销毁的生命周期都不会走，只有App再回到前台时，才会走Activity重建生命周期。 因为没有执行onRetainCustomNonConfigurationInstance()方法，Activity的数据也没有缓存下来，所以Activity重建也没有数据可以恢复。 下图是Activity中的ViewModel实例对象地址打印： 可以看出，adb模拟杀掉后台后，ViewModel地址值变了，是一个全新的地址。 如果想要系统内存不足，杀掉后台，App再次回到前台，之前的数据进行恢复，应该怎么处理？ 请听下回分析。😁 八、总结屏幕旋转前，Activity销毁时： ComponentActivity调用onRetainNonConfigurationInstance()方法，将要销毁的Activity的mViewModelStore转化为NonConfigurationInstances对象，继续调用Activity的retainNonConfigurationInstances()方法，最终在ActivityThread的performDestroyActivity()中将数据保存在ActivityClientRecord中。 Activity重建后： 在Activity启动时，ActivityThread调用performLaunchActivity()方法，将存储在ActivityClientRecord中的lastNonConfigurationInstances通过Activity的attach()方法传递到对应的Activity中，然后通过getLastNonConfigurationInstance()恢复mViewModelStore实例对象，最后根据对应的key拿到销毁前对应的ViewModel实例。 此外，当系统内存不足，系统将后台应用回收后，ViewModel中的数据不会恢复。 附上总体流程图：","link":"/2023/10/10/ViewModel/"},{"title":"RenderBlock","text":"链接：https://juejin.cn/post/7062552765117136903 https://developer.android.com/topic/performance/rendering/profile-gpu?hl=zh-cn RenderThread的作用：主线程的 draw 函数并没有真正的执行 drawCall ，而是把要 draw 的内容记录到 DIsplayList 里面（在 Measure、Layout、Draw 的 Draw 这个环节，Android 使用 DisplayList 进行绘制而非直接使用 CPU 绘制每一帧。），同步到 RenderThread 中，一旦同步完成，主线程就可以被释放出来做其他的事情，RenderThread 则继续进行渲染工作 2.3 生产者和消费者 我们再回到 Vsync 的话题，消费 Vsync 的双方分别是 App 和 sf，其中 App 代表的是生产者，sf 代表的是消费者，两者交付的中间产物则是 surface buffer。 再具体一点，生产者大致可以分为两类，一类是以 window 为代表的页面，也就是我们平时所看到的 view 树这一套；另一类是以视频流为代表的可以直接和 surface 完成数据交换的来源，比如相机预览等。 对于一般的生产者和消费者模式，我们知道会存在相互阻塞的问题。比如生产者速度快但是消费者速度慢，亦或是生产者速度慢消费者速度快，都会导致整体速度慢且造成资源浪费。所以 Vsync 的协同以及双缓冲甚至三缓冲的作用就体现出来了。 思考一个问题：是否缓冲的个数越多越好？过多的缓冲会造成什么问题？ 答案是会造成另一个严重的问题：lag，响应延迟 这里结合 view 的一生，我们可以把两个流程合在一起，让我们的视角再高一层： 我们一般都比较了解 view 渲染的三大流程，但是 view 的渲染远不止于此： 此处以一个通用的硬件加速流程来表征 Vsync 调度：很多同学的一个认知误区在于认为 vsync 是每 16ms 都会有的，但是其实 vsync 是需要调度的，没有调度就不会有回调； 消息调度：主要是 doframe 的消息调度，如果消息被阻塞，会直接造成卡顿； input 处理：触摸事件的处理； 动画处理：animator 动画执行和渲染； view 处理：主要是 view 相关的遍历和三大流程； measure、layout、draw：view 三大流程的执行； DisplayList 更新：view 硬件加速后的 draw op； OpenGL 指令转换：绘制指令转换为 OpenGL 指令； 指令 buffer 交换：OpenGL 的指令交换到 GPU 内部执行； GPU 处理：GPU 对数据的处理过程； layer 合成：surface buffer 合成屏幕显示 buffer 的流程； 光栅化：将矢量图转换为位图； Display：显示控制； buffer 切换：切换屏幕显示的帧 buffer； 2.4 机制上的保护这里我们来回答第三个问题，从系统的渲染架构上来说，机制上的保护主要有几方面： Vsync 机制的协同； 多缓冲设计； surface 的提供； 同步屏障的保护； 硬件绘制的支持； 渲染线程的支持； GPU 合成加速； 2.5 再看卡顿的成因渲染流程 Vsync 调度：这个是起始点，但是调度的过程会经过线程切换以及一些委派的逻辑，有可能造成卡顿，但是一般可能性比较小，我们也基本无法介入； 消息调度：主要是 doframe Message 的调度，这就是一个普通的 Handler 调度，如果这个调度被其他的 Message 阻塞产生了时延，会直接导致后续的所有流程不会被触发。这里直播建立了一个 FWtachDog 机制，可以通过优化消息调度达到插帧的效果，使得界面更加流畅； input 处理：input 是一次 Vsync 调度最先执行的逻辑，主要处理 input 事件。如果有大量的事件堆积或者在事件分发逻辑中加入大量耗时业务逻辑，会造成当前帧的时长被拉大，造成卡顿。抖音基础技术同学也有尝试过事件采样的方案，减少 event 的处理，取得了不错的效果； 动画处理：主要是 animator 动画的更新，同理，动画数量过多，或者动画的更新中有比较耗时的逻辑，也会造成当前帧的渲染卡顿。对动画的降帧和降复杂度其实解决的就是这个问题； view 处理：主要是接下来的三大流程，过度绘制、频繁刷新、复杂的视图效果都是此处造成卡顿的主要原因。比如我们平时所说的降低页面层级，主要解决的就是这个问题； measure/layout/draw：view 渲染的三大流程，因为涉及到遍历和高频执行，所以这里涉及到的耗时问题均会被放大，比如我们会降不能在 draw 里面调用耗时函数，不能 new 对象等等； //以下对应的是**淡蓝色、红色、橘色**色块对应的阶段 DisplayList 的更新：这里主要是 canvas 和 displaylist 的映射，一般不会存在卡顿问题，反而可能存在映射失败导致的显示问题； OpenGL 指令转换：这里主要是将 canvas 的命令转换为 OpenGL 的指令，一般不存在问题。不过这里倒是有一个可以探索的点，会不会存在一类特殊的 canvas 指令，转换后的 OpenGL 指令消耗比较大，进而导致 GPU 的损耗？有了解的同学可以探讨一下； 指令buffer 交换：这里主要指 OpenGL 指令集交换给 GPU，这个一般和指令的复杂度有关。一个有意思的事儿是这里一度被我们作为线上采集 GPU 指标的数据源，但是由于多缓冲的因素数据准确度不够被放弃了； GPU 处理：顾名思义，这里是 GPU 对数据的处理，耗时主要和任务量和纹理复杂度有关。这也就是我们降低 GPU 负载有助于降低卡顿的原因； layer 合成：这里主要是 layer 的 compose 的工作，一般接触不到。偶尔发现 sf 的 vsync 信号被 delay 的情况，造成 buffer 供应不及时，暂时还不清楚原因； 光栅化：这里暂时忽略，底层系统行为； Display：这里暂时忽略，底层系统行为； Buffer 切换：主要是屏幕的显示，这里 buffer 的数量也会影响帧的整体延迟，不过是系统行为，不能干预。 Google 将这个过程划分为：其他时间/VSync 延迟、输入处理、动画、测量/布局、绘制、同步和上传、命令问题、交换缓冲区。也就是我们常用的 GPU 严格模式，其实道理是一样的。到这里，我们也就回答出来了第二个问题：16ms 内都需要完成什么？ 准确地说，这里仍可以进一步细化：16ms 内完成 APP 侧数据的生产；16ms 内完成 sf layer 的合成 View 的视觉效果正是通过这一整条复杂的链路一步步展示出来的，有了这个前提，那就可以得出一个结论：上述任意链路发生卡顿，均会造成卡顿。 补充硬件绘制DisplayList更新详解硬件绘制还引入了一个 DisplayList 的概念，DisplayList 每个 View 内部都有一个DisplayList，当某个 View 需要重绘时，将它标记为 Dirty。当需要重绘时，仅仅只需要重绘一个 View 的 DisplayList，而不是像软件绘制那样需要向上递归。这样可以大大减少绘图的操作数量，因而提高了渲染效率 Display List 是一个缓存绘制命令的 Buffer，Display List 的本质是一个缓冲区，它里面记录了即将要执行的绘制命令序列。Display List 是视图的基本绘制元素，包含元素原始属性（位置、尺寸、角度、透明度等），对应 Canvas 的 drawXxx()方法。类似于左边图中所示一样，onDraw会被DisplayList所表示。ViewTree中每一个View都会有对应的DisplayList来代表。 本例子中，点击Item2，触发onDraw之后，DisplayList开启了如下的操作： Sync在Java层（UI Thread），我们收集组合所有信息，然后把这些信息sync给Native层，由RenderThread用GPU渲染。 Damage Area: 这个概念类似于Dirty Region，意思是需要被重新绘制的区域，在我们这个例子中就是item2的区域。 Upload non-HW Bitmaps: 把non-HW Bitmaps上传到GPU的RAM里，此时一帧刚刚开始，有比较充足的时间。相反的是， 对Hardward Bitmap没有这步操作，Hardward Bitmap是一种新的位图配置，是在Android Oh中添加的 通常当你有一个位图时我们必须在Java端分配内存，然后在需要绘制的时候 我们必须在GPU上复制位图，这在文本时间上是昂贵的，它使我们的RAM数量增加了一倍。使用Oreo中可用的硬件位图，它已经存在GPU一侧了 如果你不打算修改这个位图，从内存角度来看确实是一个非常有效的存储位图的方式。 RenderThreadAndroid 5.0 (Lollipop)引入的，此线程只在Native层跟GPU交互，在Java层没有任何调用。渲染之前，我们生成DisplayList，然后我们把这些信息sync给GPU。它是串行执行的，但是RenderThread在这之中能够以原子操作（Atomic Operations）形式执行 例如波纹动画动画，矢量动画等。这些渲染转移到RenderThread来分担之后， UI Thread就可以在idle的时候做些别的事，比如RecyclerView的prefech机制就是设计在此时发生。 **DLOps **（Display List Operations） 在GPU得到 Display List 后，DL 会转换成 DLOps。注意这个变成绿色的Fill操作，经过一系列**优化重排序(Optimization, Reordering and Batching)**后，它的位置被提到上面跟其他的Fill放在一起。优化(Optimization)包括将View setAlpha()，setHarewareLayer()这些操作的指令移到最前面执行，避免在GPU内进行昂贵的State变更操作。 重排序(Reordering)意思是当存在一系列的drawText(), drawRect()之类指令穿插存在时，相同的指令会被放在相邻的顺序执行。 而Batching表示一个drawText call就可以把整个屏幕上的需要drawText的地方全部做完。 Clip Reject在 Clip Reject中，我们判断哪些操作是必须的，换句话说哪些操作是相关脏区(Damaged Area)的。例如下图中，只有右边的三个操作是跟把item2背景变绿这个效果相关的。所以我们只需要执行右边三个DLOps。 接下来我们需要拿到缓冲区，虽然这里写的是Get Buffer，但实际情况是buffer不是申请来的，有关GPU的操作一执行，SurfaceFlinger就会分配Buffer过来，让我们执行这些操作。 然后我们发出一系列GL指令来做画背景，画线，复制bitmap之类的实际操作。当这些操作全部结束时，我们会通知SurfaceFlinger去swap buffer。这时这一帧就完成了，它将被显示在屏幕上。同时，在 SurfaceFlinger 和 HardwareCompositor 中会进行Surface合成。Status Bar，System Bar 和 Content在这里会合成在一起，然后展示在屏幕上。 补充Composition 在上面的两个例子中，都略过了composition这一步具体里面发生了什么。在这节我们会进行进一步解释，SurfaceFlinger和HardwareCompositor是怎么把不同的window合成，然后展示到屏幕上的。在我们开始前，我们需要先搞清楚下面这三个概念：BufferQueue, Producer, Consumer。 BufferQueueBufferQueue就是有若干个Buffer的Queue。Graphic Buffer存在在这里。一般会有1～3个Buffer，取决于setBufferQueue时的配置。 Producer 就和其他所有生产消费者模型一样，它负责生产内容，具体一点，在这里它生产要被展示在屏幕上的数据。 调用dequeBuffer()来从BufferQueue获得队首Buffer。这时它可以直接在Buffer写入Pixel数据，或调用OpenGL，或者使用Canvas。 当内容生产完之后，调用queueBuffer()将这个Buffer还给BufferQueue，放到队尾。 Comsumer 消费者要消费数据来展示到屏幕上。 调用acquireBuffer()拿到BufferQueue中第一个可用的(一般在队尾)Buffer，读取里面的数据。 内容消费完成后，调用releaseBuffer()给放回队首。 Create Window当我们创建一个Window时，例如activity，dialog，popup window等。在Producer侧，WindowManager会在内部创建个Window对象(这里会创建ViewRootImp来关联view的操作，surface也是跟window一一绑定)。而在Consumer侧，SurfaceFlinger会管理各个Surface相对应的生成一个Layer对象（layer的东西也太多了）。Layer是系统组件之一，它创建和管理BufferQueue。之后在App中会生成一个Surface对象。 Surface Surface 对应了一块屏幕缓冲区，每个 Window 对应一个 Surface，任何 View 都是画在 Surface 上的，传统的 View 共享一块屏幕缓冲区。 所有的绘制必须在 UI 线程中进行。 我们不能直接操作 Surface 实例，要通过 SurfaceHolder，在 SurfaceView 中可以通过 getHolder() 方法获取到 SurfaceHolder 实例。 SurfaceView简单的说 SurfaceView 就是一个有 Surface 的 View，SurfaceView 控制这个 Surface 的格式和尺寸以及绘制位置。SurfaceView的实现原理相当于在Window的Surface打个洞，漏出SurfaceView的Surface。他们两个的Surface是完全相互独立的存在。 Surface TextureConsumer是OpenGL。SurfaceTexture 会创建 BufferQueue 和 Surface。 TextureView 创建SurfaceTexture。 RenderThread是Consumer，Producer可以自己选择。 就像个功能更强大的ImageView一样，更新得更快速。 在Android O或N之前的版本上，TexutreView是比SurfaceView更推荐使用的，因为一方面可以享受更快速的渲染，另一方面可以避免SurfaceView的种种问题，比如两个Window造成的效率折损，渲染不同步导致画面割裂等。但是这些问题已经都被解决了，在18年谷歌I/O大会上更推荐在新版本的安卓上使用SurfaceView，而不是TextureView。 回到我们本节的主题Composition上。我们在应用中创建很多window，每个都有自己的layer，SurfaceFlinger来收集这些layer，SurfaceFlinger其实不是直接跟Display显示器交互，而是跟Hardware Composer沟通（HWC），它是一个硬件抽象层，我们通常为了省电，避免GPU直接在屏幕上合成显示。 Hardware Composer HAL是一个硬件抽象层用于确定通过可用硬件来合成缓冲区的最有效方法。 作为 HAL，其实现是特定于设备的，而且通常由显示硬件原始设备制造商 (OEM) 完成。 当您考虑使用叠加平面时，很容易发现这种方法的好处，它会在显示硬件（而不是 GPU）中合成多个缓冲区。例如，假设有一部普通 Android 手机，其屏幕方向为纵向，状态栏在顶部，导航栏在底部，其他区域显示应用内容。每个层的内容都在单独的缓冲区中。您可以使用以下任一方法处理合成： 将应用内容渲染到暂存缓冲区中，然后在其上渲染状态栏，再在其上渲染导航栏，最后将暂存缓冲区传送到显示硬件。 将三个缓冲区全部传送到显示硬件，并指示它从不同的缓冲区读取屏幕不同部分的数据。 后一种方法可以显著提高效率。显示处理器性能差异很大。叠加层的数量（无论层是否可以旋转或混合）以及对定位和重叠的限制很难通过 API 表达。为了适应这些选项，HWC 会执行以下计算： SurfaceFlinger 向 HWC 提供一个完整的Layer列表，并询问“您希望如何处理这些层？” HWC 的响应方式是将每个层标记为FrameBuffer或OVERLAY。 SurfaceFlinger 会处理（计算的当前显示设备的脏区域DirtyRegion等工作）所有OVERLAY，将输出buffer传送到 HWC，并让 HWC 处理其余部分。 举个例子：SurfaceFlinger告诉HWC现在有3个Layer你想怎么办。HWC一看，第一个简单，OVERLAY就可以，第二个第三个我处理不了，需要GPU先处理下才行，就标记成FrameBuffer。 标记成FrameBuffer的这两层会被先行处理，处理这两层时，需要再添加一层来放output，被绿箭头指着的这层就是output，叫做Scratch Layer（叫什么名不重要，后面不会出现，只是为了避免混淆）。 现在，剩下这两层Layer会被SurfaceFlinger用set()传到HWC，之后被渲染到屏幕上。感兴趣的大家可以用这个命令打印出SurfaceFlinger的大量信息。 1adb shell dumpsys SurfaceFlinger 到这里，整个渲染的流程就已经串联完了。我们应用的 UI 是如何变成屏幕上的像素的，相信大家看到这里已经有了一个基本的概念。了解这些的工作原理可以帮助我们弄清楚如何为App获得最佳性能。","link":"/2022/03/10/RenderBlock/"},{"title":"VirtualMemory","text":"简述：cpu以虚拟内存，通过MMU查询 页表， 映射 高4位(页号) 到页表中查询得到 页框号 和 有效位。 如果有效位 为1， 则直接将页框号和虚拟内存低12位（偏移量）组合返回即为物理地址 如果有效位为0（意味着该页表项不存在MMU中，即未向MMU注册或相关页未被加载如内存中），则产生缺页中断，系统处理中断，通过内存置换swap算法（LRU，OPT，FIFO），之后重走一遍以上逻辑 虚拟内存机制计算机的存储系统 为什么要有虚拟内存？在早期的计算机中，是没有==虚拟内存==的概念的。我们要运行一个程序，会把程序全部装入内存，然后运行。当运行多个程序时，经常会出现以下问题： 进程地址空间不隔离，没有权限保护。由于程序都是直接访问物理内存，所以一个进程可以修改其他进程的内存数据， 甚至修改内核地址空间中的数据。 内存使用效率低 当内存空间不足时，要将其他程序暂时拷贝到硬盘，然后将新的程序装入内存运行。由于大量的数据装入装出，内存使用效率会十分低下。 程序运行的地址不确定 因为内存地址是随机分配的，所以程序运行的地址也是不确定的。 进程的虚拟地址空间 每个进程都有自己独立的4G内存空间 虚拟内存空间通过MMU来和真实的物理内存产生联系 计算机明明没有那么多内存（n个进程的话就需要n*4G内存） 虚拟内存和物理内存如何建立起来联系的呢？Linux的虚拟内存技术Linux把虚存空间分成若干个大小相等的存储分区，Linux把这样的分区叫做页。为了换入、换出的方便，物理内存也就得按大小分成若干个块。由于物理内存中的块空间是用来容纳虚存页的容器，所以物理内存中的块叫做页框。页与页框是Linux实现虚拟内存技术的基础。 分页和分表我们知道系统里的基本单位都是 Byte 字节，如果将每一个虚拟内存的 Byte 都对应到物理内存的地址，每个条目最少需要 8字节（32位虚拟地址-&gt;32位物理地址），在 4G 内存的情况下，就需要 32GB 的空间来存放对照表，那么这张表就大得真正的物理地址也放不下了，于是操作系统引入了 页（Page）的概念。 在系统启动时，操作系统将整个物理内存以 4K 为单位，划分为各个页。之后进行内存分配时，都以页为单位，那么虚拟内存页对应物理内存页的映射表就大大减小了，4G 内存，只需要 8M 的映射表即可，一些进程没有使用到的虚拟内存，也并不需要保存映射关系，而且Linux 还为大内存设计了多级页表，可以进一步减少了内存消耗。操作系统虚拟内存到物理内存的映射表，就被称为页表。 虚拟内存的页、物理内存的页框及页表 物理内存和虚拟内存被分成了页框与页之后，其存储单元原来的地址都被自然地分成了两段，并且这两段各自代表着不同的意义：高位段分别叫做页框码和页码，它们是识别页框和页的编码；低位段分别叫做页框偏移量和页内偏移量，它们是存储单元在页框和页内的地址编码。下图就是两段虚拟内存和物理内存分页之后的情况： 为了使系统可以正确的访问虚存页在对应页框中的映像，在把一个页映射到某个页框上的同时，就必须把页码和存放该页映像的页框码填入一个叫做页表的表项中。这个页表就是之前提到的映射记录表。一个页表的示意图如下所示： 页模式下，虚拟地址、物理地址转换关系的示意图如下所示： 也就是说：处理器遇到的地址都是虚拟地址。虚拟地址和物理地址都分成页码（页框码）和偏移值两部分。在由虚拟地址转化成物理地址的过程中，偏移值不变。而页码和页框码之间的映射就在一个映射记录表——页表中。 页表共享在多程序系统中，常常有多个程序需要共享同一段代码或数据的情况。在分页管理的存储器中，这个事情很好办：让多个程序共享同一个页面即可。 具体的方法是：使这些相关程序的虚拟空间的页面在页表中指向内存中的同一个页框。这样，当程序运行并访问这些相关页面时，就都是对同一个页框中的页面进行访问，而该页框中的页就被这些程序所共享。下图是3个程序共享一个页面的例子： 虚拟内存带来的好处进程内存管理它有助于进程进行内存管理，主要体现在： 内存完整性：由于虚拟内存对进程的”欺骗”，每个进程都认为自己获取的内存是一块连续的地址。我们在编写应用程序时，就不用考虑大块地址的分配，总是认为系统有足够的大块内存即可。 安全：由于进程访问内存时，都要通过页表来寻址，操作系统在页表的各个项目上添加各种访问权限标识位，就可以实现内存的权限控制。 数据共享通过虚拟内存更容易实现内存和数据的共享。 在进程加载系统库时，总是先分配一块内存，将磁盘中的库文件加载到这块内存中，在直接使用物理内存时，由于物理内存地址唯一，即使系统发现同一个库在系统内加载了两次，但每个进程指定的加载内存不一样，系统也无能为力。 而在使用虚拟内存时，系统只需要将进程的虚拟内存地址指向库文件所在的物理内存地址即可。如上文图中所示，进程 P1 和 P2 的 B 地址都指向了物理地址 C。 而通过使用虚拟内存使用共享内存也很简单，系统只需要将各个进程的虚拟内存地址指向系统分配的共享内存地址即可。 SWAP虚拟内存可以让帮进程”扩充”内存。 我们前文提到了虚拟内存通过缺页中断为进程分配物理内存，内存总是有限的，如果所有的物理内存都被占用了怎么办呢？ Linux 提出 SWAP 的概念，Linux 中可以使用 SWAP 分区，在分配物理内存，但可用内存不足时，将暂时不用的内存数据先放到磁盘上，让有需要的进程先使用，等进程再需要使用这些数据时，再将这些数据加载到内存中，通过这种”交换”技术，Linux 可以让进程使用更多的内存。 实践和研究都证明：一个应用程序总是逐段被运行的，而且在一段时间内会稳定运行在某一段程序里。 这也就出现了一个方法：如下图所示，把要运行的那一段程序从辅存复制到内存中来运行，而其他暂时不运行的程序段就让它仍然留在辅存。 当需要执行另一端尚未在内存的程序段（如程序段2），如下图所示，就可以把内存中程序段1的副本复制回辅存，在内存腾出必要的空间后，再把辅存中的程序段2复制到内存空间来执行即可： 在计算机技术中，把内存中的程序段复制回辅存的做法叫做“换出”，而把辅存中程序段映射到内存的做法叫做“换入”。经过不断有目的的换入和换出，处理器就可以运行一个大于实际物理内存的应用程序了。 from: https://mp.weixin.qq.com/s/-1DHzkM--xgKIU1g71eQzQ 分段和分页：现代操作系统管理内存，到底是分段还是分页，段寄存器还有用吗？ 简述：现在基本上都是分页了，分段管理名存实亡 无论是分段还是分页，这是CPU自身的机制，操作系统在管理内存时绕不过去，但通过巧妙的分段内存设计，相当于把分段的概念给屏蔽了，由此造成了我们平时在谈论虚拟地址翻译时，忘记了段的存在，但不代表它真的不存在。 CPU硬件层面的工作必须是结合分段+分页的内存管理机制，操作系统是软件绕不过去，所以采取了上面的方式应付CPU了事。","link":"/2021/12/13/VirtualMemory/"},{"title":"Window","text":"https://www.cnblogs.com/huan89/p/14111360.html 从来都没什么Window，有的只是一个个View树，每个窗口(activity/dialog/popupWindow)都是一个view树（代码中都是叫addView，直到WMS中才叫addWindow），在需要显示时被添加进WMS中，最后通过surfalceFlinger合成后渲染到屏幕中。 每个窗口都对应一个Token，一个应用只对应一个session。 从Window视角看ActivityStartActivity简述：首先回顾一下，activity是怎么显示出来的： 为activity创建PhoneWindow和WindowManager(WindowManagerImpl)对象 在handleLaunchActivity()被回调的时候，调用WindowManagerGlobal.initialize();初始化WindoWindowManagerGlobal，之后 Application app = r.packageInfo.makeApplication(false, mInstrumentation);创建Application（如果还没有创建过Application），然后调用activity.attach()，这里面 mWindow = new PhoneWindow(this, window, activityConfigCallback);初始化PhoneWindow并给它设置WindowManager， 1234mWindow.setWindowManager( (WindowManager)context.getSystemService(Context.WINDOW_SERVICE), mToken, mComponent.flattenToString(), (info.flags &amp; ActivityInfo.FLAG_HARDWARE_ACCELERATED) != 0); Window.setWindowManager()中通过WMS创建了WindowManagerImpl（其实就是个一百多行代码的壳）。 从这里可以看到是利用系统服务的windowManager来创建新的windowManagerImpl，因而这个应用所有的WindowManagerImpl都是同个内核windowManager，而创建出来的仅仅是包了个壳。 setContentView实际上掉的是getWindow()（也就是上面的PhoneWindow）的setContentView()，其中调用PhoneWindow.installDecor()， 首先看decorView创建了没有，没有的话创建DecorView 把布局加载到DecorView中（LayoutInflater加载预设模板布局，见下） DecorView是在PhoneWindow中预设好的一个布局，这个布局长这样： 他是一个垂直排列的布局，上面是ActionBar，下面是ContentView，他是一个FrameLayout。我们的Activity布局就加载到ContentView里进行显示。所以Decorview是Activity布局最顶层的viewGroup。 // DecorView创建完成了，但还缺少了最重要的一步：把DecorView作为window添加到屏幕上。 在handleResumeActivity中，执行了最后的 wm.addView(mDecor, getWindow().getAttributes()); 123456789101112131415161718public void handleResumeActivity(IBinder token, boolean finalStateRequest, boolean isForward, String reason) { // 调用Activity的onResume方法 final ActivityClientRecord r = performResumeActivity(token, finalStateRequest, reason); ... // 让decorView显示到屏幕上 if (r.activity.mVisibleFromClient) { r.activity.makeVisible();} void makeVisible() { if (!mWindowAdded) { ViewManager wm = getWindowManager(); wm.addView(mDecor, getWindow().getAttributes()); mWindowAdded = true; } mDecor.setVisibility(View.VISIBLE);} 直接调用WindowManagerImpl的addView方法来吧decorView添加到屏幕上，至此，我们的Activity界面就会显示在屏幕上了。 进一步需要看WindowManagerImpl.addView之后是怎么将View（即Window）添加入屏幕的 wm.addView(mDecor, getWindow().getAttributes());其中wm是WindowManagerImpl实例，WindowManagerImpl.addView其实是通过桥接，调用WindowManagerGlobal的全局单例的方法WindowManagerGlobal.addView，该方法中会新建一个ViewRootImpl，然后将入参的decorView、新建的ViewRootImp等加入自身维护的mViews、mRoots列表中，同时将DecorView注入ViewRootImplroot.setView(view, wparams, panelParentView) 1234567891011121314151617181920212223242526272829303132WindowMangerGlobal.clss维护着WMS实例sWindowManagerService和以下列表 //应用所有的decorViewprivate final ArrayList&lt;View&gt; mViews = new ArrayList&lt;View&gt;();//应用所有的ViewRootImplprivate final ArrayList&lt;ViewRootImpl&gt; mRoots = new ArrayList&lt;ViewRootImpl&gt;();//应用所有的WindowManager.LayoutParamsprivate final ArrayList&lt;WindowManager.LayoutParams&gt; mParams = new ArrayList&lt;WindowManager.LayoutParams&gt;();public void addView(View view, ViewGroup.LayoutParams params, Display display, Window parentWindow) { //... 主要是校验参数和调整子窗口的参数 synchronized (mLock) { ... // 这里新建了一个viewRootImpl，并设置参数 root = new ViewRootImpl(view.getContext(), display); view.setLayoutParams(wparams); // 添加到windowManagerGlobal的三个重要list中，每一个window所对应的这三个对象都会保存在这里，之后对window的一些操作就可以直接来这里取对象了。当window被删除的时候，这些对象也会被从list中移除。 mViews.add(view); mRoots.add(root); mParams.add(wparams); // 最后通过viewRootImpl来添加window try { root.setView(view, wparams, panelParentView); } ... } } ​ 5. ViewRootImpl.setView()将调用到 1234res = mWindowSession.addToDisplay(mWindow, mSeq, mWindowAttributes, getHostVisibility(), mDisplay.getDisplayId(), mWinFrame, mAttachInfo.mContentInsets, mAttachInfo.mStableInsets, mAttachInfo.mOutsets, mAttachInfo.mDisplayCutout, mInputChannel); 这个mWindowSession来自于构造器的入参，是由WindowManagerGlobal.getWindowSession中来的， 123456789101112131415public static IWindowSession getWindowSession() { synchronized (WindowManagerGlobal.class) { if (sWindowSession == null) { try { ... sWindowSession = windowManager.openSession( new IWindowSessionCallback.Stub() { ... }); } ... } return sWindowSession; }} 可以看出，这个session是一个单例，也就是整个应用的所有viewRootImpl的windowSession都是同一个，也就是一个应用只有一个windowSession。 Session.addToDisplay实际上走的是WMS的addWindow方法，后面的逻辑就交给WMS去处理了，WMS就会创建window，然后结合参数计算window的高度等等，最后使用viewRootImpl进行绘制。 window的添加过程是通过PhoneWindow对应的WindowManagerImpl来添加window，内部会调用WindowManagerGlobal来实现。WindowManagerGlobal会使用viewRootImpl来进行跨进程通信让WMS执行创建window的业务。 每个应用都有一个windowSession，用于负责和WMS的通信，如ApplicationThread与AMS的通信。 Other Windowdialog和popupwindow的层级是10001999，在这个层级都属于子window而不是应用Window(199)，子Window需要附属于父Window（Activity，也就是应用Window）才能显示，dialog虽然创建了一个PhoneWindow，但是popupWindow最终也创建了一个Window，只是它不是PhoneWindow而已，popupWindow和dialog的显示都需要依赖父Window的Token，其实两者都需要依赖于Activiy PopupWindow那么，PopupWindow则是在构造器中时将入参的contentView直接执行 setContentView(contentView);，然后在showAtLocation（）中调用了preparePopup() 创建它的decorView（PopupDecorView）之后invokePopup()调用执行mWindowManager.addView(decorView, p); 根据参数构建popupDecorView 把popupDecorView添加到屏幕上 dismiss()中调用mWindowManager.removeViewImmediate(decorView); Dialogdialog的创建过程Activity比较像：构造器创建PhoneWindow，setContentView初始化DecorView，show时候添加DecorView。 构造函数中创建PhoneWindow，设置WindowManger（这里拿的是传入的context，实际上这context只能是actiivty，的WindowManager） Dialog.setContentView时掉PhoneWindow.setContentView来初始化DecorView show()时候调用了mWindowManager.addView(mDecor, l); dismiss()时候调用mWindowManager.removeViewImmediate(mDecor); 总结 dialog和popupWindow不同，dialog创建了新的PhoneWindow，使用了PhoneWindow的DecorView模板。而popupWindow没有，popupWindow他也对应一个window，因为它也是通过windowManager添加上去的，不属于Activity的view树。 dialog的显示层级数更高，会直接显示在Activity上面，在dialog后添加的popUpWindow也会显示在dialog下 dialog的创建流程和activity非常像 概念梳理//待整理关键类前面的源码流程中涉及到很多的类，这里把相关的类统一分析一下。先看一张图： 这基本上是我们这篇文章涉及到的所有关键类。 （图中绿色的window并不是一个类，而是表意上的window） 另外ViewRootImpl并不在PhoneWindow中，而是在View.attachInfo中，也被WindowManagerService中持有维护） window相关window的实现类只有一个：PhoneWindow，他继承自Window抽象类。后面我会重点分析他。 WindowManager相关顾名思义，windowManager就是window管理类。这一部分的关键类有windowManager，viewManager，windowManagerImpl，windowManagerGlobal。windowManager是一个接口，继承自viewManager。viewManager中包含了我们非常熟悉的三个接口：addView,removeView,updateView。windowManagerImpl和PhoneWindow是成对出现的，前者负责管理后者。WindowManagerImpl是windowManager的实现类，但是他本身并没有真正实现逻辑，而是交给了WindowManagerGlobal。WindowManagerGlobal是全局单例，windowManagerImpl内部使用桥接模式，他是windowManager接口逻辑的真正实现 view相关这里有个很关键的类：ViewRootImpl。每个view树都会有一个。当我使用windowManager的addView方法时，就会创建一个ViewRootImpl。ViewRootImpl的作用很关键： 负责连接view和window的桥梁事务 负责和WindowManagerService的联系 负责管理和绘制view树 事件的中转站 每个window都会有一个ViewRootImpl，viewRootImpl是负责绘制这个view树和window与view的桥梁，每个window都会有一个ViewRootImpl。 WindowManagerService这个是window的真正管理者，类似于AMS（ActivityManagerService）管理四大组件。所有的window创建最终都要经过windowManagerService。整个Android的window机制中，WMS绝对是核心，他决定了屏幕所有的window该如何显示如何分发点击事件等等。 从Android架构角度看Window前面我们介绍过关于PhoneWindow和window之间的关系，了解到PhoneWindow其实不是Window，只是一个window容器。不知读者有没想过一个问题，为什么谷歌要建一个不是window但却名字是window的类？是故意要迷惑我们吗？要了解这个问题，我们先来回顾一下整个android的window机制结构。 首先从WindowManagerService开始，我们知道WMS是window的最终管理者，在WMS中为每一个应用持有一个session，关于session前面我们讲过，每个应用都是全局单例，负责和WMS通信的binder对象。WMS为每个window都建立了一个windowStatus对象，同一个应用的window使用同个session进行跨进程通信，结构大概如下： 而负责与WMS通信的，是viewRootImpl。前面我们讲过每个view树即为一个window，viewRootImpl负责和WMS进行通信，同时也负责view的绘制。如果把上面的图画仔细一点就是： 图中每一个windowStatus对应一个viewRootImpl，WMS通过viewRootImpl来控制view。这也就是window机制的管理结构。当我们需要添加window的时候，最终的逻辑实现是WindowManagerGlobal，他的内部使用自己的session创建一个viewRootImpl，然后向WMS申请添加window，结构图大概如下： windowManagerGlobal使用自己的IWindowSession创建viewRootImpl，这个IWindowSession是全局单例。viewRootImpl和WMS申请创建window，然后WMS允许之后，再通知viewRootImpl绘制view，同时WMS通过windowStatus存储了viewRootImpl的相关信息，这样如果WMS需要修改view，直接通过viewRootImpl就可以修改view了。 从上面的描述中可以发现我全程没有提及到PhoneWindow和WindowManagerImpl。这是因为他们不属于window机制内的类，而是封装于window机制之上的框架。假设如果没有PhoneWindow和WindowManager我们该如何添加一个window？首先需要调用WindowGlobal获取session，再创建viewRootImpl，再访问wms，然后再利用viewRootImpl绘制view，是不是很复杂，而这仅仅只是整体的步骤。而WindowManagerImpl正是这个功能。他内部拥有WindowManagerGlobal的单例，然后帮助我们完成了这一系列的步骤。同时，windowManagerImpl也是只有一个实例，其他的windowManagerImpl都是建立在windowManagerImpl单例上。这一点在前面有通过源码介绍到。 另外，上面我讲到PhoneWindow并不是window而是一个辅助Activity管理的工具类，那为什么他不要命名为windowUtils呢？首先，PhoneWindow这个类是谷歌给window机制进行更上一层的封装。PhoneWindow内部拥有一个DecorView，我们的布局view都是添加到decorView中的，因为我们可以通过给decorView设置背景，宽高度，标题栏，按键反馈等等，来间接给我们的布局view设置。这样一来，PhoneWindow的存在，向开发者屏蔽真正的window，暴露给开发者一个“存在的”window。我们可以认为PhoneWindow就是一个window，window是view容器。当我们需要在屏幕上添加view的时候，只需要获得应用window对应的windowManagerImpl，然后直接调用addView方法添加view即可。这里也可以解释为什么windowManager的接口方法是addView而不是addWindow，一是window确实是以view的存在形式没错，二是为了向开发者屏蔽真正的window，让我们以为是在往window中添加view，window是真实存在的东西。他们的关系画个图如下： 黄色部分输于谷歌提供给开发者的window框架，而绿色是真正的window机制结构。通过PhoneWindow我们可以很方便地进行window操作，而不须了解底层究竟是如何工作的。PhoneWindow的存在，更是让window的“可见性”得到了实现，让window变成了一个“view容器”。 好了最后来总结一下： Android内部的window机制与谷歌暴露给我们的api是不一样的，谷歌封装的目的是为了让我们更好地使用window。 dialog、popupWindow等框架更是对具体场景进行更进一步的封装。 我们在了解window机制的时候，需要跳过应用层，看到window的本质，才能更好地帮助我们理解window。 在android的其他地方也是一样，利用封装向开发者屏蔽底层逻辑，让我们更好地运用。但如果我们需要了解他的机制的时候，就需要绕过这层封装，看到本质。 window与PhoneWindow的关系 解释一下标题，window是指window机制中window这个概念，而PhoneWindow是指PhoneWindow这个类。后面我在讲的时候，如果是指类，我会在后面加个‘类’字。如window是指window概念，window类是指window这个抽象类。读者不要混淆。 还记得我在讲window的概念的时候留了一个思考吗？ 思考：Android中不是有一个抽象类叫做window还有一个PhoneWindow实现类吗，他们不就是window的存在形式，为什么说window是抽象不存在的 这里我再抛出几个问题： 有一些资料认为PhoneWindow就是window，是view容器，负责管理容器内的view，windowManagerImpl可以往里面添加view，如上面我们讲过的addView方法。但是，同时它又说每个window对应一个viewRootImpl，但却没解释为什么每次addView都会新建一个viewRootImpl，前后发送矛盾。 有一些资料也是认为PhoneWindow是window，但是他说addView方法不是添加view而是添加window，同时拿这个方法的名字作为论据证明view就是window，但是他没解释为什么在使用addView方法创建window的过程却没有创建PhoneWindow对象。 我们一步步来看。我们首先来看一下源码中对于window抽象类的注释： 复制代码 1234567 Abstract base class for a top-level window look and behavior policy. An instance of this class should be used as the top-level view added to the window manager. It provides standard UI policies such as a background, title area, default key processing, etc. 顶层窗口外观和行为策略的抽象基类。此类的实例应用作添加到窗口管理器的顶层视图。它提供标准的UI策略，如背景、标题区域、默认键处理等。 大概意思就是：这个类是顶级窗口的抽象基类，顶级窗口必须继承他，他负责窗口的外观如背景、标题、默认按键处理等。这个类的实例被添加到windowManager中，让windowManager对他进行管理。PhoneWindow是一个top-level window（顶级窗口），他被添加到顶级窗口管理器的顶层视图，其他的window，都需要添加到这个顶层视图中，所以更准确的来说，PhoneWindow并不是view容器，而是window容器。 PhoneWindow是Window吗？PhoneWindow并不是view容器，而是window容器。 那PhoneWindow的存在意义是什么？ PhoneWindow只是提供了 token 机制来校验子window的合法性 第一、提供DecorView模板。如下图： 我们的Activity是通过setContentView把布局设置到DecorView中，那么DecorView本身的布局，就成为了Activity界面的背景。同时DecorView是分为标题栏和内容两部分，所以也可以可界面设置标题栏。同时，由于我们的界面是添加在的DecorView中，属于DecorView的一部分。那么对于DecorView的window属性设置也会对我们的布局界面生效。还记得谷歌的官方给window类注释的最后一句话吗：它提供标准的UI策略，如背景、标题区域、默认键处理等。这些都可以通过DecorView实现，这是PhoneWindow的第一个作用。 第二、抽离Activity中关于window的逻辑。Activity的职责非常多，如果所有的事情都自己做，那么会造成本身代码极其臃肿。阅读过Activity启动的读者可能知道，AMS也通过ActivityStarter这个类来抽离启动Activity启动的逻辑。这样关于window相关的事情，就交给PhoneWindow去处理了。（事实上，Activity调用的是WindowManagerImpl，但因PhoneWindow和WindowManagerImpl两者是成对存在，他们共同处理window相关的事务，所以这里就简单写成交给PhoneWindow处理。）当Activity需要添加界面时，只需要一句setContentView，调用了PhoneWindow的setContentView方法，就把布局设置到屏幕上了。具体怎么完成，Activity不必管。 第三、PhoneWindow提供了 token 机制来校验子window的合法性添加window需要有token，而token只有PhoneWindow拥有；因此其他的window都必须直接或间接与Activity的PhoneWindow有联系 PhoneWindow内部有一个token属性，用于验证一个PhoneWindow是否允许添加window。在Activity创建PhoneWindow的时候，就会把从AMS传过来的token赋值给他，从而他也就有了添加token的权限。而其他的PhoneWindow则没有这个权限，因而也无法添加window。 校验 token 的过程主要发生在 WindowManagerService 中。当应用程序请求操作窗口时，比如添加、移动、更新或者移除窗口，系统会通过传递 token 来确定该操作是否合法。如果 token 是无效的，系统将拒绝该操作，校验条件包括 权限检查：系统会检查当前应用程序是否有权限执行特定的窗口操作。例如，如果一个应用程序没有 SYSTEM_ALERT_WINDOW 权限，它就无法显示悬浮窗口。 安全性检查：系统可能会检查窗口的 token 是否有效、是否来自可信任的应用程序等。这可以防止恶意应用程序伪造窗口 token，尝试执行未经授权的窗口操作。 焦点和层级检查：系统可能会检查窗口的焦点状态和层级关系，以确保窗口的显示不会干扰到其他窗口或系统功能的正常运行。 附录 常见type&amp;flagAndroidDeveloper.Window flag and type window的type属性前面我们讲到window机制解决的一个问题就是view的显示次序问题，这个属性就决定了window的显示次序。window是有分类的，不同类别的显示高度范围不同，例如我把1-1000m高度称为低空，1001-2000m高度称为中空，2000以上称为高空。window也是一样按照高度范围进行分类，他也有一个变量Z-Order，决定了window的高度。window一共可分为三类： 应用程序窗口：应用程序窗口一般位于最底层，Z-Order在1-99 子窗口：子窗口一般是显示在应用窗口之上，Z-Order在1000-1999 系统级窗口：系统级窗口一般位于最顶层，不会被其他的window遮住，如Toast，Z-Order在2000-2999。如果要弹出自定义系统级窗口需要动态申请权限。 Z-Order越大，window越靠近用户，也就显示越高，高度高的window会覆盖高度低的window。 window的type属性就是Z-Order的值，我们可以给window的type属性赋值来决定window的高度。系统为我们三类window都预设了静态常量，如下（以下常用参数介绍转自参考文献第一篇文章）： 应用级window 复制代码 1234567891011121314151617// 应用程序 Window 的开始值public static final int FIRST_APPLICATION_WINDOW = 1;// 应用程序 Window 的基础值public static final int TYPE_BASE_APPLICATION = 1;// 普通的应用程序public static final int TYPE_APPLICATION = 2;// 特殊的应用程序窗口，当程序可以显示 Window 之前使用这个 Window 来显示一些东西public static final int TYPE_APPLICATION_STARTING = 3;// TYPE_APPLICATION 的变体，在应用程序显示之前，WindowManager 会等待这个 Window 绘制完毕public static final int TYPE_DRAWN_APPLICATION = 4;// 应用程序 Window 的结束值public static final int LAST_APPLICATION_WINDOW = 99; 子window 复制代码 1234567891011121314151617181920212223// 子 Window 类型的开始值public static final int FIRST_SUB_WINDOW = 1000;// 应用程序 Window 顶部的面板。这些 Window 出现在其附加 Window 的顶部。public static final int TYPE_APPLICATION_PANEL = FIRST_SUB_WINDOW;// 用于显示媒体(如视频)的 Window。这些 Window 出现在其附加 Window 的后面。public static final int TYPE_APPLICATION_MEDIA = FIRST_SUB_WINDOW + 1;// 应用程序 Window 顶部的子面板。这些 Window 出现在其附加 Window 和任何Window的顶部public static final int TYPE_APPLICATION_SUB_PANEL = FIRST_SUB_WINDOW + 2;// 当前Window的布局和顶级Window布局相同时，不能作为子代的容器public static final int TYPE_APPLICATION_ATTACHED_DIALOG = FIRST_SUB_WINDOW + 3;// 用显示媒体 Window 覆盖顶部的 Window， 这是系统隐藏的 APIpublic static final int TYPE_APPLICATION_MEDIA_OVERLAY = FIRST_SUB_WINDOW + 4;// 子面板在应用程序Window的顶部，这些Window显示在其附加Window的顶部， 这是系统隐藏的 APIpublic static final int TYPE_APPLICATION_ABOVE_SUB_PANEL = FIRST_SUB_WINDOW + 5;// 子 Window 类型的结束值public static final int LAST_SUB_WINDOW = 1999; 系统级window 复制代码 1234567891011121314151617181920212223242526272829303132333435// 系统Window类型的开始值public static final int FIRST_SYSTEM_WINDOW = 2000;// 系统状态栏，只能有一个状态栏，它被放置在屏幕的顶部，所有其他窗口都向下移动public static final int TYPE_STATUS_BAR = FIRST_SYSTEM_WINDOW;// 系统搜索窗口，只能有一个搜索栏，它被放置在屏幕的顶部public static final int TYPE_SEARCH_BAR = FIRST_SYSTEM_WINDOW+1;// 已经从系统中被移除，可以使用 TYPE_KEYGUARD_DIALOG 代替public static final int TYPE_KEYGUARD = FIRST_SYSTEM_WINDOW+4;// 系统对话框窗口public static final int TYPE_SYSTEM_DIALOG = FIRST_SYSTEM_WINDOW+8;// 锁屏时显示的对话框public static final int TYPE_KEYGUARD_DIALOG = FIRST_SYSTEM_WINDOW+9;// 输入法窗口，位于普通 UI 之上，应用程序可重新布局以免被此窗口覆盖public static final int TYPE_INPUT_METHOD = FIRST_SYSTEM_WINDOW+11;// 输入法对话框，显示于当前输入法窗口之上public static final int TYPE_INPUT_METHOD_DIALOG= FIRST_SYSTEM_WINDOW+12;// 墙纸public static final int TYPE_WALLPAPER = FIRST_SYSTEM_WINDOW+13;// 状态栏的滑动面板public static final int TYPE_STATUS_BAR_PANEL = FIRST_SYSTEM_WINDOW+14;// 应用程序叠加窗口显示在所有窗口之上public static final int TYPE_APPLICATION_OVERLAY = FIRST_SYSTEM_WINDOW + 38;// 系统Window类型的结束值public static final int LAST_SYSTEM_WINDOW = 2999; Window的flags参数flag标志控制window的东西比较多，很多资料的描述是“控制window的显示”，但我觉得不够准确。flag控制的范围包括了：各种情景下的显示逻辑（锁屏，游戏等）还有触控事件的处理逻辑。控制显示确实是他的很大部分功能，但是并不是全部。下面看一下一些常用的flag，就知道flag的功能了（以下常用参数介绍转自参考文献第一篇文章）： 复制代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 当 Window 可见时允许锁屏public static final int FLAG_ALLOW_LOCK_WHILE_SCREEN_ON = 0x00000001;// Window 后面的内容都变暗public static final int FLAG_DIM_BEHIND = 0x00000002;// Window 不能获得输入焦点，即不接受任何按键或按钮事件，例如该 Window 上 有 EditView，点击 EditView 是 不会弹出软键盘的// Window 范围外的事件依旧为原窗口处理；例如点击该窗口外的view，依然会有响应。另外只要设置了此Flag，都将会启用FLAG_NOT_TOUCH_MODALpublic static final int FLAG_NOT_FOCUSABLE = 0x00000008;// 设置了该 Flag,将 Window 之外的按键事件发送给后面的 Window 处理, 而自己只会处理 Window 区域内的触摸事件// Window 之外的 view 也是可以响应 touch 事件。public static final int FLAG_NOT_TOUCH_MODAL = 0x00000020;// 设置了该Flag，表示该 Window 将不会接受任何 touch 事件，例如点击该 Window 不会有响应，只会传给下面有聚焦的窗口。public static final int FLAG_NOT_TOUCHABLE = 0x00000010;// 只要 Window 可见时屏幕就会一直亮着public static final int FLAG_KEEP_SCREEN_ON = 0x00000080;// 允许 Window 占满整个屏幕public static final int FLAG_LAYOUT_IN_SCREEN = 0x00000100;// 允许 Window 超过屏幕之外public static final int FLAG_LAYOUT_NO_LIMITS = 0x00000200;// 全屏显示，隐藏所有的 Window 装饰，比如在游戏、播放器中的全屏显示public static final int FLAG_FULLSCREEN = 0x00000400;// 表示比FLAG_FULLSCREEN低一级，会显示状态栏public static final int FLAG_FORCE_NOT_FULLSCREEN = 0x00000800;// 当用户的脸贴近屏幕时（比如打电话），不会去响应此事件public static final int FLAG_IGNORE_CHEEK_PRESSES = 0x00008000;// 则当按键动作发生在 Window 之外时，将接收到一个MotionEvent.ACTION_OUTSIDE事件。public static final int FLAG_WATCH_OUTSIDE_TOUCH = 0x00040000;@Deprecated// 窗口可以在锁屏的 Window 之上显示, 使用 Activity#setShowWhenLocked(boolean) 方法代替public static final int FLAG_SHOW_WHEN_LOCKED = 0x00080000;// 表示负责绘制系统栏背景。如果设置，系统栏将以透明背景绘制，// 此 Window 中的相应区域将填充 Window＃getStatusBarColor（）和 Window＃getNavigationBarColor（）中指定的颜色。public static final int FLAG_DRAWS_SYSTEM_BAR_BACKGROUNDS = 0x80000000;// 表示要求系统壁纸显示在该 Window 后面，Window 表面必须是半透明的，才能真正看到它背后的壁纸public static final int FLAG_SHOW_WALLPAPER = 0x00100000; window的solfInputMode属性这一部分就是当软件盘弹起来的时候，window的处理逻辑，这在日常中也经常遇到，如：我们在微信聊天的时候，点击输入框，当软键盘弹起来的时候输入框也会被顶上去。如果你不想被顶上去，也可以设置为被软键盘覆盖。下面介绍一下常见的属性（以下常见属性介绍选自参考文献第一篇文章）： 复制代码 123456789101112131415161718192021222324252627282930313233// 没有指定状态，系统会选择一个合适的状态或者依赖于主题的配置public static final int SOFT_INPUT_STATE_UNCHANGED = 1;// 当用户进入该窗口时，隐藏软键盘public static final int SOFT_INPUT_STATE_HIDDEN = 2;// 当窗口获取焦点时，隐藏软键盘public static final int SOFT_INPUT_STATE_ALWAYS_HIDDEN = 3;// 当用户进入窗口时，显示软键盘public static final int SOFT_INPUT_STATE_VISIBLE = 4;// 当窗口获取焦点时，显示软键盘public static final int SOFT_INPUT_STATE_ALWAYS_VISIBLE = 5;// window会调整大小以适应软键盘窗口public static final int SOFT_INPUT_MASK_ADJUST = 0xf0;// 没有指定状态,系统会选择一个合适的状态或依赖于主题的设置public static final int SOFT_INPUT_ADJUST_UNSPECIFIED = 0x00;// 当软键盘弹出时，窗口会调整大小,例如点击一个EditView，整个layout都将平移可见且处于软件盘的上方// 同样的该模式不能与SOFT_INPUT_ADJUST_PAN结合使用；// 如果窗口的布局参数标志包含FLAG_FULLSCREEN，则将忽略这个值，窗口不会调整大小，但会保持全屏。public static final int SOFT_INPUT_ADJUST_RESIZE = 0x10;// 当软键盘弹出时，窗口不需要调整大小, 要确保输入焦点是可见的,// 例如有两个EditView的输入框，一个为Ev1，一个为Ev2，当你点击Ev1想要输入数据时，当前的Ev1的输入框会移到软键盘上方// 该模式不能与SOFT_INPUT_ADJUST_RESIZE结合使用public static final int SOFT_INPUT_ADJUST_PAN = 0x20;// 将不会调整大小，直接覆盖在window上public static final int SOFT_INPUT_ADJUST_NOTHING = 0x30; window的其他属性上面的三个属性是window比较重要也是比较复杂 的三个，除此之外还有几个日常经常使用的属性： x与y属性：指定window的位置 alpha：window的透明度 gravity：window在屏幕中的位置，使用的是Gravity类的常量 format：window的像素点格式，值定义在PixelFormat中 如何给window属性赋值window属性的常量值大部分存储在WindowManager.LayoutParams类中，我们可以通过这个类来获得这些常量。当然还有Gravity类和PixelFormat类等。 一般情况下我们会通过以下方式来往屏幕中添加一个window： 复制代码 12345// 在Activity中调用WindowManager.LayoutParams windowParams = new WindowManager.LayoutParams();windParams.flags = WindowManager.LayoutParams.FLAG_FULLSCREEN;TextView view = new TextView(this);getWindowManager.addview(view,windowParams); 我们可以直接给WindowManager.LayoutParams对象设置属性。 第二种赋值方法是直接给window赋值，如 复制代码 1getWindow().flags = WindowManager.LayoutParams.FLAG_FULLSCREEN; 除此之外，window的solfInputMode属性比较特殊，他可以直接在AndroidManifest中指定，如下： 复制代码 1&lt;activity android:windowSoftInputMode=&quot;adjustNothing&quot; /&gt; 最后总结一下： window的重要属性有type、flags、solfInputMode、gravity等 我们可以通过不同的方式给window属性赋值 没必要去全部记下来，等遇到需求再去寻找对应的常量即可 未整理http://3dobe.com/archives/89/ 一个Activity或一个Dialog对应一个PhoneWindow，一个PhoneWindow对应一个WindowManger，对应一个WindowManagerImpl 所以得 mChoreographer，Choreographer的实例，在SampleWindow的例子中已经见过了。Choreographer的意思是编舞指导。它拥有从显示子系统获取VSYNC同步事件的能力，从而可以在合适的时机通知渲染动作，避免在渲染的过程中因为发生屏幕重绘而导致的画面撕裂。从这个意义上讲，Choreographer的确是指导Android翩翩起舞的大师。WMS使用Choreographer负责驱动所有的窗口动画、屏幕旋转动画、墙纸动画的渲染。 mAnimator，WindowAnimator的实例。它是所有窗口动画的总管（窗口动画是一个WindowStateAnimator对象）。在Choreographer的驱动下，逐个渲染所有的动画。 mPolicy，WindowPolicyManager的一个实现。目前它只有PhoneWindowManager一个实现类。mPolicy定义了很多窗口相关的策略，可以说是WMS的首席顾问！每当WMS要做什么事情的时候，都需要向这个顾问请教应当如何做。例如，告诉WMS某一个类型的Window的ZOrder的值是多少，帮助WMS矫正不合理的窗口属性，会为WMS监听屏幕旋转的状态，还会预处理一些系统按键事件（例如HOME、BACK键等的默认行为就是在这里实现的），等等。所以，mPolicy可谓是WMS中最重要的一个成员了。 mDisplayContents，一个DisplayContent类型的列表。Android 4.2支持基于Wi-Fi Display的多屏幕输出，而一个DisplayContent描述了一块可以绘制窗口的屏幕。每个DisplayContent都用一个整型变量作为其ID，其中手机默认屏幕的ID由Display.DEFAULT_DISPLAY常量指定。DisplayContent的管理是由DisplayManagerService完成的，在本章不会去探讨DisplayContent的实现细节，而是关注DisplayContent对窗口管理与布局的影响 mTokenMap，一个HashMap，保存了所有的显示令牌（类型为WindowToken），用于窗口管理。在SampleWindow例子中曾经提到过，一个窗口必须隶属于某一个显示令牌。在那个例子中所添加的令牌就被放进了这个HashMap中。从这个成员中还衍生出几个辅助的显示令牌的子集，例如mAppTokens保存了所有属于Activity的显示令牌（WindowToken的子类AppWindowToken），mExitingTokens则保存了正在退出过程中的显示令牌等。其中mAppTokens列表是有序的，它与AMS中的mHistory列表的顺序保持一致，反映了系统中Activity的顺序。 mWindowMap，也是一个HashMap，保存了所有窗口的状态信息（类型为WindowState），用于窗口管理。在SampleWindow例子中，使用IWindowSession.add（）所添加的窗口的状态将会被保存在mWindowMap中。与mTokenMap一样，mWindowMap一样有衍生出的子集。例如mPendingRemove保存了那些退出动画播放完成并即将被移除的窗口，mLosingFocus则保存了那些失去了输入焦点的窗口。在DisplayContent中，也有一个windows列表，这个列表存储了显示在此Display-Content中的窗口，并且它是有序的。窗口在这个列表中的位置决定了其最终显示时的Z序。 mSessions，一个List，元素类型为Session。Session其实是SampleWindow例子中的IWindowSession的Bn端。也就是说，mSessions这个列表保存了当前所有想向WMS寻求窗口管理服务的客户端。注意Session是进程唯一的。 mRotation，只是一个int型变量。它保存了当前手机的旋转状态 Android 系统采用一种称为 Surface 的图形架构，简而言之，每一个 Activity 都关联有至少一个 Window（窗口），每一个 Window 都对应有一个 Surface。 Surface 这里直译过来叫做 绘图表面 ，顾名思义，其可在内存中生成一个图形缓冲区队列，用于描述 UI，经与系统服务的WindowServiceManager 通信后、通过 SurfaceFlinger 服务持续合成并送显到显示屏。 由此可见，通常情况下，一个 Activity 的 UI 渲染本质是 系统提供一块内存，并创建一个图形缓冲区进行维护；这块内存就是 Surface，最终页面所有 View 的 UI 状态数据，都会被填充到同一个 Surface 中。","link":"/2022/02/16/Window/"},{"title":"Thread","text":"线程/进程进程：进程是系统进行资源分配和调度的一个独立单位 (拥有独立内存空间)，一个app就是一个进程，进程包含线程。 线程：是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程自己基本上不拥有系统资源,只拥有一些在运行中必不可少的资源(如程序计数器,一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。 静态的是资源和动态的是计算 进程是一个资源的容器，为进程里的所有线程提供共享资源，是对程序的一种静态描述 线程是计算机最小的调度和运行（计算）单位，是对程序的一种动态描述 Java里的线程有哪些状态？JDK中，线程（Thread）定义了6种状态： NEW（新建）、RUNNABLE（可执行）、BLOCKED（阻塞）、WAITING（等待）、TIMED_WAITING（限时等待）、TERMINATED（结束）。 源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * A thread state. A thread can be in one of the following states: * &lt;ul&gt; * &lt;li&gt;{@link #NEW} * A thread that has not yet started is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #RUNNABLE} * A thread executing in the Java virtual machine is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #BLOCKED} * A thread that is blocked waiting for a monitor lock * is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #WAITING} * A thread that is waiting indefinitely for another thread to * perform a particular action is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #TIMED_WAITING} * A thread that is waiting for another thread to perform an action * for up to a specified waiting time is in this state. * &lt;/li&gt; * &lt;li&gt;{@link #TERMINATED} * A thread that has exited is in this state. * &lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt; * A thread can be in only one state at a given point in time. * These states are virtual machine states which do not reflect * any operating system thread states. * * @since 1.5 * @see #getState */public enum State { /** * Thread state for a thread which has not yet started. */ NEW, /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */ RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. * A thread in the blocked state is waiting for a monitor lock * to enter a synchronized block/method or * reenter a synchronized block/method after calling * {@link Object#wait() Object.wait}. */ BLOCKED, /** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * &lt;ul&gt; * &lt;li&gt;{@link Object#wait() Object.wait} with no timeout&lt;/li&gt; * &lt;li&gt;{@link #join() Thread.join} with no timeout&lt;/li&gt; * &lt;li&gt;{@link LockSupport#park() LockSupport.park}&lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt;A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called &lt;tt&gt;Object.wait()&lt;/tt&gt; * on an object is waiting for another thread to call * &lt;tt&gt;Object.notify()&lt;/tt&gt; or &lt;tt&gt;Object.notifyAll()&lt;/tt&gt; on * that object. A thread that has called &lt;tt&gt;Thread.join()&lt;/tt&gt; * is waiting for a specified thread to terminate. */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. * A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * &lt;ul&gt; * &lt;li&gt;{@link #sleep Thread.sleep}&lt;/li&gt; * &lt;li&gt;{@link Object#wait(long) Object.wait} with timeout&lt;/li&gt; * &lt;li&gt;{@link #join(long) Thread.join} with timeout&lt;/li&gt; * &lt;li&gt;{@link LockSupport#parkNanos LockSupport.parkNanos}&lt;/li&gt; * &lt;li&gt;{@link LockSupport#parkUntil LockSupport.parkUntil}&lt;/li&gt; * &lt;/ul&gt; */ TIMED_WAITING, /** * Thread state for a terminated thread. * The thread has completed execution. */ TERMINATED;} 状态说明线程在一个给定的时间点只能处于下面其中一种状态： 这些状态是虚拟机状态，并不能反映任何操作系统的线程状态。 NEW：尚未启动的线程处于这个状态。Thread thread = new Thread(new Runnable(){…});处于这个状态。 RUNNABLE：可运行的线程处于这个状态。对应操作系统中的两种状态：ready和running，也就是说RUNNABLE状态既可以是可运行的，也可以是实际运行中的，有可能正在执行，也有可能没有正在执行。关于这个问题的理解，可以对比想一下，thread.start()调用之后线程会立刻执行吗？ BLOCKED：阻塞，进入synchronized修饰的方法或者代码块，等待监视器锁的线程处于这个状态。 WAITING：无限期等待另一个线程执行特定操作的线程处于这种状态。 TIMED_WAITING：正在等待另一个线程执行某个操作的线程在指定的等待时间内处于这种状态。 TERMINATED：已经退出的线程处于这个状态。 状态转移NEW：线程尚未启动的线程状态。当在程序中创建一个线程的时候Thread t = new Thread(Runnable);，线程处于NEW状态。 RUNNABLE：可运行线程的线程状态。处于可运行状态的线程正在Java虚拟机中执行，但它可能正在等待操作系统中的其他资源，比如处理器。也就是说， 这个状态就是可运行也可不运行的状态。注意Runnable ≠ Running。 BLOCKED：进入synchronized修饰的方法或者代码块，等待监视器锁的阻塞线程的线程状态。比如，线程试图通过synchronized去获取监视器锁，但是其他线程已经独占了，那么当前线程就会处于阻塞状态。等到获得了监视器锁之后会再次进入RUNNABLE状态。 WAITING：调用以下方法之一，线程会处于等待状态： Object.wait()注意：括号内不带参数； Thread.join()注意：扩号内不带参数； LockSupport.park()； 其实wait()方法有多重形式，可以不带参数，可以带参数，参数表示等待时间（单位ms），如图所示： “BLOCKED（阻塞状态）”和“WAITING（等待状态）”的区别：阻塞状态在等待获取一个排它锁，这个事件将会在另外一个线程放弃这个锁的时候发生，然后由阻塞状态变为可执行状态；而等待状态则是在等待一段时间，或者等待唤醒动作的发生。 TIMED_WAITING：一个线程调用了以下方法之一（方法需要带具体的等待时间），会处于定时等待状态： Thread.sleep(long timeout) Object.wait(long timeout) Thread.join(long timeout) LockSupport.parkNanos() LockSupport.parkUntil() TERMINATED： 该线程已经执行完毕。执行完毕指的是线程正常执行完了run方法之后退出，也可以是遇到了未捕获的异常而退出。 初始(NEW)新创建了一个线程对象，但还没有调用start()方法。 运行(RUNNABLE)ReadyRunningJava线程中将就绪（ready）和运行中（running）两种状态笼统 的称为“运行”。线程对象创建后，其他线程(比如main线程）调用了该对象的start()方 法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此 时处于就绪状态（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态 （running）。 阻塞(BLOCKED)表示线程阻塞于锁。或称“挂起” 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间 等待(WAITING)等待状态，处于等待状态的线程是由于执行了Thread.join或Object.wait方法 处于waiting状态的线程会等待另外一个线程处理特殊的行为。 再举个例子，如果一个线程调用了一个对象的wait方法，那么这个线程就会处于waiting状态直到另外一个线程调用这个对象的notify或者notifyAll方法后才会解除这个状态 超时等待(TIMED_WAITING)有等待时间的等待状态，比如调用了**Thread.sleep(long timeout)、Thread.join(long timeout)、Object.wait(long timeout)**，并且指定了等待时间，线程就会处于这个状态。 终止(TERMINATED)表示该线程已经执行完毕。 对比分析Java中的各个线程相关的wait()、notify()、sleep()、interrupt()方法 线程相关方法Thread类sleep：暂停当前正在执行的线程；（类方法）​ 是Thread的静态方法，很显然它是让当前线程按照指定的时间休眠，其休眠时间的精度取决于处理器的计时器和调度器。需要注意的是如果当前线程获得了锁，sleep方法并不会失去锁。sleep方法经常拿来与Object.wait()方法进行比价，这也是面试经常被问的地方。 sleep() VS wait() 两者主要的区别： 1. sleep()方法是Thread的静态方法，而wait是Object实例方法 2. wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。而sleep()方法没有这个限制可以在任何地方种使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁； 3. sleep()方法在休眠时间达到后如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行。 yield：暂停当前正在执行的线程，并执行其他线程；（类方法）​ 是Thread的静态方法，一旦执行，它会是当前线程让出CPU，但是，需要注意的是，让出的CPU并不是代表当前线程不再运行了，如果在下一次竞争中，又获得了CPU时间片当前线程依然会继续运行。另外，让出的时间片只会分配给当前线程相同优先级的线程。 ​ yield()方法使当前线程出让CPU执行时间，但并不会释放当前线程所持有的锁。执行完yield()方法后，线程从Running状态转变为Runnable状态，既然是Runnable状态，那么也很可能马上会被CPU调度再次进入Running状态。 什么是线程优先级了？下面就来具体聊一聊。 现代操作系统基本采用时分的形式调度运行的线程，操作系统会分出一个个时间片，线程会分配到若干时间片，当前时间片用完后就会发生线程调度，并等待这下次分配。线程分配到的时间多少也就决定了线程使用处理器资源的多少，而线程优先级就是决定线程需要或多或少分配一些处理器资源的线程属性。 在Java程序中，通过一个整型成员变量Priority来控制优先级，优先级的范围从1~10.在构建线程的时候可以通过**setPriority(int)**方法进行设置，默认优先级为5，优先级高的线程相较于优先级低的线程优先获得处理器时间片。需要注意的是在不同JVM以及操作系统上，线程规划存在差异，有些操作系统甚至会忽略线程优先级的设定。 另外需要注意的是，sleep()和yield()方法，同样都是当前线程会交出处理器资源，而它们不同的是，sleep()交出来的时间片其他线程都可以去竞争，也就是说都有机会获得当前线程让出的时间片。而yield()方法只允许与当前线程具有相同优先级的线程能够获得释放出来的CPU时间片。 join：等待该线程终止；​ join()方法的作用，是等待这个线程结束，是主线程等待子线程的终止。也就是说主线程的代码块中，如果碰到了t.join()方法，此时主线程需要等待（阻塞），等待子线程结束了(Waits for this thread to die.),才能继续执行t.join()之后的代码块。 interrupt：中断该线程，interrupt()方法的工作仅仅是改变中断状态，并不是直接中断正在运行的线程。中断的真正原理是当线程被Object.wait(),Thread.join()或sleep()方法阻塞时，调用interrupt()方法后改变中断状态，而wait/join/sleep这些方法内部会不断地检查线程的中断状态值，当发现中断状态值改变时则抛出InterruptedException异常；对于没有阻塞的线程，调用interrupt()方法是没有任何作用。 Object类 wait：暂停当前正在执行的线程，直到调用notify()或notifyAll()方法或超时，退出等待状态； notify：唤醒在该对象上等待的一个线程； notifyAll：唤醒在该对象上等待的所有线程； 对比sleep VS waitsleep()和wait()方法都是暂停当前正在执行的线程，出让CPU资源。 方法 所属类 方法类型 锁 解除方法 场景 用途 sleep Thread 静态方法 不释放锁 timeout,interrupt 无限制 线程内的控制 wait Object 非静态方法 释放锁 timeout,notify,interrupt 同步语句块 线程间的通信 123456public static void sleep(long millis) throws InterruptedException public static void sleep(long millis, int nanos) throws InterruptedException public final void wait() throws InterruptedException public final void wait(long timeout) throws InterruptedException public final void wait(long timeout, int nanos) throws InterruptedException wait &amp;&amp; notify调用对象的wait()、notify()、notifyAll()方法的线程，必须是作为此对象监视器的所有者。常见的场景便是就是synchronized关键字的语句块内部使用这3个方法，如果直接在线程中使用wait()、notify()、notifyAll()方法，那么会抛出异常IllegalMonitorStateException，抛出的异常表明某一线程已经试图等待对象的监视器，或者试图通知其他正在等待对象的监视器而本身没有指定监视器的线程。。 调用wait()方法的线程，在调用该线程的interrupt()方法，则会重新尝试获取对象锁。只有当获取到对象锁，才开始抛出相应的异常，则执行该线程之后的程序。 怎么终止一个线程首先，一个线程不应该由其他线程来强制中断或停止，而是应该由线程自己自行停止。 所以，Thread.stop, Thread.suspend, Thread.resume 都已经被废弃了。 interrupt：Thread.interrupt 的作用其实也不是中断线程，而是「通知线程应该中断了」， 具体到底中断还是继续运行，应该由被通知的线程自己处理。 具体来说，当对一个线程，调用 interrupt() 时， ① 如果线程处于被阻塞状态（例如处于sleep, wait, join 等状态），那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常。仅此而已。 ② 如果线程处于正常活动状态，那么会将该线程的中断标志设置为 true，仅此而已。被设置中断标志的线程将继续正常运行，不受影响。 interrupt() 并不能真正的中断线程，需要被调用的线程自己进行配合才行。 ① 在正常运行任务时，经常检查本线程的中断标志位，如果被设置了中断标志就自行停止线程。 ② 在调用阻塞方法时正确处理InterruptedException异常。（例如，catch异常后就结束线程。） 123456789Thread thread = new Thread(() -&gt; { while (!Thread.interrupted()) { // do more work. }});thread.start();// 一段时间以后thread.interrupt(); stop():弃用，因为在stop时会释放所有的锁，可能导致线程不同步，另一个也可能导致资源如文件文件数据库的关闭行为不被执行 调用 stop() 方法会立刻停止 run() 方法中剩余的全部工作，包括在 catch 或 finally 语句中的，并抛出ThreadDeath异常(通常情况下此异常不需要显示的捕获)，因此可能会导致一些清理性的工作的得不到完成，如文件，数据库等的关闭。 调用 stop() 方法会立即释放该线程所持有的所有的锁，导致数据得不到同步，出现数据不一致的问题。 使用volatile标志位以标志位为循环条件","link":"/2024/07/26/Tread/"},{"title":".bash_profile","text":"#jdk#jdk-11.0.12.jdk or jdk1.8.0_291.jdkexport JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_291.jdk/Contents/Home#export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-11.0.12.jdk/Contents/Homeexport PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar#android sdkexport ANDROID_HOME=/Users/crow/Library/Android/sdkexport PATH=${PATH}:${ANDROID_HOME}/toolsexport PATH=${PATH}:${ANDROID_HOME}/platform-tools#android ndkexport ANDROID_NDK_HOME=/Users/crow/Library/Android/sdk/ndk-bundleexport PATH=$PATH:$ANDROID_NDK_HOME #alias#screen shot phonealias ss=’adb shell screencap /sdcard/screenshot.png &amp;&amp; adb pull /sdcard/screenshot.png . &amp;&amp; open ./screenshot.png’alias screenShot=’adb shell screencap /sdcard/screenshot.png &amp;&amp; adb pull /sdcard/screenshot.png . &amp;&amp; open ./screenshot.png’ #screen recordalias sr=’adb shell screenrecord /sdcard/video.mp4’alias startRecord=’adb shell screenrecord /sdcard/video.mp4’#control + c to stopalias showRecord=’adb pull /sdcard/video.mp4 . &amp;&amp; open ./video.mp4’ #adb input text to phonemyinput() { adb shell input text “$1” }alias input=’myinput ‘ #adb stop/start appalias stopApp=’adb shell am force-stop com.alibaba.aliexpresshd’alias startApp=’adb shell am start “com.alibaba.aliexpresshd/com.alibaba.aliexpresshd.home.ui.MainActivity”‘ #adb debug appalias debugApp=’adb shell am start -D “com.alibaba.aliexpresshd/com.alibaba.aliexpresshd.home.ui.MainActivity”‘ #gradledependencies() { ./gradlew “$1”:dependencies –configuration debugRuntimeClasspath }alias depen=’dependencies’ #incremental commandalias increment=’bash &lt;(curl -s https://gitlab.alibaba-inc.com/chenzhong.cz/incremental_scripts/raw/dev_parallel_aliexpress_mtl4/incremental.sh)'","link":"/2023/02/22/bash-profile/"},{"title":"WorkNote","text":"APM基建方案有dokit和matrix，dokit功能更多，线下监控；Matrix优化更好，支持线上监控； 最终选择了功能更全一点的dokit，以期达到线下监控，线下处理，线上预防。 基于滴滴开源框架Dokit + 自定义扩展的性能监控（如图片尺寸浪费、内存泄露误报、） 其中dokit中包括了原理与BlockCanary类似的耗时方法监控、Choreographer帧耗时统计、图片尺寸超限、函数耗时、启动耗时 耗时方法监控核心是根据handler原理，通过给Looper.loop() 中设置printer(无论是通过反射替换Looper的mLogging还是通过setMessageLogging设置printer)，监控超过 设定阈值(matrix700ms) 的主线程消息（超过5s报为ANR），printer 中判断start和end，来获取主线程dispatch该message的开始和结束时间，并判定该时间超过阈值为主线程卡慢发生，并 打印当时堆栈 + 方法耗时(matrix/dokit) 堆栈和方法耗时 dokit和matrix是每个方法插桩，但matrix的优化更细节 帧率检测核心是利用系统 Choreographer 模块，向该模块注册一个 FrameCallback 监听对象，同时通过另外一条线程循环记录主线程堆栈信息，并在每次 Vsync 事件 doFrame 通知回来时，循环注册该监听对象，间接统计两次 Vsync 事件的时间间隔，当超出阈值时，取出记录的堆栈进行分析上报。 帧率检测新版本可以考虑用 一次完整的图片优化过程 域名收敛，使用正则将多个域名收敛成一个，提高链接复用； 推服务端使用Http2，减少堵塞 同时收敛webp格式，若该图片存在webp则替换为webp链接，兜底为原链接，节省下载流量和加载速度； 调整链接中图片尺寸以符合CDN裁切尺寸（300，500等）； 单元测试覆盖（如果是现在我会用chatgpt写） 开发网络图片大小不当报警，通过插桩图片加载框架，上报图片下载尺寸与实际尺寸不符的case（页面类名+view id） 目标：监控图片下载尺寸浪费，优化图片渲染速度，减少图片下行流量（优化磁盘大小，fresco本身能够裁剪图片获得适当的内存大小。） 细节： 从 调用图片加载 到 图片真正加载完成 的时机和代码是分离的，那么 调用图片加载时候拿到的view信息 需要和 图片加载完成时拿到的下载尺寸 匹配，于是维护了一个key为url，value为view信息的ConcurrentHashMap，在加载完成时从中取出对应值判断 其他：这个功能同时也能识别图片过小带来的尺寸拉伸导致的图片模糊问题。 修复了fresco加载gif图片bug带来的内存暴涨 细节：首先描述一下现象，fresco加载gif图片，当该gif图是多次轮播时，通过Android profile的内存监控可看到内存一路上升，直到gc后又继续上涨；原因：gif图中的每一帧会在解析时包裹成一个内部对象AnimatedImageResult，复用gif图帧的开关默认是关闭的，且复用代码有bug，复用缓存的key被设置为AnimatedImageResult的hashcode值，导致每次播放同一帧时，每次都会重新解析加载到内存，每一帧会有多份内存存在； 解决方案：1、打开复用开关；2、修改复用的key，为解析后ByteBuffer的System.identityHashCode值 + option的hashcode值 相当于用解析后单帧的hashcode作为缓存key PS:fresco 后续补充： https://github.com/facebook/fresco/commit/40937a700e76e0f68353857f5bd0b567b6e909f1 fresco将之前试验性质的代码移除，有较大的缓存改动。故PR不再会被接收（如ExperimentalBitmapAnimationDrawableFactory这个类已经被替换了），同时gif图缓存新增一个AnimatedCache.kt的类，通过source(gif图url)+frameIndexNumber的方式生成缓存key。 现在通过更新frasco版本应该就可以有正常的gif图缓存了 基于内部框架奥创完成了购物车、订单页面的重构 完成一次完整的页面直开优化 一次基于内部框架奥创、MVVM设计的购物车、订单重构背景是项目是14年左右开始迭代的，模块的耦合很重，设计落后，维护性很差，于是当时借助一次产品发起的改版方案，重构了订单。 奥创是一个前后端协作的组件化协议，将页面根据各自功能拆分为多个组件，奥创协议下发每个组件所需的字段、组件对应的页面层级位置等。 端侧可以获得一份清晰的组件列表、组件位置（只分粘顶、滑动、粘底）。端侧在RecyclerView中注册每个组件对应的ViewModel和ViewHolder，解析协议中组件的数据得到组件ViewModel，recyclerView中每个组件ViewHodle将根据组件唯一Id取到对应的ViewModel。 整体设计是由数据驱动，MVVM架构下，viewmodel中的数据由生命周期安全的LiveData持有，ViewHolder作为View层监听相对应数据的变化。网络请求放在页面ViewModel的Repository层中。 一次完整的页面秒开方案预测请求本页面刷新完数据后通过对用户行为的预测，直接发起下个页面的请求并缓存内存LRUCache，这种情况进入下个页面时大概率能直接拿到缓存。节省了整个请求时间。 优点是速度很快，缺点是必不可免的存在流量浪费，需要根据线上的数据调整规则，以达到最佳的请求能效。 提前请求路由层拦截页面将目标页面的请求抽离到预请求框架提供的接口实现类中，路由层提供注册对应页面的url处理的能力，一旦监听到路由层有相关的url跳转，预请求接口实现类发起一次预请求，在页面实际发起请求时，转为向预请求框架请求数据。如有已发起预请求的标记则走预请求框架，否则继续走正常发起请求逻辑。 节省了路由耗时+activity启动耗（十几ms）、inflate耗时(几十到几百ms) 页面请求前置直接将请求前置，在onCreate最前面就发起请求，节省了inflateLayout的开销(几十到几百ms)，（为什么不用AsyncLayoutInflater：限制较多，如异步线程中没有初始化looper，view需手动加到Viewparent等） 需要注意的是，如果请求直接失败的情况下，由于布局未inflate完成可能导致失败视图展示有问题，这种情况下失败视图操作需要post一下。 优点是改动小，适用性广； 补充：一、首屏的定义：起点一定是从点击开始； 结束可为： 下个页面onResume执行一个handle.post() 下个页面recyclerView第一个item执行onBinde结束 （淘宝定义）在固定机型(最多的占比)下，下个页面前三张图加载完成（用户体验视角定义首屏时间） 二、优化首屏的手段： 预加载 上述几种方案，可以普遍使用路由拦截请求方案 本地缓存 如购物车使用本地缓存 闲时资源预热 主要针对dx模板之类的 引擎预热 dx引擎预热 推后端优化 减少机器内RT 上下行包大小优化 精简协议，减少包大小 上个页面onPause时间排查 比如上个页面onPause中处理太多事情导致下一页面唤起延迟 布局加载优化 一次rtl引发的惨案Case 1：原始数据为 端侧显示为 前提： 数字18,186.37、美元$、冒号、逗号、小数点是弱字符； 空格是中性字符； 阿拉伯语是强rtl字符； 字母MXN是强ltr字符； BIDI算法基本规则： 文本的全局方向取决于句子中首个强字符 确定了文本的全局显示方向后，若局部出现了反向字符，则连续的反向字符保持其局部顺序e.g: 若在连续的阿拉伯文中出现了中文单词，如”奔跑吧”，则其仍按照中文顺序显示，不会显示为”吧跑奔” 弱字符保持自身方向 没有被强字符包裹的中性字符追随全局方向 解析： 首先，整体的文本方向是由第一个强字符决定的，也就是rtl方向； 阿拉伯文本强rtl字符 冒号 为弱字符保持自身方向(单个看不出来)，按全局方向摆放在其左 空格 为中性字符追随全局方向(单个看不出来)，按全局方向摆放在其左 18,186.37 整个弱字符方向串保持自身方向，为ltr，按全局方向摆放在其左 MXN为强ltr字符，按全局方向摆放在其左 $为弱字符方向，按全局方向摆放在其后 解决： 使用强制ltr的领宽度字符 u202A 和 终止符u202C 使 Total + “\\u202A” + 价格 + “\\u202C” 强制价格（金额+货币单位）作为一个方向串走 ltr Case2:","link":"/2024/02/21/WorkNote/"},{"title":"卡顿监控","text":"https://mp.weixin.qq.com/s/3dubi2GVW_rVFZZztCpsKg 主线程卡顿监控方案一、Looper Printer监控每次 dispatchMessage 的执行耗时：DoKit &amp; BlockCanary &amp; Matrix滴滴的哆啦A梦的卡顿检测其实就是blockCanary，和Matrix 的EvilMethodTracer和AnrTracer （当然后来Matrix还增加了native的Signal信号监听）使用的 方案也就是Looper设置Printer监听卡顿 都是根据handler原理，通过给Looper.loop() 中设置printer(无论是通过反射替换Looper的mLogging还是通过setMessageLogging设置printer)，监控超过 设定阈值(matrix700ms) 的主线程消息（超过5s报为ANR），printer 中判断start和end，来获取主线程dispatch该message的开始和结束时间，并判定该时间超过阈值为主线程卡慢发生，并 打印当时堆栈 + 方法耗时(matrix/dokit) 123456789101112131415161718192021222324252627282930Looper.loop() { for (;;) { Message msg = queue.next(); // might block if (msg == null) { ... // 执行dispatchMessage前，执行Printer的println方法 final Printer logging = me.mLogging; if (logging != null) { logging.println(&quot;&gt;&gt;&gt;&gt;&gt; Dispatching to &quot; + msg.target + &quot; &quot; + msg.callback + &quot;: &quot; + msg.what); } ... try { msg.target.dispatchMessage(msg); dispatchEnd = needEndTime ? SystemClock.uptimeMillis() : 0; } finally { ... } ... // 执行dispatchMessage后，执行Printer的println方法 if (logging != null) { logging.println(&quot;&lt;&lt;&lt;&lt;&lt; Finished to &quot; + msg.target + &quot; &quot; + msg.callback); } ... }} Matrix：无论是通过反射替换Looper的mLogging还是通过setMessageLogging设置printer，我们只需要替换主线程Looper的printer对象，通过计算执行dispatchMessage方法之后和之前打印字符串的时间的差值，就可以拿到到dispatchMessage方法执行的时间。而大部分的主线程的操作最终都会执行到这个dispatchMessage方法中。 Looper.loop()设置Printer监控方案存在问题及解决方案：简述：Looper.loop()中设置printer的方法监控耗时还会遗漏这几个场景： 首先大致代码： 1234567891011121314151617181920Looper.loop() { for(;;) { Message msg = queue.next(); // might block logging(Printer).println() // 消息处理前的printer打印 msg.target.dispatchMessage(msg); //消息处理 logging(Printer).println() // 消息处理后的printer打印 }}//-----------------------------------------------------------------------MessageQueue.next(){ for (;;) { nativePollOnce(ptr, nextPollTimeoutMillis); //touch消息处理 //主线程空闲&amp;idle消息处理 for(int i = 0; i &lt; pendingIdleHandlerCount; i++) { keep = idler.queueIdle( } }} 如上所示就可以看到设置printer监控方案在这里有监控不到的情况，也就是queue.next阻塞的情况，分两种： 1、主线程空闲时idleHandler处理的情况。 —— 可以通过反射MessageQueue中的mIdleHandlers(ArrayList)，替代成自定义的ArrayList类，在重写的add方法中获得所有的idleHandelr 2、Touch事件的话可以通过PLT hook，hook native framework中的事件机制。 还有另一种是barrier消息泄露的情况，这种情况很少见。 Q：如果排除主线程空闲的情况，究竟会是什么原因会卡在MessageQueue的next方法中呢？下图是next方法简化过后的源码，*frameworks/base/core/java/android/os/MessageQueue.java:next()* 1234567891011121314151617181920212223242526272829303132333435for (;;) { if (nextPollTimeoutMillis != 0) { Binder.flushPendingCommands(); } nativePollOnce(ptr, nextPollTimeoutMillis); //...... // Run the idle handlers. // We only ever reach this code block during the first iteration. for (int i = 0; i &lt; pendingIdleHandlerCount; i++) { final IdleHandler idler = mPendingIdleHandlers[i]; mPendingIdleHandlers[i] = null; // release the reference to the handler boolean keep = false; try { keep = idler.queueIdle(); } catch (Throwable t) { Log.wtf(TAG, &quot;IdleHandler threw exception&quot;, t); } if (!keep) { synchronized (this) { mIdleHandlers.remove(idler); } } } //......}/*1. 如果本次循环拿到的Message为空，或者！这个Message是一个延时的消息而且还没到指定的触发时间，那么，就认定当前的队列为空闲状态，2. 接着就会遍历mPendingIdleHandlers数组(这个数组里面的元素每次都会到mIdleHandlers中去拿)来调用每一个IdleHandler实例的queueIdle方法，3. 果这个方法返回false的话，那么这个实例就会从mIdleHandlers中移除，也就是当下次队列空闲的时候，不会继续回调它的queueIdle方法了。*/ 因为有些情况的卡顿，这种方案从原理上就无法监控到。看到上面的queue.next()，这里给了注释：might block，直接跟你说这里是可能会卡住的，这时候再计算dispatchMessage方法的耗时显然就没有意义了。有的同学可能会想，那我改成计算相邻两次dispatchMessage执行之前打印字符串的时间差值不就好了？这样就可以把next方法的耗时也计算在内。 1、主线程空闲也就是queue.next()阻塞的时候，同时也是应用的Touch事件。不幸的是，主线程空闲时，也会阻塞在MessageQueue的next方法中，我们很难区分究竟是发生了卡顿还是主线程空闲，除了主线程空闲时就是阻塞在nativePollOnce之外，非常重要的是，应用的Touch事件也是在这里被处理的。这就意味着，View的TouchEvent中的卡顿这种方案是无法监控的。（微信中有大量的自定义View，这些View中充满了各种各样很多的onTouch回调，卡在这里面的情况非常普遍，这种情况的卡顿监控不到是很难接受的） 2、IdleHandler的queueIdle()回调方法。这个方法会在主线程空闲的时候被调用。然而实际上，很多开发同学都先入为主的认为这个时候反正主线程空闲，做一些耗时操作也没所谓。其实主线程MessageQueue的queueIdle默认当然也是执行在主线程中，所以这里的耗时操作其实是很容易引起卡顿和ANR的。（例如微信之前就使用IdleHandler在进入微信的主界面后，做一些读写文件的IO操作，就造成了一些卡顿和ANR问题） 3、SyncBarrier泄露。还有一类相对少见的问题是SyncBarrier（同步屏障）的泄漏同样无法被监控到 当我们每次通过invalidate来刷新UI时，最终都会调用到ViewRootImpl中的scheduleTraversals方法，会向主线程的Looper中post一个SyncBarrier，其目的是为了在刷新UI时，主线程的同步消息都被跳过，此时渲染UI的异步消息就可以得到优先处理。但是我们注意到这个方法是线程不安全的，如果在非主线程中调用到了这里，就有可能会同时post多个SyncBarrier，但只能remove掉最后一个，从而有一个SyncBarrier就永远无法被remove，就导致了主线程Looper无法处理同步消息（Message默认就是同步消息），导致卡死 A：A.1. 监控IdleHandler卡顿首先从简单的下手，对于IdleHandler的queueIdle回调方法的监控。我们惊喜的发现MessageQueue中的mIdleHandlers是可以被反射的，这个变量保存了所有将要执行的IdleHandler，我们只需要把ArrayList类型的mIdleHandlers，通过反射，替换为MyArrayList，在我们自定义的MyArrayList中重写add方法，再将我们自定义的MyIdleHandler添加到MyArrayList中，就完成了“偷天换日”。从此之后MessageQueue每次执行queueIdle回调方法，都会执行到我们的MyIdleHandler中的的queueIdle方法，就可以在这里监控queueIdle的执行时间了。 12345678910111213141516171819202122232425262728293031323334353637383940private static void detectIdleHandler() { try { MessageQueue mainQueue = Looper.getMainLooper().getQueue(); Field field = MessageQueue.class.getDeclaredField(&quot;mIdleHandlers&quot;); field.setAccessible(true); MyArrayList&lt;MessageQueue.IdleHandler&gt; myIdleHandlerArrayList = new MyArrayList&lt;&gt;(); field.set(mainQueue, myIdleHandlerArrayList); } catch (Throwable t) { t.printStackTrace(); }}static class MyArrayList&lt;T&gt; extends ArrayList { Map&lt;MessageQueue.IdleHandler, MyIdleHandler&gt; map = new HashMap&lt;&gt;(); @Override public boolean add(Object o) { if (o instanceof MessageQueue.IdleHandler) { MyIdleHandler myIdleHandler = new MyIdleHandler((MessageQueue.IdleHandler) o); map.put((MessageQueue.IdleHandler) o, myIdleHandler); return super.add(myIdleHandler); } return super.add(o); } @Override public boolean remove(@Nullable Object o) { if (o instanceof MyIdleHandler) { MessageQueue.IdleHandler idleHandler = ((MyIdleHandler) o).idleHandler; map.remove(idleHandler); return super.remove(o); } else { MyIdleHandler myIdleHandler = map.remove(o); if (myIdleHandler != null) { return super.remove(myIdleHandler); } return super.remove(o); } }} A.2. 监控TouchEvent卡顿那么TouchEvent我们有什么办法监控吗？首先想到的可能是反射View的mListenerInfo，然后进一步替换其中的mTouchListenr，但是这需要我们枚举所有需要被监控的View，全部反射替换一遍，这完全是憨憨行为。那有没有更加根本，全局性的方法呢？ 熟悉input系统的同学应该知道，Touch事件最终是通过server端的InputDispatcher线程传递给Client端的UI线程的，并且使用的是一对Socket进行通讯的。我们可以通过PLT Hook，去Hook这对Socket的send和recv方法来监控Touch事件啊！我们先捋一下一次Touch事件的处理过程： 我们通过PLT Hook，成功hook到libinput.so中的recvfrom和sendto方法，使用我们自己的方法进行替换。当调用到了recvfrom时，说明我们的应用接收到了Touch事件，当调用到了sendto时，说明这个Touch事件已经被成功消费掉了，当两者的时间相差过大时即说明产生了一次Touch事件的卡顿。这种方案经过验证是可行的！ A.3. 监控SyncBarrier泄漏最后，SyncBarrier泄漏的问题，有什么好办法能监控到吗？目前我们的方案是不断轮询主线程Looper的MessageQueue的mMessage(也就是主线程当前正在处理的Message)。而SyncBarrier本身也是一种特殊的Message，其特殊在它的target是null。如果我们通过反射mMessage，发现当前的Message的target为null，并且通过这个Message的when发现其已经存在很久了，这个时候我们合理怀疑产生了SyncBarrier的泄漏（但还不能完全确定，因为如果当时因为其他原因导致主线程卡死，也可能会导致这种现象），然后再发送一个同步消息和一个异步消息，如果异步消息被处理了，但是同步消息一直无法被处理，这时候就说明产生了SyncBarrier的泄漏。如果激进一些，这个时候我们甚至可以反射调用*MessageQueue*的*removeSyncBarrier*方法，手动把这个SyncBarrier移除掉，从而从错误状态中恢复。 坏消息是，这种方案只能监控到问题的产生，也可以直接解决问题，但是无法溯源问题究竟是哪个View导致的。其实我们也尝试过，通过插桩或者Java hook的方法，监控invalidate方法是否在非主线程中进行，但是考虑到风险以及对性能影响都比较大，没有在线上使用。所幸，通过监控发现，这个问题对我们来说，发生的概率并不高。如果发现某个场景下该问题确实较为严重，可以考虑使用插桩或者Java hook在测试环境下debug该问题。 方案二、依赖 Choreographer 模块，监控相邻两次 Vsync 事件通知的时间差利用系统 Choreographer 模块，向该模块注册一个 FrameCallback 监听对象，同时通过另外一条线程循环记录主线程堆栈信息，并在每次 Vsync 事件 doFrame 通知回来时，循环注册该监听对象，间接统计两次 Vsync 事件的时间间隔，当超出阈值时，取出记录的堆栈进行分析上报。 12345678910Choreographer.getInstance().postFrameCallback(new Choreographer.FrameCallback() { @Override public void doFrame(long frameTimeNanos) { if(frameTimeNanos - mLastFrameNanos &gt; 100) { ... } mLastFrameNanos = frameTimeNanos; Choreographer.getInstance().postFrameCallback(this); }}); 卡顿发生时堆栈的收集BlocakCanary：在执行前利用另外一条线程，通过 Thread#getStackTrace 接口，以轮询的方式获取主线程执行堆栈信息并记录起来，同时统计每次 dispatchMessage 方法执行耗时，当超出阈值时，将该次获取的堆栈进行分析上报，从而来捕捉卡顿信息，否则丢弃此次记录的堆栈信息。 Matrix：根据编译期插桩记录函数耗时，在卡顿发生时获取之前一段时间的函数进行归堆，性能更佳， 不仅在编译期时对特殊无需插桩函数排除（方法字节码中是否只包含PUT/READ FIELD等简单指令、默认或匿名构造函数）、插桩函数用ID映射 还在运行期时用long[]数组记录函数id和函数函数，极大程度的减少占用内存、另一个线程每5ms更新时间减少调用System.nanoTime的耗时 Dokit：也是插桩，但优化不细。 动画优化简述：TODO 对于同样机器环境上的应用来说，抛去受CPU、屏幕和系统GUI系统的固有时间消耗外，要实现流畅的动画的核心也就是减少视图Draw的时间。 这里有几点经验可以跟大家分享一下： 尽量不要在刷新时做耗时操作，必须准备数据，创建图片，图片变换等，数据和图片都应该在之间就加载到内存中，图片变换用canvas的变换来实现。 同一个界面中多个动画重叠出现时，尽量将动画的刷新过程统一进行刷新，避免频繁的invalidate，尤其是多个动画有时序上的关系时更应该统一。 尽量使用带有参数的invalidate来刷新，这样可以减少很多运算量。 合理的环境下使用surfaceview来操作，比如播放视频等，这种刷新耗时比较大的情况。 开启硬件加速，硬件加速由于采用了显示列表的概念，所以刷新过程也有很大的优化，但是会增加额外的8M内存占用。 Animation流畅度动画线程中，少做动画外的事情(比如拖动的时候同时做了图片加载，或进度转圈)，或用子线程去做这一件事； 多个View做动画，变成一个View做多个动画，从而减少View Tree递归调用；消失的或不在屏幕中的bg，view不绘制，减小绘制面积(bg绘制前用clipRect控制)，减小缓存尺寸； 不要用requestLayout实现动画，用矩阵变换代替，少用clipPath剪切图片； 不要设置listview的selector； 动画时间控制在400ms以内； 利用好硬件加速； 动画用nineoldandroid或者在实现的时候尽量把动画的绘制都放到一个消息循环里面； Layout加载速度 简化动画布局(包括view层级和数量)，不用的布局可以用viewstub包住在用的时候inflate； 提前将布局inflate传入，记得处理static引用；","link":"/2021/10/19/%E5%8D%A1%E9%A1%BF%E7%9B%91%E6%8E%A7/"}],"tags":[{"name":"CoreProcess","slug":"CoreProcess","link":"/tags/CoreProcess/"},{"name":"Core","slug":"Core","link":"/tags/Core/"},{"name":"SystemService","slug":"SystemService","link":"/tags/SystemService/"},{"name":"Graphic","slug":"Graphic","link":"/tags/Graphic/"}],"categories":[{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"Framework","slug":"Android/Framework","link":"/categories/Android/Framework/"},{"name":"Other","slug":"Android/Other","link":"/categories/Android/Other/"},{"name":"Common","slug":"Common","link":"/categories/Common/"},{"name":"BuildTool","slug":"Android/Other/BuildTool","link":"/categories/Android/Other/BuildTool/"},{"name":"JavaBasic","slug":"Common/JavaBasic","link":"/categories/Common/JavaBasic/"},{"name":"Code","slug":"Common/Code","link":"/categories/Common/Code/"},{"name":"ThirdPartyLib","slug":"Android/ThirdPartyLib","link":"/categories/Android/ThirdPartyLib/"},{"name":"Jvm","slug":"Common/Jvm","link":"/categories/Common/Jvm/"},{"name":"Network","slug":"Common/Network","link":"/categories/Common/Network/"},{"name":"Kotlin","slug":"Android/Kotlin","link":"/categories/Android/Kotlin/"},{"name":"AAC","slug":"Android/AAC","link":"/categories/Android/AAC/"}]}